
Die Totenhütte von Benzingerode ist ein bei archäologischen Untersuchungen im Nordosten von Benzingerode im nördlichen Harz entdecktes Gemeinschaftsgrab, das anhand der geborgenen Funde der jungsteinzeitlichen Bernburger Kultur (3100–2700 v. Chr.) zugeordnet werden kann. 
Die Totenhütte wurde 2001 bei Grabungen im Rahmen des Baus der Bundesstraße 6n entdeckt und bestand aus einem Steinplattenfundament in einer etwa 50–60 cm tiefen Grube, auf welchem eine etwa 17 m2 große, hölzerne Grabkammer errichtet wurde. Die Archäologen gehen von einem großen zweigeteilten, begehbaren Grabraum aus. Dieser war vermutlich mit einem Flachdach versehen und wurde letztlich mit Steinen abgedeckt und mit Erde überhügelt. Der genaue Aufbau der Holzhütte ist rein spekulativ, da sich keinerlei Holzreste erhalten haben.
Der Grabraum war für mehrere nachfolgende Bestattungen vorgesehen. Anthropologische Untersuchungen der gefundenen Skelette ergaben eine Mindestanzahl von 46 sowohl weiblichen als auch männlichen Individuen unterschiedlichen Alters. Genetische Untersuchungen von 21 Individuen weisen auf eine nahe biologische Verwandtschaft der Bestatteten hin.
Benzingerode befindet sich im Nordharz (Landkreis Harz in Sachsen-Anhalt) in der Nähe der Bundesstraße 6 und ist ein Ortsteil der etwa fünf Kilometer westlich gelegenen Stadt Wernigerode.
Die Fundstelle liegt im Nordosten von Benzingerode, etwa 50 Meter westlich des Hellbaches in einer Höhe von 187 m ü. NN.  Die Totenhütte selbst befindet sich auf einer weichselzeitlichen Schotterablagerung des Hellbaches. In einigen Bereichen liegt dem Schotter eine dünne Lössschicht auf. Die gesamte Fläche ist mit 30 bis 40 cm dickem Humus bedeckt, der bei direkter Auflage auf dem Schotter stark mit Steinen durchmischt ist.
In den Jahren 1975 bis 1983 wurden nach Tiefpflügarbeiten zahlreiche Scherben der Linienbandkeramik (LBK), Späten Bronze-/Frühen Eisenzeit (SBZ/EZ) sowie des Mittelalters gefunden. Auskunft zu diesen Funden geben die Ortsakten des Landesamtes für Denkmalpflege und Archäologie Sachsen-Anhalt. Auch Luftbilder aus jüngerer Zeit ließen aufgrund erkennbarer Bewuchsmerkmale archäologische Befunde vermuten.
Zudem existieren zwei große Menhire, die von der Fundstelle aus sichtbar sind, in den Gemarkungen Benzingerode und Derenburg. Den Ortsakten zufolge standen im Umkreis (zwischen Benzingerode und Heimburg) insgesamt fünf Menhire, deren genaue Lage jedoch nicht mehr bekannt ist. Aufgrund der unsicheren Datierung dieser Menhire bleibt ein Zusammenhang zur Totenhütte jedoch ungeklärt.
Die Totenhütte wurde 2001 bei archäologischen Notgrabungen im Rahmen des Großbauvorhabens der Bundesstraße 6n entdeckt.  
Die Ausgrabungen auf der Trasse bei Benzingerode und Heimburg im Landkreis Harz begannen im März 2001 und umfassten eine Fläche von etwa zweieinhalb Kilometer Länge und 30 Meter Breite (60 Meter Breite bei einer geplanten Parkplatzfläche). Aufgrund ihrer Größe wurde die Grabungsfläche in drei Abschnitte und Grabungsteams unterteilt, wobei letztlich in allen Flächen zahlreiche Befunde unterschiedlicher Kulturen zum Vorschein kamen.
Die Überreste der Totenhütte kamen im Spätherbst 2001, kurz vor dem geplanten Grabungsende, im Bereich der letzten Schnitte nahe der Containerstellfläche zu Tage. 
Bei der anschließenden, bis Ende Juli 2002 andauernden Untersuchung nutzte man die Möglichkeit der digitalen Dokumentationstechnik zur genauen Erfassung des komplexen Befundes mit den zahlreichen gut erhaltenen Bestattungen. Aufgrund zahlreicher Messdaten und der mehr als zweihundert aufgenommenen Bilder konnten schließlich Pläne und Umzeichnungen erstellt und die exakte Lage aller Skelette und Funde dauerhaft nachvollziehbar dokumentiert werden.
Zu Beginn zeigte sich der langrechteckige etwa neun Meter lange und vier Meter breite Befund (Planum 1) dem Anschein nach unberührt, er war sehr gut erhalten und wies oberflächig zunächst keinerlei Störungen oder Funde auf. Erst im dritten Planum, nach Abtrag von zwei Steinschichten und etwa 30 cm Erde, waren zahlreiche Skelette erkennbar.
Zudem zeigte sich die architektonische Struktur der Totenhütte. So fand man einen trapezförmigen Zugang im Osten der Anlage und ein 50–70 cm unter der Erdoberfläche liegendes, umlaufendes Steinplattenfundament im untersten Planum. Aufgrund von senkrecht aufgestellten Steinen im Bereich des Steinplattenfundaments wird von den Archäologen eine hölzerne Grabkammer rekonstruiert. Zudem wurden weitere Bereiche mit ausgelegten Steinplatten gefunden. Das beim Bau der Hütte verwendete Gestein stammt, wie petrologische Untersuchungen der geborgenen Steine (etwa 4,5 t) gezeigt haben, aus der unmittelbaren Umgebung der Fundstelle bzw. aus Steinbrüchen aus dem Harz.
Des Weiteren konnten zwei Bauabschnitte bzw. -phasen im Verlauf der Freilegung dokumentiert werden.
Da der archäologische Befund nicht alle Details wiedergeben kann, ist eine exakte, originalgetreue Wiedergabe der Totenhütte von Benzingerode unmöglich. Dennoch versuchte sich die Ausgräberin Birgitt Berthold anhand der Befundpläne an einer Rekonstruktion der Totenhütte:  
In einer etwa 50–60 cm tiefen Grube wurde ein Steinplattenfundament ausgelegt, auf welches die etwa 17 m² große, hölzerne Grabkammer gesetzt wurde. Dabei wurde die Kammer in einigen Bereichen mit weiteren Steinplatten verstärkt. 
Die beiden Bauabschnitte bzw. -teile werden als etwa gleichzeitig angesehen, so dass man von einem großen, zweigeteilten Grabraum ausgehen kann. Der genaue Aufbau der Holzhütte ist dabei rein spekulativ, da sich keinerlei Holzreste erhalten haben. Auch über die Höhe der Hütte können nur Vermutungen angestellt werden. Die Ausgräberin gibt zu bedenken, dass die Kammer zumindest begehbar gewesen sein und dass es genügend Platz für die „Stapelung“ der Bestatteten gegeben haben muss. 
Der Eingang befand sich an der östlichen Schmalseite und war über eine rampenartige Vertiefung zugänglich. Aufgrund von fehlenden tiefen Pfostengruben im Befund, die für die Stützung eines Giebeldaches vonnöten gewesen wären, wird ein Flachdach vermutet. Der ganze Bau wurde letztlich mit Steinen abgedeckt und mit Erde überhügelt.
Der Bestattungsritus der Bernburger Totenhütten steht in der der Kollektivgrabsitte der Megalithkultur. So gab es auch in Benzingerode einen Grabraum für mehrere nachfolgende Bestattungen, wobei sich die Skelette hauptsächlich im westlichen Teil der Hütte befanden. 
Die an die Grabungen anschließenden anthropologischen Untersuchungen der Skelette ergaben eine Mindestanzahl von 46 sowohl weiblichen als auch männlichen Individuen unterschiedlichen Alters (außer der Altersstufe senil). Da bei (Nach-)Bestattungen möglicherweise Skelettteile oder ganze Skelette entfernt wurden, könnten es möglicherweise auch mehr Individuen gewesen sein. Grund für diese Überlegung sind zwei größere Knochenteilverbände, die im Osten der Totenhütte geborgen und keinem anderen Individuum zugewiesen werden konnten (Individuum 47 und 48). Vereinzelte Brandspuren sowohl an Menschen- als auch Tierknochen weisen ebenfalls auf Nachbehandlungen bzw. rituelle Handlungen hin.  
Die Toten wurden in acht erkennbare, nicht vollständig abgegrenzte Bereiche, bei B. Berthold ‚Quartiere‘ genannt, niedergelegt. Die Bestattungen waren, wenn noch in situ befindlich, in bis zu drei übereinander liegenden Schichten, größtenteils mit derselben Ausrichtung, anzutreffen. Der Grund der Niederlegung in diese verschiedenen Bereiche bleibt allerdings ungeklärt. Eine Aufteilung nach Geschlecht oder Alter ist nicht erkennbar. Bei der genetischen Untersuchung von 21 Individuen konnten jedoch vier Individuenpaare mit derselben weiblichen Abstammungslinie ermittelt werden. Somit ist bei diesen Individuen eine nahe biologische Verwandtschaft sehr wahrscheinlich. Auffallend hierbei ist, dass drei der vier Paare in direktem Kontakt, also neben- oder übereinander bestattet wurden.
14C-Untersuchungen des physikalischen Instituts der Universität Erlangen an fünf Skeletten und einem Teilverband ergaben eine Datierung in die frühe Bernburger Kultur.
Aufgrund der hohen Standardabweichung von rund sechzig Jahren ist dabei keine genaue Belegungsabfolge zu ermitteln. Lediglich eine grobe zeitliche Abfolge innerhalb der einzelnen Quartiere und zwischen den Bereichen der westlichen und östlichen Teilflächen selbst kann dadurch ermittelt werden. Insgesamt betrachtet, lässt sich auf eine Nutzung in mehreren Phasen schließen, die nur schwer im Detail nachempfunden werden kann. Im Allgemeinen geht die Ausgräberin bei der Totenhütte von einem etwa fünfzig Jahre andauernden Belegungszeitraum aus.
Zwischen den Toten wurden insgesamt zwölf, zum Teil unbeschädigte Gefäße und 18 Keramikscherben gefunden, die sich keinem Individuum, sondern lediglich verschiedenen Quartieren und Bestattungsebenen zuordnen lassen. Die Ausgräberin vermutet aufgrund der geringen Fundzahl, dass auch die Keramik verschoben oder ausgeräumt wurde. Bei den Gefäßen handelt es sich, bis auf eine frühbronzezeitliche Aunjetitzer Tasse ausschließlich um bernburgzeitliches Keramikinventar, wie verzierte Tassen, Tonnengefäße (darunter ein Miniaturgefäß) und Fragmente einer Tontrommel. Der Ton weist eine feine Magerung auf und wurde hart gebrannt; die Oberflächen wurden geglättet. An einem Gefäß konnten Reste von weißer Inkrustation festgestellt werden. Die Keramik datiert in die klassische Bernburger Kultur der Stufe 2/3.  Außerdem fand man vier kleine Feuersteinabschläge bzw. -splitter, ein Quarzitmesser und zwei Pfeilspitzen, von denen sich eine auf dem Brustbein eines der Individuen befand und als Beigabe oder Geschoss zu verstehen ist.  Zu den weiteren Funden zählen über zweihundert durchbohrte Tierzähne, die teils als dicht nebeneinanderliegende Ketten, teils einzeln auf oder neben den Skeletten gefunden wurden. Des Weiteren fand man drei Fuchskieferfragmente und zwei Nadeln aus Knochen und Geweih. Einige dieser Funde konnten einzelnen Individuen als eventueller Trachtbestand zugewiesen werden. Weitere 56 unbearbeitete Tierknochen streuten über den gesamten Befund.
Birgitt Berthold: Die Totenhütte – eine mittelneolithische Begräbnisstätte. In: Archäologie in Sachsen-Anhalt. Sonderband 2, 2005, S. 55–72.
Birgitt Berthold: Forschung: Bernburger Kultur. Die Hütte der Toten von Benzingerode. In: Archäologie in Deutschland. Heft 3, 2006, S. 6–11.
Birgitt Berthold: Stein für Stein: Das Baumaterial der Bernburger Totenhütte von Benzingerode, Ldkr. Wernigerode. In: Jahresschrift für mitteldeutsche Vorgeschichte. Bd. 90, 2006, S. 173–199.
Birgitt Berthold u. a.: Die Totenhütte von Benzingerode: Archäologie und Anthropologie (= Archäologie in Sachsen-Anhalt. Sonderband 7). Landesamt für Denkmalpflege und Archäologie Sachsen-Anhalt, 1. Auflage, Halle (Saale) 2008, ISBN 978-3-939414-12-4.
Harald Meller (Hrsg.): Lebenswandel. Früh- und Mittelneolithikum (Begleithefte zur Dauerausstellung im Landesmuseum für Vorgeschichte Halle; Bd. 3). Landesamt für Denkmalpflege und Archäologie Sachsen-Anhalt und Landesmuseum für Vorgeschichte, Halle (Saale) 2008, S. 213–218, ISBN 978-3-939414-16-2.
Marcel Torres-Blanco: Bernburger Kultur. In: Hans-Jürgen Beier, Ralph Einicke (Hrsg.): Das Neolithikum im Mittelelbe-Saale-Gebiet und in der Altmark. Eine Übersicht und ein Abriss zum Stand der Forschung (Beiträge zur Ur- und Frühgeschichte Mitteleuropas; Bd. 4). Verlag Beier & Beran, Wilkau-Hasslau 1994, S. 159–177, ISBN 978-3-930036-05-9.

Toto ist eine US-amerikanische Rockband, die 1976 in Los Angeles gegründet wurde. Insgesamt veröffentlichte die Band 19 Alben (13 Studio, 1 Soundtrack, 5 Live) und wurde mit sechs Grammys ausgezeichnet. Zu den bekanntesten Stücken von Toto zählen Rosanna, Africa, Hold the Line, Child's Anthem und Georgy Porgy.
Toto hat bis heute über 40 Millionen Alben verkauft und wurde 2009 in die Musicians Hall of Fame aufgenommen.
Die Musik von Toto lässt sich in die Stilrichtungen des kommerziell ausgerichteten, sogenannten Mainstream- bzw. Adult-oriented Rock (AOR) einordnen. Bei der als Westcoast-Style bezeichneten Musik der Band spielen Keyboards und Klavier eine wichtige Rolle. Die als Triolen zum 4/4-Takt auf dem Klavier gespielten Akkorde des Liedes Hold the Line wurden beispielsweise oft kopiert.
Häufig sind von den Keyboards dominierte, orchestral wirkende Mittelteile. Die Lieder werden größtenteils in mittlerem Tempo gespielt und sind von einer eingängigen Melodie geprägt. Großen Einfluss auf die Wirkung der Lieder hat zudem das Schlagzeugspiel. So wechselt zum Beispiel Jeff Porcaro im Titel Rosanna von einem kraftvollen ternären Shuffle-Rhythmus zu einer binären Spielweise, um nach einem Break mit einer die Spannung steigernden Pause wieder den Shuffle-Rhythmus aufzunehmen.
Extrem schnelle Stücke oder gar Hard Rock spielte Toto eher selten, obwohl Steve Lukather ab und zu harte Powerchords sowie handfeste Rocksoli einstreute.
Die Musiker von Toto zeichneten sich dadurch aus, dass sie stets songdienlich spielten. Dennoch wurden in den Liedern immer wieder überraschende Passagen eingebaut. So zum Beispiel in dem Titel Stop Loving You: Hier wird der von flächigen Keyboardsounds und einem leicht rhythmisierten Piano geprägte Song, der einer herkömmlichen Kadenzfolge (F-Dur, B-Dur, d-Moll, C-Dur) folgt, von einer Phrase des Basses und der Bläser abgelöst, die eher in die Funkmusik passt.
Zu den anspruchsvollsten Stücken zählen Jake To The Bone vom Kingdom Of Desire-Album sowie Dave’s Gone Skiing, zu finden auf der CD Tambu. Großen Erfolg hatte die Band mit ihren von Keyboardsounds geprägten Balladen wie Africa, I’ll be over you oder Somewhere Tonight. In diesen Titeln lässt der Schlagzeuger bei Live-Konzerten oft Raum für zusätzliche lateinamerikanische Perkussion-Instrumente.
Die Band tourte über 30 Jahre lang durch die Welt und kam dabei regelmäßig nach Europa bzw. Deutschland. Die Live-Konzerte von Toto waren musikalisch auf einem ähnlich hohen Niveau wie die Studio-Aufnahmen, da alle Mitglieder der Band als Studiomusiker in der Lage waren, den Sound der Studioaufnahmen live bei Bedarf beinahe identisch wiederzugeben.
Das Arrangement der im Verlauf des Konzerts gespielten Musikstücke änderte sich zu jeder Tournee und wurde bisweilen sogar zu einzelnen Auftritten spontan angepasst. Neben Totos bekanntesten Hits wie Rosanna, Hold the Line und Africa wurden Musikstücke aus über 25 Jahren Bandgeschichte gespielt. Seit 1996 ließ die Band regelmäßig im Vorfeld der Konzerte Fans per Internet über diese Setlist abstimmen, nachdem sie das noch für die Tournee 1992 per Postkarten von Fanclubs in ihrer Heimatstadt Los Angeles machen ließ.
Zusätzlich zu den Musikstücken bot Toto den Konzertbesuchern eine Reihe von Soli. Obligatorisch sind dabei ein Schlagzeug-, ein Keyboard- und ein Gitarren-Solo, letzteres von Steve Lukather; in den letzten Jahren vielfach mit akustischer Gitarre. Der Bassist Mike Porcaro spielte selten Soli. In den letzten Jahren vor der Auflösung spielte er jedoch aufgrund häufiger Nachfragen von Fans am Ende des Liedes Africa einige Male ein Bass-Solo.
Begleitet wurde die Musik von Toto bei den Tourneen von einer Bühnenshow. So war bei der Reunion-Tour im Jahr 1999 eine 120 m² große Videoleinwand im Einsatz, die im Wechsel Ausschnitte aus Musikvideos und Material der vier Live-Kameras zeigte, die während des Konzerts die Künstler und die Instrumente in Nahaufnahmen filmten.
Bisweilen kam es bei Toto-Konzerten zu Auftritten von Gastmusikern. Im Sommer 2004 besuchte die Sängerin Marla Glen ein Toto-Konzert in Rottweil und wurde für die Zugabe auf die Bühne gebeten. Gäste in Deutschland waren in den letzten Jahren unter anderem Ian Anderson und der Gitarrist Al Di Meola. Seit 1999 tourte Tony Spinner als musikalische Unterstützung mit der Band. Er spielte die zweite Gitarre und war Background-Sänger.
Seit Mitte 2005 wurde die Band durch Greg Phillinganes verstärkt, einen der bekanntesten Keyboarder der US-amerikanischen Musikszene. Er war von David Paich in die Band gebeten worden, da dieser durch Erkrankungen in seiner Familie nicht mehr außerhalb der USA auf Tournee gehen wollte. Bis zur Auflösung 2008 war er festes Mitglied bei Toto und wirkte am letzten Album der Band mit. Von Februar 2007 an ersetzte Leland Sklar als Bassist den erkrankten Mike Porcaro. Diese Zusammenarbeit endete nach der "Falling In Between"-Tour im Jahre 2007 bzw. mit der vorübergehenden Auflösung der Band 2008. Von 2010 bis 2014 spielte Nathan East für Mike Porcaro als Tourmitglied den Bass. 2016 engagierte man erneut Leland Sklar.
Nach dem Debütalbum TOTO im Jahr 1978 startete die Band ihre erste Tournee in den USA. Die folgenden Jahre wurden bestimmt durch die beiden nächsten Alben und vielen hundert Sessions, die die Bandmitglieder für andere Musiker und Bands spielten.
Die Popularität von Toto erreichte mit dem Album TOTO IV 1982 ihren Höhepunkt. Danach ging die Band auf ihre erste große Welttournee. Die Grammy-Verleihung 1983 war der Höhepunkt ihrer Popularität in den USA.
Mit den nachfolgenden Alben Isolation, Fahrenheit und vor allem The Seventh One wuchs Totos Popularität in Europa und Asien, während sie in den USA stetig sank. Grund dafür waren unter anderem zahlreiche Probleme mit dem damaligen Musiklabel CBS (später Sony Music). So wurden einige der Alben Mitte der 1980er Jahre in den USA erst mit großer Verspätung und ohne vernünftiges Marketing veröffentlicht. Während die Band in Europa und Asien von Jahr zu Jahr in größeren Hallen spielte und mehr und mehr Platten verkaufte, hatten Toto vor allem in den englischsprachigen Ländern wie USA, Kanada, England und Australien große Popularitätsprobleme. Die Tourneen der Band führten deshalb fast jährlich durch Europa.
Doch auch der Wechsel zum Musiklabel EMI brachte nicht den gewünschten Erfolg. EMI veröffentlichte das Album Through the Looking Glass in den USA mit Verspätung. So trennte sich Toto nach einem Album erneut von ihrem Musiklabel und veröffentlichte die Live-DVD bei dem Label Eagle Vision, ein englisches, auf Live-Konzerte spezialisiertes Unternehmen. In den letzten Jahren hatte die Band ihr eigenes Label namens TOTO Records gegründet. Eine Bindung an ein Musiklabel über mehrere Jahre lehnte die Band zuletzt ab, neue Alben wurden nur noch einzeln für den Vertrieb an ein Major-Label lizenziert.
Gegründet wurde Toto 1976–1977. Die beiden Gründungsmitglieder Jeff Porcaro und David Paich spielten bereits in einer High-School-Band zusammen und arbeiteten als Studiomusiker in Los Angeles. Bei einem Engagement von Boz Scaggs entstand die Idee zur Gründung der Band, zu der Steve Lukather, Jeff Porcaros Bruder Steve, Bobby Kimball und David Hungate dazugeholt wurden. In diesen Tagen entstand der Name Toto (siehe Abschnitt Name).
Das erste Musikalbum mit dem Titel TOTO (1978) war die erste gemeinsame musikalische Produktion der Band. Im selben Jahr wurden sie für den Grammy als „Bester Newcomer“ nominiert.
Das zweite Album Hydra (1979) mit dem Hit 99 und das dritte Album Turn Back (1981) hatten mäßigen Erfolg. Weltweit populär wurde die Band mit ihrem vierten Album Toto IV (1982), für das sie in mehreren Ländern die Platin-Auszeichnung, in Deutschland doppelt, erhielten. Insbesondere die darin enthaltenen Hits „Rosanna“ und „Africa“ machten Toto weltweit bekannt. Das Album verkaufte sich bis ins Jahr 1983 millionenfach und die Band erhielt insgesamt sechs Grammys (siehe Auszeichnungen).
Vor der anschließenden Tournee verließ der Bassist David Hungate die Band und wurde durch den dritten Porcaro-Bruder Mike ersetzt.
Zu den Olympischen Spielen 1984 in ihrer Heimatstadt Los Angeles komponierte die Band die Musik, im selben Jahr den Soundtrack zu David Lynchs Verfilmung Dune.
Die Folgezeit war von Problemen mit der Bandbesetzung geprägt. So verließ Bobby Kimball 1984 wegen Drogenproblemen die Band. Auf dem im selben Jahr erschienenen Album Isolation war er laut Bandmitgliedern nur noch als Background-Sänger zu hören. Den Lead-Gesang übernahm von da an Fergie Frederiksen, ab 1986 Joseph Williams (bis 1988, Alben Fahrenheit und The Seventh One).
1986 bis 1987 ging die Band auf ihre zweite Welt-Tournee, 1988 auf ihre dritte. 1988 verließ Steve Porcaro offiziell die Band, um sich eigenen Projekten zu widmen, ging aber 1988 mit auf Tournee und hat seitdem auch an jedem neuen Album der Band als Gastmusiker mitgewirkt. Der vom damaligen Musiklabel Sony (CBS) geforderte neue Lead-Sänger Jean-Michel Byron übernahm lediglich vier neue Songs auf der 1990 erschienenen Greatest-Hits-Kompilation Past to Present 1977–1990 und wurde dann nur noch für die gleichnamige Tournee eingesetzt. Für die Compilation gab es in mehreren Ländern Platin-Auszeichnungen. Steve Lukather übernahm 1992 vollständig den Lead-Gesang, da die Band nach dem Abgang von Byron, dem nunmehr vierten Lead-Sänger seit Gründung, keinen neuen mehr suchen wollte.
Mit dem Tod von Jeff Porcaro im Jahr 1992 kurz vor der Veröffentlichung des Albums Kingdom of Desire (1992) geriet die Band in eine Krise. Nachdem man sich zum Weitermachen entschieden hatte, trat der Schlagzeuger Simon Phillips der Band bei und nahm unmittelbar im Anschluss an Totos vierter Welt-Tournee teil.
Im Herbst 1994, während einer Tourpause der Solo-Tournee von Gitarrist Steve Lukather mit seiner Band Los Lobotomys, trat Toto zum ersten Mal bei der Nokia Night of the Proms auf.
1995 folgte das Album Tambu mit der Single I Will Remember, die in einigen europäischen Ländern mit Gold ausgezeichnet wurde. Nach einer weiteren Welt-Tournee 1996 legte die Band zunächst eine kurze Pause ein, die einige Mitglieder für Soloprojekte nutzten.
1997 spielten Toto das erste Mal in Afrika. Die wenigen Konzerte in Südafrika waren ausverkauft und wurden von einem afrikanischen Chor begleitet.
Nachdem das Gründungsmitglied Bobby Kimball schon an dem Jubiläumsalbum teilweise mitgearbeitet hatte, trat er 1998 wieder der Band bei. 1999 folgte eine weitere Tournee durch Europa, Japan und erstmals seit sechs Jahren auch wieder durch die USA.
Die Band veröffentlichte 1999 das Musikalbum Mindfields und das Live-Album Livefields. 2000 wurden Toto, bzw. ihr Toningenieur Elliott Scheiner, erneut für einen Grammy nominiert: Mindfields als „Best Engineered Album, Non-Classical“ (deutsch: „Bestes aufgenommenes, nicht-klassisches Album hinsichtlich der Tontechnik“). Nach insgesamt zwei Jahren Tournee pausierte die Band erneut für zwei Jahre, um den Bandmitgliedern Zeit für eigene Soloprojekte zu geben.
Nach der Pause veröffentlichte Toto im Jahr 2002 das Album Through the Looking Glass, auf dem sie „die Lieblings-Songs der Bandmitglieder“ coverte (u. a. Bodhisattva von Steely Dan und While My Guitar Gently Weeps von den Beatles). Die folgende Jubiläums-Tournee zum 25-jährigen Bestehen führte durch Europa und Asien, wurde im Januar 2003 in Amsterdam aufgezeichnet und auf DVD veröffentlicht. Anschließend tourte die Band durch USA, erneut im Rahmen der Nokia Night of the Proms durch Europa und bis ins Jahr 2004 durch Asien und Südamerika.
Im Sommer 2005 trat der Keyboarder Greg Phillinganes der Band bei. Gemeinsam mit ihm, sowie den ehemaligen Mitgliedern Steve Porcaro und Joseph Williams, arbeitete Toto am Album Falling In Between, das im Februar 2006 erschien. Seit dem Frühjahr 2006 fand zudem eine mehrjährige Tournee durch Europa, Südostasien, die Vereinigten Staaten sowie, erstmals seit 13 Jahren wieder, durch Australien statt. Seit Anfang 2007 wurde dabei der an ALS erkrankte Mike Porcaro durch den Bassisten Leland Sklar vertreten. Im Rahmen der Tour wurden im März 2007 im Pariser Zénith Aufnahmen für eine Live-CD gemacht, die am 29. Oktober in Europa und am 23. November in Deutschland erschien. Am 14. März 2008 erschien nun auch eine Live-DVD des Konzerts die sich weltweit in den TOP 10 der Charts platzierte, so. u. a. in den deutschen Amazon Verkaufscharts auf Platz 1 (DVD Musik), offizielle deutsche DVD Musikcharts Platz 4 (KW 12.08), Schweden Platz 1, Frankreich Platz 2, Holland Platz 3, Norwegen Platz 4, Dänemark Platz 4, Finland Platz 5, Italien Platz 6, Australien Platz 9 und Japan Platz 9.Im März 2008 absolvierten Toto eine ausverkaufte Tournee mit acht Konzerten in Japan. Bei diesen Konzerten trat Boz Scaggs (siehe Teil Geschichte) im Vorprogramm auf. Gründungsmitglied David Paich stand nach über 2 Jahren Bühnenabstinenz wieder mit der Band auf der Bühne, Ex-Sänger Joseph Williams trat als Gastmusiker auf. Steve Lukather und David Paich spielten dabei auch einige Songs bei Boz Scaggs, im Gegenzug kam Boz Scaggs mit seiner Band zur Zugabe von Toto mit auf die Bühne, und gemeinsam wurde With a Little Help from My Friends von den Beatles als letzte Zugabe gespielt.
In einem am 25. Mai 2008 veröffentlichten Zeitungsinterview mit dem Kölner Stadt-Anzeiger gab Steve Lukather an, dass die Band nicht mehr existiere: „Toto gibt es nicht mehr. Ich habe die Band gerade aufgelöst. Zu viele Urmitglieder sind nicht mehr dabei. Toto hat seine Identität verloren. Ich mache solo weiter.“ Kurz darauf bestätigte er die Trennung auf seiner offiziellen Homepage. Mitte 2008 gaben Toto in einer offiziellen Erklärung auf ihrer Internetseite die Auflösung der Band bekannt.
Am 12. Oktober 2009 wurden die Gründungsmitglieder Totos in die Musicians Hall of Fame aufgenommen – mit Ausnahme von Bobby Kimball, da er als Sänger nicht als Musiker im Sinne der Hall of Fame gilt.Am 27. Februar 2010 kündigte die Band auf ihrer Website an, dass sie zur Unterstützung ihres an ALS erkrankten Bassisten Mike Porcaro noch einmal für eine zweiwöchige Tour zusammenkommen werde. Neben Steve Lukather, Simon Phillips und David Paich waren bei der im Juli 2010 in Europa stattfindenden Tour auch die einst ausgeschiedenen Mitglieder Steve Porcaro und Joseph Williams wieder dabei. Als Gast spielte der Bassist Nathan East. Im November 2010 stellte Steve Lukather dann die aktuelle Situation der Band klar. Er erklärte, dass es kein neues Album geben werde, die Band aber in der Besetzung der 2010er Tour weiter live auftreten werde, soweit es die anderen Verpflichtungen der Bandmitglieder erlaubten. Mike Porcaro blieb Vollmitglied der Band und wurde daher weiterhin an allen Einnahmen beteiligt, auch wenn er nicht mehr in der Lage war, zu musizieren. Er starb im März 2015.
Im Sommer 2011 gingen Toto erneut in Europa und Asien auf Tour, bei der statt Mike Porcaro erneut Nathan East Bass spielte. Zudem kehrte Jenny Douglas, die bereits in den frühen 1990er Jahren Mitglied der Tourbesetzungen war, als Backgroundsängerin zurück. Auch im Jahr 2013 nahm die Gruppe das 35-jährige Bestehen der Band zum Anlass, erneut auf Tournee zu gehen, die auf einer DVD dokumentiert wurde und im Jahr 2014 erschien. Dazu wurde ein Konzert am 25. Juni in der polnischen Stadt Łódź aufgezeichnet.
Im Gegensatz zu der Ankündigung, nie wieder ein Album veröffentlichen zu wollen, gaben Steve Lukather und David Paich am 5. November 2013 über die Facebook-Seite der Band bekannt, dass die Arbeiten an einem neuen Album begonnen hätten. Der seit 1992 als Schlagzeuger agierende Simon Phillips hat sich von Toto zu Gunsten seiner eigenen Solokarriere in einem freundschaftlichen Verhältnis getrennt. Die Nachfolge trat der unter anderem bei Sting bekannt gewordene Musiker Keith Carlock an. Bereits nach der Nordamerika-Tournee im Frühjahr 2014 übernahm Shannon Forrest den Platz am Schlagzeug. Im November 2014 gab Steve Lukather auf seiner Facebook-Seite bekannt, dass das Album unter dem Namen Toto XIV im Frühjahr 2015 weltweit veröffentlicht werden solle. Das Album erschien am 20. März 2015.Am 24. September 2016 kündigte Steve Lukather auf Totos Facebookseite an, dass die Band an einem neuen Album arbeitet. Es soll von Sony veröffentlicht werden.
Der Name Toto gibt nahezu seit Beginn der Bandgeschichte Anlass zu Spekulationen über seine Herkunft. Gerüchte, Ursprung des Bandnamens sei der bürgerliche Name Bobby Kimballs „Robert Toteaux“, sind jedoch falsch. Bobby Kimball wurde als Robert Troy Kimball am 29. März 1947 in Louisiana (USA) geboren.
Jeff Porcaro erklärte die richtige Entstehungsgeschichte in einem Interview von 1988. Er erklärte, dass die Band 1977 einen Namen suchte, und alle Bandmitglieder sich bis zum nächsten Tag einen solchen überlegen sollten. An jenem Abend lief der Film Der Zauberer von Oz im Fernsehen und Jeff hörte den Namen „Toto“ (Dorothys Hund). Ihm gefiel der Name und so schlug er ihn am nächsten Tag der Band vor. Bassist David Hungate erklärte der Band, dass „toto“ bzw. „in toto“ im Lateinischen soviel heißt wie all umfassend und ein passender Name für eine Band sei, die sich nicht auf einen Musikstil festlegen wollte.
Auf seiner Homepage erklärte Steve Lukather anlässlich des mehr als 25-jährigen Bestehens der Band, dass der Name seinen Ursprung bei einem Eingeborenenstamm am Fuße des Himalayas hat, von dem Steve Lukather zur Zeit der Bandgründung hörte und fasziniert war. Diese Erklärung war jedoch lediglich ein Scherz, der auch auf der Toto-Homepage als solcher lanciert wurde.
Bobby Kimball war Gründungsmitglied und Sänger von Toto. Aufgrund von Drogenproblemen schied er 1984 aus der Band aus. Seine markante Stimme war bis dahin kennzeichnend für viele Lieder von Toto. Zwischenzeitlich war er für Frank Farians Far Corporation aktiv. Nachdem er 1998 an dem Jubiläumsalbum zum 20-jährigen Bandbestehen mitgearbeitet und seine Drogenprobleme überwunden hatte, trat er 1999 nach 15-jähriger Abwesenheit offiziell wieder der Band bei.Steve Lukather
Steve Lukather ist Gründungsmitglied, Gitarrist und Sänger von Toto. Bei Toto übernahm er immer wieder – insbesondere während der Abwesenheit von Bobby Kimball – die erste Stimme der Band.
Neben seinem Hauptengagement bei Toto ist Lukather bei einigen anderen Musikprojekten aktiv. So gründete er im Jahr 1985 zusammen mit David Garfield die Band Los Lobotomys und veröffentlichte bislang fünf Solo-Alben. Für sein Instrumental-Album No Substitutions erhielt er im Jahr 2002 einen Grammy in der Kategorie „Best Pop Instrumental Album for solo artists, duos or groups“ (deutsch: „Bestes Pop-Instrumental-Album eines Solo-Künstlers, Duos oder einer Musikgruppe“). Daneben arbeitet er seit einigen Jahren auch mit Derek Sherinian (ehemaliger Keyboarder u. a. von Alice Cooper und Dream Theater, z. Z. Tourmusiker bei Billy Idol) zusammen. Gemeinsam mit Schlagzeuger Phillips und anderen Gastmusikern wird unter Sherinians Namen (zuletzt Mythology, InsideOutMusic, 2004) zumeist hochkomplexer, instrumentaler Progrock angeboten.David Paich
David Paich ist Gründungsmitglied, Keyboarder und mit Steve Lukather aktivster Komponist der Band. In den frühen Jahren war er auch ein sehr aktiver Sänger, zum Beispiel sang er das Lied Africa, später sang er jedoch nur noch Balladen, wie Spiritual Man auf dem vorletzten Album Falling In Between. Neben Liedern wie Rosanna, Stranger in Town, und vielen mehr, schrieb und produzierte er den Toto-Soundtrack zu dem Film Dune von David Lynch. Nachdem mit Greg Phillinganes wieder ein zweiter Keyboarder (und Sänger) in der Band war, trat Paich aus familiären Gründen etwas kürzer und verzichtete auf alle Konzertauftritte außerhalb der USA. Im Studio war er jedoch immer noch für Toto sehr aktiv. Bei der Tour durch Europa im Juli 2010 war er wieder mit dabei.
Jeff Porcaro war Gründungsmitglied und Schlagzeuger von Toto. Er war schon in jungen Jahren ein begehrter Studiomusiker. Bekannt wurde Porcaro vor allem durch den so genannten Rosanna-Halftime-Shuffle-Groove, den er für Rosanna erstellte. Diese spezielle Art des Shuffle-Groove setzt sich aus zwei Liedern zusammen, die Porcaro miteinander verband und somit eine eigene Art des Shuffle kreierte.
1992 erlitt Porcaro bei der Gartenarbeit einen Kreislaufzusammenbruch, weil er auf ein von ihm eingesetztes Insekten-Pestizid stark allergisch reagierte. Obwohl er sofort medizinisch versorgt wurde, verstarb er noch am selben Tag im Krankenhaus aufgrund eines Herzstillstands, der als Folge seines anaphylaktischen Schocks eintrat. Dieser Verlust stürzte Toto in eine schwere Krise und führte beinahe zur Auflösung der Band. Seine Nachfolge trat noch im selben Jahr Simon Phillips an.Steve Porcaro
Steve Porcaro ist Gründungsmitglied und war bis zu seinem Ausscheiden neben David Paich zweiter Keyboarder. 1988 verließ der jüngere Bruder von Jeff Porcaro die Band, wirkte jedoch auch auf allen nachfolgenden Studioalben der Band mit. Nach seinem Ausscheiden entwickelte sich Porcaro zu einem der gefragtesten Keyboarder von Los Angeles. Zudem schrieb Porcaro zu zahlreichen Filmen die Filmmusik. Seit der Europatour 2010 ist er wieder Mitglied der Band.David Hungate
David Hungate ist Gründungsmitglied und war erster Bassist der Band. Er stieg am Höhepunkt des Erfolgs dieser Band 1982 aus privaten Gründen nach dem großen Erfolg des Albums Toto IV vor der bevorstehenden Tournee aus und arbeite fortan als Session-Musiker. Mitte 2014 war er live und im Studio dabei.Mike Porcaro
Mike Porcaro war der zweite Bassist der Band. Der dritte Porcaro-Bruder kam 1982 als Nachfolger von David Hungate in die Band. Seit 2006 arbeitete er zunächst wegen einer Handverletzung und später wegen einer ALS-Erkrankung nicht mehr mit der Band zusammen. Er starb an den ALS-Folgen am 15. März 2015 im Alter von 59 Jahren.Fergie Frederiksen
Fergie Frederiksen übernahm nach Kimballs Ausstieg dessen Rolle und sang dessen Lieder. Bei den Aufnahmen zum Isolation-Album sang er mit seiner markanten Stimme unter anderem den Song Endless. Aufgrund von Differenzen bezüglich der weiteren musikalischen Entwicklung der Band blieb er nur für ein Jahr in der Band. 2007 war er im Rahmen der Falling In Between-Tournee bei einigen Konzerten als Gastmusiker dabei.Joseph Williams
Joseph Williams kam als Nachfolger von Fergie Frederiksen in die Band und arbeitete an den beiden Alben Fahrenheit und The Seventh One mit. Nach der Tournee 1988 verließ er die Band wieder, da seine Stimme die Strapazen einer Toto-üblichen, langen Tour nicht vertrug. Trotz seines Ausscheidens arbeitete er auch später noch mit der Band zusammen, beispielsweise auf dem letzten Album Falling In Between. Seit der Europatour 2010 ist er wieder der Leadsänger der Band.Jean-Michel Byron
Jean-Michel Byron wurde 1989 von der damaligen Plattenfirma Sony als neuer Leadsänger eingesetzt. Jedoch baten ihn die anderen Bandmitglieder nach nur einem Album und einer kurzen Tournee, Toto wieder zu verlassen, da seine Stimme und seine Live-Performances nicht dem Stil der Band entsprachen.Simon Phillips
Simon Phillips ist ein britischer Schlagzeuger, der 1992 als Nachfolger des verstorbenen Jeff Porcaro der Band beitrat. Phillips hatte bereits mit einer Vielzahl von Künstlern wie Asia, Peter Gabriel, Mick Jagger, Mike Oldfield, Gary Moore und The Who (auch mit Pete Townshend solo) als hoch nachgefragter Schlagzeuger, sowohl als Studiomusiker oder auch als Tour-Mitglied, zusammengearbeitet.Greg Phillinganes
Greg Phillinganes war von 2005 bis 2008 zweiter Keyboarder bei Toto und ersetzte, wenn nötig, David Paich bei Auftritten, insbesondere in Europa. Er hatte eine ähnliche Stimme wie Paich und sang dessen Parts, z. B. in Africa, aber auch neue Titel. Schon von zahlreichen gemeinsamen Aufnahmen in den 1980er Jahren (u. a. für Michael Jackson) waren Phillinganes und Toto sich bekannt.Außerdem arbeiteten einige andere Musiker an verschiedenen Alben mit. So arbeitete Lenny Castro, meist mit Joe Porcaro, dem Vater von Jeff, Mike und Steve Porcaro an Liedern wie Africa, It’s a Feeling oder Good for You mit. Weitere gelegentliche Mitglieder waren Timothy B. Schmit (Background-Sänger), Paulinho da Costa (Congas/Percussion), Michael Fisher (Percussion), Jenny Douglas-McRae (Gesang), Tom Kelly (Background-Gesang), Jon Anderson (Sänger der Gruppe Yes) und viele mehr. Als Gastmusiker spielte Miles Davis den Titel Don’t Stop Me Now auf dem Album Fahrenheit mit ein. Michael McDonald ergänzte Hintergrundgesang bei dem Titel I`ll be over you.
Toto waren unter anderem in der US-amerikanischen Sitcom Scrubs und den Trickfilmserien Family Guy und South Park zu hören bzw. zu sehen.
Die Toto-Mitglieder sind einige der Hauptcharaktere der zehnteiligen Videoserie „Yacht Rock“, in der es um den sogenannten Smooth Rock der 1980er Jahre wie z. B. Michael McDonald, Hall & Oates, Steely Dan, Michael Jackson, Kenny Loggins und weitere geht.
Bei der Entstehung des meistverkauften Albums der Tonträgergeschichte „Thriller“ von Michael Jackson waren einige Mitglieder der Band maßgeblich beteiligt. Steve Porcaro schrieb den Hit „Human Nature“ für Michael Jackson.
Das Instrumentallied Child's Anthem ist die Titelmelodie der ZDF-Jahresrückblicksendung „Menschen“.
Von den Mitgliedern der Band wurde mehrfach dementiert, dass der Hit Rosanna der Schauspielerin Rosanna Arquette gewidmet sei, die mit Steve Porcaro liiert war, als David Paich den Song schrieb. Vielmehr habe man ihren Vornamen für den ansonsten bereits fertig geschriebenen Song „einfach genommen“, weil er gut als Titel und für den Refrain passte.
Sowohl der Songtext als auch das Musikvideo von Stranger in Town beziehen sich auf den Roman Whistle Down the Wind der englischen Autorin Mary Hayley Bell, der 1961 von Bryan Forbes verfilmt und Mitte der 1990er Jahre von Andrew Lloyd Webber und Jim Steinman zum Musical umarrangiert wurde.
In einem Interview mit dem Magazin „Guitar for the Practicing Musician“ (Ausgabe September 1993) sagte Eddie Van Halen über die Band: „To me Toto as a band are collectively the best musicians on the planet“ (übersetzt: „Für mich sind Toto als gemeinsame Band die besten Musiker auf dem Planeten“).
Frank Zappa persiflierte Hold the Line 1979 auf seinem Album Joe’s Garage in dem Instrumentalstück Toad-O Line. Auf späteren Ausgaben wurde der Titel jedoch umbenannt zu On the Bus.
Frank Laufenberg, Ingrid Laufenberg: Frank Laufenbergs Hit-Lexikon des Rock und Pop. Ullstein, München 2002, ISBN 3-548-36362-8.
Christian Graf, Burghard Rausch: Rockmusiklexikon Amerika, Afrika, Asien, Australien. Fischer, Frankfurt am Main 2003, ISBN 3-596-15869-9.
Griffschriften und Liedtexte von Toto (englisch) (Memento  vom 2. Dezember 2008 im Internet Archive)

Die Tötungsdelikte an der Startbahn West des Frankfurter Flughafens am 2. November 1987 waren die ersten und bisher einzigen tödlichen Angriffe auf Polizeibeamte in der Geschichte der Bundesrepublik Deutschland während einer Demonstration.
Der damals 33-jährige Andreas E., Mitglied einer autonomen Gruppe, feuerte während einer Versammlung gegen die damals bereits seit drei Jahren in Betrieb befindliche Startbahn West 14 Schüsse mit einer Pistole auf Einsatzkräfte der hessischen Bereitschaftspolizei ab. Ein 43-jähriger und ein 23-jähriger Polizeibeamter starben, sieben weitere wurden durch die Schüsse verletzt, teilweise schwer. Die Tat erregte bundesweit großes Aufsehen und markierte das Ende der organisierten Proteste gegen die Startbahn West. Zwei Jahre nach Beginn des sogenannten Frankfurter Startbahnprozesses wurde der Täter im März 1991 zu einer 15-jährigen Freiheitsstrafe verurteilt; im Oktober 1997 wurde er nach insgesamt zehn Jahren aus der Haft entlassen.
1979 hatte sich die „Aktionsgemeinschaft gegen die Flughafenerweiterung“ gegründet, die sich wenige Monate später in „Bürgerinitiative gegen die Flughafenerweiterung Frankfurt Rhein-Main“ umbenannte. Ein Jahr später begannen die Vorbereitungsarbeiten des Frankfurter Flughafens an der Startbahn West. Dadurch nahm eine massive Protestwelle ihren Anfang und wurde zu einer der größten Bürgerbewegungen der Bundesrepublik Deutschland. In der Folge kam es unter anderem zu verschiedenen Protestaktionen durch die Bürgerinitiative, zur Errichtung eines Hüttendorfes und zu mehreren Demonstrationen, auf denen sich gewalttätige Protestierer und die Polizei stundenlange Straßenschlachten lieferten. Die Situation eskalierte zunehmend, es kam zu schweren, gewalttätigen Auseinandersetzungen. Es gab sowohl auf Seiten der Demonstranten als auch auf Seiten der Polizei zahlreiche Verletzte.
Am 2. November 1981 wurde das Hüttendorf friedlich geräumt. In mehreren deutschen Städten, insbesondere in Frankfurt am Main, kam es am selben sowie am darauffolgenden Tag wiederum zu blutigen Auseinandersetzungen. Ihren Höhepunkt hatten die Proteste der Startbahngegner am 14. November 1981, als 150.000 Menschen in Wiesbaden demonstrierten und 220.000 Unterschriften gegen die Startbahn gesammelt werden konnten. Ab Frühjahr 1982 flauten die Proteste ab. Danach kam es nur noch zu sogenannten Sonntagsspaziergängen. Ortsansässige Bürger und autonome Gruppen bildeten den Kern der sonntäglichen Spaziergänger zur Startbahn, die am 12. April 1984 eingeweiht und dem Flugverkehr übergeben wurde. Über die darauffolgenden Jahre hinweg etablierte sich ein „Ritual zwischen Spiel und Protest, Folklore und Militanz“. Während die Proteste gegen die Startbahn selbst bei den Grünen politisch keine Rolle mehr spielten und die Verhinderung der Startbahn wegen ihres Bestehens faktisch gar nicht mehr möglich war, entstand aus dem sonntäglichen Protestgang zur Startbahnmauer eine eigene „Widerstandskultur“. Zum 300. Sonntagsspaziergang kam es am 1. November 1987.
Die letzte größere Protestaktion gegen die Startbahn West fand schließlich am 2. November 1987 statt. Dieser Tag war der sechste Jahrestag der Räumung des Hüttendorfes.
Bereits Ende Oktober 1987 hatte die Bürgerinitiative gegen die Flughafenerweiterung Frankfurt Rhein-Main zu einem „Jubiläumsprotest“ an der Startbahn West aufgerufen. Etwa zwei- bis dreihundert Teilnehmer folgten am 2. November 1987 dem Aufruf. Es gab zahlreiche Hinweise, dass es an diesem Tag zu Gewalttaten kommen würde. Bereits im Vorfeld waren bei Fahrzeugkontrollen Molotowcocktails sichergestellt worden. Die Polizei notierte die Kennzeichen der Fahrzeuge der angereisten Demonstranten.
Offiziell verlautbarter Treffpunkt war um 18:00 Uhr am Vereinslokal der SKG Walldorf 1888. Zu diesem Zeitpunkt war es bereits dunkel. Um nicht von der Polizei beobachtet zu werden, trafen sich die Protestierer durch mündlich-persönliche Weitergabe tatsächlich jedoch etwa zwei Kilometer weiter entfernt an einem Wildgatter in Mörfelden. Von dort aus setzte sich der Demonstrationszug gegen 19:20 Uhr in Bewegung und gelangte etwa eine halbe Stunde später an eine Weggabelung, knapp 250 Meter vor der Südspitze der Startbahn-West-Mauer entfernt. Von dort aus führt der einzige Weg an das Tor in der Mauer der Startbahn West. An dieser Stelle errichteten einige Demonstranten Barrikaden, indem sie Autoreifen mit Ketten und Moniereisen im Boden verankerten und anschließend mit Gaskartuschen versehene Strohballen aufeinanderschichteten. Das Terrain war durch mobile Lichtmasten der Polizei, die auf dem Gelände der Startbahn aufgestellt waren, hell erleuchtet.Gegen 20:02 Uhr erging der Einsatzbefehl an alle eingesetzten Polizeieinheiten, aufgrund zu erwartender „Kleingruppentaktik“ der Demonstranten auf eine erhöhte Eigensicherung zu achten. Etwa zu diesem Zeitpunkt – um 20:00 Uhr – begannen gewaltsame Auseinandersetzungen. Demonstranten zündeten die errichteten Barrikaden an. Molotowcocktails flogen in Richtung der eingesetzten Polizeikräfte, ebenso Steine, durch Zwillen abgeschossene Stahlkugeln und abgefeuerte Signalmunition. Auf den Feldern gingen Heuballen in Flammen auf. Auf den schmalen Stegen brannten Barrikaden aus Ästen und abgeschlagenen Bäumen.Um 20:31 Uhr löste die Polizei die Versammlung „angesichts der Gefahrenlage“ auf. Über den Lautsprecherwagen gab sie bekannt, dass der Fackelzug verboten sei, der Aufzug gefährde die öffentliche Sicherheit und Ordnung. Auf Seiten der Polizei rückten nun ab 20:38 Uhr die eingesetzten Hundertschaften sowie Wasserwerfer aus, um die Demonstranten über die etwa 600 Meter breiten Mönchbruchwiesen in Richtung Gundbach und die hinter ihm angrenzenden Waldgebiete zurückzudrängen. Das Wiesengelände war durch den Mond, die Scheinwerfer eines Polizeihubschraubers und die beiden mobilen Lichtmasten gut ausgeleuchtet.Gegen 20:57 Uhr, als die gewaltsamen Auseinandersetzungen noch im vollen Gange waren, kam der Einsatzbefehl über Lautsprecher, das Gebiet nur bis zum Beginn der Mönchbruchwiese zu räumen. Die Polizeibeamten der eingesetzten Hundertschaft hatten diese Durchsage offenbar nicht mehr gehört. Sie stürmten auf das Wiesengelände, was den Regeln über die Eigensicherung der Beamten widersprach, die der Arbeitskreis II der Innenministerkonferenz erst kurze Zeit zuvor für den Einsatz gegen gewalttätige Störer aufgestellt hatte. Hierdurch gaben sie auf der flachen, mit nur kniehohem Gras bewachsenen, ausgeleuchteten Wiese „gut sichtbare Zielscheiben“ ab.
Zu diesem Zeitpunkt hielt sich Andreas E. gemeinsam mit anderen Demonstranten am Waldrand am Ufer des Gundbaches auf. Gegen 21:05 Uhr zog er eine Pistole. Auf welche Weise Andreas E. an die Schusswaffe gelangt war, blieb ungeklärt. Er gab aus dem Dunkeln heraus innerhalb weniger Minuten insgesamt 14 Einzelschüsse auf die eingesetzten Polizeikräfte ab, die insbesondere aufgrund der weißen Schutzhelme und der flachen, übersichtlichen Mönchbruchwiese gut erkennbar waren. Hierbei nahm er zwischen den Schüssen drei verschiedene, bis zu 55 Meter auseinander liegende Standorte ein und wechselte einmal das Magazin. Andreas E. traf insgesamt neun Polizeibeamte.
Der 43-jährige Polizeihauptkommissar Klaus Eichhöfer, Hundertschaftsführer der IV. Bereitschaftspolizeiabteilung Hanau, war 516 Meter vom Täter entfernt, als er einen Schuss in den Unterbauch erhielt. Der 23-jährige Polizeimeister Thorsten Schwalm war Angehöriger der III. Bereitschaftspolizeiabteilung in Mühlheim und seit drei Jahren im Dienst. Er war 83 Meter vom Täter entfernt, als er ebenfalls im Unterbauch getroffen wurde. Der für die beiden Opfer angeforderte Rettungshubschrauber traf gegen 21:20 Uhr ein. Auf dem Flug in die Universitätsklinik Frankfurt stellten die Rettungskräfte die Wiederbelebungsversuche für Klaus Eichhöfer ein. Er hinterließ eine Ehefrau und drei Kinder. Thorsten Schwalm erlag in der Universitätsklinik um 22:15 Uhr seinen inneren Verletzungen.Weitere durch die Schüsse Getroffene waren der 26-jährige Polizeimeister Uwe K., der durch einen Lungendurchschuss schwer verletzt wurde, und der 23-jährige Polizeimeister Uwe T., der einen Oberschenkeldurchschuss erhielt. Fünf weitere Polizeibeamte wurden ebenfalls getroffen, jedoch leichter verletzt. Sie wurden mit Rettungswagen in die Flughafenklinik gefahren.
Ein Zeuge hatte unmittelbar nach der Tat den vermummten Andreas E. im Wald mit der Waffe in der Hand gesehen, woraufhin dieser im Gespräch die Schüsse in Richtung der Polizeibeamten zugab. Andreas E. wies den Zeugen allerdings an, ja „das Maul“ zu halten. Der Zeuge konnte den Täter später nicht sicher identifizieren.Die Tötungsdelikte waren die beiden ersten und bisher einzigen Fälle in der Geschichte der Bundesrepublik Deutschland, in denen Polizisten von einem Demonstranten getötet wurden. Das Komitee für Grundrechte und Demokratie sprach daher von einer „Zäsur“ in der Geschichte der Bundesrepublik, da erstmals „die Handlungslogik von Protest und Widerstand in die des Bürgerkriegs, die kalkulierte Vernichtung des Gegners, umgeschlagen zu sein“ schien.
Noch am Abend des Tattages zog der Generalbundesanwalt beim Bundesgerichtshof das Verfahren an sich, da der Verdacht bestand, dass „die Ermordung der Polizeibeamten nach den Umständen bestimmt und geeignet ist, den Bestand der inneren Sicherheit der Bundesrepublik Deutschland zu beeinträchtigen.“ Die besondere Bedeutung des Falles ergab sich nach Auffassung des Generalbundesanwaltes aus der „Tötung von Polizeibeamten mit Schusswaffen am Rande einer Demonstration, aus der heraus vermummte Täter Gewalttaten begangen haben.“Nach der Tat durchsuchte die Kriminalpolizei rund vier Dutzend Häuser und Wohnungen in Wiesbaden, Rüsselsheim und Frankfurt am Main. Auch den Täter suchten die Beamten auf. Über den Werdegang des damals 33-jährigen Werbegrafikers ist bekannt, dass er eine Ausbildung an der Werbefachschule in Kaiserslautern absolviert hatte und als kaufmännischer Angestellter im Dachziegelvertrieb einer Frankfurter Firma beschäftigt war, zuletzt als Werbeleiter. Andreas E.s Aktivitäten waren der Kriminalpolizei nicht unbekannt: Bereits seit 1980 gehörte er der Protestbewegung an und war auch an Gewaltaktionen beteiligt. Er galt als „Rädelsführer“ einer neunköpfigen Gruppe aus militanten Autonomen, die insbesondere Anschläge auf Hochspannungsmasten und Einrichtungen der Startbahn West plante und verübte. In der „revolutionären Szene“ war er kein anonymer Mitläufer, sondern sehr stark eingebunden. Ein Jahr vor der Tat wurde er an der deutsch-französischen Grenze festgenommen, weil sein Auto unter anderem mit „pyrotechnischem Gerät“ beladen war. Gegen ihn lief ein Ermittlungsverfahren wegen mehrerer Sabotageakte an Hochspannungsmasten; seine Wohnung war in diesem Zusammenhang bereits zweimal durchsucht worden. Andreas E.s Telefongespräche waren zur Tatzeit bereits seit geraumer Zeit überwacht worden. Aus einem Telefonat vom Nachmittag des Tattages erfuhren die Ermittler, dass am Abend ein Treffen an der „Spinnenbrücke“ stattfinden solle. Mit der „Spinnenbrücke“ konnte nur ein Ort an der Hochspannungstrasse südlich der Startbahn West gemeint sein, an dem drei Hochspannungsmasten parallel nebeneinander stehen – in unmittelbarer Nähe zum Tatort, an dem Andreas E. später die Schüsse abgab. Die Kriminalpolizei konnte sich diese Information zunächst nur so erklären, dass Andreas E. dort einen weiteren Strommast umsägen wolle.Als Andreas E. am Morgen nach der Tat seine Wohnung in Frankfurt am Main nicht öffnete, fuhren die Ermittler zur Wohnung seiner Freundin in Frankfurt-Niederrad. Gegen 06:30 Uhr ließ die Kriminalpolizei die Wohnungstür durch einen Schlüsseldienst öffnen. Als die Kriminalbeamten das Schlafzimmer der Dachgeschosswohnung betraten, sahen sie Andreas E. auf der Fensterbank stehen. Er hatte kurz zuvor seinen Leinenrucksack in einer Dachgaube oberhalb des Schlafzimmerfensters verstecken wollen. Im Rucksack befanden sich neben der durchgeladenen Tatwaffe – einer 9-mm-Pistole P225 des Herstellers SIG Sauer – auch ein mit fünf Schuss gefülltes Magazin, zwei leere, passende Magazine, drei Handfunkgeräte, eine Strumpfmaske sowie ein Paar Handschuhe. Später fanden Ballistiker heraus, dass die tödlichen Schüsse aus dieser Waffe stammten, und die Kriminaltechnik stellte fest, dass die Handschuhe Schmauchspuren aufwiesen.Am Folgetag, dem 3. November 1987, kommentierte Generalbundesanwalt Kurt Rebmann die ersten Fahndungserfolge: „Wir vermuten die Täter natürlich im Kreis der militanten Startbahngegner, und wir kennen diesen Kreis in etwa. Wir suchen bei Personen, die wir als tatverdächtig im weitesten Sinne ansehen. Diese Durchsuchungen haben zu einigen Festnahmen geführt.“Der Haftbefehl gegen Andreas E. wegen des Verdachts des Mordes erging am 4. November 1987. Andreas E. bestritt die Tat jedoch. Er gab an, er könne sich den Waffenfund bei ihm nur so erklären, dass ihm jemand die Pistole unbemerkt zugesteckt habe. Später nannte er auch einen Namen: Der Mitdemonstrant Frank H. habe ihm etwas in den Rucksack gelegt, was Andreas E. abwechselnd als Funkgerät, als Schreckschusspistole oder auch einfach nur als Gegenstand identifiziert haben will. Anfang Dezember 1987 ließ er eine Erklärung durch seinen Verteidiger verbreiten: „Die gegen mich erhobenen Vorwürfe treffen nicht zu. Ich habe nicht mit der bei mir gefundenen Waffe auf Polizisten geschossen und bin an der Tat auch nicht beteiligt. Ich verurteile die jetzt mir vorgeworfene Tat, und ein derartiges Vorgehen hat und hätte nie meine Billigung gefunden.“
Die ersten Aussagen des Beschuldigten Andreas E. belasteten im Wesentlichen den Mitbeschuldigten, den damals 24-jährigen arbeitslosen, zwangsexmatrikulierten Politologie- und Musikstudenten Frank H. So gab Andreas E. an, er und sein Komplize hätten kurz vor der Tat auf einer Art improvisierten Schießstand in einem Wald nahe Walldorf die Tatwaffe ausprobiert. Die Spurensicherung der Kripo fand nach der Beschreibung tatsächlich den beschriebenen Ort. Dort befanden sich zwei Styroporstücke, auf denen Zielscheiben aufgezeichnet waren. Die Beschuldigten hatten gemeinsam 20 Schüsse auf die Zielscheiben abgegeben, denn es wurden 20 Patronenhülsen gefunden. Die Zielscheiben wiesen insgesamt elf Treffer auf.Am 6. November 1987 erließ der Ermittlungsrichter am Bundesgerichtshof auch gegen Frank H. Haftbefehl wegen Mordes. Das Bekanntwerden der Festnahme Andreas E.s und dessen Angaben sowie der ausgestellte Haftbefehl veranlassten den Tatverdächtigen Frank H. dazu, unterzutauchen und Mitte November 1987 nach Amsterdam zu flüchten. In einem offenen Brief bestritt er, etwas mit der Tat zu tun zu haben. Da er kein rechtsstaatliches Verfahren erwarte, werde er sich den Behörden nicht stellen. Die Kriminalpolizei hatte unterdessen bei der Durchsuchung seiner Wohnung ein Papier beschlagnahmt, in dem er darüber sinnierte, ob es „eventuell möglich“ sei, „die Startbahn zum Kippen zu bringen, wenn wir den Kampf mit Mollis und Stahlkugeln verstärken und Bullen töten, um den politischen Preis für die Herrschenden so in die Höhe zu treiben, daß sie uns hören und neue Verhandlungen eingehen?“Die Ergreifung des Tatverdächtigen Frank H. am 18. März 1988 war schließlich auf einen Zufall zurückzuführen: Am besagten Tag suchte er im Amsterdamer Drogenviertel eine Straßenprostituierte auf. Frank H. war nicht fehlsichtig, er trug zur Tarnung eine Brille mit normalem Glas. Diese Prostituierte nahm häufig brillentragenden Männern, mit denen sie auf der Straße ins Gespräch kam, die Brille weg, um den nun unscharf Sehenden für die Rückgabe der Brille Geld abzupressen. Den Trick versuchte sie nunmehr auch bei Frank H. Diesen Vorfall beobachteten jedoch uniformierte Polizisten, die sogleich in die Situation eingriffen. Sie baten Frank H., sie zur Anzeigenerstattung aufs Polizeirevier zu begleiten. Frank H. machte sich allerdings verdächtig, da er in diesem Augenblick versuchte zu fliehen. Die anschließende Personalienüberprüfung führte dann zu seiner Festnahme. Frank H. wurde im Januar 1989 an die Bundesrepublik ausgeliefert.
Die von Andreas E. verwendete Tatwaffe stammte ihrerseits selbst aus einem Verbrechen, das ein Jahr zuvor gegenüber einem Kriminalbeamten begangen worden war: Am 8. November 1986 war ein 33-jähriger Kriminalhauptmeister während einer Kundgebung zur zivilen Aufklärung vor den Hanauer Nuklearbetrieben (Alkem/Nukem) eingesetzt. Rund ein Dutzend mit Motorradmützen oder Palästinensertüchern maskierte Demonstranten kamen auf ihn zu und umzingelten ihn. Nach der Frage, ob er „ein Zivi“ sei, entwendeten sie ihm seine Handschellen und sein Reizgassprühgerät; ebenso sein Portemonnaie mit Dienstausweis, Führerschein und EC-Karte. Als die Vermummten seine Dienstwaffe forderten, griff er zu ihr und hielt sie im Holster fest. Die Angreifer stießen ihn zu Boden und zerrten ihn an den Haaren ziehend wieder auf die Beine. Einer von ihnen raubte dem Kriminalbeamten schließlich die SIG-Sauer-Dienstwaffe aus seinem Holster. Der Beamte flüchtete anschließend zu seinem Dienstfahrzeug.Später hatten Polizeieinheiten den Autonomentreff „Brückenkopf“ in Hanau umstellt, da sie dort die geraubte Schusswaffe vermuteten. Die Polizeieinheiten durften jedoch keine weiteren Maßnahmen treffen und mussten unverrichteter Dinge abziehen, da die Einsatzleitung keine gewaltsame Auseinandersetzung riskieren wollte. Bis heute ist ungeklärt, wer an dem Raub der Dienstwaffe beteiligt war. Die Bundesanwaltschaft ging davon aus, dass Andreas E. einer der Autonomen war, die den Kriminalbeamten beraubten.
Die Bundesanwaltschaft klagte Andreas E., Frank H. sowie sieben weitere Personen aus der Gruppe an, deren Kopf Andreas E. gewesen sein soll. Die Anklage lautete gegen die beiden Hauptangeklagten auf Mord in zwei Fällen und versuchten Mord in zwei weiteren Fällen. Die Bundesanwaltschaft warf ihnen vor, „ihrem gemeinsamen Tatplan entsprechend im Schutze der Dunkelheit“ auf die Polizeibeamten abwechselnd geschossen zu haben. Daneben sollen die beiden Hauptangeklagten den Raub der Dienstwaffe in Hanau ein Jahr vor den tödlichen Schüssen begangen haben. Die Ankläger wollten nachweisen, dass sich innerhalb der Anti-Startbahn-Bewegung ein militanter Kern gebildet hatte, der in strafrechtlicher Hinsicht anfangs eine kriminelle, später eine terroristische Vereinigung war. Denn in wechselnder Beteiligung, aber stets langfristig geplant hätten die Mitglieder Anschläge auf Hochspannungsmasten und Einrichtungen der Startbahn West zu verantworten. Es sei ein Gesamtschaden von 4,9 Millionen D-Mark entstanden.
Der sogenannte Frankfurter Startbahnprozess begann am 23. Februar 1989 vor dem 5. Strafsenat (Staatsschutzsenat) des Oberlandesgerichtes Frankfurt am Main. Schon kurze Zeit später wurden die Verfahren gegen vier Angeklagte wegen der Strommastaktionen abgetrennt: Sie räumten die Taten ein, im Gegenzug wurden die Anklagen wegen Mitgliedschaft in einer kriminellen bzw. terroristischen Vereinigung fallengelassen. Drei Angeklagte erhielten Freiheitsstrafen unter zwei Jahren, die zur Bewährung ausgesetzt wurden, eine Angeklagte wurde nicht verurteilt.
Am 113. Verhandlungstag im Dezember 1990 wurden zwei Entlastungszeugen vor Gericht gehört. Die Verteidigung des Angeklagten Frank H. hatte sie benannt. Der erste Zeuge, ein Berliner Student, schilderte, dass er den ihm vom Sehen her bekannten Angeklagten Frank H. an der Weggabelung nahe den Barrikaden getroffen habe. Nachdem die Hundertschaften der Polizei vom Startbahngelände in Richtung der Barrikaden vorgerückt seien, seien er und Frank H. über die Mönchbruchwiesen in Richtung Gundbach gelaufen. Dort hätten sich beide noch einige Minuten aufgehalten, bevor sie sich vom Ort der Auseinandersetzungen entfernt hätten.
Der zweite Zeuge, ein EDV-Techniker aus Bonn, gab an, er habe sich nach der polizeilichen Auflösungsverfügung in Richtung Gundbach abgesetzt. Dort habe er den Angeklagten Frank H. gesehen, mit dem er einige Worte gewechselt habe. Danach sei er auf mehrere vermummte Personen gestoßen, von denen eine mit einer scharfen Schusswaffe in die Luft geschossen habe und die Flutlichter der Polizei habe treffen wollen. Ob es sich bei dieser Person jedoch tatsächlich um den ihm vom Sehen und Vornamen her bekannten Angeklagten Andreas E. gehandelt habe, konnte der Zeuge weder ausschließen noch bestätigen.Am 17. Januar 1991 gab das Oberlandesgericht Frankfurt am Main bekannt, dass der Mordvorwurf gegen die beiden Angeklagten nicht mehr haltbar sei. Letztlich komme anstelle des Mordvorwurfs eine Verurteilung wegen Totschlags, auch in Alleintäterschaft, in Betracht. Die Bundesanwaltschaft hielt allerdings in ihrem Plädoyer am 18. Februar 1991 am Mordvorwurf fest und forderte für beide Hauptangeklagte jeweils eine lebenslange Freiheitsstrafe.
Am 15. März 1991 sprach das Gericht das Urteil: Andreas E. wurde wegen Totschlags, versuchten Totschlags und Mitgliedschaft in einer kriminellen Vereinigung zur für diese Delikte höchstmöglichen Strafe von 15 Jahren verurteilt. Das Gericht sah es als nicht erwiesen an, dass Andreas E. und Frank H. abwechselnd geschossen hatten. Das Gericht hielt die Tat auch weder für heimtückisch, noch habe Andreas E. aus niedrigen Beweggründen gehandelt. Es habe offenbleiben müssen, „welche Motive ihn zu den Schüssen auf die Polizeibeamten steuerten“.Der Angeklagte Frank H. wurde vom Vorwurf des Totschlags und versuchten Totschlags freigesprochen. Er erhielt wegen der Mitgliedschaft in einer kriminellen Vereinigung viereinhalb Jahre Freiheitsstrafe. Durch die Untersuchungs- und Auslieferungshaft waren bereits drei Jahre abgegolten, der Rest wurde zur Bewährung ausgesetzt.Sowohl die Anklagebehörde, die nach wie vor von Mord ausging, als auch der Verurteilte Andreas E. hielten das Urteil für fehlerhaft und legten jeweils Revision ein. Der Bundesgerichtshof bestätigte im Februar 1993 die Rechtsauffassung des Oberlandesgerichtes Frankfurt am Main. Zur heimtückischen Tötung gehöre die Arglosigkeit des Opfers. Angesichts der „fortdauernden offenen Feindseligkeiten zwischen Polizei und Demonstranten“ sei diese vom Oberlandesgericht rechtsfehlerfrei verneint worden. Auch lägen keine niedrigen Beweggründe vor, die Erschießung der beiden Polizeibeamten unterscheide sich in „wesentlichen Punkten“ von terroristischen Anschlägen, für die die Rechtsprechung niedrige Beweggründe stets annahm. Trotz der Bestätigung durch den BGH blieb das Urteil umstritten. Die Revision des Verurteilten gegen das Urteil als solches verwarf der BGH als unbegründet.Andreas E. wurde im Oktober 1997 nach verbüßten zwei Dritteln aus der Haft entlassen.
In Frankfurt am Main formierte sich einen Tag nach der Tat ein langer Trauerzug mit Fackelträgern. Er bestand aus rund 6000 zumeist uniformierten Polizeibeamten und zog vom Polizeipräsidium bis zur Paulskirche. Der damalige Hessische Ministerpräsident Walter Wallmann und der damalige Frankfurter Oberbürgermeister Wolfram Brück führten den Schweigemarsch an. Wallmann hielt in diesem Zusammenhang an der Paulskirche eine Rede, in der er der Polizei für ihren täglichen Einsatz dankte. In Hamburg beteiligten sich ebenfalls mehr als 6000 zumeist uniformierte Polizeibeamte an einem Trauermarsch vom Polizeipräsidium bis in die Innenstadt. Der Schweigemarsch wurde vom damaligen Innensenator Volker Lange und den Fraktionsvorsitzenden der in der Hamburger Bürgerschaft vertretenen Parteien – mit Ausnahme der Grün-Alternativen Liste – angeführt. In West-Berlin demonstrierten etwa 2000 Polizeibeamte, darunter annähernd die gesamte Berliner Polizeiführung. Der Landespolizeidirektor Kittlaus warnte vor Überreaktionen der Polizei und der Politiker. An der Demonstration beteiligte sich auch beinahe die gesamte Fraktion der Alternativen Liste Berlin. In vielen anderen westdeutschen Städten demonstrierten ebenfalls Hunderte oder Tausende Polizisten; in Dortmund verteilten rund 250 Polizeibeamte Flugblätter, in denen sie vor einer Überreaktion warnten.Auf die Tat reagierten auch die drei Gewerkschaften innerhalb der Polizei. Die Deutsche Polizeigewerkschaft gab an, in die Trauer um den Tod der beiden Bereitschaftspolizisten mische sich „eine unbeschreibliche Wut aller Polizeibeamten über ihre Rolle, Gewalt tolerieren zu müssen, wo längst konsequentes Handeln gefordert“ gewesen sei. Die Gewerkschaft der Polizei beklagte eine Eskalation der Gewalt, in der sich die Gesellschaft längst an „Mollis und Stahlkugeln“ bei Demonstrationen gewöhnt habe. Der Bund Deutscher Kriminalbeamter forderte die „konsequente Verfolgung und vollständige Zerschlagung der Strukturen der Verbrechertrupps vermummter Gewalttäter“.
Innerhalb der Szene der Startbahngegner kam es nach den tödlichen Schüssen zur Bildung eines sogenannten „Ermittlungsausschusses“, der aus 20 bis 25 Personen bestand. Diese Personen waren seit Jahren in der Startbahnbewegung aktiv und genossen das Vertrauen der Startbahngegner. Während einer der exponiertesten Startbahngegner, Alexander Schubart, nach der Tat dazu aufforderte, über einen „einseitigen Gewaltverzicht“ auf Seiten der Demonstranten nachzudenken, ging der zur Militanz neigende Teil der Bewegung dazu über, Andreas E. als Opfer der Fahndungshysterie der Sonderkommission und der Bundesanwaltschaft zu bezeichnen. Der „Ermittlungsausschuss“ indes spekulierte zunächst darüber, ob ein Agent Provocateur oder jemand aus den eigenen Reihen hinter dem Verbrechen stehe, ob es ein Einzeltäter oder ob es die Entscheidung einer Gruppe gewesen sei, ob der Tod der eingesetzten Polizeibeamten geplant oder ob die Schüsse spontan aus der Situation heraus abgegeben worden seien. Später konzentrierten sich die Anstrengungen des „Ermittlungsausschusses“ darauf, den möglichen Ablauf der Tat herauszufinden und eine eigene politische Einschätzung hierzu zu erarbeiten. Die Kriminalpolizei hatte nach den Taten reihenweise Startbahngegner als mögliche Zeugen vorgeladen und sowohl zu den Tötungsdelikten als auch zu anderen militanten Aktionen vernommen. In diesen Vernehmungen war es auch zu belastenden Aussagen gekommen. Daher war es die Absicht des „Ermittlungsausschusses“, die Spirale aus Aussagen, Belastungen, Einlassungen und gegenseitigen Verratsvorwürfen zu beenden, indem sie unter dem Slogan „Anna und Arthur halten’s Maul“ zu einer Kampagne aufriefen, künftig die Aussagen zu verweigern und die bereits gemachten Aussagen vor Gericht zurückzuziehen. Drei Monate lang bewerteten über 40 Startbahngegner den Vorfall und kamen zum Schluss:
Innerhalb der autonomen Szene war die Ablehnung der Tötungsdelikte einhellig. Am Tag nach der Tat erklärten Frankfurter Autonome, dass die bisher angewandte Gewalt „immer eine andere Dimension“ gehabt und mit „blankem banalem Mord“ nichts gemein habe. Diese Distanzierung von den Tötungsdelikten hielt der damalige Leiter des Hamburger Verfassungsschutzes Christian Lochte zwar einerseits für glaubwürdig, andererseits konstatierte er, dass sich der Schwarze Block die politische Verantwortung für die Tat vorhalten lassen müsse: Wer so viel Hass auf die Polizei predige und mit Molotowcocktails auf Polizeibeamte ziele, dürfe sich nicht wundern, wenn jemand zur Waffe greife und abdrücke.In einer Stellungnahme der Frankfurter Autonomen distanzierten sich diese erstmals uneingeschränkt vom „feigen Mord“ und erklärten in deutlichen Worten, dass der Täter nicht in „ihre Reihen gehört, auch wenn er sich selbst dazu zählen mag.“ Am der Tat folgenden Sonntagsspaziergang wandte die Polizei die „Strategie der Bürgernähe“ an, indem sie sich ohne Helm in kleinen Gruppen unter die Sonntagsspaziergänger mischte. Das Mauertor zur Startbahn war weit geöffnet, und es gab einen freien Durchgang auf das Startbahngelände. Auch etwa 70 Autonome signalisierten Gewaltfreiheit, in dem sie sich nicht vermummten und anstandslos vor dem Spaziergang auf den Waldwegen von der Polizei durchsuchen ließen. Eine Gruppe von Autonomen hielt in einem Flugblatt „militante Gegenwehr“ zwar weiterhin für sinnvoll, allerdings sei „die Anwendung von Schußwaffen in solchen Situationen undenkbar“.Im Vorfeld des Startbahnprozesses anderthalb Jahre später erschien in der Zeitung Arbeiterkampf ein verklausulierter Beitrag mit autonomer Selbstkritik. Dort hieß es, dass Andreas E. nicht vom „Himmel gefallen“, also kein außenstehender Täter sei, sondern dass er seine Geschichte mit der Startbahnbewegung habe: „Er steht, wie viele andere, für die Tendenz, (zu zögernd) geforderte Auseinandersetzungen um kontroverse Vorstellungen in der Herangehensweise zu boykottieren“.
Die Protestbewegung gegen die Startbahn West als solche brach in der Folge der tödlichen Schüsse schließlich auseinander. Der erste organisierte Protest gegen die Startbahn löste sich auf und sollte über Jahre hinweg nicht mehr erstarken. Einer der Sprecher der Bürgerinitiative, Dirk Treber, brachte es so auf den Punkt: „Die Kugeln trafen auch die Bewegung tödlich. Danach gab es keinen organisierten Protest mehr gegen die Startbahn. Die Tat war damals für alle absolut unbegreiflich.“Das Komitee für Grundrechte und Demokratie konstatierte 1988, dass „die Linke, die sich bislang als Opfer“ gesehen habe, sich „plötzlich in der Rolle des Täters“ wiederfinde. Außerdem könnte sich „das moralische Gefälle, das die Akteure zumeist stillschweigend im Verhältnis zwischen Bewegungen und Staat unterstellt“ hätten, umgekehrt haben.Joschka Fischer, damals Fraktionsvorsitzender der Grünen im Hessischen Landtag, gab seinerzeit an, dass in dieser Nacht ein Tabu verletzt worden sei, die „Zeit der sozialen Bewegungen“ sei nun vorbei.

Die Tour de Ski 2008/09 (Sponsorenname: Viessmann FIS Tour de Ski performance by Craft Sportswear) war ein im Rahmen des Skilanglauf-Weltcups 2008/09 veranstaltetes Etappenrennen. Es fand zwischen dem 27. Dezember 2008 und dem 4. Januar 2009 an vier verschiedenen Orten in drei Ländern statt.
Bei den Frauen siegte die Finnin Virpi Kuitunen, die schon Siegerin der ersten Tour de Ski gewesen war, vor ihrer Landsfrau Aino-Kaisa Saarinen und der Slowenin Petra Majdič. Bei den Herren gewann der Schweizer Dario Cologna ohne einen einzigen Etappensieg – ausgenommen Handicapstarts – vor Petter Northug aus Norwegen und Axel Teichmann, der bei drei Einzeletappen siegte.
Zum ersten Mal fand die Tour de Ski tatsächlich in drei Ländern statt. Bei den ersten beiden Austragungen hatten jeweils einmal Nové Město na Moravě und Oberstdorf die Organisation kurzfristig absagen müssen. Während der gesamten Tour de Ski legten die Frauen eine Distanz von 60 Kilometern zurück, die Männer liefen insgesamt 102 Kilometer.
Schon direkt nach der Austragung 2007/08 kritisierten schwedische Trainer den ungünstigen Zeitplan der Tour de Ski ein Jahr darauf. Nur wenige Tage nach dieser sollten in Vancouver die Testläufe für die Olympischen Winterspiele 2010 stattfinden, sodass den Athleten kaum Zeit zum Erholen bliebe.Im Dezember 2008 mehrten sich die Absagen von einigen prominenten Skilangläufern. Johan Olsson, der schon ein Weltcuprennen gewonnen hatte, wollte sich intensiver auf die Nordische Skiweltmeisterschaft 2009 vorbereiten, Odd-Bjørn Hjelmeset ging aus gesundheitlichen Gründen nicht an den Start. Simen Østensen, der bei den ersten beiden Austragungen erfolgreich teilgenommen hatte, wurde ebenso wie Betty-Ann Bjerkreim Nilsen nicht nominiert. Der Österreicher Christian Hoffmann konnte wegen eines grippalen Infektes ebenfalls nicht starten und wurde durch Martin Stockinger ersetzt.Im Gegensatz zu Tobias Angerer, der sich von seiner Grippe rechtzeitig erholte, musste auch die Schweizerin Laurence Rochat wegen eines Virus absagen. Freiwillig verzichtete Sprintspezialist Ola Vigen Hattestad, bis dahin Gesamtweltcupsführender, auf die Teilnahme, da er die Tour de Ski als zu anstrengend betrachtete. Letzter prominenter Ausfall war die Vorjahressiegerin Charlotte Kalla, die kurz vor dem Start die Tour de Ski wegen einer Erkältung endgültig absagte.
Da bereits vor der Tour de Ski sieben Weltcuprennen stattgefunden hatten, handelte die FIS diese Athleten vor der Tour als Favoriten. Dabei sind die ausgewählten Top-Favoriten mit einem Sternchen (*) markiert, die Favoriten mit einer hochgestellten Eins (1). Alle nicht markierten Athleten wurden als Herausforderer angesehen. Außerdem ist in der letzten Spalte angegeben, welche Platzierung der Läufer tatsächlich erreichte.
Während sich bei den Frauen die meisten Prognosen bewahrheiteten, stimmten viele Vor-Favoriten bei den Herren nicht mit den Top-10-Athleten überein. Besonders Titelverteidiger Lukáš Bauer erfüllte nicht die in ihn gesteckten Erwartungen, er konzentrierte sich jedoch auch besonders auf die Nordische Ski-WM, die 2009 mit Liberec in seinem Heimatland stattfand. Auch der spätere Tour-Sieger Dario Cologna galt vor dem Etappenrennen als ein möglicher Favorit, da er sich bereits in den ersten Weltcup-Wettbewerben als Allrounder profiliert hatte und auf dem zweiten Rang im Gesamtweltcup lag. Axel Teichmann selbst sah sich vor der Tour de Ski nicht als Favorit, übernahm aber nach guten Ergebnissen bei den ersten Rennen diese Rolle.
In den sieben Weltcuprennen vor der Tour de Ski hatten sich sowohl bei den Frauen als auch bei den Männern einige Athleten hervorgetan, darunter auch solche, die bis dahin kaum in Erscheinung getreten waren.
Bei den Frauen war Aino-Kaisa Saarinen zwar schon 2007 Staffelweltmeisterin geworden, sie hatte jedoch erst einen Einzelweltcupsieg gefeiert. Im November und Dezember 2008 trat sie jedoch stärker auf als in den Vorjahren und sicherte sich mit vier Podiumsplatzierungen in den ersten fünf Rennen sowie zwei weiteren Top-Ten-Resultaten die Führung im Gesamtweltcup. Nur acht Punkte dahinter folgte die Slowenin Petra Majdič, die schon in den Vorjahren stark gewesen war, jedoch eher als Sprintspezialistin. Auch in dieser Saison hatte sie alle drei bis zum Tourbeginn ausgetragenen Sprints für sich entschieden, was sie in die Favoritenstellung besonders für die Sprintwertung brachte. Auf den Rängen drei und vier befanden sich mit Marit Bjørgen und Virpi Kuitunen zwei etablierte Athletinnen.
Das Gesamtklassement der Herren führte mit Ola Vigen Hattestad ein Skilangläufer an, der seine Punkte ausschließlich in Sprints holte, wo er dafür in allen drei Rennen gesiegt hatte. Hattestad nahm als reiner Sprintspezialist jedoch nicht an der Tour de Ski teil, sodass sich dem jungen Schweizer Dario Cologna die Chance auf die Führung im Gesamtweltcup bot. Der U23-Weltmeister hatte in der Vorsaison nur wenige Punkte gesammelt und galt daher als Überraschung. Zu seiner guten Position im Gesamtweltcup verhalfen ihm besonders die Allrounder-Qualitäten; obwohl er nur einen Podiumsplatz erreicht hatte, standen schon 208 Punkte auf seinem Konto. Mit Tor Arne Hetland auf dem dritten Rang folgte ein weiterer Sprinter, der Distanzläufer und Viertklassierte Johan Olsson verzichtete auf den Tourstart. Petter Northug auf dem fünften Rang hatte sich in der Saison besonders in den Distanzrennen stark gezeigt, in den Vorwintern war er aber auch im Sprint erfolgreich gewesen.
28. Dezember: Verfolgung, klassisch, Handicapstart*, 10 km (Frauen) und 15 km (Männer).Tschechien Prag:
4. Januar: Bergverfolgung, freie Technik, Handicapstart*, 9 km (Frauen) und 10 km (Männer).(*) Handicapstart: Bei diesem Rennen wird in der Reihenfolge des aktuellen Gesamtklassements gestartet, das heißt die/der Führende zuerst. Der Startabstand ergibt sich aus der Differenz der Gesamtzeiten zwischen den Startern aller bis dahin absolvierten Rennen.
Die Gesamtwertung basiert auf den kumulierten Zeiten aller sieben Tour-Etappen. Bei Sprintwettbewerben wird dabei die Qualifikationszeit gewertet. Des Weiteren werden Bonussekunden von der Endzeit abgezogen, bevor diese zur Gesamtzeit addiert wurde. Bonussekunden werden sowohl bei Sprint-Etappen als auch bei Distanz-Etappen vergeben.
Für die Gesamtwertung der Tour de Ski wird die vierfache Anzahl an Punkten gemäß FIS-Punktesystem an die besten 30 Athleten vergeben. Diese Punkte werden nur für den Gesamtweltcup gewertet.
Zunächst eroberten die Deutschen Axel Teichmann und Claudia Nystad als Prologsieger das Führungstrikot. Nystad verlor dieses auf der zweiten Etappe, einem Verfolgungsrennen nach der Prologzeit, schon auf den ersten Kilometern. Aus der sechsköpfigen führenden Favoritengruppe konnte sich nun die Finnin Virpi Kuitunen an die Spitze des Gesamtklassements setzen. Bei den Herren gelang dies dem Schweizer Dario Cologna, der wenige Sekunden vor Teichmann die Führung übernahm. Während Cologna als guter Sprinter das Trikot auch beim ersten Sprintrennen in Prag verteidigte, fiel Kuitunen weit zurück und überließ die Gesamtführung der Italienerin Arianna Follis. Diese wiederum büßte erneut auf Kuitunen beim Distanzrennen in Nové Město na Moravě viel Zeit ein, sodass die Finnin und Siegerin der Tour de Ski 2006/07 sich wieder an die Spitze setzte. Cologna dagegen gelang es auch diesmal seine Führung zu behaupten, obwohl er eine halbe Minute auf Axel Teichmann verlor.
Beim zweiten Sprint konnte Aino-Kaisa Saarinen das Trikot bei den Frauen erobern, da sie sich besser als Kuitunen platzierte. Cologna verteidigte die Spitze abermals, indem er auch in diesem Wettkampf das Finale erreichte. Auch beim Massenstartrennen im Val di Fiemme behielt der Schweizer die Gesamtführung inne, er hatte jedoch nur noch eine gute halbe Minute Vorsprung auf seinen dichtesten Verfolger Axel Teichmann. Zum dritten Mal ging Virpi Kuitunen bei den Damen wieder in Front, nachdem sie sich einige Bonussekunden gesichert hatte. Auf der letzten Etappe schließlich behaupteten sich beide Führenden an der Spitze, wobei Cologna deutlich, Kuitunen eher knapp gewann.
Für die Sprintwertung wurden alle vergebenen Bonussekunden gewertet. Da diese auch bei Zwischensprints während des Massenstartrennens errungen werden konnten, hatten nicht nur reine Sprinter die Chance auf den Sieg in dieser Wertung. Insgesamt waren maximal 225 Bonussekunden bei vier Rennen erreichbar. Dazu siehe auch die folgende Tabelle:
Im Prolog übernahmen mit Claudia Nystad und Axel Teichmann die Sieger ihrer jeweiligen Rennen die Spitze. Da sich im Frauenwettbewerb Petra Majdič und Justyna Kowalczyk zeitgleich auf dem dritten Platz klassierten, erhielten beide fünf Bonussekunden. Nach dem ersten Sprint von Prag gingen die Trikots der Führenden an die beiden Sieger Arianna Follis und Tor Arne Hetland, die jeweils 60 Sekunden gutgeschrieben bekommen hatten. Während Hetland dennoch im Gesamtklassement weiter hinten blieb, übernahm Follis auch dort die Spitze, sodass Claudia Nystad, die mit insgesamt 57 Bonussekunden am zweitmeisten gesammelt hatte, das Trikot auf der vierten Etappe tragen durfte.
Follis gewann auch den zweiten Sprint in Nové Město na Moravě und verteidigte die Führung deutlich, ebenso Hetland mit seinem zweiten Platz. Trotz des Doppelerfolgs bei den Sprints gelang der Italienerin nicht der Sieg in der Sprintwertung, weil Petra Majdič sich auf der vorletzten Etappe bei den Zwischensprints noch 35 Bonussekunden sicherte und Follis so um achtzehn Sekunden im Klassement auf Abstand hielt. Hetland dagegen schaffte auch auf der letzten Etappe mit Zeitbonifikationen die Verteidigung seines Trikots, indem er selbst noch fünfzehn Sekunden dazugewann. Zweiter wurde hier der Schweizer Dario Cologna.
Für die Nationenwertung werden pro Etappe die jeweils zwei besten männlichen und weiblichen Athleten einer Nation gewertet.
Bei Verfolgungwettbewerben mit Handicap-Start wird jeweils die reine Laufzeit zur Ermittlung des Etappenergebnisses herangezogen, sodass der Zieleinlauf nicht mit dem Etappenergebnis identisch sein muss. Bei jeder Etappe wurden für die besten 30 Teilnehmer Weltcuppunkte vergeben. Diese Punkte gingen sowohl in die Weltcup-Gesamtwertung als auch in die Disziplinenwertungen ein. Voraussetzung für den Erhalt der Weltcuppunkte war die Beendigung aller Etappen der Tour de Ski.
Der Auftakt der Tour de Ski 2008/2009 wurde vor heimischer Kulisse durch die deutschen Starter geprägt. Claudia Nystad gelang nach mäßigem Saisonauftakt völlig unerwartet ihr dritter Sieg in einem Weltcupwettbewerb. Dabei verwies sie die italienische Sprintspezialistin Arianna Follis auf den zweiten Platz. Den dritten Platz teilten sich die Mitfavoritinnen für den diesjährigen Gesamtsieg Petra Majdič und Justyna Kowalczyk.
Bei den Herren wurde das Rennen durch Axel Teichmann dominiert. Der Oberhofer verwies mit einem Vorsprung von acht Sekunden den Schweizer Dario Cologna deutlich auf den zweiten Platz. Der Norweger Petter Northug, der wie Cologna einer der Sieganwärter dieser Tour war, kam auf den dritten Rang.
Das Rennen wurde in den Abständen gestartet, die im Prolog entstanden waren (Handicapstart), wobei auch die Bonussekunden berücksichtigt wurden. Bei den Damen bildeten sich mehrere Gruppen, in der vorderen befanden sich die meisten Favoritinnen. Claudia Nystad fiel rasch von der Spitze zurück und konnte auch nicht mit der Favoritengruppe mithalten. Vorne blieb die Sechsergruppe um Virpi Kuitunen, Marit Bjørgen, Justyna Kowalczyk, Arianna Follis, Aino-Kaisa Saarinen sowie Petra Majdič lange Zeit recht kompakt, ehe Majdič wenige Kilometer vor dem Ziel abreißen lassen musste. Kurz vor dem Ziel bekamen auch Kowalczyk, Follis und Saarinen leichten Rückstand von wenigen Sekunden. Virpi Kuitunen übernahm knapp die Führung im Gesamtklassement vor Marit Bjørgen, weniger als zehn Sekunden dahinter noch die drei abgefallenen Athletinnen. Lediglich Majdič erhielt einen größeren Rückstand, der knapp eine halbe Minute betrug.
Bei den Männern lief Dario Cologna seinen 13-Sekunden-Rückstand auf Axel Teichmann bereits wenige Kilometer nach dem Start zu. Diese beiden Skilangläufer bildeten nun eine Führungsgruppe, die den Abstand auf das sehr große Verfolgerfeld immer bei ungefähr 25 Sekunden hielt. Vor dem Ziel setzte sich Cologna knappe fünf Sekunden von Teichmann ab und eroberte damit die Spitze des Gesamtklassements. Dahinter platzierten sich Sami Jauhojärvi und Devon Kershaw auf den Rängen drei und vier.
Hinweis: In dieser Tabelle wird nur die Zeit genannt, die der jeweilige Athlet auf der Verfolgungsstrecke erreichte, nicht die Zeiten des Zieleinlaufs. Da die Resultate im Prolog jedoch recht dicht beieinander lagen, ist die Differenz zwischen diesen beiden Ergebnissen nicht sehr deutlich.
Wie bei Weltcup-Sprints starteten zunächst alle Läufer in einem individuell gelaufenen Prolog. Die dreißig Athleten, die dort die kürzeste Zeit benötigt hatten, qualifizierten sich für fünf Viertelfinals à sechs Starter. So ging es im K.-o.-System weiter bis zum Finale, wo bei Frauen und Männern jeweils sechs Skilangläufer an den Start gingen. Die Plätze 7 bis 12 wurden im B-Finale festgelegt. Danach erhielten die Athleten gemäß ihren Endergebnissen Bonussekunden, die von der Gesamtzeit abgezogen wurden.
Bereits im Prolog der Männer schied mit Axel Teichmann der Zweite in der Gesamtwertung bis dahin aus. Auch bei den Frauen scheiterte mit der Trägerin des roten Trikots, Virpi Kuitunen, eine Favoritin frühzeitig im Viertelfinale. Nachdem auch Dario Cologna bei den Herren ausgeschieden war, qualifizierte sich kein Athlet aus Deutschland, Österreich oder der Schweiz für das Männer-Finale. Bei den Frauen gelang dies der Deutschen Claudia Nystad, die allerdings dort stürzte und so die Führung in der Sprintwertung nicht verteidigen konnte, die von der Siegerin Arianna Follis übernommen wurde. Auch bei den Herren setzte sich mit Tor Arne Hetland der Sieger des Sprints an die Spitze. Im Gesamtklassement der Damen fiel Kuitunen weit zurück, auch hier übernahm Follis die Führung. Trotz des Halbfinal-Aus ganz vorne behauptete sich Dario Cologna dagegen bei den Herren.
Hinweis: Die Liste ist nach dem Endresultat im Sprint, also den erreichten Bonussekunden, sortiert. Zusätzlich geht auch die Prologzeit in die Gesamtwertung ein, diese ist in der Spalte Zeit vermerkt.
Das Distanzrennen war das einzige neben dem Prolog, das einzeln gelaufen wurde, das heißt, in festgelegten Abständen von einer halben beziehungsweise einer Minute.
Bei den Frauen gab es zunächst häufige Wechsel bei den schnellsten Zeiten, ehe die Favoritinnen kamen. Virpi Kuitunen, durch den Sprint im Gesamtklassement zurückgefallen, setzte bei jedem Zwischenmesspunkt eine neue Bestzeit, die schließlich mehr als eine Minute unter der bisherigen lag. Ihre Konkurrentinnen verloren ebenfalls viel Zeit auf die Finnin, hielten aber den Rest des Feldes ebenfalls deutlich auf Abstand. Kuitunens Landsfrau Aino-Kaisa Saarinen, Gesamtweltcupführende, hatte im Ziel fast 40 Sekunden Rückstand, die bisher führende Italierin Arianna Follis sogar über eine Minute und 45 Sekunden. Kuitunen übernahm trotz ihres Rückstandes vor dem Rennen deutlich die Gesamtführung zurück.
Im Gegensatz zum Frauenwettkampf verlief das Männerrennen knapper. Überraschend ging zunächst der international wenig erfolgreiche Kasache Nikolai Tschebotko in Führung, die er lange hielt. Erst Axel Teichmann, der bereits den Prolog gewonnen hatte und wie Kuitunen im Sprint zurückgefallen war, unterbot als erster Favorit Tschebotkos Vorgabe. Zuvor hatte bereits Martin Johnsrud Sundby Tschebotkos Zeit verbessert, der Norweger fiel jedoch fünf Sekunden hinter Teichmann zurück. Nachdem sich weitere Favoriten Rückstand eingehandelt hatten, konnte der Russe Wassili Rotschew beim letzten Messpunkt eine Zwischenbestzeit setzten. Rotschew, der lange Zeit gemeinsam mit Teichmann unterwegs gewesen war, verlor allerdings auf der letzten Drei-Kilometer-Runde noch über eine halbe Minute auf den Deutschen. Auch Dario Cologna kam nicht an dessen Zeit heran, verteidigte aber die Gesamtführung. Für den Kasachen Tschebotko war der letztlich erreichte dritte Rang sein bestes bis dahin gelungenes Weltcupergebnis.
Beim zweiten Sprint galten die Regeln des ersten. Da der Kurs in Nové Město viel schwerer eingeschätzt wurde als die Stadtstrecke von Prag und zudem zwischen den beiden Sprints das Distanzrennen über 9 beziehungsweise 15 Kilometer lag, rechneten sich auch die Distanzläufer Chancen auf eine vordere Platzierung aus. Tatsächlich qualifizierten sich sowohl bei den Damen als auch bei den Herren alle Favoriten für die Viertelfinals. Auch dieses fand bei den Frauen mit Ausnahme Justyna Kowalczyks ohne Favoritenausfälle statt, während bei den Männern Axel Teichmann sein Rennen beenden musste, ebenfalls der Finne Sami Jauhojärvi.
Im Halbfinale scheiterte bei den Frauen die Gesamtführende Virpi Kuitunen, sodass sich vor allem ihrer Landsfrau Aino-Kaisa Saarinen die Gelegenheit bot, die Spitze zu übernehmen. Bei den Männern scheiterten Wassili Rotschew und Eldar Rønning in der Vorschlussrunde, Dario Cologna gelang dagegen der Sprung ins Finale, sodass er seine Führung weiter ausbauen konnte. Im B-Finale siegten die Schwedin Anna Haag und Rotschew. Das Finale der Damen begann damit, dass Magda Genuin mit ihren für besonders gut erklärten Skiern die Führung übernahm. Auf der Ziellinie wurde sie schließlich von ihrer Teamkollegin Arianna Follis passiert, die so auch im zweiten Sprint triumphierte. Genuin fiel auch noch hinter die neue Gesamtführende Saarinen sowie die Slowenin Petra Majdič zurück und wurde Vierte.
Im Finale der Herren waren drei der sechs Starter Norweger. Petter Northug, sonst dafür bekannt, in den meisten Rennen erst auf der Zielgerade zu attackieren, fuhr den Sprint wie auch die vorherigen Runden von vorne. Nikolai Tschebotko, der sich nach seinem ersten Podestrang am Vortag erneut für das Finale qualifiziert hatte, fiel ebenso wie Dario Cologna ein wenig zurück. Einen Dreifachtriumph der Norweger verhinderte nur Cristian Zorzi, der sich beim Sieg Northugs auf dem dritten Rang platzierte. Tor Arne Hetland behielt dank seines zweiten Platzes die Führung in der Sprintwertung, genauso Arianna Follis.
Dieser Wettkampf war der einzige Massenstart der gesamten Tour de Ski, das heißt, alle Teilnehmer starteten gleichzeitig und die Abstände im Ziel wurden zu der Gesamtzeit addiert. Dazu gab es drei beziehungsweise sechs Punkte, an denen jeweils die ersten drei Athleten 15, 10 und 5 Bonussekunden erhielten. Diese gingen auch in die Sprintwertung ein.
Beim Frauenrennen über 10 Kilometer gelang Virpi Kuitunen der Sieg, die Finnin setzte sich so zum dritten Mal wieder an die Spitze des Gesamtklassements. Außerdem sicherte sich Kuitunen noch zusätzlich 40 Bonussekunden, mit denen sie den Vorsprung auf ihre härteste Verfolgerin Aino-Kaisa Saarinen auf 32 Sekunden ausbaute. Petra Majdič, die bei diesem Rennen Zweite und in der Gesamtwertung Dritte wurde, sammelte ebenfalls 35 Bonussekunden. Damit gewann sie die Sprintwertung vor Arianna Follis, die zwar bei beiden Spezialsprints triumphiert hatte, auf der vorletzten Etappe jedoch leer ausging.
Die ersten Runden im 20-Kilometer-Männerrennen waren von ständigen Attacken geprägt, sodass sich die Bonussekunden auf viele Athleten verteilten, die teilweise in der Gesamtwertung schon weiter zurücklagen. Nachdem diese Angriffe vom großen Hauptfeld abgewehrt worden waren, sprinteten besonders die beiden Spitzenreiter Dario Cologna und Axel Teichmann um Zeitgutschriften. Auf der letzten Runde versuchte Cologna noch einmal sich von Teichmann abzusetzen, der Deutsche wurde von seinem Teamkameraden Jens Filbrich jedoch wieder an die vordere Gruppe herangeführt und holte im Zielsprint schließlich seinen dritten Tagessieg. Dahinter platzierten sich der Finne Sami Jauhojärvi und der Kasache Nikolai Tschebotko, welcher schon sein zweites Podestergebnis bei der Tour de Ski erreichte. Cologna wurde zwei Sekunden hinter Teichmann Vierter, verlor zwar durch die Zwischensprints zwanzig Bonussekunden auf den Deutschen, behielt aber die Führung in der Gesamtwertung. Auch in der Sprintwertung änderte sich an der Spitze nichts, diese verteidigte Tor Arne Hetland.
Wie in den Vorjahren fiel die Entscheidung der Tour de Ski auf dem Final Climb im Val di Fiemme. Das Handicap-Damenrennen über neun Kilometer begann auf dem anfänglich flacheren Terrain damit, dass Virpi Kuitunen ihren Vorsprung auf die Verfolgerin Aino-Kaisa Saarinen bis Kilometer sechs auf über 50 Sekunden ausbaute. Die drittplatzierte Petra Majdič verlor anfangs auch Zeit auf Kuitunen, tat sich dann jedoch mit Saarinen zusammen. Gemeinsam holten die beiden Verfolgerinnen mehr als eine halbe Minute auf die Finnin an der Spitze auf, ehe wiederum Majdič Saarinens Tempo nicht halten konnte und von ihr abfiel. Dennoch gelang Kuitunens Landsfrau das Ein- und Überholen der Führenden, bei der letzten Zwischenzeit 900 Meter vor dem Ziel lag Saarinen 3,4 Sekunden vor der Vorjahreszweiten. Anders als im letzten Jahr, wo Kuitunen ihre Konkurrentin Charlotte Kalla gewinnen lassen musste, schaffte sie dieses Mal noch die Rückkehr an die Spitze. Nun gelang es Saarinen nicht mehr, Kuitunen zu halten, sodass diese zum zweiten Mal bei der Tour de Ski triumphierte. Über eine halbe Minute nach der Siegerin kam Petra Majdič ins Ziel, danach Justyna Kowalczyk aus Polen, die Italienerin Marianna Longa sowie die Norwegerin Therese Johaug, die sich mit der besten Laufzeit des Tages von Rang 11 auf den sechsten Platz vorschub. Einen schlechten Tag erwischte dagegen Johaugs Teamgefährtin Marit Bjørgen, welche sechs Plätze verlor und vom vierten auf den zehnten Rang zurückfiel. Insgesamt hatte sie auf den neun Kilometern fast vier Minuten auf Johaug verloren. Ebenfalls ein starkes Rennen absolvierte Kristin Størmer Steira, die sich dadurch wie Johaug noch in den Top-10 klassierte.
Bei den Männern ging der Führende Dario Cologna das Rennen wie Kuitunen schnell an, der Abstand auf Axel Teichmann wuchs bis zu Beginn des Anstiegs von 35 Sekunden auf eine Minute an. Dahinter hatte sich eine dreiköpfige Gruppe zusammengefunden, die aus dem Russen Wassili Rotschew sowie den beiden Norwegern Eldar Rønning und Petter Northug bestand. Diese Gruppe wiederum hatte mehr als eine Minute Vorsprung auf das eine große Verfolgergruppe von zehn Athleten. Schon während der ersten 500 Meter des Anstiegs fiel Rønning von Rotschew und Northug ab und wurde von der dahinterliegenden Gruppe überholt. Aus dieser setzte sich Giorgio Di Centa ab, der bis dahin ein starkes Rennen gelaufen war und auch Cologna einige Sekunden abgenommen hatte. Teichmann hatte 1,5 Kilometer vor dem Ziel auf der Alpe Cermis anderthalb Minuten Rückstand auf Cologna und noch zehn Sekunden Vorsprung auf Rotschew und Northug. Während der führende Schweizer auf dem letzten Kilometer einen beruhigenden Vorsprung hatte, hielt Teichmann sein knappes Zeitpolster von zehn Sekunden auf die beiden Verfolger. Mit nur zehn bis zwanzig Sekunden hinter diesen folgten die beiden Italiener di Centa und Pietro Piller Cottrer sowie der Franzose Jean-Marc Gaillard. Kurz nach dem letzten Zeitmesspunkt hielt Rotschew Northug nicht mehr, obwohl letzterer eher als Sprinter erfolgreich startete. Während Rotschew schnell von Giorgio Di Centa überholt wurde, kam Northug an Axel Teichmann heran und überspurtete diesen auf der Zielgeraden. Der Norweger hatte schließlich 59 Sekunden Rückstand auf Dario Cologna, der souverän die Tour de Ski gewann ohne dabei bei einer einzigen Etappe Schnellster gewesen zu sein. Di Centa kam als Vierter ins Ziel, dahinter Rotschew, Gaillard sowie Piller Cottrer. Vorjahressieger Lukáš Bauer aus Tschechien lief zwar noch von Rang 19 auf den elften Platz vor, verpasste aber dennoch mit mehr als zwei Minuten Rückstand auf Cologna die Top-10. Der Schnellste des Tages war jedoch überraschend der Kanadier Ivan Babikov, der dadurch allerdings im Gesamtklassement kaum profitierte und sich mit gut sieben Minuten Rückstand auf dem 36. Platz einreihte. Nur 1,5 Sekunden langsamer als Babikov war Tom Reichelt, welcher die Tour de Ski als 29. beendete.
Hinweis: In dieser Tabelle wird nur die Zeit genannt, die der jeweilige Athlet auf der Verfolgungsstrecke erreichte, nicht die Zeiten des Zieleinlaufs. Der Zieleinlauf ist entsprechend dem Endresultat der Tour de Ski.
In dieser Liste werden die Athleten verzeichnet, die nach der Tour de Ski 2008/2009 auf den ersten zehn Rängen im Gesamtklassement lagen. Dazu werden die Punkte vor und nach der Tour de Ski sowie die Platzierungen bei den einzelnen Etappen genannt. Bei letzteren wurden Punkte nach dem folgenden Muster vergeben.
In der Gesamtwertung der Tour de Ski erhielten die besten 30 Sportler zudem noch die vierfache Anzahl der normalen Weltcup-Punkte des FIS-Punktesystems, der Sieger bekam also deren 400, der Zweite 320, usw…
8-14: Die Platzierungen und Punkte bei den Tour-de-Ski-Wettbewerben mit Links auf die einzelnen Wettkämpfe
Die Liste ist sortierbar: Durch Anklicken eines Spaltenkopfes wird die Liste nach dieser Spalte sortiert, zweimaliges Anklicken kehrt die Sortierung um. Durch das Anklicken mehrerer Spalten hintereinander lässt sich jede gewünschte Kombination erzielen.
In 59 Ländern, darunter auch in Deutschland, übernahm der Sportsender Eurosport die Liveübertragung der Tour de Ski. Dabei kommentierten Kommentator Stéphane Franke und Expertin Viola Bauer für die deutschsprachigen Zuschauer. Zusätzlich zu Eurosport sendeten in Deutschland auch die öffentlich-rechtlichen Rundfunkanstalten ARD und ZDF abwechselnd teils Liveberichte, teils Aufzeichnungen von der Tour de Ski. Beim ZDF moderierte Yorck Polus (ohne Experten), der Reporter war Peter Leissl, bei der ARD berichtete Jens-Jörg Rieck als Reporter von den Etappen. Aufgrund der guten Leistungen von Athleten aus der Schweiz wie Dario Cologna vor der Tour de Ski entschloss sich auch der Schweizer Sender SF zwei für eine Berichterstattung zur Tour de Ski. Dabei sollten einige Rennen live, andere in Aufzeichnungen übertragen werden. Insgesamt wurde das Finale am Schlussanstieg zur Alpe Cermis von zwölf Fernsehanstalten live gezeigt.
Das Ergebnis der Frauen überraschte letztlich wenig, da Virpi Kuitunen bereits bei den ersten beiden Austragungen Erste und Zweite geworden war. Die Finnin selbst meinte, dass dieser Erfolg für sie schöner war als die vorherigen, da sie mehr um den Sieg habe kämpfen müssen. Ihre Landsfrau Aino-Kaisa Saarinen zeigte sich insgesamt zufrieden mit dem zweiten Rang hinter Kuitunen, wenngleich sie direkt nach der Tour „etwas enttäuscht“ war.Bei den Männern kam Dario Colognas Sieg zwar unerwartet, war aber letztlich ungefährdet. Die nationalen Medien nahmen den Erfolg eines Schweizers in der eher als Randsportart betrachteten Disziplin Skilanglauf als größten Erfolg seit mehr als 20 Jahren auf; 1988 hatte Andreas Grünenfelder die olympische Bronzemedaille über 50 Kilometer gewonnen. Auch der Toursieger selbst äußerte sich zufrieden, als größeres Ziel gab er jedoch die Olympischen Winterspiele 2010 in Vancouver aus. Petter Northug, der wie Cologna erst 22 Jahre alt war, meinte, Cologna und er werden „in Zukunft oft gegeneinander kämpfen“. In den Medien war ebenfalls von einem beginnenden ewigen Duell die Rede. Der Sieger der Sprintwertung, Tor Arne Hetland, zeigte sich wie Axel Teichmann erfreut über den Ausgang der Tour de Ski. Das Fazit für die deutsche Männermannschaft zog der deutsche Bundestrainer Jochen Behle, der sich zufrieden über die Leistungen der männlichen Athleten, besonders über die von Axel Teichmann, zeigte.Insgesamt bescheinigten Medien und Trainer der Tour de Ski einen positiven Verlauf, Jochen Behle kritisierte jedoch die Bevorteilung von Läufern, die im klassischen Stil und im Sprint Stärken besaßen. Der Norweger Vegard Ulvang, einer der Entwickler der Tour de Ski, sah hingegen im zweiten Rang des Freistil-Läufers Petter Northug bei den Männern ein Indiz dafür, dass die Mischung zwischen den Rennen der unterschiedlichen Stile stimmte. Am Schlusstag der Tour de Ski wurde zudem ihre Zukunft verkündet; da sie sich etabliert hatte und auch FIS-Präsident Gian-Franco Kasper von dem Etappenrennen überzeugt war, wird es bis mindestens 2013 fortgesetzt. In dieser Zeitdauer wird zudem immer Oberhof den Tourstart und Val di Fiemme samt Final Climb das Tourende bilden. Daneben bewarben sich Städte aus Österreich, Liechtenstein, der Schweiz, Deutschland sowie Tschechien um weitere Etappen.
Wie erwartet veränderte sich durch die Vergabe der maximal erreichbaren 750 Weltcuppunkte (davon alleine 400 für den Sieg) die Gesamtwertung des Weltcups deutlich. Der bis dahin Führende bei den Männern, Ola Vigen Hattestad, fiel durch seine Nichtteilnahme auf den 13. Rang zurück, dagegen verbesserten sich Athleten wie Jean-Marc Gaillard oder Wassili Rotschew deutlich durch ihre gute Tour-Platzierung. Nicht so deutlich veränderte sich das Klassement der Damen; dort schaffte Virpi Kuitunen trotz ihres Sieges nicht die Übernahme der Spitze, an der weiterhin Aino-Kaisa Saarinen blieb. Beste Athletin ohne Tourteilnahme war zunächst Charlotte Kalla als 19.
Insgesamt bewirkten die 400 Punkte im Frauenweltcup an der Spitze wenig, hier siegte Justyna Kowalczyk (Tourvierte) vor Petra Majdič (Tourdritte). Die beiden Finninnen Saarinen und Kuitunen fielen auf die Ränge drei und vier zurück. Anders verlief es bei den Herren, wo Dario Cologna lange die Führung behielt, ehe Petter Northug beim vorletzten Weltcup wieder an die Spitze ging. Cologna sicherte sich jedoch beim Weltcup-Finale den Sieg im Gesamtweltcup, sodass bei den Männern zum dritten Mal in Folge nach Tobias Angerer und Lukáš Bauer der Tour-de-Ski-Gewinner auch zum Gesamtweltcupsieger wurde. Ola Vigen Hattestad konnte zwar noch viele Weltcuppunkte sammeln und den Sprintweltcup gewinnen, im Gesamtweltcup hatte er als guter Dritter jedoch großen Rückstand auf Cologna und Northug.

Die Tour Down Under (offiziell: Santos Tour Down Under) ist ein Etappenrennen für Radrennfahrer im australischen Bundesstaat South Australia rund um die Hauptstadt Adelaide. Es ist das größte und wichtigste Radrennen Australiens und Ozeaniens. Das Rennen wurde 1999 zum ersten Mal ausgetragen und findet jährlich Mitte Januar statt. Mit Beginn der Saison 2008 ist die Tour Down Under ein Rennen der UCI ProTour und seit 2011 der Nachfolgeserie UCI WorldTour.
Zwei Tage vor der Tour Down Under findet ein ungefähr 50 Kilometer langes Kriterium in Adelaide statt, das sogenannte "Cancer Council Classic", das ab dem Jahr 2012 "Down Under Classic" hieß und seit 2014 People's Choice Classic und in dessen Vorfeld die Teilnehmer des Rennens vorgestellt werden. Die Ergebnisse dieses Classic zählen aber weder zur Gesamtwertung noch gibt es Punkte für die UCI WorldTour.
Das Rennen selbst startet jedes Jahr am dritten Dienstag im Januar und umfasst sechs Tagesabschnitte, von denen in der Regel keiner länger als 170 Kilometer ist. Es beginnt mit vier überwiegend flachen Abschnitten. Da es in Südaustralien keine so hohen Berge, wie beispielsweise in den Alpen gibt, ist der schwierigste Anstieg der Willunga Hill (3 Kilometer lang; 7,6 % steil), der zumeist auf der vorletzten Etappe zweimal befahren werden muss und das Rennen entscheidet. Am letzten Tag, einem Sonntag, endet die Tour Down Under traditionell mit einem ungefähr 80 Kilometer langen Rundkurs in Südaustraliens Hauptstadt Adelaide. Auf eine bei anderen größeren Rundfahrten durchaus übliche Zeitfahr-Etappe wird seit jeher verzichtet.
Viele europäische Profi-Mannschaften nutzen die Tour Down Under als Vorbereitung für die im März mit Paris–Nizza und Tirreno–Adriatico beginnende Saison, weil in Europa noch Winter ist, während die Fahrer der australischen Teams im Hochsommer auf der Südhalbkugel mitten in ihrer Saison stehen. In den letzten Jahren nahm die Attraktivität der Rundfahrt immer weiter zu, so startete beispielsweise Lance Armstrong, sein Comeback 2009 in Australien. An gleicher Stelle absolvierte er zwei Jahre darauf auch das letzte internationale Rennen seiner Laufbahn. 2010 nahmen neben den Topsprintern um André Greipel auch der amtierende Weltmeister Cadel Evans und der zwischenzeitlich gesperrte Alejandro Valverde teil. Seit das Rennen zur UCI ProTour (seit 2011: UCI WorldTour) gehört, sind automatisch die UCI ProTeams, also die größten professionellen Mannschaften, zum Start verpflichtet. Außerdem vergibt der Veranstalter in jedem Jahr einen Startplatz an ein australisches Nationalteam, welches von der südaustralischen Universität unterstützt wird. Jedes teilnehmende Team besteht aus sieben Fahrern.
Die Tour Down Under wurde von der South Australian Tourism Commission (der Tourismuskommission) ins Leben gerufen, um den Bundesstaat im Ausland zu repräsentieren und ist zudem das einzige bedeutende Profiradrennen Australiens. Die Tour Down Under steht jährlich im Mittelpunkt des "Festival of Cycling", einer Veranstaltungsreihe, bei der sich in South Australia alles um das Fahrrad dreht.
Renndirektor ist seit Gründung des Rennens der ehemalige Berufsradfahrer Michael Turtur, auf dessen Idee das Rennen beruht. Immer noch ist die südaustralische Tourismuskommission Inhaber der Rundfahrt. Finanziell unterstützt wird die Tour Down Under aber auch von der südaustralischen Regierung.
Die erste Tour Down Under wurde im Jahr 1999 ausgetragen. Rasch entwickelte sich das Rennen zum größten Radsportwettbewerb Australiens und Ozeaniens. Heute gilt die Tour Down Under sogar als das größte Radrennen der südlichen Hemisphäre.
Mit dem Ziel, die Provinz Südaustralien nicht zuletzt für Touristen durch die Fernsehübertragungen in andere Länder bekannt zu machen, begann die erste Tour Down Under im Jahr 1999 mit einem ungefähr 40 Kilometer langen Rundkurs in Adelaide. Der Däne Nicolai Bo Larsen war im Massensprint am 19. Januar der erste Etappensieger, der Australier Stuart O’Grady wurde der erste Gesamtsieger. Seit dem Entstehungsjahr wird das Rennen in sechs Etappen ausgetragen, erst seit 2000 startet die Tour allerdings an einem Dienstag, die erste Austragung war noch an einem Sonntag begonnen worden.
2001 und 2002 bildete in Glenelg ein ähnlich langes Rundstreckenrennen wie in den ersten Jahren in der Provinzhauptstadt den Auftakt der Tour, bis die Tour von 2003 bis 2005 wieder mit einem ungefähr 50 Kilometer langen Rundkurs in Adelaide begann. Nachdem die Schlussetappe in Adelaide 1999 noch 120 Kilometer lang gewesen war, wurde sie ein Jahr darauf auf 90 Kilometer verkürzt. Nachdem der Abschnitt einige Jahre lang sogar nur 80 Kilometer umfasste, stockte man die Distanz 2006 wieder um zehn Kilometer auf. Neben Adelaide sind die Orte Norwood, Strathalbyn, Victor Harbor oder Tanunda häufige Etappenorte. Die "Königsetappe" über den Willunga Hill im Ort Willunga findet seit 2003 am vorletzten Tag statt.
Seit 2006 trägt der Gesamtführende ein oranges Trikot, zuvor war das Leadertrikot Gelb. Außerdem wird seit diesem Jahr darauf verzichtet, das Ergebnis der Auftaktetappe in Adelaide zur Gesamtwertung zu zählen. Stattdessen wird diese seither als "Cancer Council Classic" zwei Tage vor dem eigentlichen Beginn der Rundfahrt gesondert ausgetragen. 
Von 1999 bis 2004 gehörte die Tour Down Under zur UCI-Kategorie 2.3. Ab 2005 zählte das Rennen zur UCI Oceania Tour und war in die höchste Kategorie 2.HC eingestuft. Seit 2008 ist das Rennen in die UCI ProTour – heute UCI WorldTour – eingestuft und damit eines der größten internationalen Rennen.
Die Tour Down Under wird aufgrund ihrer nicht sehr schwierigen Topographie oft von Sprintern gewonnen, die sich durch die Zeitbonifikationen im Ziel einen Vorsprung erarbeiten konnten, aber auch Fahrer, die einen Ausreißversuch erfolgreich abschließen konnten, haben das Rennen schon gewonnen, zum Beispiel der Sieger von 2011, Cameron Meyer. Rekordsieger mit vier Erfolgen ist der Einheimische Simon Gerrans. 2001, 2002 und 2006 konnte die gastgebende Nation alle drei Podestplätze belegen. Die Australier sind mit insgesamt sieben Gesamterfolgen auch die erfolgreichste Nation.
Wie bei nahezu allen übrigen internationalen Radrennen gibt es auch bei der Tour Down Under verschiedene Sonderwertungen, deren Führende spezielle Wertungstrikots tragen, die sich von den übrigen Teamtrikots farblich abheben. Die Wertungstrikots werden den Führenden nach jeder Etappe auf einem Podium verliehen, auch der Etappensieger wird geehrt. Jedes Wertungstrikot wird dabei von einem Sponsor präsentiert. Die Fahrer sind verpflichtet, die entsprechenden Wertungstrikots auf der jeweils folgenden Etappe zu tragen. Wenn ein Fahrer im Besitz mehrerer Wertungstrikots ist, trägt er das wichtigere. Dabei gilt folgende Reihenfolge: Oranges, Weißes, Blaues, Schwarzes Trikot. In diesem Fall wird das nächstniedrigere Trikot von dem Zweitplatzierten in der jeweiligen Sonderwertung präsentiert. Als Träger gilt dennoch der Führende, auch wenn er es – außer bei der Siegerehrung – gar nicht tatsächlich am Leibe trägt.
Mit zwölf Etappensiegen ist Robbie McEwen der erfolgreichste Fahrer in dieser Hinsicht. Ein Österreicher hat noch keine Etappe gewinnen können. Auch einen Schweizer Etappensieger gab es bislang noch nicht, jedoch konnte Martin Elmiger 2007 die Gesamtwertung für sich entscheiden. Neben Rekordsieger André Greipel gab es noch drei weitere deutsche Etappensieger – Erik Zabel, der in den ersten beiden Jahren insgesamt drei Etappen gewann, Kai Hundertmarck und Steffen Wesemann.
Der Fahrer mit der geringsten Gesamtzeit trägt das Orange Trikot, offiziell Santos Tour Down Under Ochre Leader’s Jersey. Für die wichtigste Wertung wird die Gesamtzeit eines jeden Fahrers von allen Etappen addiert. Eventuelle Zeitgutschriften werden von der Gesamtzeit des betreffenden Fahrers abgezogen: der Sieger einer Etappe erhält zehn Sekunden Bonifikation, der Etappenzweite sechs Sekunden und der -dritte vier Sekunden. Auch bei den auf jedem Abschnitt ausgefahrenen Zwischensprints gibt es Zeitgutschriften: drei Sekunden für den Ersten, zwei für den Zweiten und noch eine Sekunde für den Dritten. Wer nach der letzten Etappe die geringste Gesamtzeit aufweist, ist der Sieger der Rundfahrt. Da die Zeitabstände bei der Tour Down Under meist sehr gering sind, spielen die Zeitgutschriften eine wichtige Rolle für die Gesamtplatzierung eines Fahrers. Liegen zwei oder mehr Fahrer in der Gesamtwertung in der gleichen Zeit, so entscheiden die bessern Etappenplatzierungen über die genaue Platzierung.
Die einzigen Fahrer in der Geschichte des Rennens, denen es gelang, das Orange Trikot von der ersten bis zur letzten Etappe zu verteidigen, sind André Greipel (2010) und Simon Gerrans (2006).
Ebenfalls seit der ersten Austragung der Tour Down Under wird eine Bergwertung ausgefahren. Das zugehörige Führungstrikot ist weiß. Im Gegensatz zu vielen anderen Radrennen sind die Anstiege der Rundfahrt, an denen es Bergpunkte gibt, nicht in verschiedene Kategorien eingeteilt, stattdessen wird auf jedem Gipfel dieselbe Punktzahl für die ersten Fahrer vergeben, die außerdem von Jahr zu Jahr immer wieder verändert wird.
Mit drei Erfolgen in der Bergwertung ist der Australier Cadel Evans Rekordsieger dieser Sonderwertung.
Seit der ersten Austragung des Rennens gibt es auch eine Punktewertung, die offiziell Sprintwertung heißt und deren Führender ein Blaues Trikot erhält. Punkte für die Punktwertung gibt es aber nicht nur an den Zwischensprints, sondern auch im Ziel einer jeden Etappe für die ersten Fahrer.
Seit 1999 wird bei der Tour Down Under ein Schwarzes Trikot für den Führenden der Nachwuchswertung vergeben. Diese Wertung ermittelt die besten Fahrer, die im Jahr der jeweiligen Rundfahrt höchstens 25 Jahre alt sind. Bis 2007 wurde das Trikot allerdings nur für Fahrer bis zu einem Alter von 23 Jahren vergeben.
Der Spanier José Joaquin Rojas Gil hat die Nachwuchswertung bereits zweimal für sich entschieden und ist damit Rekordgewinner. 2005 (Luis León Sánchez) und 2011 (Cameron Meyer) konnte ein Fahrer sowohl die Nachwuchswertung als auch das Orange Trikot erringen.
Nach jeder Etappe der Tour Down Under ermittelt eine Jury den kämpferischsten Fahrer des Tages. Der Betreffende erhält bei der Siegerehrung des Tages ein Rotes Trikot, das er allerdings auf der nächsten Etappe nicht tragen darf, da laut dem Reglement des Radsportweltverbandes UCI während der Etappen von internationalen Rennen nur vier Wertungstrikots präsentiert werden dürfen. Der kämpferischste Fahrer des Vortages wird allerdings durch eine rote Rückennummer gekennzeichnet. Die Jury ermittelt nach dem Ende der Rundfahrt auch einen Gesamtsieger in dieser Sonderwertung.
Für die seit 1999 vergebene Mannschaftswertung werden bei jeder Etappe die Zeiten der schnellsten vier Fahrer einer Mannschaft addiert. Ähnlich wie beim Preis für den kämpferischsten Fahrer wird die führende Mannschaft nur bei den Siegerehrungen in den hellblauen Führungstrikots präsentiert.
Von 2006 bis 2010 erhielt der Sieger des "Cancer Council Classic" ebenfalls ein Blaues Trikot, das er auf der folgenden ersten Etappe präsentierte.
Im Jahr 2003 wurde statt des Preises für den kämpferischsten Fahrer eine Gesamtwertung nach Zeit für Fahrer aus Südaustralien ausgeschrieben.
Die Tour Down Under wird nach dem Reglement des Weltradsportverbands UCI, insbesondere den Regeln für Etappenrennen, ausgetragen.
Im Ziel werden die Abstände zwischen den einzelnen Fahrern beziehungsweise Fahrergruppen gemessen. Alle Fahrer einer geschlossenen Gruppe werden mit der gleichen Zeit bewertet. Bei einem Sturz auf den letzten drei Kilometern werden die darin verwickelten Fahrer mit der gleichen Zeit gewertet wie die Gruppe, der sie zum Zeitpunkt des Sturzes angehörten. Bei allen Etappen gilt ein Zeitlimit ("Karenzzeit"), innerhalb dessen jeder Fahrer das Ziel erreichen muss. Das Zeitlimit wird nach Schwierigkeitsgrad und Durchschnittsgeschwindigkeit der jeweiligen Etappen berechnet. Das Limit schwankt dementsprechend zwischen 104 und 110 Prozent der Zeit des Etappensiegers. Allerdings hat die Rennleitung die Möglichkeit, das Zeitlimit flexibel zu verlängern, wenn sonst mehr als zwanzig Prozent der Fahrer nach Kontrollschluss einträfen. Aufgrund der überwiegend flachen Etappen der Rundfahrt stellt das Zeitlimit allerdings meist kein Problem für die Fahrer dar.
Der Sieger einer Etappe erhält zehn Sekunden Zeitbonifikation, der Etappenzweite sechs Sekunden und der -dritte vier Sekunden. Auch bei den auf jedem Abschnitt ausgefahrenen Zwischensprints gibt es Zeitgutschriften: drei Sekunden für den Ersten, zwei für den Zweiten und noch eine Sekunde für den Dritten. Die Gutschriften werden von der Gesamtzeit des betreffenden Fahrers abgezogen.
Auf jeder Etappe gibt es ungefähr zur Hälfte der Distanz eine gekennzeichnete Verpflegungszone, in der Mitarbeiter der Teams ihren Fahrern Verpflegungsbeutel reichen dürfen. Das Entgegennehmen von Verpflegung, die Zuschauer den Profis anbieten, erfolgt wie bei allen anderen Radrennen auf eigene Gefahr. Bis zwanzig Kilometer vor Ende der Etappe dürfen zudem die sportlichen Leiter ihren Fahrern Getränke und Nahrung aus dem Teamfahrzeug reichen. Jeder Mannschaft der Tour stehen dabei zwei Fahrzeuge auf jedem Tagesabschnitt zur Verfügung.
Eine Pannenhilfe für die Fahrer mit Defekt wird entweder durch das Team oder den neutralen Materialwagen durchgeführt. Pannenhilfe ist immer nur hinter einer Fahrergruppe und hinter dem Hauptfeld am rechten Straßenrand erlaubt. Benötigt ein Fahrer einen Arzt, darf es nur ein Arzt des offiziellen ärztlichen Dienstes sein. Der Fahrer wird dann am Ende des Pelotons behandelt. Bei Stürzen oder Pannen auf den letzten drei Kilometern werden die Fahrer mit der gleichen Zeit wie die Gruppe, der sie angehörten, gewertet.
Die Regeln werden von den Rennkommissaren überwacht, die auf Motorrädern das Rennen begleiten. Sehen sie Rennverstöße, können sie diese nach den Regeln des Weltradsportverbands UCI ahnden. Verstöße gegen das Reglement werden mit Geldstrafen, Zeitstrafen oder der Disqualifikation geahndet. Regelwidrigkeiten bei Sprints (verlassen der Fahrlinie, anschieben eines Mannschaftskameraden usw.) werden mit Rückstufungen im Tagesklassement (ohne Zeitstrafe) bestraft.
Das Reglement untersagt, Autos oder Motorräder als Windschatten zu benutzen. Eine Ausnahme stellt dar, wenn der Fahrer während der Fahrt vom offiziellen Tourarzt medizinisch behandelt wird oder sein Rad von einem Mechaniker reparieren lässt. Wenn ein Fahrer eine Panne hatte, benutzt er oft die Autos der Sportlichen Leiter, um in deren Windschatten wieder Anschluss an das Peloton zu bekommen. Solche Verstöße werden wie bei fast allen anderen internationalen Wettbewerben fast nie geahndet.
Fahrer, die das Rennen während einer Etappe aufgeben, müssen ihre am Rahmen sowie am Trikot befestigte Startnummer am Besenwagen abgeben.
Jährlich verfolgen viele Zuschauer die Tour Down Under am Straßenrand, wobei sich die Zuschauerzahl über die Jahre immer wieder erhöht hat. 2010 verfolgten insgesamt 760.660 Zuschauer die Rundfahrt, davon 36.100 Menschen aus anderen Ländern und anderen Teilen Australiens.Außerdem verfolgen die Fans der Rundfahrt jedes Jahr einen besonderen Brauch, indem sie vor Rennbeginn einen unbekannten Fahrer, meist einen Profi, der Helferaufgaben im Team wahrnimmt, aus der Startliste auswählen, um ihn dann während des Rennens wie einen großen Star zu feiern und ihm auch nach Rennende eine Aufwartung vor dem Hotel zu machen.
Geldeinnahmen erhält die organisierende Tourismusbehörde nicht nur durch Zuschüsse von der Provinzregierung, sondern vor allem durch Sponsoren. Das Energieunternehmen Santos ist Namenssponsor der Rundfahrt und auch der Titelsponsor des orangen Trikots und der Rahmenveranstaltung Festival of Cycling. Andere Partner sind beispielsweise der Wohnwagenhersteller Jayco, der jährlich Namenssponsor eines Abschnitts ist und außerdem das blaue Sprinttrikot präsentiert. Der Autohersteller Škoda zeigt seinen Namen nicht nur auf dem Bogen, der die Ein-Kilometer-Marke einer jeden Etappe darstellt, sondern auch auf dem weißen Trikot des Führenden in der Bergwertung. Die Firma Europcar sponsert das Trikot für den kämpferischsten Fahrer, die Initiative "Cycle Instead", die die Südaustralier dazu bewegen will, zur Fortbewegung öfter das Fahrrad zu benutzen, präsentiert das Jersey für den besten Nachwuchsfahrer. Neue Sponsoren für 2012 sind die Sicherheitsfirma Colemans, ebenso Namensgeber für eine Etappe wie die private Krankenversicherung Bupa. Weitere Sponsoren können durch Bandenwerbung oder Werbung im offiziellen Tour-Dorf in Adelaide auf sich aufmerksam machen.
Ähnlich wie bei der Tour de France fährt auf jeder Etappe eine Werbekarawane ungefähr eine halbe Stunde vor dem Fahrerfeld die Strecke ab und verteilt Geschenke. Dabei zeigt sich auch das Känguru Oppy, das offizielle Maskottchen der Rundfahrt.
Die Tour Down Under ist eingebettet im jährlich stattfindenden Festival of Cycling in Adelaide, bei dem sich eine Woche lang alles um das Fahrrad und den Radsport dreht. Im Rahmen dieses Festivals werden ein Abend mit Stars des Radsports sowie weitere Angebote wie ein Mitflug im Helikopter während der Etappen oder ein Wettbewerb, bei dem der am schönsten geschmückte Etappenort gesucht wird, veranstaltet.
Seit 2003 wird während des Festival of Cycling auch ein Rennen für Jedermann-Fahrer, die sogenannten Breakaway Series, angeboten. Von 2004 bis 2007 hieß das Rennen "Be Active Tour", von 2007 bis 2011 "Mutual Community Challenge". Dabei legen die Teilnehmer eine Etappe der Tour Down Under dieses Jahres zurück und lernen so die gleiche Strecke kennen, die auch die Profis in ihrem Rennen fahren. Zudem wird ein Rennen für Kinder angeboten, das auf dem Rundkurs der letzten Etappe der Tour Down Under in Adelaide veranstaltet wird. Die Teilnehmerzahl und damit die Beliebtheit dieser Wettbewerbe stieg von Jahr zu Jahr, 2010 waren schon 8000 Athleten am Start.
Ungefähr zeitgleich zum Rennen der Männer wurde bei der Tour Down Under auch eine Rennserie aus drei Kriterien für Frauen veranstaltet. Nach der Abschaffung dieser Veranstaltung wurde bis 2010 nur noch ein einziges Kriteriumsrennen ausgetragen, bevor 2011 wieder zwei Rennen in Adelaide, der sogenannte Rendition Homes-Santos Women’s Cup ausgerichtet wurde. Das erste Kriterium fand am selben Tag wie das Cancer Council Classic zur Eröffnung des Männerrennens statt, das zweite Kriterium einen Tag darauf.

Als Trachealkollaps bezeichnet man bei Haushunden ein Zusammenfallen der Luftröhre (lat. Trachea), durch das Erweichen der stützenden Knorpelspangen. Daraus resultiert eine Abnahme vor allem des Vertikaldurchmessers und somit eine Verengung der Luftröhre, die zu schweren Atemproblemen führen kann. Beim Menschen kann ein Trachealkollaps als Folge einer Tracheomalazie auftreten. Der Trachealkollaps der Hunde kann zumeist lange Zeit konservativ mit Medikamenten beherrscht, aber nicht geheilt werden. Eine chirurgische Therapie ist möglich, allerdings aufwändig und nicht in jedem Fall erfolgreich.
Ein Trachealkollaps kommt vor allem bei Haushunden, insbesondere bei zwergwüchsigen Hunderassen (Yorkshire Terrier, Chihuahua, Malteser, Zwergspitz und Zwergschnauzer), vor. Vor allem Tiere mittleren Alters sind betroffen. Gelegentlich tritt ein Trachealkollaps auch bei Hauspferden und -rindern auf, sehr selten auch bei Hauskatzen.
Die Ursache der Erkrankung ist bislang nicht geklärt. Vermutlich ist der Trachealkollaps genetisch bedingt (Erbkrankheit). Aber auch die Genese durch das Zusammentreffen verschiedener Faktoren (multifaktoriell) ist nicht ausgeschlossen. Die Erkrankung kann durch eine Reihe anderer Faktoren, darunter Infektionen der Atemwege, Allergien, Verengungen der Luftröhre, toxische Stäube und Dämpfe sowie Herzinsuffizienz, begünstigt werden.
Die Knorpelerweichung kommt durch Veränderungen der Knorpelgrundsubstanz, vor allem durch einen verminderten Gehalt an Glykosaminoglykanen (insbesondere Chondroitinsulfat) und Glykoproteinen zustande, wodurch die Wasserbindungskapazität des Knorpels und damit dessen Elastizität sinkt. Die Zellzahl im Knorpel ist erniedrigt und die Grundsubstanz ist porös. Die Abnahme des Luftröhreninnendurchmessers geht mit einem erhöhten Strömungswiderstand der Luft einher und führt zu Turbulenzen.
Sekundär kommt es durch den Trachealkollaps zu einer Degeneration des Flimmerepithels, zu einer Hypertrophie der Drüsen in der Schleimhaut der Luftröhre, gelegentlich auch zur Bildung von Polypen.
Das klinische Erscheinungsbild ist sehr variabel, ein Trachealkollaps kann lange symptomlos bleiben und der Grad der Verengung muss nicht mit dem Ausmaß klinischer Erscheinungen korrelieren. Die Symptome entwickeln sich allmählich und die Erkrankung schreitet langsam voran.
Eine typische Früherscheinung ist ein anfallsartiger Husten, der vor allem bei Aufregung oder stärkerer körperlicher Belastung auftritt. Auch ein Halsband kann bei starkem Zug an der Leine Druck auf die Luftröhre ausüben und somit die Hustenanfälle auslösen. Der Husten tritt zunächst als „trockener“ Husten in Erscheinung, mit den eintretenden Sekundärveränderungen (vermehrte Schleimsekretion durch die Drüsenhyperplasie) kann er in einen „feuchten“ Husten übergehen. Darüber hinaus kommt es zu einer verminderten Leistungsfähigkeit des Tieres.
Klinisch treten infolge ein verstärktes „tracheales Atemgeräusch“ (Stridor trachealis, zumeist in Form von Brummtönen), eine erhöhte Atemfrequenz (Tachypnoe) und zunehmende Atembeschwerden (Dyspnoe) auf. Diese treten bei Lokalisation im Halsabschnitt der Luftröhre vor allem bei der Einatmung (Inspiration), bei Manifestation im Brustteil eher bei der Ausatmung (Exspiration) auf. Die Ursache hierfür ist darin zu sehen, dass bei einer Instabilität im Halsbereich der Kollaps durch den beim Einatmen entstehenden Unterdruck verursacht wird, während eine Instabilität im Brustbereich meist ein Zusammenfallen der Luftröhre durch den beim Ausatmen auftretenden Überdruck in der Brusthöhle (bezogen auf den Druck innerhalb der Luftröhre) zur Ursache hat. Mit zunehmender Dyspnoe kommt es zu einem Sauerstoffmangel, der sich in einer Blauverfärbung (Zyanose) der Schleimhäute äußert.
Bei Lokalisation im Halsteil der Luftröhre lässt sich die Erweichung der Knorpelspangen bereits durch Abtasten (Palpation) feststellen, wobei meist auch Husten ausgelöst wird. Weitere Hinweise kann die Röntgendarstellung der Luftröhre liefern, da der Kollaps aber ein dynamischer Prozess ist, kann bei einer Momentaufnahme wie einem Röntgenbild auch ein Normalbefund auftreten. Eine eindeutige Diagnose ist nur durch die Endoskopie oder einem CT zu erbringen.
Abzugrenzen sind vor allem entzündliche bedingte Erkrankungen der Luftröhre (Tracheitis) durch Infektionen oder Allergien. Auch Fremdkörper in und Tumoren der Luftröhre können Verengungen und tracheale Atemgeräusche hervorrufen. Schließlich kann eine Verengung der Luftröhre auch durch Kompression von außen durch Vergrößerung benachbarter Organe zustande kommen. Hier kommen insbesondere der Luftröhre benachbarte Organe wie die tiefen Hals- und die vorderen und mittleren mediastinalen Lymphknoten (Lnn. cervicales profundi und mediastinales craniales et medii), die Schilddrüse und die Epithelkörperchen in Frage. Auch Abszesse und Blutergüsse in der Nachbarschaft der Luftröhre können zu einer Kompression von außen führen.
Relativ häufig tritt eine Kompression der Endaufzweigung der Luftröhre infolge einer Vergrößerung des linken Vorhofes des Herzens auf, dessen Ursache wiederum eine Insuffizienz der Mitralklappe des Herzens ist (Klappenendokardiose). Hierbei wird die Symptomatik neben der Verengung des Lumens maßgeblich durch die dauernde mechanische Reizung der Luftröhre infolge der Herzbewegung verstärkt.
Bei einigen Hunderassen (Englische Bulldogge, Boston Terrier) muss auch an eine erblich bedingte Wachstumsstörung der Luftröhre (Trachea-Hypoplasie) in Betracht gezogen werden.
Eine kausale Therapie ist nicht möglich. Konservativ kann die Krankheit bei den meisten Hunden relativ lange beherrscht werden. Einfache Maßnahmen, wie die Nutzung eines Brustgeschirrs statt eines Halsbandes, das Vermeiden übermäßiger körperlicher Anstrengungen und Vermeidung von Übergewichtigkeit können durch den Hundehalter selbst durchgeführt werden.
Zur Linderung der Symptome können hustenstillende Mittel wie Hydrocodon, Butorphanol oder Codein eingesetzt werden. Ein weiterer konservativer Therapieansatz ist die Gabe von Parasympatholytika (Atropin, auch in Kombination mit Diphenoxylat), der vor allem im angloamerikanischen Sprachraum beliebt ist. Da der Trachealkollaps mit einer Entzündung einhergeht, ist zunächst auch Prednisolon angezeigt, das in der Langzeitbehandlung ausgeschlichen werden sollte oder alternierend verabreicht wird. Da es durch den Husten auch zu einer Refluxösophagitis kommen kann, die ihrerseits auch wieder hustenauslösend wirkt, wird in jüngerer Zeit auch die dauerhafte Gabe von Protonenpumpenhemmern propagiert. Bei den seltenen Begleitinfektionen kann auch ein Antibiotikum angezeigt sein, wobei Tetracycline wegen ihrer Wirkung gegen Mycoplasmen bevorzugt werden. Bei schweren akuten Hustenanfällen kann ein Sedativum wie Acepromazin eingesetzt werden.Im experimentellen Stadium ist das Einsetzen von ursprünglich für die Humanmedizin entwickelten Stents, die eine passive Stützung der Luftröhre gewährleisten. Obwohl dieses Verfahren als derzeit effektivste Behandlungsmethode der Erkrankung angesehen wird (bei knapp 70 Prozent der Patienten wird nach dem Eingriff eine deutliche klinische Verbesserung festgestellt), konnte es sich noch nicht als Standardtherapie etablieren. Hauptursache hierfür sind die hohen Kosten des Stents; außerdem können Komplikationen auftreten, wenn die nicht von der Endoprothese stabilisierten Anteile der Luftröhre und Hauptbronchien kollabieren. Bei einigen Tieren tritt infolge der Ansammlung von Sekret im Bereich nicht vollständig an der Luftröhrenwand anliegender Stentanteile auch weiterhin Husten auf. Selten kommt es zu einer Beeinträchtigung der Atmung durch überschießende Bildung von Granulationsgewebe; diese Symptome scheinen jedoch mit der Gabe von Glukokortikoiden behebbar zu sein. Einzelberichte erwähnen das Kollabieren eines Stents mit anschließender Verengung der Luftröhre. Als chirurgische Alternative zum Stent ist die Fixierung der Luftröhre durch ein um die Luftröhre gelegtes Kunststoffgerüst die am weitesten verbreitete Vorgehensweise. Als weitere Möglichkeiten sind Eingriffe an der obenliegenden Membran der Luftröhre sowie direkte Manipulationen der Knorpelspangen beschrieben. Diesen Techniken gemeinsam ist, dass sie hochgradig invasiv und chirurgisch sehr anspruchsvolle Verfahren sind.
R. W. Nelson, C. G. Couto: Small animal internal medicine. 3. Auflage. Mosby, 2003, ISBN 0-323-01724-X, S. 289–291.

Das Trägheitsmoment, auch Massenträgheitsmoment oder Inertialmoment, gibt die Trägheit eines starren Körpers gegenüber einer Änderung seiner Winkelgeschwindigkeit bei der Drehung um eine gegebene Achse an (Drehmoment geteilt durch Winkelbeschleunigung). Damit spielt es die gleiche Rolle wie im Verhältnis von Kraft und Beschleunigung die Masse; deswegen ist in der älteren Literatur auch die Bezeichnung Drehmasse gebräuchlich. Als physikalische Größe kommt es erstmals 1749 im Werk Scientia Navalis von Leonhard Euler vor.Das Trägheitsmoment hängt von der Massenverteilung in Bezug auf die Drehachse ab. Je weiter ein Massenelement von der Drehachse entfernt ist, desto mehr trägt es zum Trägheitsmoment bei; der Abstand geht quadratisch ein. Nimmt die Dichte des Körpers nach innen hin zu, ist sein Trägheitsmoment kleiner, als wenn seine Masse im selben Volumen homogen verteilt wäre. Bei rasch rotierenden Planeten lässt sich deshalb aus der Abplattung auf den Dichteverlauf schließen.
Ist die Drehachse nicht fest vorgegeben, so reicht zur Beschreibung des Trägheitsverhaltens eine einzelne Zahl nicht aus. Aus dem Trägheitstensor kann das Trägheitsmoment für jede beliebige Achse durch den Schwerpunkt berechnet werden.
Beim Seiltanz werden als Balancierhilfe bevorzugt lange Stangen verwendet. Im Vergleich zu einem gleich schweren kompakten Körper, etwa einem Sandsack, hat so eine Stange ein sehr großes Trägheitsmoment. Ein Zur-Seite-Kippen wird dadurch nicht verhindert, aber so verlangsamt, dass der Artist genug Zeit für eine ausgleichende Bewegung hat.
Den Effekt kann man leicht selbst ausprobieren: Ein 30-cm-Lineal (kürzer ist schwieriger) lässt sich hochkant auf der Handfläche balancieren. Quer jedoch, auf eine seiner langen Kanten gestellt, fällt es komplett um, bevor man reagieren kann. Die Drehachse ist in beiden Fällen die aufliegende Kante, während das mittlere Abstandsquadrat von dieser Achse mit über 900 cm2 bzw. rund 16 cm2 stark verschieden ist.
Dass der Abstand quadratisch in das Trägheitsmoment eingeht, lässt sich leicht einsehen: Eine gegebene Winkelbeschleunigung bedeutet für ein Massenelement in doppeltem Abstand eine doppelt so große tangentiale Beschleunigung und damit eine doppelt so große Trägheitskraft. Das Drehmoment, doppelte Kraft × doppelter Hebelarm, ist damit vierfach so groß.
Mit einem weiteren einfachen Experiment kann man eine Änderung des Trägheitsmoments veranschaulichen. Man setzt sich möglichst mittig auf einen drehbaren Bürostuhl und lässt sich mit gestreckten Armen und Beinen in Drehung versetzen. Wenn man dann die Arme und Beine an den Körper heranzieht, nimmt das Trägheitsmoment ab. Das führt dazu, dass die Drehbewegung schneller wird, weil der Drehimpuls erhalten bleibt (siehe Drehimpulserhaltung). Erneutes Ausstrecken verlangsamt die Bewegung wieder. Um den Effekt zu verstärken, kann man in jede Hand schwere Gegenstände nehmen, etwa Hanteln. Je größer deren Masse, desto deutlicher wird der Effekt.
Ein ähnliches Beispiel ist der Pirouetteneffekt, der aus dem Eiskunstlaufen bekannt ist. Die Kontrolle der Drehgeschwindigkeit kann allein aus der Verlagerung der Körpermasse relativ zur Drehachse erfolgen. Zieht der Eiskunstläufer die Arme an oder richtet sich aus einer Hockstellung gerade auf, so dreht er sich schneller – ein erneutes Schwungholen ist nicht nötig.
  , zurückgehend auf das lateinische Wort iners, das untätig und träge bedeutet. Da beide Symbole aber auch in der Elektrotechnik Verwendung finden, ist weiterhin ein 
   einer linearen (geradlinigen) Bewegung (ausführlich siehe Rotation (Physik)#Vergleich mit der Translationsbewegung). Man vergleiche folgende Gleichungen:
   Massenpunkten besteht, ergibt sich aus der Summe der kinetischen Energien der einzelnen Massenpunkte:
    {\displaystyle E_{\mathrm {rot} }={\frac {1}{2}}\ \underbrace {\left(\sum _{i}^{N}m_{i}r_{i,\perp }^{2}\right)} _{:=I}\ \omega ^{2}}
    {\displaystyle E_{\mathrm {kin} }={\frac {1}{2}}\ \underbrace {\left(\sum _{i}^{N}m_{i}\right)} _{=M}\ v^{2}}
  .Durch diese Definition kann man folgende Größen rotierender Massenpunkte mit den Größen linear bewegter Massenpunkte identifizieren:
  .Wählt man die z-Achse des Koordinatensystems in Richtung der Rotationsachse, so lässt sich noch folgende praktische Gleichung ableiten:
Der Index „z“ ist wichtig, da das Trägheitsmoment eines Körpers immer auf eine Rotationsachse (hier die z-Achse) bezogen ist. Aus der Gleichung ist auch ersichtlich, dass das Trägheitsmoment nicht von den z-Koordinaten der einzelnen Massenpunkte abhängt. Das Trägheitsmoment ist unabhängig von den Koordinaten der Massenpunkte in Richtung der Rotationsachse.
Die Formel für das Massenträgheitsmoment einer allgemeinen Massenverteilung erhält man, in dem man sich die Massenverteilung aus vielen kleinen Massenelementen 
    {\displaystyle E_{\mathrm {rot} }=\lim _{N\to \infty ,\,\Delta m_{i}\to 0}{\frac {1}{2}}\left(\sum _{i}^{N}\Delta m_{i}r_{i,\perp }^{2}\right)\omega ^{2}}
    {\displaystyle E_{\mathrm {rot} }={\frac {1}{2}}\omega ^{2}\int _{V}\mathrm {d} \,mr_{\perp }^{2}={\frac {1}{2}}\omega ^{2}\int _{V}\mathrm {d} V\,\varrho ({\vec {r}})r_{\perp }^{2}}
  .Hieraus ergibt sich die oben angegebene allgemeine Definition des Trägheitsmomentes mit einer ortsabhängigen (also im Allgemeinen inhomogenen) Massendichte 
    {\displaystyle {L}_{i,\parallel }=|{\vec {r}}_{i,\perp }\times (\Delta m_{i}{\vec {v}}_{i})|=r_{i,\perp }^{2}\Delta m_{i}\omega }
    {\displaystyle L_{\parallel }=\sum _{i}L_{i,\parallel }=\omega \sum _{i}r_{i,\perp }^{2}\Delta m_{i}=\omega I}
Bei einer homogenen Masseverteilung ist die Dichte örtlich konstant. Die Dichte kann vor das Integral gezogen werden und die Formel für das Trägheitsmoment vereinfacht sich zu
Das Trägheitsmoment rotationssymmetrischer Körper, die um ihre Symmetrieachse (z-Achse) rotieren, kann einfach mit Hilfe von Zylinderkoordinaten berechnet werden. Dazu muss entweder die Höhe als Funktion des Radius
   für eine Achse durch den Schwerpunkt eines Körpers bekannt, so kann mit Hilfe des „steinerschen Satzes“ das Trägheitsmoment 
Man kann den steinerschen Satz für zwei beliebige parallele Drehachsen verallgemeinern. Dazu muss der Satz zweimal hintereinander angewendet werden: Zunächst verschiebe man die Drehachse so, dass sie durch den Schwerpunkt des Körpers geht, danach auf den gewünschten Zielort.
    {\displaystyle I_{\mathrm {neu} }=I_{\mathrm {alt} }+m\left(d_{\mathrm {neu} }^{2}-d_{\mathrm {alt} }^{2}\right)}
Der Satz über senkrechte Achsen behandelt den Sonderfall flacher Körper mit einer gleichmäßigen Dicke, die im Vergleich mit anderen Abmessungen des Körpers vernachlässigt werden kann. Dann ist die Summe der Trägheitsmomente um zwei beliebige zueinander senkrechte Drehachsen in der Ebene des Körpers gleich dem Trägheitsmoment um die Drehachse, die durch ihren Schnittpunkt und senkrecht zu der Ebene des Körpers verläuft. Für einen Körper in der xy-Ebene bei z = 0 wie im Bild heißt das:
    {\displaystyle J_{z}=\int \left(x^{2}+y^{2}\right)~\mathrm {d} m+\int y^{2}~\mathrm {d} m=J_{x}+J_{y}}
   eines Körpers ist eine Verallgemeinerung des Trägheitsmomentes. In einem kartesischen Koordinatensystem lässt sich der Trägheitstensor als Matrix darstellen, die sich aus den Trägheitsmomenten bezüglich der drei Koordinatenachsen und den Deviationsmomenten zusammensetzt. Die drei Trägheitsmomente bilden die Hauptdiagonale der Matrix, die Deviationsmomente sind die Nebendiagonalelemente. Mit Hilfe des Trägheitstensors lässt sich z. B. das Trägheitsmoment bezüglich einer beliebigen durch den Schwerpunkt gehenden Achse berechnen. Wenn ein starrer Körper um eine solche Achse mit der Winkelgeschwindigkeit 
    {\displaystyle I={\frac {1}{\omega ^{2}}}\sum _{i=1}^{3}\sum _{j=1}^{3}I_{ij}\;\omega _{i}\;\omega _{j}}
    {\displaystyle I={\frac {1}{\omega ^{2}}}\,{\vec {\omega }}^{T}\cdot {\underline {I}}\cdot {\vec {\omega }}}
  . Man kann diesen z. B. dadurch erhalten, dass man den Einheitsvektor in z-Richtung mittels einer Drehmatrix R dreht:
    {\displaystyle {\vec {e}}={\underline {R}}\cdot \left({\begin{matrix}0\\0\\1\end{matrix}}\right)}
    {\displaystyle {\underline {R}}=\left({\begin{matrix}\cos \varphi \cdot \cos \vartheta &-\sin \varphi &\cos \varphi \cdot \sin \vartheta \\\sin \varphi \cdot \cos \vartheta &\cos \varphi &\sin \varphi \cdot \sin \vartheta \\-\sin \vartheta &0&\cos \vartheta \ \end{matrix}}\right)}
    {\displaystyle {\vec {e}}=\left({\begin{matrix}\cos \varphi \cdot \sin \vartheta \\\sin \varphi \cdot \sin \vartheta \\\cos \vartheta \end{matrix}}\right)}
  .Mit Hilfe dieser Drehmatrix kann nun der Trägheitstensor in ein Koordinatensystem transformiert werden, in dem die z-Achse in Richtung der Rotationsachse zeigt:
    {\displaystyle {\underline {I'}}={\underline {R}}^{T}\cdot {\underline {I}}\cdot {\underline {R}}}
  .Das Trägheitsmoment für die neue z-Achse ist jetzt einfach das 3. Diagonalelement des Tensors in der neuen Darstellung. Nach Ausführung der Matrizenmultiplikation und trigonometrischen Umformungen ergibt sich
    {\displaystyle {\begin{aligned}I=&(I_{xx}\cos ^{2}\varphi +I_{yy}\sin ^{2}\varphi +I_{xy}\sin 2\varphi )\sin ^{2}\vartheta \\&+I_{zz}\cos ^{2}\vartheta +(I_{yz}\sin \varphi +I_{zx}\cos \varphi )\sin 2\vartheta \end{aligned}}}
Wir betrachten als Beispiel dazu den Trägheitstensor eines rotationssymmetrischen Körpers. Wenn eine der Koordinatenachsen (hier die z-Achse) mit der Symmetrieachse zusammenfällt, dann ist dieser Tensor diagonal. Die Trägheitsmomente für Rotation um die x-Achse und die y-Achse sind gleich (
    {\displaystyle {\underline {I}}=\left({\begin{matrix}I_{1}&0&0\\0&I_{1}&0\\0&0&I_{2}\end{matrix}}\right)}
  .Transformiert man diesen Tensor wie oben beschrieben in ein Koordinatensystem, das um den Winkel 
    {\displaystyle {\underline {I'}}=\left({\begin{matrix}I_{1}\cos ^{2}\vartheta +I_{2}\sin ^{2}\vartheta &0&\left(I_{1}-I_{2}\right)\sin \vartheta \cos \vartheta \\0&I_{1}&0\\\left(I_{1}-I_{2}\right)\sin \vartheta \cos \vartheta &0&I_{1}\sin ^{2}\vartheta +I_{2}\cos ^{2}\vartheta \end{matrix}}\right)}
Betrachtet man einen beliebig geformten Körper, der um eine Achse durch seinen Massenmittelpunkt rotiert, so variiert dessen Trägheitsmoment je nach Lage dieser Drehachse. Dabei gibt es – im Allgemeinen – eine Achse, bezüglich der das Trägheitsmoment des Körpers maximal anliegt, und eine, für das es minimal anliegt. Diese beiden Achsen stehen immer senkrecht zueinander und bilden zusammen mit einer dritten, wiederum senkrecht auf den beiden anderen stehenden Achse, die Hauptträgheitsachsen des Körpers.
In einem von den Hauptträgheitsachsen aufgespannten Koordinatensystem (Hauptträgheitssystem genannt) ist der Trägheitstensor diagonal. Die zu den Hauptträgheitsachsen gehörenden Trägheitsmomente sind also die Eigenwerte des Trägheitstensors, sie heißen Hauptträgheitsmomente.
Ist wie im Bild ein kartesisches Koordinatensystem im Massenmittelpunkt parallel zum Hauptträgheitssystem ausgerichtet, dann berechnen sich die Hauptträgheitsmomente zu:
    {\displaystyle {\begin{aligned}I_{1}=&\int _{V}(x_{2}^{2}+x_{3}^{2})\,\varrho \mathrm {d} V\\I_{2}=&\int _{V}(x_{3}^{2}+x_{1}^{2})\,\varrho \mathrm {d} V\\I_{3}=&\int _{V}(x_{1}^{2}+x_{2}^{2})\,\varrho \mathrm {d} V\end{aligned}}}
    {\displaystyle i_{\alpha }:=\int _{V}x_{\alpha }^{2}\,\varrho \mathrm {d} V>0\quad {\text{mit}}\quad \alpha =1,2,3}
    {\displaystyle {\begin{aligned}I_{1}&=i_{2}+i_{3}\\I_{2}&=i_{1}+i_{3}\\I_{3}&=i_{1}+i_{2}\end{aligned}}}
    {\displaystyle {\begin{aligned}I_{1}+I_{2}&=i_{1}+i_{2}+2i_{3}=I_{3}+2i_{3}>I_{3}\\I_{2}+I_{3}&=2i_{1}+i_{2}+i_{3}=I_{1}+2i_{1}>I_{1}\\I_{3}+I_{1}&=i_{1}+2i_{2}+i_{3}=I_{2}+2i_{2}>I_{2}\,.\end{aligned}}}
  Die Summe zweier Hauptträgheitsmomente ist also immer größer als das dritte (Dreiecksungleichung).
Sind zwei Hauptträgheitsmomente gleich groß, so sind alle Drehachsen in der Ebene, die von den zugehörigen Hauptträgheitsachsen aufgespannt wird, ebenfalls Hauptträgheitsachsen mit dem gleichen Trägheitsmoment. Das ist bei zylindersymmetrischen Körpern unmittelbar klar, gilt aber z. B. ebenso für einen Stab mit quadratischer oder hexagonaler Grundfläche.
Für den Fall, dass alle drei Hauptträgheitsmomente identisch sind, ist, wie oben gezeigt wurde, jede Drehachse durch den Massenmittelpunkt eine Hauptträgheitsachse mit dem gleichen Trägheitsmoment. Dies gilt für alle regelmäßigen Körper wie Kugel, gleichseitiges Tetraeder, Würfel usw.
   im Gegensatz zur oben angegebenen Formel nicht das Trägheitsmoment, sondern der Trägheitstensor. Im Allgemeinen hat der Drehimpuls 
   und ist zeitlich nicht konstant, so dass die Lager ständig Drehmomente aufbringen müssen (dynamische Unwucht). Nur bei Rotation um eine der Hauptträgheitsachsen ist 
  ausgedrückt werden. Diese Formeln zeigen die Analogie zu den entsprechenden Formeln für Impuls und kinetische Energie der Translationsbewegung.
Fast alle größeren Körper im Weltall (Sterne, Planeten) sind annähernd kugelförmig und rotieren mehr oder weniger schnell. Das Trägheitsmoment um die Rotationsachse ist immer das größte des jeweiligen Himmelskörpers.
Die Differenz dieses „polaren“ und des äquatorialen Trägheitmoments hängt mit der Abplattung des Körpers zusammen, also seiner Verformung der reinen Kugelgestalt durch die Fliehkraft der Rotation. Bei der Erde liegt die Differenz dieser zwei Hauptträgheitsmomente bei 0,3 Prozent, entspricht also etwa der Erdabplattung von 1:298,24. Beim rasch rotierenden Jupiter ist die Differenz und die Abplattung rund 20-mal größer.
Wenn nicht ausdrücklich anders angegeben, liegt der Schwerpunkt der geometrischen Körper auf der Drehachse, auf die sich das Trägheitsmoment bezieht. 
   ist die Masse des rotierenden Körpers. Das Trägheitsmoment für Drehungen um andere Achsen kann man dann mit Hilfe des Satzes von Steiner berechnen. Für Drehungen um beliebige Achsen  kann man die Liste von Trägheitstensoren heran ziehen.
Zum Verständnis dieses Abschnittes sind grundlegende Kenntnisse der Integralrechnung und Koordinatentransformation hilfreich.Um das Trägheitsmoment einer massiven homogenen Kugel bezüglich einer Drehachse durch den Kugelmittelpunkt zu berechnen, wird das im Abschnitt „Berechnung“ angegebene Integral verwendet. Der Einfachheit halber soll der Kugelmittelpunkt im Ursprung eines kartesischen Koordinatensystems liegen und die Drehachse entlang der 
  auszuwerten, empfiehlt es sich statt kartesischen lieber Kugelkoordinaten zu verwenden. Beim Übergang müssen dabei die kartesischen Koordinaten x, y, z und das Volumenelement dV durch die Kugelkoordinaten 
    {\displaystyle \mathrm {d} V=r^{2}\sin \vartheta \,\mathrm {d} r\,\mathrm {d} \vartheta \,\mathrm {d} \varphi }
    {\displaystyle I=\rho \int _{0}^{R}\!\mathrm {d} r\,\int _{0}^{\pi }\!\mathrm {d} \vartheta \,\int _{0}^{2\pi }\!\mathrm {d} \varphi \;\;r^{4}\sin ^{3}\vartheta }
  .Hier zeigt sich der Vorteil der Kugelkoordinaten: Die Integralgrenzen hängen nicht voneinander ab. Die beiden Integrationen über r und 
    {\displaystyle I={\frac {2}{5}}\pi \rho R^{5}\int _{0}^{\pi }\sin ^{3}\vartheta \,\mathrm {d} \vartheta }
    {\displaystyle I={\frac {2}{5}}\cdot {\frac {4}{3}}\pi \rho R^{5}={\frac {2}{5}}\rho VR^{2}={\frac {2}{5}}mR^{2}}
Zur Messung eines Trägheitsmoments eines Körpers verwendet man einen Drehtisch. Dieser besteht aus einer Kreisscheibe, die um ihre Symmetrieachse drehbar ist und einer Schneckenfeder (Spiralfeder). Sie bewirkt bei einer Drehung der Scheibe ein rücktreibendes Drehmoment 
   nennt man Direktionsmoment oder Richtmoment. Ihr Wert hängt von der Stärke der Feder ab. Die Scheibe führt nun harmonische Schwingungen mit der Schwingungsdauer
   das Trägheitsmoment der Scheibe ist. Legt man nun zusätzlich einen Körper mit bekanntem Trägheitsmoment 
   des Drehtisches. Legt man nun einen beliebigen Körper auf den Drehtisch, so kann man sein Trägheitsmoment 
Momente sind in Naturwissenschaften und Technik Kenngrößen einer Verteilung, welche die Lage und Form dieser Verteilung beschreiben. Sie werden durch Integration über die mit einem potenzierten Abstand gewichteten Verteilung berechnet. In diesem Sinne ist das Massenträgheitsmoment mit dem Flächenträgheitsmoment verwandt.
Paul A. Tipler: Physik. 3. korrigierter Nachdruck der 1. Auflage 1994, Spektrum Akademischer Verlag Heidelberg Berlin, 2000, ISBN 3-86025-122-8.
Ernst W. Otten: Repetitorium Experimentalphysik. Springer-Verlag Berlin Heidelberg, 1998, ISBN 3-540-62987-4.
Torsten Fließbach: Mechanik. 3. Auflage, Spektrum Akademischer Verlag, Heidelberg 1999, ISBN 3-8274-0546-7.
Herbert Goldstein, Charles Poole, John Safko: Classical mechanics. International Edition, 3. Auflage, Pearson/Addison-Wesley, Upper Saddle River, N.J., 2002, ISBN 0-321-18897-7.
Wolfgang Demtröder: Experimentalphysik 1. 5. neu bearbeitete und aktualisierte Auflage, Springer-Verlag Berlin Heidelberg, 2008, ISBN 978-3-540-79294-9.
Trägheitsmomente geometrischer Körper bei Matheplanet – Anleitungen zum Berechnen diverser Trägheitsmomente mit Beispielen.
Die Transformationskurve, auch Produktionsmöglichkeitenkurve oder Kapazitätslinie, ist in der Volkswirtschaftslehre die grafische Darstellung aller effizienten Gütermengenkombinationen bei gegebenem Ressourcen-Einsatz. Sie ist ein wirtschaftswissenschaftliches Instrument, das dazu dient, das grundsätzlich bestehende Problem der Knappheit und die daraus entstehenden Alternativen aufzuzeigen.
Die Realität wird im Modell der Produktionsmöglichkeiten stark vereinfacht anhand von zwei Gütern oder zwei Produktionsfaktoren dargestellt. Jedoch können Konzept, Erkenntnisse und Ergebnisse ohne Schwierigkeiten auf viele Güter und ganze Volkswirtschaften übertragen werden.Die geschlossene Menge unter der Transformationskurve wird Produktionsraum oder Production Possibility Set genannt. Er enthält alle möglichen Güterkombinationen, die mit den vorhandenen Produktionsfaktoren produziert werden können – allerdings weniger effizient als genau auf der Transformationskurve.
Sowohl in der Betriebswirtschaftslehre als auch in der Volkswirtschaftslehre stellt die Transformationskurve ein wichtiges Werkzeug dar, um verschiedene Alternativen der Produktionsmöglichkeiten abzubilden. Dabei findet die Transformationskurve vor allem in der volkswirtschaftlichen Außenhandelstheorie besondere Bedeutung. Hierbei dient die Kurve als Grundlage für weitere Theorien und Modelle, wie das Ricardo-Modell, Heckscher-Ohlin-Modell oder das Rybczynski-Theorem. Die Tatsache, dass die in einer Volkswirtschaft jeweils verfügbaren Produktionsfaktoren wegen ihrer Knappheit nur wahlweise für die eine oder die andere Verwendung eingesetzt werden können, dass demnach – bei gegebener Produktionstechnik – das Produktionspotenzial begrenzt ist, begründet die Notwendigkeit des Instruments der Transformationskurve. Die Kurve könnte man daher auch als den geometrischen Ort aller maximal möglichen Mengenkombinationen von Gütern, Gütergruppen oder Produktionsfaktoren bezeichnen. Im Modell der Transformationskurve wird dabei angenommen, dass alle Ressourcen vollständig in Anspruch genommen und nach dem ökonomischen Prinzip eingesetzt wurden.Aufgrund der Annahme von Knappheit oder Vollauslastung müssen sowohl in einem Unternehmen als auch in einer Volkswirtschaft Wahlentscheidungen getroffen werden, um eine alternative Gütermengenkombination oder Produktionsfaktorenkombination festzulegen. Eine Entscheidung zu treffen bedeutet immer auch, einen Verzicht in Kauf zu nehmen. Diesen Verzicht, genauer den Nutzenentgang, nennt man Opportunitätskosten oder auch Kosten der zweitbesten Alternative. Bei einer Bewegung entlang der Transformationskurve kommt es daher zu einem Zuwachs der Menge des einen Gutes, aber gleichzeitig auch zum Verzicht auf eine entsprechende Menge des anderen Gutes.Die Achsen des Produktionsmöglichkeitendiagramms können Mengen von Gütern (bspw. Brot oder Maschinen), Gütergruppen (bspw. Konsum- oder Investitionsgüter), Produktionsfaktoren (bspw. Arbeit oder Kapital) sowie sonstigen wirtschaftlichen Einheiten abbilden. In der folgenden Betrachtung soll aus Vereinfachungsgründen von einem Zwei-Güter-Fall ausgegangen werden.
In der Literatur wird die Kurve zum Teil auch als Produktionsmöglichkeitengrenze bezeichnet. Gemeint ist damit die Beschränkung der möglichen Produktionsmenge, die durch die Transformationskurve gesetzt wird. Bezogen auf die Grafik (Abb. 2) bedeutet dies, dass nur diejenigen Güterkombinationen unterhalb bzw. links von und auf der Kurve möglich sind. Alle außerhalb dieses Bereichs liegenden Mengenkombinationen sind bei gleichbleibendem Stand von Technik, Wissen und Produktivität nicht realisierbar. Eine Ausnahme kann eine Volkswirtschaft im internationalen Handel aufzeigen. So kann es durch einen komparativen Vorteil dieser Volkswirtschaft möglich sein, eine Kombination außerhalb bzw. rechts von der Produktionsmöglichkeitenkurve zu erreichen. Generell verschiebt sich die Transformationskurve dagegen nach außen und es werden somit bisher unerreichbare Mengenkombinationen realisierbar, wenn langfristig technisches Wissen und/oder Faktorausstattung wachsen. Die damit zusammenhängenden Fragen sind Gegenstand der Wachstumstheorie. Des Weiteren kann anhand der Kurve die Effizienz beurteilt werden. Effizienz liegt vor, wenn alle Ressourcen vollständig genutzt sind. Nur die Kombinationen von Gütermengen auf der Kurve können daher als effizient bezeichnet werden. Dagegen gelten alle Mengenzusammensetzungen unterhalb der Funktion als ineffizient, weil bei gleichem Faktoreinsatz mehr von einem der beiden Güter produziert werden könnte. Eine weitere denkbare Erklärung ist, dass die mögliche produktive Leistung nicht in dem Umfang genutzt wird, wie es beim gegebenen Stand des Wissens möglich gewesen wäre. Mit diesem Problem befassen sich die Preistheorie und Allokationstheorie.
Wie in Abb. 3 zu erkennen, unterscheidet man grundsätzlich zwischen zwei Arten des Verlaufs von Produktionsmöglichkeitskurven, der linear und der konkav zum Ursprung verlaufenden. Der in Abb. 3 a) dargestellte lineare Verlauf der Kurve wird durch die zugrunde liegenden Produktionsfunktionen bestimmt. Unabhängig vom Produktionsniveau wird dabei eine konstante Faktormenge pro Produkteinheit bei den beiden Gütern beansprucht. Ist diese Bedingung nicht erfüllt, nimmt die Transformationskurve in der Regel – wie in Abb. 3 b) zu erkennen – einen konkaven, also einen nach außen gekrümmten Verlauf an. Produktionsfunktion, Faktorintensität sowie die Produktionselastizität bestimmen also die Gestalt der Kapazitätslinie. Dabei haben ungleiche Elastizitäten und/oder unterschiedliche Faktorintensitäten eine Konkavität der Funktion zur Folge.
Ein alternativ verständlicher und praxisorientierter Ansatz zur Art der Gestalt der Transformationskurve ist die Betrachtung der Verbundvorteile bei der Produktion. Nimmt man auf den Zwei-Güter-Fall bezogen an, dass mit der kombinierten Erzeugung der beiden Güter gegenüber einer separaten Produktion gewisse Verbundvorteile einhergehen, wird die Kurve einen konkaven Verlauf annehmen. Verbundvorteile meinen eine Ersparnis an zur Herstellung notwendigen Produktionsfaktoren. In der Praxis könnte die zusammengelegte Produktion zweier Güter beispielsweise zur Reduzierung der Verwaltungskosten oder dem Einkaufspreis gemeinsam verwendeter Rohstoffe aufgrund von Mengenrabatt bedeuten. Sollten sich dagegen aus der kombinierten Herstellung der Güter keine Verbundvorteile ergeben, wird die Produktionsmöglichkeitenkurve einen linearen Verlauf annehmen.In der Theorie sind zudem konvexe oder auch linear aus mehreren Teilstücken bestehende Verläufe denkbar. Die zusammengesetzte lineare Variante wird verursacht, wenn die Faktorintensitäten von zwei Gütern mit linear limitationalen Produktionsfunktionen ungleich sind. Konvexität kann aufgrund Überlinearität einer Produktionsfunktion oder aus Negativwirkung bei kombinierter Produktion folgen. Negativwirkung bedeutet in dem Fall, dass bei zusammengelegter Herstellung Nachteile wie höhere Kosten im Gegensatz zur getrennten Erzeugung der Güter entstehen.
Die Steigung der Produktionsmöglichkeitenkurve, auch als Grenzrate der Transformation bezeichnet, weist typischerweise eine negative Steigung, also einen von links oben nach rechts unten fallenden Verlauf auf (siehe Abb. 3a). Die Opportunitätskosten – der unvermeidbare Verzicht auf eine bestimmte Menge des einen Gutes beim Produzieren einer zusätzlichen Mengeneinheit des anderen Gutes – erklären die fallende Steigung der Kurve. Das bedeutet, zwischen den in der Abbildung 3 dargestellten Gütern X und Y besteht eine inverse Beziehung, man könnte dies auch als einen „trade-off“ zwischen den Gütern bezeichnen. Mathematisch betrachtet entspricht die Grenzrate der Transformation dem Transformationsverhältnis, folglich dem Verhältnis der beiden Produktmengenänderungen von Gut X und Gut Y unter Verwendung deren Differentiale 
  : DifferentialUm für die Grenzrate einen positiven Betrag zu erhalten, wird vor das Verhältnis ein Negativzeichen gesetzt. Zugleich gibt dieses Verhältnis die marginalen Verzichts- bzw. Alternativkosten an.
Bei einer linearen Funktion bleibt das Transformationsverhältnis den kompletten Verlauf über unverändert, es liegen also konstante Alternativkosten vor. Bezogen auf den Zwei-Güter-Fall hätten beide Güter stets relative Kosten im gleichen Verhältnis, das heißt, sie wären in jedem Punkt auf der Funktion im gleichbleibenden Verhältnis der Grenzrate der Transformation substituierbar.
Vielfach tritt jedoch der in Abb. 3b beschriebene Fall der nach außen gekrümmten (= konkaven) Produktionsmöglichkeitenkurve auf. Hierbei verändert sich der Betrag der Steigung entlang des fallenden Verlaufs der Funktion degressiv. Grund dafür ist das „Gesetz der abnehmenden Alternativkosten“ in Verbindung mit dem Ertragsgesetz (= „Gesetz vom abnehmenden Ertragszuwachs“). Dabei wird angenommen, dass die Erträge durch zusätzlichen Input geringer werden, je mehr Faktorleistung in einer bestimmten Produktion bereits vorhanden ist. In Abb. 4 ist das Ertragsgesetz grafisch zu erkennen, verzichtet man auf eine Einheit des Gut Y, kann man ∆X1 Einheiten mehr von Gut X produzieren – das ist gleichzusetzen mit einem Ertrag in Höhe von ∆X1, bei einem Verzicht auf eine Einheit von Gut Y. Wird nun auf weitere Einheiten von Gut Y verzichtet, so nehmen die Erträge (in der Grafik ∆X2 … ∆X4) kontinuierlich ab. Ein möglicher Grund dafür ist, dass je mehr Produktionsfaktoren für die Herstellung des Gut X aus der Herstellung des Gut Y abgezogen werden, diese sich dabei umso weniger eignen für die zusätzliche Produktion von Gut X. Auch denkbar wäre, dass eines der beiden Produkte konstante und das andere Produkt sinkende Skalenerträge aufweist oder beide Produkte sinkende Skalenerträge aufweisen. Im Zwei-Güter-Fall hätten beide Güter entlang der Kurve stets relative Kosten in einem differenten Verhältnis, das heißt, sie wären in jedem Punkt auf der Funktion im jeweiligen Verhältnis der Grenzrate der Transformation substituierbar.
Um die Herleitung verständlicher zu machen, bedient man sich dem im oberen Teil der Abb. 5 zu erkennenden Schachteldiagramm, auch genannt Edgeworth-Box. Dabei wird von der Produktion zweier Güter und nur begrenzt zur Verfügung stehenden Produktionsfaktoren ausgegangen. Unter dieser Bedingung werden die Isoquanten für die beiden darzustellenden Güter X und Y in das Diagramm abgetragen. Verbindet man nun die Tangentialpunkte, also die Berührungspunkte der Isoquanten (in der Grafik A, B, C und D), erhält man die Linie der effizienten Produktion, auch als Kontraktkurve bezeichnet. Die Lage der sich berührenden Isoquanten zum jeweiligen Ursprung repräsentiert die verschiedenen Produktionsmengen in diesen Punkten. Die Steigung der Isoquanten wird bestimmt durch das Verhältnis der Grenzproduktivitäten. Da in den Berührungspunkten die Steigung der jeweiligen Isoquanten (hier der Güter X und Y) identisch ist, muss demnach auch das Verhältnis der Grenzproduktivitäten der beiden Güter einen gleichen Wert annehmen. Somit kann von Gut X nicht mehr hergestellt werden, ohne auf eine bestimmte Menge des Gut Y zu verzichten – die Tangentialpunkte stellen folglich durch die Isoquanten bestimmte pareto-optimale Mengenkombinationen der Güter X und Y dar. Diese in der Edgeworth-Box abgebildeten Gütermengenkombinationen A, B, C und D lassen sich in ein bekanntes X-Y-Produktmengendiagramm übertragen. In der Abb. 5 erfolgt diese Übertragung senkrecht nach unten, man beachte an dieser Stelle, dass die Übertragungslinien dabei nicht völlig senkrecht verlaufen müssen, da die Achsen beider Diagramme durch verschiedene Variablen bezeichnet sind. Verbindet man nun wiederum die übertragenen Punkte A, B, C und D im unteren Diagramm, entsteht die Produktionsmöglichkeitenkurve. Diese verläuft in der Abbildung exemplarisch konkav, denkbar sind auch andere Verläufe (siehe Lage und Gestalt der Kurve).
Mathematisch lässt sich die Transformationsfunktion aus den Produktionsfunktionen der beiden Güter X und Y herleiten. Dies soll anhand einer Beispiel-Rechnung unter gewissen Annahmen gezeigt werden. Hierbei wird davon ausgegangen, dass es sich um zwei linear homogene Produktionsfunktionen mit gleichen partiellen Produktionselastizitäten von ½ handelt. Weiterhin gibt es analog zur grafischen Herleitung nur zwei Produktionsfaktoren, Kapital und Arbeit. Die Produktionsfunktionen für die Güter X und Y lauten:
  : Produktionsfaktor ArbeitWie bereits erläutert, sind die Gütermengenkombinationen pareto-optimal, die Steigung der Isoquanten – somit die Grenzraten der technischen Substitution – der Güter X und Y müssen in den Tangentialpunkten identisch sein. Daher ergibt sich:
    {\displaystyle {GRTS}_{X}={\frac {{GP}_{L,X}}{{GP}_{K,X}}}={\frac {{dX/dL}_{X}}{{dX/dK}_{X}}}={\frac {{(1/2)X/L}_{X}}{{(1/2)X/K}_{X}}}={\frac {K_{X}}{L_{X}}}}
    {\displaystyle {GRTS}_{Y}={\frac {{GP}_{L,Y}}{{GP}_{K,Y}}}={\frac {{dY/dL}_{Y}}{{dY/dK}_{Y}}}={\frac {{(1/2)Y/L}_{Y}}{{(1/2)Y/K}_{Y}}}={\frac {K_{Y}}{L_{Y}}}}
  : DifferentialWerden die Beziehungen (3) und (4) gleichgesetzt, erhält man das gewünschte Optimum für das vorliegende Beispiel:
  .Die Gleichungen (5) und (6) zeigen deutlich eine lineare Beziehung der einzusetzenden Faktoren auf. Aus Vereinfachungsgründen wurden in dem zu Grunde liegenden Beispiel lineare Produktionsfunktionen verwendet. So ergibt sich auch für die in Abb. 5 in der Edgeworth-Box zu erkennende Kontraktkurve – für die Verbindungslinie der Tangentialpunkte A bis D – ein linearer Verlauf mit dem Verhältnis 
   als Steigung. Im folgenden Schritt zur Herleitung der Transformationsfunktion wird der Ausdruck der effizienten Kapitalverwendung (5) in die Produktionsfunktion von Gut X (1) gesetzt:
    {\displaystyle X=\left({\frac {K_{g}}{L_{g}}}L_{X}\right)^{1/2}L_{x}^{1/2}=\left({\frac {K_{g}}{L_{g}}}\right)^{1/2}L_{x}}
  .Bezogen auf die vorangestellten Produktionsfunktionen (1) und (2) stellt die Gleichung (9) die dazugehörige Transformationsfunktion dar. Oben stehende mathematische Herleitung ist dabei nur als exemplarisch für die beiden fiktiv angenommenen Produktionsfunktionen und damit für eine spezielle lineare Produktionsmöglichkeitenkurve zu betrachten. Analog der oben angeführten Vorgehensweise – jedoch mathematisch anspruchsvoller – können sowohl eine konkave Transformationskurve wie in Abb. 5 gezeigt, als auch sämtliche individuell verlaufende Kapazitätslinien analytisch hergeleitet werden.
Abschließend sollen mittels eines in der volkswirtschaftlichen Literatur oft verwendeten Standardbeispiels die verschiedenen Aspekte der Produktionsmöglichkeitenkurve noch einmal verständlicher erläutert werden. Im genannten Beispiel wird von einer Modell-Volkswirtschaft ausgegangen, die lediglich zwei Güter – Kanonen und Butter – produzieren kann. Die Erzeugnisse stehen dabei stellvertretend für die Kategorien Konsumgüter und Verteidigungsgüter. Abb. 6 zeigt verschiedene Produktionsmöglichkeiten der betrachteten Volkswirtschaft, so wird die Produktion dahingehend eingeschränkt, dass entweder nur 10 Mio. Stück Kanonen oder 10 Mio. Pfund Butter hergestellt werden können. Dies verdeutlicht die in der Realität bestehende Knappheit von Inputfaktoren. Es muss also eine Entscheidung getroffen werden, ob man einen der Extremfälle – nur Konsumgüter (Butter) bzw. nur Verteidigungsgüter (Kanonen) – wählt, oder etwa eine der zahlreichen effizienten Gütermengenkombinationen auf der Transformationskurve (Pkt. B–D). Darüber hinaus besteht die Möglichkeit, alle ineffizienten Kombinationen unterhalb der Kurve (beispielsweise Pkt. F) zu produzieren. In der vorangegangenen Betrachtung wurde bereits festgestellt, dass eine Entscheidung treffen ferner bedeutet, einen Verzicht im Sinne von Opportunitätskosten in Kauf zu nehmen. Es sei angenommen, in der Ausgangssituation befindet man sich im Anwendungsbeispiel in Punkt B, d. h. es werden 9 Mio. Kanonen und 4 Mio. Pfund Butter produziert. Aufgrund zunehmender Bevölkerungszahlen stellt sich nun ein höherer Bedarf an Lebensmitteln ein – es wird daher entschieden 3 Mio. Pfund mehr Butter herzustellen. Zieht man die Grafik in Abb. 6 zu Hilfe, ist zu erkennen, dass sich Punkt B bereits auf der Kurve befindet, somit alle zur Verfügung stehenden Ressourcen genutzt sind. Um 3. Mio. Pfund mehr von der Butter produzieren zu können, bleibt also nur die Gütermengenkombination in Punkt C, das bedeutet einen Verzicht in Höhe von 2 Mio. Stück Kanonen – dieser Verzicht an Kanonen wird als Opportunitätskosten betrachtet.
Findet eine Bewegung auf der Kurve statt, werden also Mengen des einen Produkts (Kanonen) in Mengen des anderen Produkts (Butter) transformiert. Da die Produktionsmöglichkeitenkurve in Abb. 6 nach außen gekrümmt ist, verändert sich das Transformationsverhältnis von Kanonen in Butter entlang der Funktion. Das Beispiel zeigt damit deutlich das Gesetz des abnehmenden Ertragszuwachses. Während bei einem Wechsel von der Mengenkombination A zu B für einen Verzicht von 1 Mio. Stück Kanonen gleich 4 Mio. Pfund Butter substituiert werden können, bleibt bei einer Veränderung von Punkt D zu E für einen Verzicht von 4 Mio. Stück Kanonen gerade einmal ein Ertrag von 1 Mio. Pfund Butter. Analog der abnehmenden Erträge ändern sich die Alternativkosten.
Sollte das volkswirtschaftliche Ziel sein, die gesamtwirtschaftliche Produktion zu erhöhen, beispielsweise zur Gütermengenkombination im Punkt G zu gelangen, ist dies unter gleichbleibenden Bedingungen nicht realisierbar. In diesem Fall wäre es notwendig, den Input bzw. die Faktorausstattung zu erhöhen. Eine Ausweitung der Produktionskapazitäten durch eine Erhöhung der Produktionsfaktoren Arbeit, Kapital oder Wissen, speziell durch Zuwanderung von Gastarbeitern, Kapitalzufluss aus dem Ausland oder neue technische Forschungserkenntnisse, kann dieses Problem lösen.
Ulrich Brösse: Einführung in die Volkswirtschaftslehre – Mikroökonomie. Oldenbourg, München/Wien 1997, ISBN 3-486-23699-7.
Horst Demmler: Einführung in die Volkswirtschaftslehre. 7. Auflage. Oldenbourg, München/Wien 2001, ISBN 3-486-25623-8.
Gustav Dieckheuer: Internationale Wirtschaftsbeziehung. 5. Auflage. Oldenbourg, München/Wien 2001, ISBN 3-486-25806-0.
Ulrich Fehl, Peter Oberender: Grundlagen der Mikroökonomie. 9. Auflage. München 2004, ISBN 3-8006-3107-5.
Rainer Fischbach: Volkswirtschaftslehre – Einführung und Grundlagen. 8. Auflage. Oldenbourg, München 1994, ISBN 3-486-22792-0.
Gabriele Hildmann: Mikroökonomie – Intensivtraining. In: Volker Drosse, Ulrich Vossebein (Hrsg.): Repetitorium Wirtschaftswissenschaften. 2. Auflage. München 2005, ISBN 3-409-22620-6.
Paul R. Krugman, Maurice Obstfeld:  – Theorie und Politik der Außenwirtschaft. 7. Auflage. München 2006, ISBN 3-8273-7199-6.
Robert S. Pindyck, Daniel L. Rubinfeld:  Mikroökonomie. 5. Auflage. München 2003, ISBN 3-8273-7025-6.
Paul A. Samuelson, William D. Nordhaus: Volkswirtschaftslehre – Grundlagen der Makro- und Mikroökonomie. 8. Auflage. Köln 1987, ISBN 3-7663-0986-2.
Andreas Zenthöfer: Grundlagen der Mikroökonomie. In: H.P. Richter (Hrsg.): Wirtschaftswissenschaftliche Grundkurse. Kiel 2006, ISBN 3-935150-51-2.

Ein Transformator (von lateinisch transformare ‚umformen, umwandeln‘; auch Umspanner, kurz Trafo) ist ein Bauelement der Elektrotechnik. Er besteht meist aus zwei oder mehr Spulen (Wicklungen), die in der Regel aus isoliertem Kupferdraht gewickelt sind und sich auf einem gemeinsamen Magnetkern befinden. Ein Transformator wandelt eine Eingangswechselspannung, die an einer der Spulen angelegt ist, in eine Ausgangswechselspannung um, die an der anderen Spule abgegriffen werden kann. Dabei entspricht das Verhältnis von Eingangs- und Ausgangsspannung dem Verhältnis der Windungsanzahlen der beiden Spulen. So wird zum Beispiel bei einem Windungsverhältnis von 20 zu 1 eine Eingangsspannung von 240 Volt in eine Ausgangsspannung von 12 Volt transformiert. Je nach Auslegung des Transformators kann die Ausgangsspannung somit kleiner, größer oder gleich der Eingangsspannung sein.
Transformatoren dienen vielfach zur Spannungswandlung in Energieversorgungsanlagen und in technischen Geräten, dabei insbesondere in Netzteilen zur Bereitstellung von Kleinspannungen in vielen Arten von elektrischen und elektronischen Geräten. Weiterhin werden sie bei der Signalübertragung und der Schutztrennung benötigt.
Obwohl das Induktionsprinzip seit den Entdeckungen Michael Faradays von 1831 bekannt war, wurde der Transformator erst 44 Jahre später entwickelt. Pawel Nikolajewitsch Jablotschkow entwickelte 1875 eine verbesserte Form der Kohlebogenlampe und verwendete für deren Betrieb Induktionsspulen, die prinzipiell einen Transformator darstellten. Er beschäftigte sich jedoch nicht weiter mit diesen Geräten.
Lucien Gaulard und John Dixon Gibbs stellten 1881 einen Transformator in London aus und 1882 wurde ihnen dafür das englische Patent Nr. 4362 zuerkannt. Der Begriff Transformator war zur damaligen Zeit noch nicht üblich; die Geräte wurden als Sekundär-Generator bezeichnet. Davon leitet sich die bis heute übliche Zuordnung der Transformatoren zum Bereich der elektrischen Maschinen ab. Károly Zipernowsky, Miksa Déri und Ottó Titusz Bláthy (alle drei Ungarn) erhielten 1885 ein Patent auf den Transformator. Dieser war mechanisch nach dem umgekehrten Prinzip der heutigen Transformatoren aufgebaut; die Leiterspulen waren um einen festen Kern aus unmagnetischem Material gewunden, darüber wurden dicke Eisendraht-Lagen gelegt, die eine ferromagnetische Schale bildeten. Dieser Transformator wurde vom Unternehmen Ganz & Cie aus Budapest weltweit vertrieben.
Wesentlichen Anteil an der Verbreitung des Wechselstromsystems und mit ihm des Transformators hatte der Amerikaner George Westinghouse. Er erkannte die Nachteile der damals von Thomas A. Edison betriebenen und favorisierten Energieverteilung mittels Gleichstrom und setzte stattdessen auf Wechselstrom (vgl. Stromkrieg). 1885 erwarb Westinghouse die Patentrechte von Gaulard und Gibbs und importierte eine Anzahl von deren Sekundär-Generatoren sowie einen Generator von Siemens. Damit baute er in Pittsburgh ein Stromnetz mit Wechselspannung für die elektrische Beleuchtung. William Stanley führte im gleichen Jahr als Chefingenieur von Westinghouse in Pittsburgh wesentliche Verbesserungen an Lucien Gaulards und John Gibbs’ Gerät durch.
Westinghouse installierte 1886 in Great Barrington, Massachusetts, einen Wechselspannungsgenerator, dessen 500 V Wechselspannung zur Verteilung auf 3.000 V hochtransformiert und zum Betrieb der elektrischen Beleuchtung an den Anschlussstellen wieder auf 100 V heruntertransformiert wurde. Der wachsende Einsatz von Transformatoren führte in Verbindung mit der Schaffung von Wechselstromnetzen zum weltweiten Fortschreiten der Elektrifizierung.
Michail Dolivo-Dobrowolski entwickelte Anfang der 1890er-Jahre bei der AEG in Berlin den ersten Transformator für dreiphasigen Wechselstrom und führte den Begriff Drehstrom ein. Sein Drehstromtransformator wurde 1891, auf Anregung von Oskar von Miller, für die erste Fernübertragung elektrischer Energie mit Dreiphasenwechselstrom eingesetzt. Die Leitung ging am 24. August 1891 zwischen Lauffen am Neckar und der Internationalen Elektrotechnischen Ausstellung im 175 km entfernten Frankfurt am Main in Betrieb. Die in einem Wasserkraftwerk erzeugte Spannung von 50 V wurde zur Übertragung auf 15 kV hochtransformiert.
Bereits 1888 veröffentlichte der Münchner Elektroingenieur Friedrich Uppenborn ein Buch zur Geschichte des Transformators. Gisbert Kapp erarbeitete bis 1907 die Grundlagen für die Berechnung und den Bau von Transformatoren.
Idealtypisch besteht ein Transformator aus einem magnetischen Kreis, welcher als Transformatorkern bezeichnet wird und  mindestens zwei stromdurchflossene Wicklungen hat. Die der elektrischen Energiequelle zugewandte Wicklung wird als Primärseite bezeichnet. Diejenige, an welcher sich die elektrische Last befindet, wird als Sekundärseite bezeichnet.
Eine Wechselspannung auf der Primärseite des Transformators bewirkt entsprechend dem Induktionsgesetz einen wechselnden magnetischen Fluss im Kern. Der wechselnde magnetische Fluss wiederum induziert auf der Sekundärseite des Transformators eine Spannung (Spannungstransformation).
Ein Wechselstrom in der Sekundärwicklung bewirkt dem Ampèreschen Gesetz entsprechend einen Wechselstrom in der Primärwicklung (Stromtransformation).Bei niedriger Wechselstromfrequenz wird typischerweise ein Eisenkern aus einem ferromagnetischen Material hoher Permeabilität verwendet. Damit können gegenüber Transformatoren ohne Eisenkern hohe magnetische Wechselflussdichten und damit eine wesentlich höhere Windungsspannung erzielt werden, was gewährleistet, dass die übertragbare Leistung groß ist im Vergleich zur Verlustleistung, die durch den ohmschen Widerstand in den Wicklungen entsteht. Einfach ausgedrückt, benötigt ein Transformator mit Eisenkern wesentlich weniger Windungen auf den Wicklungen als ein Trafo ohne Eisenkern.
Zum magnetischen Fluss im Unterpunkt 1 gehört ein Magnetfeld, welches ähnlich wie in einem Elektromagneten einen Stromfluss in der Primärspule bedingt. Der zum Aufbau des magnetischen Feldes benötigte Strom heißt Magnetisierungsstrom. Der Primärstrom, der entsprechend Unterpunkt 2 von der Stromtransformation herrührt, heißt primärer Zusatzstrom. Er fließt zusätzlich zum Magnetisierungsstrom und ist in der Regel als Wirkstrom wesentlich größer als dieser.
Unter einem idealen Transformator versteht man einen in der Praxis nicht realisierbaren, verlustfreien Transformator. Diese Modellvorstellung ist hilfreich bei der Funktionsbeschreibung. In der Praxis treten mehr oder weniger große Abweichungen auf, die Gesetzmäßigkeiten gelten nur näherungsweise.
Beim idealen Transformator sind die Spannungen an den Wicklungen aufgrund der elektromagnetischen Induktion proportional zur Änderungsgeschwindigkeit des magnetischen Flusses und zur Windungszahl der Wicklung. Daraus folgt, dass sich die Spannungen so zueinander verhalten wie die Windungszahlen. Sind N1, N2, U1 und U2 die Windungszahlen beziehungsweise die Effektivwerte der primär- und sekundärseitigen Spannungen, so gilt beim idealen Transformator
  Durch geeignete Wahl der Windungszahlen N1 und N2 können mit einem Transformator Wechselspannungen sowohl hochtransformiert werden, indem N2 größer als N1 gewählt wird, oder heruntertransformiert, wenn N2 kleiner als N1 gewählt ist.
Wird an die sekundäre Wicklung ein Verbraucher angeschlossen, so entnimmt dieser der Sekundärspule elektrische Energie. Dabei kommt ein Strom auf der Sekundärseite zustande und der Primärstrom vergrößert sich. Im Gegensatz zu den Spannungen an den Wicklungen sind die Ströme in den Wicklungen jedoch entgegengesetzt gerichtet: Wenn der Primärstrom bezogen auf den Kern rechtsherum durch die Spule fließt, fließt der Sekundärstrom linksherum und umgekehrt (Lenzsche Regel). Physikalisch lässt sich der gegensinnige Stromfluss mit dem Durchflutungssatz erklären. Dabei wird davon ausgegangen, dass die von der Primärspannung U1 erzeugte Flussdichte B im Kern nur endlich große Werte annimmt und dass die Permeabilitätszahl μr des Kerns sehr groß ist. Unter diesen Umständen wird die magnetische Feldstärke H im Kern so klein, dass sie nahezu vernachlässigbar ist (H → 0), und die Anwendung des Durchflutungssatzes auf einen Integrationsweg entlang des Kernes ergibt:
  .Die gegensinnige Flussrichtung des Stromes wird im Schaltbild durch den aus dem Transformator herausgerichteten Strompfeil I2 gekennzeichnet.
Die Kombination der Gleichungen für die Spannungs- und Stromtransformation zeigt, dass bei einem idealen Transformator die primärseitig zugeführte Energie gleich der sekundärseitig entnommenen Energie ist. Der Transformator führt weder eine Zwischenspeicherung von Energie durch, noch erzeugt er Wärmeverluste. Für die Leistung gilt bspw.:
Ideale Transformatoren sind praktisch nicht realisierbar. Ein realer Transformator unterscheidet sich folgendermaßen vom idealen Transformator:
nicht der gesamte magnetische Fluss, der die Primärwicklungen durchströmt, führt auch durch die Sekundärwicklungen, es treten vielmehr Streuflüsse auf;
die Sättigungseffekte des Kerns führen dazu, dass die Induktivität der Primärwicklungen nicht konstant ist, sondern vom primärseitigen Magnetisierungsstrom abhängt, der sich wiederum beim Durchlaufen der Magnetisierungskurve während einer Spannungshalbschwingung ändert und der beim Erreichen der totalen Eisenkernsättigung hohe Amplituden annehmen kann;
der Kern ändert aufgrund der Magnetostriktion in geringem Maß seine Form, wenn sich das Magnetfeld ändert, was sich z. B. bei 50-Hz-Netztrafos als typisches Netzbrummen akustisch bemerkbar macht (es kann aber auch durch lockere Wicklungen oder Trafobleche verursacht werden).
bei Leerlauf im Sekundärkreis fließt immer ein Magnetisierungsstrom im Primärkreis, der von der Größe des induktiven Blindwiderstandes der Primärtrafospule abhängt und u. U. im Primärdrahtquerschnitt mit berücksichtigt werden sollte.Die Widerstände der Wicklungen, die Ummagnetisierung und die Wirbelströme führen zu Energieverlusten. Die Verluste aufgrund der Widerstände der Wicklungen heißen Kupferverluste, die Verluste durch die Ummagnetisierung heißen Hystereseverluste, und die Verluste aufgrund von Wirbelströmen heißen Wirbelstromverluste. Hystereseverluste und Wirbelstromverluste werden unter dem Begriff Eisenverluste zusammengefasst.
Die Kupferverluste hängen quadratisch von der Belastung des Transformators ab, d. h., sie sind proportional zum Quadrat der Ströme in jeder Wicklung Ix. Die Eisenverluste sind fast unabhängig von der Belastung, aber in etwa proportional zum Quadrat der magnetischen Flussdichte im Kern. Die Hystereseverluste sind außerdem proportional zur Frequenz, die Wirbelstromverluste sind proportional zum Quadrat der Frequenz.Streuflüsse bewirken, dass die Sekundärspannung etwas geringer ist als beim idealen Transformator.
Die Sättigungsmagnetisierung begrenzt die mögliche Betriebsfrequenz nach unten beziehungsweise bei gegebener Frequenz und Windungszahl die mögliche Primärspannung nach oben. Wird die Grenze überschritten und die Sättigung erreicht, fließen primärseitig sehr hohe Ströme, während sekundärseitig die Spannung sehr gering wird. Durch Erhöhung der Primärwindungszahl lässt sie sich jedoch auf Kosten des Wickelraumes und der Zunahme der Kupferverluste im Praxisfall gegebenenfalls verhindern. Die Sekundärwindungszahlen erhöhen sich dann natürlich entsprechend ebenfalls. Die Sättigungsmagnetisierung spielt auch beim Einschalten des Transformators eine wichtige Rolle; der Einschaltstrom kann dabei kurzzeitig ein Vielfaches des Nennstroms betragen.
Wenn an der Sekundärwicklung kein Verbraucher angeschlossen ist, liegt Leerlauf vor. Der Transformator ist unbelastet. Ein verlustloser Transformator im Leerlauf verhält sich wie eine ideale Spule. Wird primärseitig eine sinusförmige Wechselspannung angeschlossen, fließt ein um 90 Grad phasenverschobener Strom, der als Magnetisierungsstrom bezeichnet wird und dem Aufbau des magnetischen Feldes dient. Beim realen Transformator ist die Phasenverschiebung des Leerlaufstroms gegenüber der Primärspannung aufgrund der Eisenverluste kleiner als 90 Grad. Im Leerlauf sind die Eisenverluste aufgrund des nur geringen Eingangsstroms viel größer als die Kupferverluste durch den Leerlaufstrom in der Primärspule.
   im Kern ist der Magnetisierungsstrom, anders als beim verlustlosen Transformator, nicht sinusförmig.Wenn der Transformator sekundärseitig belastet wird, fließt ein Sekundärstrom. Dieser ändert den Fluss im Kern und damit die in der Primärwicklung induzierte Gegenspannung. Um das Spannungsgleichgewicht auf der Primärseite aufrechtzuerhalten, muss diese Flussänderung durch einen primärseitigen Zusatzstrom zusätzlich zum Magnetisierungsstrom kompensiert werden. Es muss sich ein Gleichgewicht zwischen der vom Sekundärstrom erzeugten Durchflutung und der durch den primärseitigen Zusatzstrom bedingten Durchflutung einstellen. Bei Nennlast ist der Primärstrom deswegen viel größer als im Leerlauffall. Bei Belastung sinkt die magnetische Flussdichte geringfügig ab.
Wird die Sekundärseite kurzgeschlossen und der Eingangsstrom auf den Strom bei Nennlast geregelt, muss dazu die Primärspannung reduziert werden. Die so eingestellte Primärspannung wird als Kurzschlussspannung bezeichnet, welche nicht absolut, sondern als prozentuales Verhältnis zur Nennspannung angegeben wird. Bei Leistungstransformatoren beträgt sie zwischen 5 % und 20 %, bei Kleintransformatoren liegt sie zwischen 15 % und 40 %, bei Schweißtransformatoren beträgt sie 100 %.
Transformatoren mit hoher Kurzschlussspannung heißen spannungsweich, solche mit niedriger Kurzschlussspannung heißen spannungssteif. Die Kurzschlussspannung hängt wesentlich von der Konstruktion des Kerns und der Lage der Spulen zueinander ab: hohe Streuflüsse führen zu hohen Kurzschlussspannungen. Siehe auch Streufeldtransformator.
Als Kurzschlussstrom wird jener Strom bezeichnet, der bei sekundärseitigem Kurzschluss und Nennspannung fließt. Er ist viel höher als der Nennstrom und kann den Transformator in kurzer Zeit zerstören. Der Kurzschlussstrom ist umso höher, je niedriger die Kurzschlussspannung ist. Für Transformatoren mit niedriger Kurzschlussspannung sind Kurzschlüsse daher gefährlich. Transformatoren, die so ausgelegt sind, dass sie im Kurzschlussfall nicht zerstört werden, werden als kurzschlussfest bezeichnet. In der Regel werden nur Kleintransformatoren bis zu wenigen VA Leistung, wie zum Beispiel Klingeltrafos, kurzschlussfest ausgelegt. Aber auch große Leistungstrafos müssen zumindest einen kurzfristigen Stoßkurzschlussstrom ohne mechanische Beschädigung durch die auftretenden Lorentzkräfte überstehen können.
Der Wirkungsgrad eines Transformators ist das Verhältnis der elektrischen Leistung, die den Transformator sekundärseitig verlässt, zur Leistung, die primärseitig in ihn hineinfließt. Wegen der Eisen- und Kupferverluste ist er kleiner als 1. Transformatoren hoher Nennleistung haben Wirkungsgrade von mehr als 99 %, während der Wirkungsgrad von Kleintransformatoren (z. B. 100 VA) um 80 % liegt, und Kleinsttransformatoren (1 VA) kaum auf 50 % Wirkungsgrad kommen. Bei höherer Frequenz, z. B. in Schaltnetzteilen, können auch kleine Transformatoren einen hohen Wirkungsgrad erreichen.
Kurzzeitig können Transformatoren stark überlastet werden. Vom Kurzzeit-Betrieb wird zum Beispiel bei Lötpistolen, aber auch bei Elektrolokomotiven Gebrauch gemacht. Transformatoren liefern ein Maximum an Ausgangsleistung bei einem Wirkungsgrad von 50 % (Leistungsanpassung). Im nebenstehenden Diagramm ist dieser Punkt ganz rechts am Kurvenende – der dem Beispiel zugrunde liegende Transformator liefert dort etwa das 2,5fache seiner Nennleistung.
Maschinentransformatoren sind dauernd belastet, sie werden auf maximalen Wirkungsgrad dimensioniert, d. h., dass bei Nennlast Eisen- und Kupferverluste etwa gleich hoch sind.Bei einem Ortsnetztransformator, der im Stromnetz verwendet wird, liegt die mittlere Belastungsdauer nur bei ungefähr 40 % der Einschaltdauer, daher können hier höhere Kupferverluste in Kauf genommen werden, während die Eisenverluste stärker reduziert werden. Solche Transformatoren werden auf ihren Jahreswirkungsgrad optimiert. Damit wird das Verhältnis der insgesamt pro Jahr primär- und sekundärseitig umgesetzten Energiemengen bezeichnet. Der Jahreswirkungsgrad liegt umso höher, je größer das Verhältnis zwischen Belastungs- und Einschaltdauer ist.
Die Netzwerkmodellierung eines Transformators verfolgt das Ziel, die wesentlichen nichtidealen Eigenschaften eines Transformators mit einer geringen Zahl an Parametern zu beschreiben. Das nebenstehende Ersatzschaltbild zeigt eine häufig vorgenommene Modellierung mithilfe von linearen Bauelementen. Dabei haben die einzelnen Bauelemente die folgende Bedeutung:
  : lineare Modellierung der meist nichtlinearen Eisenverluste im Kern (Fe: Eisen)Auf die Modellierung der parasitären Kapazitäten der Wicklungen wurde im abgebildeten Modell verzichtet. Ebenso werden nichtlineare Eigenschaften des Transformators nicht abgebildet.
    {\displaystyle {\frac {{\underline {U}}_{1}}{{\underline {U}}_{2}}}=\gamma {\text{ und }}{\frac {{\underline {I}}_{1}}{{\underline {I}}_{2}}}={\frac {1}{\gamma }}.}
Die Größen, die mit einem zusätzlichen Strich ' gekennzeichnet sind, wurden von der Sekundärseite zur Primärseite transformiert. Bei der Transformation einer Impedanz 
  Die Impedanztransformation bedeutet, dass die Eingangsklemmen eines Transformators für einen elektrischen Schaltkreis wie ein Widerstand 
   wirken, wenn an die Sekundärseite ein Widerstand R angeschlossen wird. Somit können mithilfe eines Transformators Widerstände vergrößert oder verkleinert werden, indem das Windungsverhältnis 
Die Impedanztransformation wird in elektronischen Schaltungen häufig zur Anpassung eines Netzwerkes an den Wellenwiderstand einer Leitung oder zur Leistungsanpassung eingesetzt. Anders als bei gyratorischer Kopplung bleibt bei transformatorischer Kopplung die Struktur des Netzwerkes erhalten, das heißt Reihen- und Parallelschaltungen bleiben erhalten, und induktives und kapazitives Verhalten werden nicht gegeneinander ausgetauscht.
Wenn es auf die galvanische Trennung des Transformators nicht ankommt, kann der ideale Transformator im Ersatzschaltbild nach Transformation aller sekundärseitigen Bauelemente auf die Primärseite entfallen.
Die Speisung mit einer sinusförmigen Eingangsspannung ist typisch für Leistungstransformatoren, wie sie beispielsweise im öffentlichen Stromnetz eingesetzt werden. Die Netzfrequenz in einem Stromnetz ist durch die Umdrehungsgeschwindigkeit der Generatoren vorgegeben. Typische Werte für die Netzfrequenz sind 50 Hz (öffentliches Stromnetz in Europa) und 60 Hz (Stromnetz in den USA). In der Bahnstromversorgung gibt es darüber hinaus auch Netze mit Netzfrequenzen von 16,7 Hz und 25 Hz.
In PC-Netzteilen, Frequenzumrichtern und den Wechselrichtern der Photovoltaik werden in speziellen Schaltnetzteilen Rechteckspannungen mit wesentlich höheren Frequenzen erzeugt und transformiert. Die dabei eingesetzten Transformatoren dienen vorwiegend zur galvanischen Trennung und zur Spannungsanpassung, wobei eine Sättigung des Transformatorkerns vermieden wird.In Sperrwandlern werden zwei magnetisch gekoppelte Spulen mit einem Kern mit Luftspalt als Energiespeicher verwendet. Die über die Primärseite ins magnetische Feld eingebrachte Energie wird nicht sofort entnommen, sondern erst nach Abschalten der Eingangsspannung an der Sekundärseite abgegriffen. Bei rechteckförmigen Eingangsspannungen ergeben sich somit annähernd dreieckförmige Eingangsströme.Bei der Übertragung von Signalen mit einem Transformator ist es wichtig, dass die Signalanteile aller relevanten Frequenzen übertragen werden. Bei Verwendung einer ohmschen Last weist der Transformator ein sogenanntes Bandpassverhalten auf. Bei ungeeigneter Dimensionierung oder falscher Beschaltung kann ein Transformator darüber hinaus ein unerwünschtes Schwingverhalten, eine sogenannte Resonanzüberhöhung, aufweisen.
   zustande. Sie schließt Signale niedriger Frequenzen kurz. Nach oben erfolgt die Begrenzung der Bandbreite im Netzwerkmodell allein durch die Streuinduktivitäten 
  . Ihre Impedanz steigt mit der Frequenz und verhindert auf diese Weise eine Signalübertragung. Bei hohen Frequenzen ist außerdem die kapazitive Kopplung zwischen den einzelnen Windungen relevant.
In der Praxis ist der Frequenzbereich von Transformatoren nach unten vorwiegend durch die erforderliche Größe begrenzt, die mit sinkender Frequenz stark ansteigt. Der typische Frequenzbereich von Niederfrequenztransformatoren reicht bis 16,7 Hz hinunter, der Nennfrequenz für die Bahnstromversorgung. Am oberen Ende des Frequenzbereiches stehen Transformatoren der Hochfrequenztechnik, bei denen die Wicklungen häufig nur noch aus wenigen oder sogar nur einer einzigen Windung bestehen. Die Frequenzspanne handelsüblicher Hochfrequenztransformatoren umfasst einen Bereich von wenigen MHz bis etwa 1 GHz.
Entgegen einer weitverbreiteten Vorstellung findet die Energieübertragung beim Transformator nicht über den Transformatorkern selbst, sondern über das elektromagnetische Feld im umgebenden Medium statt. Der Poyntingvektor, der die Richtung des Energieflusses angibt, steht dabei senkrecht auf den elektrischen Feldlinien, die ringförmig um den Transformatorkern laufen, und den magnetischen Feldlinien des Streufeldes, die durch Primär- und Sekundärströme gebildet werden. Eine Visualisierung der Zusammenhänge findet sich im Artikel von Herrmann und Schmid. Die Darstellung zeigt, dass sich sowohl in elektrischen Stromkreisen, als auch in magnetischen Kreisen die Energie nie in den Leitungen selbst, sondern immer entlang der Leitungen bewegt.
Da die Energieübertragung mittels des Transformator-Streufeldes geschieht, steht die Vorstellung eines idealen Transformators ohne Streufeld streng genommen im Widerspruch zu den maxwellschen Gleichungen. Im American Journal of Physics formuliert Newcomb diesen Zusammenhang folgendermaßen:
In der Zeitschrift Praxis der Naturwissenschaften – Physik in der Schule (PdN-PhiS) empfiehlt Herrmann im Zusammenhang mit der Energieübertragung beim Transformator, das Feld zwischen den Schenkeln eines Transformators nicht als Streufeld zu bezeichnen, da es für den Energietransport wichtig sei. Beim Transformator solle darüber hinaus nicht nur das Feld der magn. Flussdichte, sondern auch das Feld der magnetischen Feldstärke diskutiert werden und bei möglichst vielen Gelegenheiten die Frage nach dem Weg der Energieübertragung gestellt werden.
Einschaltvorgänge und Netzstörungen bewirken besonders starke Abweichungen des Transformatorverhaltens vom idealen Verhalten. Beide Vorgänge können den Transformatorkern sättigen und zu beträchtlichen Überströmen führen.
Entsprechend dem Induktionsgesetz entscheidet allein der Verlauf der Eingangsspannung, ob bei einem Transformator Sättigungserscheinungen auftreten oder nicht. Der Belastungszustand spielt keine wesentliche Rolle; selbst ein Kurzschluss auf der Sekundärseite führt nicht zur Sättigung.Bei einer typischen Netzstörung im 230-V-Netz fallen vereinfacht betrachtet einzelne oder mehrere Spannungshalbwellen beziehungsweise Teile davon aus. Der Transformator reagiert auf das Ausfallen der Netzhalbwelle mit einem großen Sättigungsstrom in der darauf folgenden Halbwelle. Den wesentlichen Beitrag zur Kernsättigung liefert die Vormagnetisierung des Kerns, die durch die Störung der Eingangsspannung verursacht wird.
Beim Abschalten oder Ausfall der Spannung verharrt der Magnetisierungszustand des Kerns in dem Remanenzpunkt, der der Magnetisierung im Abschaltzeitpunkt am nächsten liegt. Abhängig von Polarität und Phasenlage der wiederkehrenden Netzspannung kann das dazu führen, dass ausgehend von diesem Remanenzpunkt der verbleibende Induktionshub bis zur beginnenden Sättigung kleiner ist als die Zeitfläche der wiederkehrenden Spannungshalbwelle. Die durch die Zeitfläche der wiederkehrenden Halbwelle erzwungene Flussänderung im Kern treibt diesen in die Sättigung, wobei große Magnetisierungsströme benötigt werden.
Der ungünstigste Fall für einen Luftkern ist das Einschalten einer vollen Halbwelle, was zum 2-fachen Magnetisierungsstrom des Nennwertes führt. Der ungünstigste Fall für einen Ringkern ist das Einschalten, wenn die Remanenz bei 
   liegt und die Polarität der wiederkehrenden Spannung identisch ist mit der vor dem Abschalten. Diesen Verlauf zeigt die untere Prinzipskizze. Der Magnetisierungsstrom ist in diesem Fall im Wesentlichen nur noch durch die Restinduktivität und durch den ohmschen Widerstand der Primärspule und die Impedanz der Netzzuleitung begrenzt. Er kann demnach extreme Werte annehmen, weil der Transformatorkern restlos gesättigt ist und keine Magnetflussänderung mehr aufnehmen kann. Die Sättigungsmagnetisierung spielt auch beim Einschalten des Transformators eine wichtige Rolle; der Einschaltstrom kann dabei kurzzeitig ein Vielfaches des Nennstromes betragen.
Diese Einschaltvorgänge klingen in jedem Fall im Verlauf einiger Halbwellen ab, da aufgrund der Asymmetrie der Magnetisierungsströme auch die beiden gegenpoligen Spannungshalbwellen mit unsymmetrischen Spannungsabfällen behaftet sind. Das hat zur Folge, dass in der Sättigungshalbwelle stets etwas weniger Spannung zur Aufmagnetisierung zur Verfügung steht als bei der dazu gegenpoligen Spannungshalbwelle die zur Abmagnetisierung führt. Dadurch zentriert sich der Magnetisierungs-Schleifendurchlauf selbsttätig nach einigen Netzperioden, wobei die Zeitkonstante dafür aus dem Quotienten der Induktivität dividiert durch die Ohmschen Widerstände im Stromkreis errechnet werden kann. Bei sehr großen Transformatoren kann diese Zeitkonstante deshalb einige Minuten betragen.
Schlienz gibt als Zahlenwert für einen daraufhin optimierten 1,6-kVA-Transformator (230 V), der mit 1 kW belastet wird, einen Strom von 200 A aufgrund der Sättigung an. Im Vergleich dazu fließen im Normalbetrieb weniger als 10 A.
In der Energietechnik verbinden Transformatoren die verschiedenen Spannungsebenen des Stromnetzes miteinander. Maschinentransformatoren sind noch Teil der Kraftwerke und transformieren die im Generator induzierte Spannung zur Einspeisung in das Stromnetz in Hochspannung (in Westeuropa 220 kV oder 380 kV). Umspannwerke verbinden das überregionale Höchstspannungsnetz mit dem Mittelspannungsnetz der regionalen Verteilnetze. In Transformatorenstationen wird die Elektrizität des regionalen Verteilnetzes mit der Mittelspannung von 10 bis 36 kV zur Versorgung der Niederspannungsendkunden auf die im Ortsnetz verwendeten 400-V-Leiter-Leiter-Spannung transformiert. Wegen der hohen übertragenen Leistungen heißen die in der Stromversorgung verwendeten Transformatoren Leistungstransformatoren.
Leistungstransformatoren sind meist Drehstromtransformatoren, die entweder mit Transformatorenöl gefüllt oder als Trockentransformatoren ausgeführt sind. Für erstere gilt in der EU die Norm IEC (EN) 60076-1, für letztere die Norm IEC (EN) 60076-11. Parallel zu den EU-Normen existiert die IEEE-Normenreihe C57.Insbesondere in ringförmigen und mehrfach gespeisten Verteilnetzen ist es üblich, die übertragbare Leistung durch Parallelschaltung von Transformatoren zu erhöhen. Die hierzu eingesetzten Transformatoren haben gleiche Spannungsübersetzung, eine identische Schaltgruppe, nahezu gleiche Kurzschlussspannung und ähnliche Bemessungsleistungen. Das Übersetzungsverhältnis kann bei Drehstromtransformatoren, je nach Schaltgruppe, auch einen komplexen Wert annehmen, d. h., neben dem Betrag der Ausgangsspannung ändert sich auch deren Phasenlage. Zur Steuerung werden direkt in das Transformatorgehäuse Stufenschalter integriert.
Es kann zur Steuerung des Leistungsflusses notwendig sein, in räumlich ausgedehnten Verteilnetzen mit mehreren parallelen Leitungen mit unterschiedlichen Übertragungsleistungen (auch bei parallel zu Freileitungen betriebenen Kabelsystemen) spezielle Phasenschiebertransformatoren einzusetzen.
Das Transformatorprinzip findet in der Energietechnik auch in Stromwandlern Anwendung. Mit diesen werden hohe Stromstärken gemessen, indem der Strom zunächst heruntertransformiert wird. Stromwandler bestehen oft aus einem Ringkern mit Sekundärspule, der den Leiter umschließt, dessen Strom gemessen werden soll. Rogowskispulen sind wie Stromwandler aufgebaut, besitzen jedoch keinen magnetischen Kern.
Ein Tokamak, ein Kandidat für die Auslegung zukünftiger Fusionskraftwerke und Gegenstand aktueller Forschung, funktioniert ebenfalls nach dem Transformatorprinzip. In einem ringförmigen Vakuumgefäß wird eine Gasentladung herbeigeführt, indem in Leitern (Poloidalfeldspulen), die in Ringrichtung um das Gefäß angeordnet sind, der Strom langsam erhöht wird. Die Spulen bilden dabei die Primärwicklung, während das Gas im Vakuumgefäß die Sekundärwicklung darstellt.
In Elektrogeräten, die nicht direkt mit Netzspannung arbeiten, wandeln Transformatoren die an der Steckdose anliegende Netzwechselspannung von typischerweise 230 V auf die Betriebsspannung des Elektrogeräts um.
Netzteile von Elektrogeräten enthalten entweder einen konventionellen Netztransformator, welcher mit Netzfrequenz und primärseitig (prinzipiell) direkt am Stromnetz betrieben wird, oder ein Schaltnetzteil, welches den Transformator mit einer höheren Frequenz als der Netzfrequenz betreibt. Schaltnetzteile sind heute weit verbreitet, konventionelle Netztransformatoren eher selten anzutreffen. Eine höhere Frequenz anstelle der Netzfrequenz ermöglicht bei gleicher Leistung einen wesentlich kleineren und damit leichteren Transformator und kleinere Tiefpass-Siebglieder zur Glättung der vom entsprechenden Gerät benötigten Gleichspannung.
Sicherheitstransformatoren liefern sekundärseitig eine Kleinspannung, z. B. 6 V, 12 V oder 24 V. Sie müssen kurzschlussfest sein und die Isolation der Sekundär- von der Primärwicklung muss durch eine Zwischenwand aus Isolationsmaterial sichergestellt werden. Zu den Sicherheitstransformatoren gehören Spielzeugtransformatoren wie beispielsweise Transformatoren für den Betrieb von Modelleisenbahnen und Klingeltransformatoren. Trenntransformatoren dienen primär dazu, eine galvanische Trennung zwischen Primär- und Sekundärseite zu erreichen. Sie sind daher meist symmetrisch aufgebaut, d. h., die Primärspannung entspricht der Sekundärspannung. Ist eine galvanische Trennung nicht erforderlich, können Netztransformatoren in speziellen Fällen ohne galvanische Trennung als so genannte Spartransformatoren ausgeführt sein.
Ältere Fernsehgeräte oder Computermonitore mit Kathodenstrahlröhre enthalten einen Zeilentransformator, mit dem neben der Versorgung der Zeilen-Ablenkspulen auch die für die Beschleunigung der Elektronen erforderliche Spannung (20–30 kV) erzeugt wird. Mittelfrequenztransformatoren sind für Frequenzen von einigen Hundert Hertz bis zu einigen Kilohertz ausgelegt. Sie werden beispielsweise beim Widerstandsschweißen eingesetzt.
Transformatoren mit Primärspannungen bis 1000 V unterliegen in Deutschland der ersten Verordnung zum Geräte- und Produktsicherheitsgesetz, welche die europäische Niederspannungsrichtlinie umsetzt. Sie müssen die Norm EN 61558 erfüllen, was mit der CE-Kennzeichnung dokumentiert wird. Ein Transformator mit CE-Kennzeichnung kann ohne weitere Kontrollen und Prüfungen innerhalb der EU in den Verkehr gebracht werden.
Nur selten wird ein Transformator mit der Zielsetzung verwendet, einen möglichst großen Sekundärstrom zu erzeugen (wobei dann die Sekundärspannung nachrangig ist). Dies geschieht zum Beispiel beim Elektroschweißen.
Übertrager und Pulstransformatoren sind Transformatoren, die nicht auf verlustarme Energieübertragung, sondern auf möglichst unverfälschte Transformation von Signalen optimiert sind. Jedoch gibt es auch Trafos, die z. B. zur Thyristorzündung genutzt werden, die aus Rechtecksignalen mit einigen Zusatzbauelementen, wie R-C-Dioden-Beschaltungen, kurze Zündnadelimpulse formen. Übertrager werden im Niederfrequenzbereich mit Eisenkern, bis in den Megahertzbereich mit Ferrit- oder Eisenpulverkern und ab einigen 100 kHz oft auch als Lufttransformatoren gefertigt. Sie dienen der Impedanzanpassung und/oder der galvanischen Trennung der Signalstromkreise.
In der Messtechnik werden Transformatoren zur Impedanzwandlung eingesetzt. In der Tontechnik spielen sie in jeder Stufe der Signalverarbeitung eine Rolle, so in Mikrofonen, DI-Boxen, Verstärkern und Lautsprechern. In ELA-Anlagen werden die Audiosignale meist per 100-Volt-Technik fast verlustfrei über längere Leitungen übertragen und erst direkt am Lautsprecher wieder durch einen Transformator an die Impedanz des Lautsprechers angepasst. Über die oft vorhandenen Anzapfungen der Primärwicklung lässt sich die Lautstärke (Leistung) in groben Schritten (oft 6 W, 3 W und 1,5 W) einstellen.
Bei der Signalübertragung dienen Transformatoren bis in den dreistelligen MHz-Frequenzbereich zur Gleichtaktunterdrückung. Typische Beispiele für Gleichtaktsignale, die gefiltert werden sollen, sind Spannungen, die mit gleichem Vorzeichen an beiden Übertragungsleitungen anliegen. Da Transformatoren ausschließlich die Differenz der an beiden Klemmen anliegenden Spannungen registriert, werden Gleichtaktstörungen nicht über den Transformator übertragen. In der Audiotechnik kann man auf diese Weise die sogenannten Brummschleifen verhindern. In gestörten Messumgebungen blockieren Transformatoren Störungen auf den Übertragungsleitungen, die beispielsweise durch Motoren oder Schaltnetzteile verursacht werden.
Auch in den Bandpässen der Zwischenfrequenzverstärker, z. B. für 455 kHz oder 10,7 MHz, befinden sich häufig Spulenanordnungen – oft auch noch mit Anzapfungen, die wie kleine (Spar-)Transformatoren magnetisch gekoppelt sind und die unterschiedlichen Ein- und Ausgangsimpedanzen der Transistoren anzupassen haben.
Ein ähnliches Ziel verfolgt die Symmetrische Signalübertragung, bei der ein zu übertragendes Wechselspannungssignal doppelt übertragen wird: Eine Leitung überträgt das Originalsignal, während eine zweite Leitung das mit (−1) multiplizierte Signal überträgt. Zur Generierung des Signalpaars aus einem unsymmetrischen, auf Erde bezogenen Signal wird typischerweise ein Transformator mit Mittelanzapfung verwendet. Zur Wandlung oder Rückwandlung kann auch eine auf Operationsverstärkern oder Transistoren basierende elektronische Schaltung verwendet werden.
Der Weltmarkt für Transformatoren hat ein Jahresvolumen von ungefähr 10 Milliarden Euro. Er wird bisher von europäischen Gesellschaften dominiert, die jedoch zunehmend von asiatischen Unternehmen herausgefordert werden. Der größte Absatzmarkt ist China mit ungefähr 25 % des Weltmarktvolumens, gefolgt von den USA, Japan und Deutschland. In reifen Märkten wie Europa oder den USA spielen Betriebskosten und energetischer Wirkungsgrad für die Absatzchancen eines Produktes eine große Rolle, während in jüngeren Märkten wie China verstärkt über den Preis verkauft wird.China ist auch der größte Transformatorproduzent der Welt: 90 % der dort verkauften Transformatoren werden in diesem Land gebaut, die meisten davon von ausländischen Gesellschaften. Die weltweit führenden Hersteller von Transformatoren sind ABB und Alstom. Weitere große europäische Hersteller sind Areva, Siemens und die 2005 von Siemens übernommene VA Technologie. Die führenden Anbieter der USA sind Cooper Industries, General Electric.
Transformatoren gibt es von Daumennagelgröße für die Übertragung von weniger als einem Tausendstel Voltampere (VA) (zum Beispiel für Bühnenmikrophone) bis hin zu großen Einheiten mit einem Gewicht von mehreren 100 Tonnen, die für die Kopplung nationaler Stromnetze verwendet werden und für Leistungen im Bereich von mehreren Millionen Voltampere ausgelegt sind. Sie werden für zahlreiche verschiedene Zwecke eingesetzt. Entsprechend vielfältig fällt die Ausführung der Wicklungen, des Transformatorkerns und der Montage- und Befestigungselemente aus. Zur Abführung der Verlustwärme großer Leistungstransformatoren können zusätzlich bei Luftkühlung Rippenkühlkörper mit oder ohne Lüfter bzw. Kühlflüssigkeitsbehälter mit Isolieröl zum Einsatz kommen.
Aus dem Induktionsgesetz folgt für sinusförmige Spannungen die als Transformatorenhauptgleichung bezeichnete Beziehung:
    {\displaystyle U_{\mathrm {eff} }={{\sqrt {2}}\cdot \mathrm {\pi } \cdot B_{\mathrm {max} }\cdot A\cdot f\cdot N}\!\approx 4{,}44\cdot B_{\mathrm {max} }\cdot A\cdot f\cdot N}
Die Transformatoren­hauptgleichung verbindet grundlegende Parameter eines Transformators. Die maximale magnetische Flussdichte 
   ist durch die Sättigungsmagnetisierung des Kernmaterials begrenzt. Bei gegebenen Werten der Ausgangsspannung 
   aus Querschnittsfläche des Kerns und Windungszahl festgelegt. Diese beiden Parameter bestimmen wesentlich den Raum- und Materialbedarf eines Transformators.
Wird bei gleicher Ausgangsspannung die Betriebs­frequenz erhöht, erniedrigt sich entsprechend das Produkt 
  . Wird etwa ein Transformator bei 5 kHz statt bei 50 Hz betrieben, so kann das Produkt aus Windungszahl und Kernquerschnitt um einen Faktor 100 kleiner gewählt werden, was eine entsprechende Verkleinerung des Transformators bedeutet. In der Praxis wird dieses nicht ganz ausgenutzt, da sich mit höherer Frequenz auch die Hysterese­verluste nach der Steinmetzformel vergrößern und deswegen bei höheren Frequenzen auch 
Höhere Betriebsfrequenzen führen also zu einem geringeren Raum- und Materialbedarf und damit auch zu einem geringeren Gewicht. Dieses ist der Grund für die geringere Baugröße von Schaltnetzteilen.
Die maximale Betriebsspannung hat auch einen kleinen Einfluss auf den Raumbedarf. Da der Kupfer-Füllfaktor aufgrund der Isolation bei steigender Speisespannung sinkt, sind Transformatoren bei gleicher Übertragungsleistung umso größer, je höher die zu verarbeitenden Spannungen sind. Die Stromdichte in den Wickeldrähten kann bei kleinen Transformatoren höher sein als bei großen, denn die Wärme kann bei jenen besser entweichen. Dementsprechend haben kleinere Transformatoren (und solche für geringere Übertragungsleistungen) üblicherweise einen kleineren Wirkungsgrad.
Als Leitermaterial für die Wicklungen wird meist massiver Kupferdraht verwendet. Große Querschnitte werden in Einzelleiter aufgeteilt (Roebelstab), die gegeneinander isoliert sind und zyklisch vertauscht werden. Weiterhin kommen Folie, Band aus Weichkupfer oder Hochfrequenzlitze zum Einsatz. Bänder, Folien von Schaltnetzteiltransformatoren und Drähte von Großtransformatoren bestehen häufig aus Aluminium. Folien haben häufig nur reine Schirmfunktionen.Zur Isolierung hat der Draht eine Kunstharz-Lackierung (Kupferlackdraht) oder – früher – auch eine Umspinnung. Die dünnere Lackschicht hat ein höheres Isoliervermögen und erlaubt eine kompaktere Wicklung, als es mit umsponnenen Drähten möglich war. Relativiert wird dies bei nachfolgendem Tränken des Transformatorwickels oder beim Betrieb in Isolieröl (Transformatorenöl).
Um die Spannung zwischen benachbarten Windungen nicht allzu hoch werden zu lassen, werden Lagenisolationen eingebracht oder der Draht wird beim Wickeln in mehrere nebeneinanderliegende Kammern verlegt. Eine weitere Methode, die Spannungsfestigkeit zu erhöhen, sind Folien-Wickel. Sie werden teilweise bei Schaltnetzteil-Transformatoren, aber auch bei Großtransformatoren verwendet.
Konstruktives Ziel ist eine möglichst kompakte Wicklung, um in einem durch den Kern gegebenen Wickelquerschnitt möglichst viel Kupfer oder Aluminium unterbringen zu können. Die Art der Isolierung begrenzt die mögliche Betriebstemperatur nach oben (siehe Isolierstoffklasse). Eine kompakte, möglicherweise getränkte Wicklung verbessert auch die Wärmeableitung aus dem Inneren.
Ein Spulenkörper (englisch coil former oder bobbin) hilft, die Wicklung in der passenden Form herzustellen und bietet zusätzliche Isolation zum Kern oder zu Nachbarwicklungen (Mehrkammer-Spulenkörper). Spulenkörper sind meist aus Kunststoffspritzguss und besitzen oft eingespritzte Kontaktstifte oder Führungen für ein- und auslaufende Wicklungsenden. Damit ist auf einer automatischen Wickelmaschine eine geordnete Wicklung möglich.
In einigen Fällen ist ein Spulenkörper zu teuer oder er schränkt den Wickelraum zu stark ein. Dann wird ein selbsttragender Wickel hergestellt und auf dem Kern mit Keilen oder anderen Zwischenlagen befestigt. Nur selten wird direkt auf die Schenkel des Transformatorkerns gewickelt, da solche Wicklungen maschinell schwer herzustellen sind und nur eine geringe Spannungsfestigkeit gegenüber dem Kern aufweisen.
Bei Netztransformatoren mit nur einer Wickelkammer ist die Primärwicklung meist zuunterst gewickelt – bei niedrigeren Ausgangsspannungen schützt so der meist dickere Draht der Sekundärwicklung den dünnen Draht der Primärwicklung. Bei hoher Ausgangsspannung wird durch diesen Wicklungsaufbau die Isolation zum Kern erleichtert. Das Übereinanderwickeln von Primär- und Sekundärspule wird auch Mantelwicklung genannt.
Bei Sicherheitstransformatoren sind Primär- und Sekundärwicklung in getrennten Kammern des aus Isolierstoff bestehenden Wickelkörpers untergebracht, um sie sicher voneinander zu isolieren.
Mehrkammer-Wickelkörper: senkt die Lagenspannung und verringert die Eigenkapazität der Wicklung; bessere Isolation auch bei nicht getränkten Wickeln
verschachtelte Wicklungen: Audio-Transformatoren (Übertrager und Ausgangstransformatoren) haben oft unterteilte, ineinandergreifende Primär- und Sekundärwicklungen, um die Streuinduktivität zu verringern und so die Übertragung hoher Frequenzen zu verbessern.Netz- und Signaltransformatoren besitzen eine Schirmwicklung, wenn der Ableitstrom unterbunden werden soll, der ohne Schirm von der Primärseite zur Sekundärseite durch kapazitive Kopplung der Wickel gelangt. Dieser Schirm ist an Masse angeschlossen und dient zur Verringerung der kapazitiven Kopplung zwischen Primär- und Sekundärwicklung. Der Schirm besteht aus einer einlagigen Drahtwicklung oder aus Folie, die nur an einem Ende angeschlossen ist. Die Schirmwicklung darf keine elektrisch geschlossene Schleife darstellen, weshalb die Überlappung der beiden Folienenden elektrisch isoliert sein muss. Dieser Schirm kann bei sogenannten Störschutztransformatoren auch aus hochpermeablem Material bestehen. Damit wird der Übergang von hochfrequenten Störungen zur Sekundärseite gedämpft.
Ein Transformator kann statt einer einzelnen auch mehrere getrennte Sekundärwicklungen für unterschiedliche Spannungen oder für getrennte Stromkreise haben.
Häufig wird die Wicklung mit Tränk- oder Gießharz fixiert. Dadurch verbessern sich die Isolation, die Wärmeableitung und die mechanische Festigkeit; das Brummen des Transformators wird reduziert und die Gefahr, dass Feuchtigkeit eindringt, wird geringer. Besonders Schaltnetzteil- und kleine Hochspannungstransformatoren werden unter Vakuum getränkt oder beim Verguss entlüftet. Dadurch werden Lufteinschlüsse beseitigt, die andernfalls zu lebensdauerverringernden Teilentladungen führen.
Die Primärwicklung kann mehrere Anzapfungen haben; damit ist ein solcher Transformator für unterschiedlich hohe Primärspannungen geeignet, wobei dennoch auf gleiche Ausgangsspannungen transformiert wird. Ein Transformator, der sowohl für den amerikanischen (120 V) als auch den europäischen Markt (230 V) einsetzbar sein soll, kann z. B. mit einer Anzapfung der Primärwicklung am Netztransformator und einem Umschalter versehen sein. Oft werden hierzu jedoch zwei Wicklungen für je 120 V aufgebracht, die wahlweise parallel oder in Reihe geschaltet werden können. Dabei kann man die geringe Spannungsabweichung zugunsten des geringeren Kupferbedarfes meistens in Kauf nehmen.
Auch die Sekundärwicklung kann Anzapfungen besitzen, um den Transformator zum Beispiel an unterschiedliche Belastungsfälle anzupassen oder mehrere Spannungen mit gleichem Bezug zu erzeugen. Die Anzapfungen können unter Last mit speziellen Lastschaltern je nach Erfordernis (Spannungs- oder Leistungsänderung) frei gewählt werden, beispielsweise bei elektrischen Lichtbogenöfen oder Bahnfahrzeugen. Eine Stromunterbrechung wird dabei durch kleine Hilfs-Stelltransformatoren vermieden.
Wird die Wicklung der Sekundärseite nach der Hälfte der Gesamtanzahl der Windungen aufgetrennt und nach außen geführt, so wird dies als Mitten- oder Mittelanzapfung bezeichnet. So stehen drei Spannungen im Verhältnis 1:1:2 zur Verfügung. Solche Transformatoren werden als Treiber- oder Ausgangsübertrager von Gegentaktendstufen sowie zur Speisung einer Zweiwege-Gleichrichtung eingesetzt. Eine solche Mittelanzapfung kann man auch schaffen, indem man zwei Wicklungen mit gleicher Anzahl von Windungen auf die Sekundärseite aufbringt und diese polrichtig in Reihe schaltet. Dadurch erhält man zwei gleiche Spannungen, die sich addieren.
Bei Stelltransformatoren kann ein beweglicher Gleitkontakt jede einzelne Windung der Ausgangswicklung kontaktieren, wodurch eine stufenlose Einstellung der Ausgangsspannung ermöglicht wird.
Der Transformatorkern besteht je nach Einsatzgebiet des Transformators aus Eisen oder aus Ferriten. Einige Transformatoren haben überhaupt keinen Kern; diese bezeichnet man als Lufttransformatoren. Ferromagnetisches Material im Spulenkern hat eine wesentlich bessere magnetische Leitfähigkeit als Luft und erlaubt so einen stärkeren magnetischen Fluss, hat aber die Eigenschaft, ab bestimmten magnetischen Flussdichten zu sättigen. Bei Sättigung reduziert sich die magnetische Leitfähigkeit, was zu einem nichtlinearen Übertragungsverhalten führt.
Wirtschaftlich größte Bedeutung haben Eisenlegierungen und ferromagnetische Stähle. Für Transformatoren (Betriebsfrequenz 50 Hz oder 60 Hz) verwendet man überwiegend sogenanntes Dynamoblech nach DIN EN 10107, das aus Eisen-Silizium-Legierungen besteht. Bei Signalübertragern werden auch Nickel-Eisen-Legierungen eingesetzt. Die maximale Flussdichte liegt bei Eisen je nach Spezifikation bei 1,5 bis 2 Tesla.
Der Kern wird aus einem Stapel aus einzelnen Blechen aufgebaut, zwischen denen elektrisch isolierende Zwischenschichten liegen, wobei die Blechfläche parallel zur Richtung des magnetischen Flusses und damit senkrecht zum induzierten elektrischen Feld ist. Dadurch werden die Wirbelstromverluste reduziert. Je höher die Frequenz ist, desto dünner müssen die Bleche gewählt werden. Eine Beschädigung der Isolierung der einzelnen Blechpakete kann bei großen Transformatoren zu einer erheblichen lokalen Erwärmung des Paketes führen.
Ab Frequenzen im Kilohertzbereich würden die Wirbelstromverluste bei Eisenkernen auch bei sehr dünnen Blechen zu groß. Es werden Kerne aus amorphen oder nanokristallinen Bändern oder Ferritkerne verwendet. Ferrite haben eine hohe Permeabilität, aber nur eine geringe elektrische Leitfähigkeit. Zur Herstellung von Ferritkernen wird das meist pulverförmige Ausgangsmaterial in eine Form gegeben und unter Druck gesintert (gepresst). Hierdurch ergeben sich mehr Gestaltungsmöglichkeiten als bei den Blechpaketen, insbesondere bei der Anpassung an den Spulenkörper. Bei Ferriten liegt die maximale Flussdichte bei etwa 400 mT. Die Grenze zur Verwendung von Ferritmaterial liegt in der Herstellbarkeit im Press- und Sinterprozess. Kerne für größere Trafos werden teilweise aus Ferritblöcken zusammengesetzt. Die amorphen und nanokristallinen Kerne erlauben durch ihre natürliche Banddicke von typ. 0,02 mm die Verwendung bei höheren Frequenzen und haben sehr geringe Verluste. Typische Kernformen für diese Bänder sind Ringkerne oder seltener Schnittbandkerne.
Der Querschnitt des Kerns wird aus wirtschaftlichen Gründen im Bereich der Energietechnik (16…60 Hz, geblechter Eisenkern) im Verhältnis zur Windungszahl der Primärwicklung, der Betriebsspannung und der Frequenz meist so gewählt, dass die Flussdichte bei der maximal zulässigen Spannung und dabei im Leerlaufbetrieb nahe an die zulässige magnetische Sättigungsflussdichte kommt.
Bei Ferritkernen und höheren Frequenzen ist das nicht möglich, weil die Verluste dann zu hoch wären. Die Aussteuerung liegt hier oft nur bei einem Zehntel der Sättigungsflussdichte.
Bei einem Ringkerntransformator ist ein vergleichsweise hoher Wirkungsgrad bei kleiner Baugröße möglich. Dafür ist das Wickeln der Spule aufwendiger. Ringkerne bestehen aus Blechband, Pulver oder Ferriten. Ringkerntransformatoren haben bei homogen über den Umfang verteilten Wicklungen nur ein sehr geringes Streufeld und entsprechend geringe Streuinduktivität.
Bei Schnittbandkernen versucht man, die Vorteile von leicht herstellbaren Drahtwickeln mit den Vorteilen eines aus Band gewickelten Kernes zu vereinen. Zur Herstellung eines Schnittbandkerns wird ein Blechband (Dicke 0,025–0,3 mm) auf einen Dorn mit rechteckigem Querschnitt aufgewickelt und verklebt. Anschließend wird der Wickel in der Mitte quer zerteilt und die Trennflächen werden poliert. Schließlich werden die Hälften in die bewickelten Spulenkörper gesteckt und verklebt. Für Schnittbandkerne werden auch texturierte Blechbänder eingesetzt.
Schnittbandkerne haben aufgrund ihrer Restluftspalte eine kleinere Remanenz als Ringkerntransformatoren und damit kleinere Einschaltströme als diese. Durch die beiden Rest-Luftspalte im Kern und dessen rechteckige Form ist die Materialausnutzung jedoch nicht so hoch wie beim Ringkerntransformator. Schnittbandkerne haben dennoch ähnlich gute Eigenschaften wie Ringkerne, die Wicklungsherstellung ist gegenüber jenen einfacher, die Schnittbandkern-Herstellung ist jedoch gegenüber anderen Kernbauformen etwas teurer.
Es wird zwischen Mantelbauform und Kernbauform unterschieden. Bei der Einphasenausführung eines Manteltransformators befinden sich beide Windungen auf dem Mittelschenkel, entweder nebeneinander oder übereinander. Der Mittelschenkel ist in dieser Bauform durch zwei Außenschenkel ergänzt, welche je den halben Querschnitt des Mittelschenkels aufweisen, und keine Windungen tragen. Die Mantelbauform wird beispielsweise aus wechselseitig geschichteter Stapeln aus Blechen in E- und I-Form gebildet, daraus folgt die Bezeichnung EI-Kern. Eine weitere Möglichkeit sind sogenannte M-Bleche, die die gesamte Mantelform bilden und zur Montage einen Trennschnitt am Ende des Mittelschenkels haben.
Bei der Kernbauform fehlt der Mittelschenkel, der Kern bildet in Seitenansicht die Form eines Rechtecks und weist einen einheitlichen Querschnitt auf. Die Windungen befinden sich im Regelfall getrennt auf den beiden Außenschenkeln, können aber auch gemeinsam auf einem Schenkel angebracht sein. Die Kernbauform wird beispielsweise durch wechselseitig geschichtete Stapel aus Blechen in der Form eines U und I gebildet, daraus folgt die Bezeichnung UI-Kern. Eine weitere Möglichkeit sind LL-Bleche - hier wird für die Zweischenkelbauweise nur eine Blechform benötigt.
Insbesondere bei Ferritkernen gibt es eine Vielzahl von Bauformen, unter anderem besonders flache Ausführungen für eine bessere Wärmeableitung und solche mit zylindrischem Mittelschenkel für ein leichteres Bewickeln des Spulenkörpers. Schalen- bzw. Topfkerne weisen geringe Streufelder auf. RM-Kerne und EP-Kerne sind eine Mischform aus EE-Kern und Schalenkern.
Im Regelfall ist, um die gespeicherte Energie im Kern gering zu halten, kein Luftspalt im Kern gewünscht. Man schichtet daher Bleche wechselseitig oder poliert die Grenzflächen der Kernhälften. Manche Transformatorkerne dienen jedoch der Zwischenspeicherung magnetischer Energie wie beim Sperrwandler. Dies kann durch einen Luftspalt im magnetischen Kreis erreicht werden, in dem ein wesentlicher Teil der magnetischen Feldenergie gespeichert wird. Der Feldstärkebedarf und damit der Magnetisierungsstrom steigen, die Kennlinie wird geschert beziehungsweise linearisiert. Die im Luftspalt gespeicherte magnetische Energie vergrößert die Blindleistung, wird jedoch fast verlustfrei wieder abgegeben. Die Remanenz im Kern liegt wegen der Scherung der Magnetisierungskennlinie nahe bei der Induktion Null.
Luftspalte im Kern werden auch bei Gleichstrom-Anteilen im Primärstrom wie bei Ausgangsübertragern benötigt. In sehr einfachen Schweißstromquellen erfüllen sie ebenfalls diese Funktion, denn dort wirkt der Schweißlichtbogen als Gleichrichter.Luftspalte vergrößern lokal in der Nähe des Spaltes den Streufluss, der möglicherweise dort (z. B. im Trafokessel) zu Verlusten und Störungen führt. Auch in der weiteren Umgebung besitzen solche Transformatoren oft einen erhöhten Streufluss, da ein größerer Anteil des Gesamtfeldes außerhalb des Kernes auftritt.
Luftspalte werden z. B. bei Ferritkernen und M-Blechen durch unterschiedlich lange Schenkel erreicht, bei E/I-Blechen durch gleichsinnige Stapelung und eine Zwischenlage.
Pulverkerne und Kerne aus Sintermetall besitzen einen sogenannten verteilten Luftspalt, der aus den isolierenden Schichten zwischen den Pulverkörnchen besteht. Diese Kerne vertragen daher natürlicherweise eine höhere Gleichstrom-Vormagnetisierung.
Durch ein zusätzliches unbewickeltes Joch mit Luftspalt wird unter anderem bei Lichtbogen-Schweißtransformatoren und Streutransformatoren (u. a. für Leuchtröhren) eine Strombegrenzung bewirkt. Das Joch dient als magnetischer Nebenschluss. Solche Transformatoren sind oft auch kurzschlussfest und besitzen im Falle von Schweißtransformatoren und manchen Leuchtröhren-Transformatoren eine mechanische Verstellmöglichkeit des Joches, sodass der abgegebene Strom eingestellt werden kann. Der magnetische Fluss in diesem Joch steigt mit dem abgegebenen Strom und kann zur Auslösung einer Überstromabschaltung herangezogen werden. Das war zum Beispiel bei Modellbahn-Transformatoren ME002 der Marke PIKO/DDR der Fall. Dort diente das Joch ausschließlich diesem Zweck und bestand lediglich aus einer Blechkonstruktion ähnlich einem Klappankerrelais. Auch Transformatoren in Mikrowellengeräten und manche Klingeltransformatoren besitzen aus diesen Gründen einen magnetischen Nebenschluss.
Höhere Betriebsfrequenzen erlauben einen geringeren Material­einsatz - siehe den Abschnitt Raumbedarf und Konstruktionsparameter. Jedoch erfordern höhere Betriebs­frequenzen oftmals aufwendigere Konstruktionen wie dünnere, teurere Bleche, Wicklungen aus Litze oder einen verschachtelten Wicklungsaufbau. Kerne aus Ferriten erlauben nur eine geringere Aussteuerung als diejenigen aus Eisen. Dennoch gelingt es mit höheren Arbeitsfrequenzen bis in den MHz-Bereich, die Baugröße und Masse von Transformatoren extrem zu verringern. So wiegt ein Ringkerntransformator für 3 kW für 50 Hz 30 kg; ein Trafo gleicher Leistung für 100 kHz wiegt lediglich 0,5 kg.
Netztransformatoren (50 oder 60 Hz, 115 oder 230 V) haben ein mit der Nennleistung leicht sinkendes Masse-Leistungs-Verhältnis, welches aufgrund des höheren Isolierstoffanteiles bei kleineren Transformatoren schlechter sein sollte. Andererseits können kleinere Transformatoren mit höheren Stromdichten im Wickeldraht betrieben werden (die Wärme kann besser abgegeben werden wegen geringerem Wärmeleitweg und höherer spezifischer Oberfläche), was zu einem schlechteren Wirkungsgrad führt. Daher ist das Masse-Leistungsverhältnis dennoch fast eine Gerade.
Das Masse-Leistungs-Verhältnis lässt sich durch eine hohe Induktion und damit mittels hochwertigem, bei Blechen texturiertem Kernmaterial verbessern. Ringkerntransformatoren und Schnittbandkerne sind anderen geblechten Kernen überlegen, da bei diesen die Textur immer entlang der Feldlinien gerichtet sein kann.
Peter Bastian, Horst Bumiller, Monika Burgmeier, Walter Eichler, Franz Huber, Jürgen Manderla, Jürgen Schwarz, Otto Spielvogel, Klaus Tkotz, Ulrich Winter, Klaus Ziegler: Fachkunde Elektrotechnik. 26., überarbeitete und erweiterte Auflage. Europa-Lehrmittel, Haan-Gruiten 2008, ISBN 978-3-8085-3160-0. 
Hans Rudolf Ris: Elektrotechnik für Praktiker. 5., vollständig überarbeitete Auflage. Electrosuisse, Fehraltorf 2011, ISBN 978-3-905214-71-0 (mit CD-ROM). 
Hans-Ulrich Giersch, Hans Harthus, Norbert Vogelsang: Elektrische Maschinen. 5. Auflage. Teubner, Stuttgart 2003, ISBN 3-519-46821-2. 
Helmut Vosen: Kühlung und Belastbarkeit von Transformatoren. VDE, Berlin 1997, ISBN 3-8007-2225-9. 
Adolf J. Schwab: Elektroenergiesysteme – Erzeugung, Transport, Übertragung und Verteilung elektrischer Energie. Springer, 2006, ISBN 3-540-29664-6.
National High Magnetic Field Laboratory der Florida State University: Simulation eines Transformators (Java-Applet, engl.)
