
Phokas (mittelgriechisch Φωκάς Fokas, lateinisch Focas oder Phocas; * nach 547 in Thrakien; † 5. Oktober 610 in Konstantinopel) war von 602 bis 610 Kaiser des Oströmischen bzw. Byzantinischen Reiches. Der erste erfolgreiche Usurpator der byzantinischen Geschichte gilt traditionell als ein despotischer Herrscher, dessen Regierung das Oströmische Reich erschüttert haben soll.
Das überaus negative Bild des Phokas, das von den Quellen gezeichnet wird (siehe etwa Johannes von Antiochia, Theophylaktos Simokates oder Theophanes) und das bis heute auch die Forschungsmeinung vielfach dominiert, sollte mit einer gewissen Vorsicht betrachtet werden: Alle diese Berichte stammen aus der Zeit nach dem Tod des Kaisers und entstanden teils (wie Theophylaktos) unter der Herrschaft des Herakleios, der Phokas 610 gestürzt hatte und natürlich ein Interesse daran hatte, diesen in ein möglichst schlechtes Licht zu rücken. Einige ältere Ansichten zu Phokas gelten heute daher als widerlegt, etwa die Annahme, die römische Balkanherrschaft sei bereits während seiner Regierungszeit schlagartig zusammengebrochen.
Phokas war Centurio im kaiserlichen Heer und Teilnehmer an den Balkanfeldzügen des Maurikios, als Kaiser Maurikios im Winter 602 den Befehl gab, in der Walachei am Donauufer zu überwintern und trotz beziehungsweise gerade wegen der ungünstigen Witterung eine neue Offensive vorzunehmen. Die Soldaten der Armee des magister militum per Thracias meuterten schließlich und ernannten Phokas, der sie angeblich durch aufpeitschende Reden unermüdlich gegen den Kaiser zur Rebellion gereizt hatte, zu ihrem Anführer. Das Heer wandte sich gegen Konstantinopel. In der Hauptstadt erhob sich die Zirkuspartei der Grünen gegen den offenbar wenig populären (wenngleich militärisch durchaus erfolgreichen) Maurikios. Der Kaiser floh auf eine Insel vor Chalkedon, während Phokas laut dem Chronicon Paschale am 23 November 602 von seinen Truppen vor den Toren der Hauptstadt gekrönt wurde und anschließend mit Unterstützung von Teilen des Senats und den Grünen, die ihm die Tore öffneten, am 25. November 602 in Konstantinopel einrückte. Laut Theophanes ließ Phokas am  27. November 602 auch seine Frau Leontia, mit der bereits vor der Revolte verheiratet war, zur Augusta krönen. Laut Theophylaktos Simokates kam es bald zu erneuten Konflikten zwischen den beiden Zirkusparteien. Als die Blauen schließlich an der Legitimität des neuen Kaisers zweifelten und darauf verwiesen, dass der gestürzte Kaiser Maurikios noch am Leben sei, ließ Phokas Maurikios und dessen Söhne ergreifen und auf ausgesprochen brutale Art umbringen.
Die Quellen zeichnen ein düsteres Bild, das von Tyrannentopik geprägt ist: Phokas, ein ungebildeter Mann, der sich im sacrum palatium angeblich Trinkgelagen und Schändlichkeiten jeder Art hingab, war demnach einer jener römischen Kaiser, die jeglicher Eignung für den Thron ermangelten. Binnen kurzer Zeit hatte er, der offenbar wenig Ahnung von den Pflichten eines Kaisers oder von staats- und kirchenrechtlichen Zusammenhängen hatte und sich auch nicht anstrengte, ihnen gerecht zu werden, jeglichen Realitätssinn verloren und glaubte sich von Gott auserwählt. Da er sich durch Verschwörungen bedroht sah, ließ Phokas große Teile der senatorischen Elite hinrichten und fügte auf diese Weise dem oströmischen bzw. byzantinischen Reich kaum wiedergutzumachenden Schaden zu.
Auch dem Volk gegenüber soll er sich als Tyrann gegeben haben: als im Zuge einer Darbietung im Hippodrom der Kaiser nach erfolgter Darbietungspause den Zuschauern nicht schnell genug wieder in seiner Loge erschien, begannen diese angeblich in respektloser Manier zu schreien: „Hast du wieder mal so viel gesoffen, dass du doppelt siehst? Du bist schon längst verrückt geworden!“ Der Augustus schickte daraufhin angeblich seine Leibwache gegen das Volk, und Köpfe, Nasen und Ohren wurden abgeschnitten.Die phokasfeindliche Überlieferung schildert den Kaiser also als eine Art „Bilderbuchtyrannen“ und ist daher nur eingeschränkt glaubwürdig. Allerdings räumen selbst solche Forscher, die vielen Quellenaussagen, die den Kaiser sehr negativ darstellen, kritisch gegenüberstehen, ein, dass das Regime des Phokas offenbar zumindest gegen Ende nicht frei von Schrecken war und der Kaiser wohl tatsächlich ein ausschweifendes Leben führte, selbst wenn die spätere Überlieferung vieles verzerrte und übertrieb. Die Ermordung des Maurikios und seiner Familie zeigt, dass Phokas nicht vor Gewaltexzessen zurückschreckte. So brach er ein altes Tabu und ließ zahlreiche Senatoren hinrichten, was seine Herrschaft in den Augen vieler Aristokraten völlig delegitimierte. Selbst die Grünen, jene Zirkuspartei, die Phokas zum Thron verholfen hatte, wurden angeblich Opfer des Terrors, als Phokas sie verdächtigte, gegen ihn zu konspirieren, nachdem sie als Helfer des Kaisers die andere Zirkuspartei, die Blauen, nach Kräften zu dezimieren geholfen hatten. Phokas versuchte nun offenbar, seinen Handlungsspielraum zu vergrößern, indem er die Zirkusparteien gegeneinander ausspielte; er wandte sich von den allzu mächtig gewordenen Grünen ab und verbündete sich mit den Blauen. Praefectus urbi von Konstantinopel wurde nun der Anführer (demarchos) der Blauen, womit die Grünen erbitterte Feinde des Kaisers wurden und das Reich in einen in zahlreichen Städten ausgetragenen Bürgerkrieg stürzten, über den Phokas bald jede Kontrolle verlor. Die Ernennung des Demarchen zum praefectus urbi stieß zudem die Aristokratie noch weiter vor den Kopf, denn eigentlich war dieses Amt den höchsten Kreisen des Senats vorbehalten.
Wenn Ostrom unter diesem Chaos nicht bereits in diesen Jahren zusammenbrach, so wohl nur, weil das Reich noch immer durch eine im Prinzip funktionsfähige spätrömische Verwaltung getragen wurde. Vom Bürgerkrieg verschont blieben nur die Exarchate Ravenna und Karthago. Vermutlich hatte das aber völlig unterschiedliche Gründe: In Ravenna wurde der Exarch Kallinikos nach der Usurpation des Phokas durch die zweite Amtsperiode des Smaragdus abgelöst. Vermutlich hatte sich Smaragdus auf die Seite des Phokas geschlagen, während Kallinikos in Opposition zu diesem stand. In Karthago hingegen konnte sich der ebenfalls noch von Maurikios eingesetzte Herakleios der Ältere halten, da Phokas wohl nicht ausreichend Macht besaß, um auch dort die Dinge in seinem Sinne zu regeln, da er durch den Perserkrieg (s. u.) vollauf ausgelastet war. Die Besetzung Ägyptens durch Herakleios’ Neffen Niketas im Jahre 608 zeigt jedenfalls, dass Karthago bereits früh in Opposition zu Phokas stand, ja, dass es dies vermutlich sogar die ganze Zeit seiner Herrschaft über war. Von dort aus wurde schließlich auch das Ende der Herrschaft Phokas’ eingeläutet.
Bald nach Maurikios’ Tod brach im Osten eine Rebellion los. Ein Unruheherd war auch Armenien, wo sich der Feldherr Narses an die Spitze des Aufruhrs gesetzt hatte und Edessa einnahm. Phokas entsandte den Feldherrn Bonosos nach Syrien, das sich ebenfalls empört hatte; Bonosos konnte jedoch die Rebellion in Antiochia und Jerusalem blutig niederschlagen.
Als Chosrau II., der Großkönig von Persien, von dem Thronwechsel hörte, erklärte er Phokas den Krieg, um – wie er sagte – die Römer von dem Usurpator zu befreien. Unter diesem Vorwand entsetzte er Edessa, das vom kaiserlichen Heer schon belagert wurde, und verbündete sich mit Narses. Chosrau II. präsentierte Theodosios, einen angeblichen Sohn des Maurikios, als Thronkandidaten. Doch bald schlug der angeblich freundschaftliche Beistand Chosraus, der 591 mit tatkräftiger Hilfe seines Adoptivvaters Maurikios auf den Thron gelangt war, in einen Eroberungskrieg um. Nordmesopotamien, Armenien und Teile Ostkleinasiens fielen in Chosraus Hände, auch wenn die römischen Truppen unter Domentiolos und Komentiolos teilweise durchaus erfolgreich Widerstand leisteten (siehe auch Römisch-Persische Kriege).
Unter Phokas’ Herrschaft konnten die Feldzüge gegen Awaren und Slawen, die die römischen Balkanprovinzen geschützt hatten, nicht lange fortgesetzt werden. Dennoch brach die römische Herrschaft auf dem Balkan während seiner Regierungszeit nicht zusammen. Vielmehr könnte die Ruhe vor dem Sturm die friedlichste Zeit seit langem gewesen sein. Seine Untätigkeit war jedoch die Ursache für die Landnahme der Slawen auf dem Balkan ab 612, zwei Jahre nach seinem Sturz.
Phokas sah, so die Quellen, schon bald nach seiner Machtergreifung ein, dass er angesichts seiner prekären Lage inmitten des Chaos wenig Auswahl an Bundesgenossen hatte und sich nicht auch noch den Bischof von Rom zum Feind machen durfte. So schlug er – im Gegensatz zur Politik seines Vorgängers, der in Italien gegen die Langobarden Krieg geführt und hierbei wie auch in anderer Beziehung auf den Papst wenig Rücksicht genommen hatte – einen fast vorbehaltlos papstfreundlichen Kurs ein. Dies bedeutete Waffenstillstand mit den Langobarden und damit endgültig den weitgehenden Verlust weiter Teile Italiens für das Imperium mit Ausnahme des Exarchats von Ravenna, das sich noch bis 751 halten konnte.
Allerdings kann man diesen Schritt auch anders bewerten: So hatte der Kaiser wohl ohnehin keine Alternative, denn verglichen mit den durch die Sassaniden bedrohten Orientprovinzen war das ausgeblutete Italien fast wertlos und weit entfernt. Hatten unter Maurikios die Einwohner Italiens unter den ewigen Kämpfen grausam gelitten, gratulierte jetzt Papst Gregor I. dem Friedensstifter mit einem Gloria in excelsis Deo zu seinem „Sieg“ über Maurikios, obwohl er gewusst haben muss, auf welche Weise Phokas den Thron errungen hatte. Dem Papst, dessen Lage durch die ihn von allen Seiten bedrängenden Langobarden immer schwieriger geworden war, wog dies jedoch leicht gegenüber dem bitter nötigen Frieden in Italien. Allerdings stellte sich heraus, dass der 603 geschlossene zweijährige Waffenstillstand nicht länger als eben für den Zeitraum hielt, für den er geschlossen war. Der Langobarde Agilulf bemächtigte sich vom Jahr 605 an weiterer Teile der italienischen Halbinsel. Phokas war froh, immerhin Ravenna zu halten, und setzte Agilulfs Vormarsch keinen besonderen Widerstand entgegen. Im Jahr 610, als der Kaiser stürzte, war es schließlich endgültig zu spät, der langobardischen Macht noch Grenzen zu setzen – aber ob unter Phokas dazu wirklich noch eine realistische Chance bestanden hätte, darf bezweifelt werden.
Phokas schenkte Papst Bonifatius IV. im Jahre 608 das Pantheon in Rom, der es 609 zur Kirche weihte. Phokas wird von der Nachwelt gemeinhin das Verdienst angerechnet, dass der Bau dank dieser Schenkung erhalten geblieben sei.
Nachdem Phokas im Jahr 607 ein Gesetz erlassen hatte, durch das er die Würde des Ökumenischen Patriarchen dem Patriarchen von Konstantinopel nahm, dem Papst übertrug und damit die Rechte Roms auf den Primat der gesamten Kirche anerkannte, wurde mit der Phokas-Säule 608 das letzte antike Bauwerk auf dem Forum Romanum errichtet, „zur Erinnerung an die unzähligen Wohltaten des Kaisers, weil er Italien wieder den Frieden gegeben und die Freiheit verteidigt hat“. Sie trug ursprünglich eine goldene Statue des Kaisers und ist noch heute zu sehen. Durch das kaiserliche Gesetz traten die Gegensätze zwischen dem Patriarchen von Konstantinopel und Rom auf kirchenrechtlicher Ebene in zunehmender Weise auf, und das Verhältnis beider Kirchenfürsten bewegte sich nun durch die Jahrhunderte langsam auf das Schisma des Jahres 1054 zu. In jedem Fall aber trug die romfreundliche Kirchenpolitik des Kaisers dazu bei, dass sein Bild in der Tradition der Ostkirche sehr negativ gezeichnet wurde.
Der Opposition in Konstantinopel gelang es trotz des regelrechten „Polizeistaats“, den Phokas den Quellen zufolge zu seinem Schutz aufgebaut haben soll, sich mit Herakleios dem Älteren, dem Exarchen von Karthago und Vater des späteren gleichnamigen Kaisers, auf eine Verschwörung zu verständigen. Offenbar spielten dabei auch einige mächtige Provinzstatthalter eine Rolle, ebenso sein Schwiegersohn Priskos. 608 begann in Karthago die Revolte.
Der Neffe Herakleios’ des Älteren, Niketas, eroberte 609 in harten Kämpfen Alexandria. Als sich die Rebellen die reichen oströmischen Provinzen Afrika und Ägypten militärisch gesichert hatten, zog der Sohn des Exarchen, der jüngere Herakleios, schließlich 610 von Karthago mit der Flotte gegen Konstantinopel aus. Er beanspruchte dabei noch nicht den Titel Augustus, sondern bezeichnete sich als Konsul. Bereits als die Masten der Flotte auf dem Marmarameer sichtbar wurden, soll in Konstantinopel sogleich eine Revolte ausgebrochen sein; es deutet allerdings einiges darauf hin, dass sich Herakleios in Wahrheit längere Zeit im Marmarameer aufhielt, während seine Anhänger in der Stadt den Umsturz organisierten. Anfang Oktober 610 begannen dann die Kämpfe. Der gegenüber Phokas loyale comes Orientis Bonosus wurde von Excubitores (zu Herakleios Übergelaufenen) erschlagen. Zwei Tage später wechselten der Patricius Probus und der Curopalatus Photius die Seiten und verhafteten Phokas im Palast. Nach manchen Berichten schleppte man Phokas nun auf das Admiralsschiff vor Herakleios. Als dieser den um sein Leben zitternden Phokas vor sich sah, fragte er ihn angeblich: „Du hast das Reich regiert?“ Phokas soll ihm mit einer Gegenfrage geantwortet haben: „Wirst Du es besser machen?“ Berichten nach soll Phokas geköpft, anschließend verstümmelt und zur Schau gestellt worden sein. Anderen Quellen zufolge war Phokas allerdings bereits ermordet worden, als Herakleios in Konstantinopel eintraf, der Wortwechsel zwischen den beiden ist also wahrscheinlich nur erfunden. Einig sind sich die Quellen aber darin, dass Phokas' Kopf auf einer Lanze durch die Stadt paradiert wurde, wie es bei gestürzten Kaisern Sitte war.
Auch die herakleiosfreundliche Überlieferung kann nur schwer verbergen, dass die Krise des Reiches erst unter Herakleios, dem die Sassaniden Syrien und Ägypten entrissen, voll ausbrach, bevor dieser dann langsam und unter Mühen die Lage verbessern konnte: Befand sich Ostrom spätestens seit dem Tod des Maurikios in einer Krise, so brach diese erst 611 mit voller Härte aus. Und ob Herakleios wirklich ein selbstloser Befreier des Volkes war, darf ungeachtet seiner späteren Leistungen bezweifelt werden, zumal er zwei volle Jahre brauchte, um Phokas in einem regelrechten Bürgerkrieg zu stürzen; dieser hatte offensichtlich zahlreiche Unterstützer, die lange Widerstand leisteten.
Inwieweit eine solch neue Rekonstruktion zutrifft (wie sie etwa Ralph-Johannes Lilie geliefert hat), bedarf allerdings noch weiterer Diskussion, zumal unter Phokas bereits Armenien verloren ging und Herakleios anfangs noch mit Kämpfen gegen phokastreue Truppen gebunden war, danach (ab 613) aber durchaus in die Offensive ging. Sicher ist aber, wie geschildert, dass die spätantiken und mittelbyzantinischen Berichte über Phokas stark von Tyrannentopik geprägt sind, was es sehr erschwert, die Herrschaft des Kaisers zu würdigen. Allerdings würde eine wirklich positive Einschätzung des Phokas wohl doch zu weit führen – zu deutlich geriet das Reich in seiner Herrschaftszeit in die Krise, wobei der Perserkrieg die schlimmsten Folgen haben sollte.
Phokas’ Herrschaft stellt in jedem Fall eine recht deutliche Zäsur in der Geschichte des oströmischen Reichs dar. Während seiner Herrschaft, die in eine Zeit des Umbruchs fiel, fiel Byzanz als Ordnungsmacht offenbar vorübergehend aus. In dieser Zeit scheint auch die Bereitschaft der Germanenreiche, Ostrom als Vormacht und Oberherren anzuerkennen, geschwunden zu sein. So hat Phokas weniger durch Taten als vielmehr einerseits durch Unterlassen und Treibenlassen, andererseits durch Vernichtung und Zerstörung gewirkt, wobei der objektive Betrachter in vielen Punkten einräumen muss, dass die schwierige ökonomische und militärische Lage des Reiches wohl auch die meisten anderen Herrscher überfordert hätte. Wenn man so will, ist – schlagwortartig gesagt – Phokas der letzte spätantike Kaiser, während sein Nachfolger Herakleios durch seine Reformen das byzantinische Frühmittelalter einleitete, damit aber auch den Fortbestand des Reiches sicherte.
Traditionell (und nicht völlig zu Unrecht) gilt die Bilanz der Regierung als katastrophal: Phokas überließ Italien den Langobarden, gab auf dem Balkan den Slawen und Awaren die entscheidende Atempause und schwächte unmittelbar vor Beginn der islamischen Expansion das Reich durch den persischen Angriff, dem er kaum Einhalt gebot und der die schwerste Hypothek für seinen Überwinder und Nachfolger wurde. Er säte, so heißt es, weitere Zwietracht zwischen dem Patriarchen von Konstantinopel und dem von Rom. Allerdings stellt sich auch hier die Frage, ob all diese Vorwürfe wirklich gerechtfertigt sind. Ein Grund für die Probleme war sicherlich auch die Ablehnung des Kaisers durch die herrschenden Eliten, die ihn nie als ihresgleichen akzeptierten und sich durch Obstruktion und Sabotage rächten.
In Konstantinopel selbst hatte Phokas daher angeblich fast die gesamte senatorische Oberschicht auf dem Gewissen – trotz der offensichtlichen Übertreibungen und Verzerrungen in den Quellen deutet vieles darauf hin, dass die alte Funktionselite in dieser Zeit tatsächlich in eine Krise geriet. Die spätantike Gesellschaft von Ostrom war geschwächt, Phokas’ Nachfolger setzten den Staat mit der Themenverfassung auf eine neue Grundlage (wenn auch diese Maßnahmen nicht von Herakleios durchgeführt wurden, wie noch in der älteren Forschung oft vertreten). Auch war Phokas der letzte Kaiser, der während seiner gesamten Regierungszeit den lateinischen Titel Imperator Augustus trug. Sein Nachfolger änderte den Titel im Zuge der Reorganisierung des Reichs in Basileus, um dem griechischen Charakter des Reichs gerecht zu werden, wenngleich damit keine Aufgabe der Rechtsnachfolgerschaft der antiken römischen Kaiser verbunden war. Es erscheint daher nur folgerichtig, dass gerade Phokas das letzte Bauwerk auf dem antiken Forum Romanum gewidmet wurde: Er war der letzte Kaiser, der – wenn auch nur wenig erfolgreich – noch aktiv in die Geschicke des Westens eingreifen konnte.
Auch für die heutigen Archäologen stellt er in gewisser Weise einen Wendepunkt dar. Da er offenbar den Bart wieder in Mode brachte, werden seit seiner Zeit die Abbildungen, nicht zuletzt die von Christus, mit Bärten ausgeführt, was die Datierung erleichtert. Während seit Konstantin I. fast alle Kaiser nach römischer Art glattrasiert gewesen waren – mit Ausnahme Julians, der sich einen Philosophenbart stehen ließ – trugen sie nach Phokas (der ihn angeblich wachsen ließ, um eine Narbe zu verbergen) fast alle einen Bart.
Ralph-Johannes Lilie: Byzanz. Das zweite Rom. Siedler, Berlin 2003, ISBN 3-88680-693-6, S. 75–81 (Lilie bemüht sich um eine neue Bewertung des Kaisers, wobei seine Thesen allerdings weiterer Diskussion bedürfen).
Mischa Meier: Kaiser Phokas (602–610) als Erinnerungsproblem. In: Byzantinische Zeitschrift 107, 2014, S. 139–174.
John Robert Martindale: Phokas. In: The Prosopography of the Later Roman Empire (PLRE). Band 3B, Cambridge University Press, Cambridge 1992, ISBN 0-521-20160-8, S. 1030–1032 (knapper Überblick mit Quellenhinweisen).
Frank Thiess: Die griechischen Kaiser. Die Geburt Europas. Zsolnay, Hamburg u. a. 1959 (populärwissenschaftliche Bearbeitung der Zeit von Justinian I. bis Justinian II.).

Phosphor (von altgriechisch φωσφόρος phōsphóros, deutsch ‚lichttragend‘, vom Leuchten des weißen Phosphors bei der Reaktion mit Sauerstoff) ist ein chemisches Element mit dem Symbol P und der Ordnungszahl 15. Im Periodensystem steht es in der fünften Hauptgruppe, bzw. 15. IUPAC-Gruppe oder Stickstoffgruppe.
Phosphor kommt in mehreren, sich stark voneinander unterscheidenden Modifikationen vor, deren am einfachsten herzustellende, thermodynamisch aber nicht stabilste der aus P4-Molekülen aufgebaute weiße Phosphor ist.
Phosphorverbindungen sind für alle Lebewesen essenziell und bei Aufbau und Funktion der Organismen in zentralen Bereichen beteiligt, wie der DNA und der zellulären Energieversorgung (ADP/ATP). Die biogeochemische Umsetzung von Phosphor erfolgt im Rahmen des Phosphorkreislaufs.
Phosphor wurde 1669 von Hennig Brand, einem deutschen Apotheker und Alchemisten, entdeckt, als dieser – auf der Suche nach dem „Stein der Weisen“ – Urin bis zur Trocknung eindampfte. Als er den Rückstand unter Luftabschluss glühte, entstand durch Reduktion mit organischer Materie weißer Phosphor, der im Dunkeln aufgrund der Chemolumineszenz leuchtete. Obwohl Phosphor zu dieser Zeit noch keine Verwendung außer als Nachtlampe fand, wurde er mit Gold aufgewogen. Hennig Brand wurde durch diese Entdeckung trotzdem nicht reich und verkaufte das Herstellungsrezept an einen Alchemisten, der wiederum damit ein Vermögen machte. Johann Daniel Kraft, besagter Alchimist, demonstrierte die Herstellung von Phosphor 1677 vor Robert Boyle. Bemerkenswert ist, dass Hennig Brand seinen Phosphorus in Hannover auch dem Wissenschaftler und Philosophen Gottfried Wilhelm Leibniz vorstellte, der aus Begeisterung über den geheimnisvollen Lichtträger „Phosphorus Mirabilis“ ein Gedicht verfasste.
Weißer Phosphor wurde anfangs auf Grund seiner faszinierenden Eigenschaft – der Chemolumineszenz – als Heilmittel verwendet. Später erhielt er eine wichtige Bedeutung bei der Streichholzherstellung; da weißer Phosphor hochgiftig ist, kam es jedoch oft zu schweren Vergiftungen bei Arbeitern, die mit ihm in Berührung kamen.
Weißer Phosphor spielte in der Militärgeschichte als Waffe eine Rolle. Er wurde als Füllmaterial von Brandbomben, den sogenannten Phosphorbomben, verwendet. So setzte die britische Luftwaffe im Zweiten Weltkrieg ein Gemisch aus weißem Phosphor und Kautschuk ein. Durch den Kautschuk klebt die zähflüssige Masse und lässt sich deshalb schlecht abstreifen. Sie verursachte auf der Haut schlecht heilende Wunden.
Schon früh entdeckten Chemiker, dass weißer Phosphor, der Licht ausgesetzt war rot wurde, auch im Vakuum. Jöns Jakob Berzelius vermutete, dass dies eine Modifikation des weißen Phosphors war, nachgewiesen wurde das erst 1847 von Anton Schrötter von Kristelli (Anton Schrötter) in Wien, der die Substanz isolierte und analysierte. Violetten Phosphor entdeckte 1865 Johann Wilhelm Hittorf. und die Hochdruckvariante schwarzer Phosphor Percy Williams Bridgman 1914.
In der Natur kommt Phosphor ausschließlich in gebundener Form, das heißt nicht gediegen, meist in Form der Phosphate in der Erdkruste vor (Gehalt in der Erdkruste: ~ 0,09 %). Typische Mineralien sind etwa die Apatite Ca5(PO4)3(F,Cl,OH). Besonders der Fluorapatit und der mit Calciumcarbonat durchsetzte Phosphorit stellen ökonomisch die wichtigsten Phosphate dar. Darüber hinaus gibt es weitere phosphorhaltige Mineralien, wie beispielsweise den Wavellit Al3(PO4)(F,OH) · 5 H2O, den Vivianit Fe3(PO4)2 · 8 H2O und den Türkis CuAl6[(PO4)(OH2)]4 · 4 H2O.
Die größten Vorkommen an Phosphat-Mineralien findet man in Afrika, in China und den USA (Florida). Vier Länder besitzen rund 80 % an den weltweiten Phosphatgestein-Reserven, die mit derzeitiger Technologie wirtschaftlich abbaubar sind: Marokko (zusammen mit Westsahara 36,5 %), China (23,7 %), Jordanien und Südafrika (je 9,6 %). Die kontinentalen Vorkommen reichen nur noch für wenige Jahrzehnte; Schätzungen aus den 2000er Jahren variieren zwischen 50 (2008) und 130 Jahren (2006). Infolge neu gefundener Lagerstätten hauptsächlich in Nordafrika und Irak geht eine Schätzung der Bundesregierung von 2012 jedoch davon aus, dass keine Verknappung unmittelbar bevorsteht und die bisher bekannten Vorräte noch 380 Jahre reichen. Weiterhin existieren große Vorkommen unter Wasser, die momentan aber nicht ökonomisch abgebaut werden können.Außer in Mineralien kommt Phosphor auch in Ablagerungen von Vogelkot von Meeresvögeln, dem sogenannten Guano (enthält 7–8 %, selten bis 60 % Chilesalpeter und maximal etwa 40 % Phosphate) vor. Dieser findet sich vorwiegend auf einigen Inseln im Pazifischen Ozean, wie Nauru oder Kiribati und in Südamerika (Peru/Chile). Auf Nauru gehen die Phosphor-Vorräte seit Mitte der 1970er Jahre kontinuierlich zurück und sind mittlerweile fast völlig erschöpft.
Von den weltweit jährlich geförderten etwa 180 Millionen Tonnen (Stand 2010) an Rohphosphaten werden etwa 90 % zur Herstellung von Düngemitteln verwendet. Phosphor kann in Düngemitteln durch keinen anderen Stoff ersetzt werden.Phosphor hat auch in der organischen Welt eine wichtige Bedeutung und kommt in verschiedensten Bereichen der Fauna und Flora vor: etwa als Hydroxylapatit Ca5(PO4)3OH, der einer der Hauptbestandteile der Gerüstsubstanz ist, die in Knochen und Zähnen vorkommt. Weiterhin spielen Phosphorverbindungen als Bestandteile der Nukleinsäuren und als Bestandteil des Energieträgers ATP eine wichtige Rolle in lebenden Organismen.
Phosphor entsteht in massereichen Sternen beim Sauerstoffbrennen aus Sauerstoff bei Temperaturen über 1,5·109 Kelvin und Dichten von mindestens 1010 kg/m3.
Es wird postuliert, dass der für frühe Lebewesen verwertbare Phosphor erst durch Meteorite verfügbar war, die während des Hadaikums auf die Erde gelangten. Das bereits auf der Erde vorkommende Phosphat ist reaktionsträge und schwer löslich und wäre daher für die ersten Lebewesen nur begrenzt nutzbar gewesen. Dagegen reagieren die von den Meteoriten mitgebrachten Schreibersite mit Wasser zu reduzierten Phosphiden. Diese wären für eine präbiotische Synthese phosphorylierter Biomoleküle (wie Ribonukleinsäure) plausible Ausgangsstoffe.
Gewonnen wird Phosphor aus Phosphatmineralien wie Phosphorit oder Apatit, in dem diese in einem elektrischen Schmelz-Reduktionsofen zusammen mit Quarzkies auf 1500 °C erhitzt und so zu weißem Phosphor umgesetzt werden.
Der Ofen ist als geschlossener Niederschachtofen ausgeführt, die Wärme wird über Söderberg-Elektroden zugeführt.Die in der Elektrode enthaltene Kohlenstoffmasse wirkt dabei als Reduktionsmittel und das Siliciumdioxid des Quarzes dient als Schlackenbildner. Der beim Prozess gasförmig anfallende Phosphor wird kondensiert und unter Wasser gesammelt.
Nach der Pleite von Thermphos, dem letzten europäischen Hersteller, basiert die Versorgung mit weißen Phosphor fast ausschließlich auf der Firma Kazphosphate, die ein Werk in Tschimkent betreibt. Weitere Hersteller sind Monsanto mit einem Werk in Soda Springs (Idaho) sowie verschiedene chinesische Firmen.
Phosphor tritt in vier allotropen Modifikationen als weißer, roter, schwarzer und violetter Phosphor auf. Jeder dieser Grundtypen bildet verschiedene Kristallstrukturen. Dadurch kommt es zu sehr großen Unterschieden in physikalischen Eigenschaften und Reaktivität.Da die anderen Modifikationen schwer direkt zu gewinnen sind, wird zunächst immer weißer Phosphor produziert und dieser dann in andere Modifikationen umgewandelt. Diese können durch hohen Druck und hohe Temperatur ineinander überführt werden. Der schwarze Phosphor ist bei Raumtemperatur die eigentlich stabile Modifikation, die anderen sind allerdings auf Grund der geringen Umwandlungsgeschwindigkeit metastabil. Weißer Phosphor kann im Labor durch Erhitzung von rotem Phosphor unter Ausschluss von Sauerstoff hergestellt werden. Umgekehrt kann roter Phosphor auch durch mehrstündiges Erhitzen von weißem Phosphor auf etwa 180–350 °C erzeugt werden.
Im Phosphordampf überwiegen unterhalb von 1200 °C P4-Tetraeder als kleinste molekulare Einheiten. Der Dissoziationsgrad beträgt bei 800 °C ~ 1 %. Zwischen 1200 und 2000 °C überwiegen P2-Moleküle mit stickstoffanaloger Valenzelektronenstruktur, oberhalb von 2000 °C dissoziieren diese mit steigenden Temperaturen schließlich langsam zu atomarem Phosphor.
Weißer Phosphor ist die flüchtigste und reaktivste Modifikation des Phosphors. Er hat eine Dichte von 1,82 g/cm3, einen Schmelzpunkt von 44,25 °C und einen Siedepunkt von 280 °C und ist durchscheinend und wachsartig. Verunreinigt wird der weiße Phosphor auch als gelber Phosphor bezeichnet. Der kubische weiße Phosphor ist in Phosphortrichlorid und Kohlenstoffdisulfid CS2 sehr leicht löslich; 100 g Kohlenstoffdisulfid lösen mehr als 1 kg Phosphor. In Tetrachlorkohlenstoff, Benzol oder Ether ist Phosphor schwach löslich. In Wasser ist er praktisch unlöslich.
Bei −76,9 °C geht die kubische Form (α-Form) in eine hexagonale Form (β-Form) über (Rotation der freien Außenelektronen „eingefroren“). In jeder Form (α-, β-, in Lösung) bildet weißer Phosphor P4-Tetraeder mit einem Bindungswinkel von 60°.
In fein verteiltem Zustand entzündet sich weißer Phosphor an der Luft von selbst, ab etwa 50 °C entzünden sich auch kompakte Stücke und verbrennen zu Phosphor(V)-oxid. Daher muss weißer Phosphor unter Wasser aufbewahrt werden. Brennender Phosphor darf nicht mit Wasser gelöscht werden, da die Gefahr besteht, dass der Phosphorstaub in feine Ritzen gespült wird und sich nach Verdunstung des Wassers wieder selbst entzündet. Brennender Phosphor wird am besten mit Sand gelöscht.
  An der Luft kann weißer Phosphor eine bläuliche Chemolumineszenz zeigen. Diese entsteht aus dem durch den hohen Dampfdruck des weißen Phosphors in der Umgebung vorhandenen gasförmigen P4, das durch Gasphasenoxidation über P4O6 zu P4O10 reagiert. Meist in heftiger exothermer Reaktion verbindet sich Phosphor mit Halogenen, Metallen oder Schwefel. Die hieraus entstehenden Verbindungen sind Phosphorsulfide, Phosphor(III)- oder Phosphor(V)-Verbindungen sowie Phosphide. Unter Einwirkung von starken Laugen bei hoher Temperatur disproportioniert Phosphor zu Phosphan und Hypophosphit. Phosphor hat eine hohe Affinität zu Sauerstoff, wirkt also stark reduzierend. So wird z. B. Schwefelsäure beim Erwärmen mit weißem Phosphor zu Schwefeldioxid reduziert.
Das bei der Verbrennung von Phosphor entstehende Phosphorpentoxid ist stark hygroskopisch und bildet mit der Luftfeuchtigkeit dichte Nebel aus Phosphorsäure. Weißer Phosphor wird deshalb in Nebelgranaten verwendet.
Weißer Phosphor ist hochgiftig; schon 50 mg sind für den Menschen tödlich. Der Tod tritt erst nach fünf bis zehn Tagen ein. Auch wird weißer Phosphor nur langsam ausgeschieden. Die langsame Giftwirkung macht(e) Phosphor als Rattengift geeignet. Hierzu waren sogenannte „Phosphorlatwergen“ in Gebrauch. Wegen der allgemeinen Gefahren, und weil geeignetere Mittel zur Verfügung stehen, ist weißer Phosphor als Rattengift obsolet.
Die Toxizität des weißen Phosphors wird vor allem auf sein hohes Reduktionsvermögen zurückgeführt, wodurch intrazelluläre oxidative Stoffwechselabläufe wie Eiweiß- und Kohlenhydratsynthese gestört werden. Dies betrifft vorwiegend enzymatisch gesteuerte Stoffwechselvorgänge in der Leber. Eine weitere Gefahr bilden die durch Reaktion mit Wasser gebildeten hochgiftigen Phosphane, die als starke Stoffwechselgifte eine besondere Affinität zum Zentralnervensystem besitzen. Weißer Phosphor kann mit einer Kupfer(II)-sulfat-Lösung unschädlich gemacht werden. Dabei bildet sich schwerlösliches Kupfer(I)-phosphid.Seit 1845 wurden bei Arbeitern, vorwiegend in der industriellen Produktion von Streichhölzern mit weißem Phosphor, schwere Kiefer-Nekrosen beobachtet (engl. phossy jaw). Die im 19. Jahrhundert vollkommen ungeschützt mit Phosphorbädern hantierenden Arbeiter (oft auch Kinder und Jugendliche, die beim Verpacken der Streichhölzer beschäftigt waren) wurden schnell arbeitsunfähig. Eine wirksame Therapie gab es nicht. Die Patienten wurden stark entstellt, oft arbeitslos, die Letalität betrug 20 %. Das arbeitsmedizinische Problem der Phosphornekrosen, insbesondere der massiven Kiefernekrosen, führte zu den ersten arbeitsmedizinischen Konsequenzen in der Geschichte der modernen Medizin. Die Berner Konvention führte 1906 zum Verbot des weißen Phosphors in der Streichholzherstellung. Ähnliche Kiefernekrosen sieht man heute bei der Bisphosphonat-Therapie (Bisphosphonatassoziierte Knochennekrose).
Die bei Zimmertemperatur stabilste Modifikation existiert in einer amorphen und drei kristallinen Formen. Schwarzer Phosphor ist aufgrund seiner polymeren Form unlöslich, deutlich schwerer entflammbar, sehr reaktionsträge und besitzt eine Dichte von 2,69 g/cm3. Daher ist der schwarze Phosphor ebenso wie der rote Phosphor ungiftig. Das dem schwarzen Phosphor zugrundeliegende Kristallgitter besteht aus gewellten Doppelschichten, in dem die Phosphoratome pyramidal mit drei weiteren in der Nachbarschaft befindlichen Phosphoratomen in einem Bindungswinkel von 100° verbunden sind. In dieser Konfiguration besitzt Phosphor Halbleitereigenschaften. In feuchter Luft oxidiert schwarzer Phosphor etwas schneller als roter Phosphor, überzieht sich dabei aber mit einer farblosen, viskosen Flüssigkeitshaut aus Phosphorsäuren, so dass der weitere Sauerstoffzutritt verhindert und eine Entzündung erschwert wird.
Der normale schwarze Phosphor kristallisiert orthorhombisch; bei 80.000 Bar wandelt sich dieser reversibel in eine rhomboedrische und bei 110.000 Bar in eine kubische metallische Modifikation.
Schwarzer Phosphor entsteht unter hohem Druck (12.000 Bar) und erhöhter Temperatur (200 °C) aus weißem Phosphor und unterscheidet sich durch seine Farbe stark von der vorgenannten Modifikation. Er sieht grau-schwarz, glänzend und faserig wie Holz aus. Neuerdings wurde auch eine Niederdruckmodifikation hergestellt.
Eine Reihe amorpher und kristalliner Formen mit Dichtevariationen zwischen 2,0 und 2,4 g/cm3 und Schmelzpunkten zwischen 585 °C und 610 °C werden unter der Bezeichnung roter Phosphor zusammengefasst. Gemeinhin ist roter Phosphor amorph, lässt sich aber durch Rekristallisation aus geschmolzenem Blei in den monoklinen Hittorfschen (violetten) Phosphor überführen, welcher eine dreidimensional vernetzte polymere Form bildet.
Gewonnen wird roter Phosphor durch mehrstündiges Erhitzen von weißem Phosphor auf etwa 260 °C unter Luftabschluss. Eine langsame Umwandlung geschieht auch bei Lichteinwirkung. Iod katalysiert die Umwandlung von weißem in roten Phosphor.
Die Unterschiede zwischen den kristallinen Anteilen im roten Phosphor bedingen die verschiedenen Formen desselben. Einfluss haben hier die Korngröße, die Art des Gitters, Verunreinigungen und die verschiedenen Absättigungen der Randgruppen mit Halogenen, Sauerstoff und Hydroxygruppen.
Roter Phosphor ist zwar nicht selbstentzündlich, kann aber mit starken Oxidationsmitteln durch geringe Energiezufuhr (Reibung, Schlag) zur schlagartigen Entzündung oder gar zur Explosion gebracht werden. Bezogen auf die Reaktivität gleicht der violette Phosphor eher dem schwarzen Phosphor, während sich der Schencksche Phosphor sehr viel reaktionsfreudiger zeigt als „normaler“ roter Phosphor.
Roter Phosphor ist, im Gegensatz zu weißem Phosphor, nicht giftig. Seine Erstbeschreibung wird Anton Schrötter von Kristelli zugeschrieben.
Der Hellrote oder auch Schencksche Phosphor (Rudolf Schenck, 1902) entsteht durch Kochen von weißem Phosphor in Phosphortribromid (PBr3). Das Produkt ist eine Mischverbindung aus Phosphor mit 10 bis 30 % Brom, deren Dichte bei 1,88 g/cm3 liegt.
Violetter Phosphor entsteht beim ein- bis zweiwöchigen Erhitzen von weißem Phosphor auf ca. 550 °C.Entdeckt wurde er von Johann Wilhelm Hittorf. Es handelt sich um ein nichtleitendes Polymer, das unlöslich in CS2 ist. Die Strukturaufklärung gelang Ende der 1960er Jahre an der Universität Stuttgart durch Herbert Thurn. Auch der violette Phosphor ist ungiftig.
Im August 2004 ist es deutschen Forschern gelungen, zwei weitere Modifikationen des vielgesichtigen Elements zu isolieren und strukturell zu charakterisieren: Phosphor-Nanostäbchen. Bei diesen beiden Modifikationen liegen die Phosphoratome in Form von Kettenmolekülen (Polymeren) vor. Entdecker der neuen Modifikationen sind Arno Pfitzner von der Universität Regensburg und Hellmut Eckert von der Westfälischen Wilhelms-Universität in Münster. Die rotbraunen Fasern, die sich deutlich von der roten Phosphormodifikation unterscheiden, sind an der Luft in trockenem Zustand über Wochen stabil. Elektronenmikroskopisch zeigte sich diese rotbraune Phosphor-Form als lange, parallel ausgerichtete Nanostäbe mit Durchmessern von ungefähr 0,34 nm (Nanometer) bis 0,47 nm.
Phosphor hat nur ein stabiles Isotop, 31P; dies ist das einzige in der Natur vorkommende Isotop des Phosphors. Er ist somit ein Reinelement (anisotop).
Phosphor hat mehrere weitere Isotope, die allerdings alle radioaktiv sind. Das Phosphorisotop 33P hat mit 25,3 Tagen die längste Halbwertszeit. 32P hat eine Halbwertszeit von 14,3 Tagen und wird in der Medizin verwendet. Außerdem dient es in der Molekularbiologie als Tracer. Es kann beispielsweise verwendet werden, um Gensonden radioaktiv zu markieren und mittels Autoradiographie nachzuweisen.
Der größte Teil (80 %) des hergestellten weißen Phosphors wird zu Phosphor(V)-oxid verbrannt, das als Ausgangsmaterial für die Phosphorsäureherstellung sowie für die Darstellung verschiedener Phosphate verwendet wird. Die Hauptmenge der Phosphate wiederum kommt als Dünger zum Einsatz. Phosphor(V)-oxid hat außerdem noch als eine der wirksamsten wasserentziehenden Substanzen (Trockenmittel) Bedeutung.
Ein weiterer Teil wird zu Phosphortrichlorid (PCl3) und Phosphor(V)-sulfid (P4S10) verarbeitet, die wiederum als Grundstoffe für die Herstellung von Flammschutzmitteln, Additiven, Weichmachern und Pflanzenschutzmitteln dienen.
Roter Phosphor findet Verwendung bei der Streichholzherstellung. Paradoxerweise wird roter Phosphor in fein verteilter Form auch Kunststoffen (z. B. Polyamid) als Flammschutzmittel zugesetzt: Die Reaktionsprodukte von Phosphor, Luftsauerstoff und Wasser (Luftfeuchte, Restfeuchte im Kunststoff) bilden dabei eine verkohlte Schutzschicht gegen die Flammen. Außerdem fungieren gebildete Phosphorsuboxide, z. B. PO, als Radikalfänger und unterbrechen auf diese Weise die Verbrennung in der Gasphase.Des Weiteren werden die als Dünger wichtigen Phosphate direkt aus Calciumphosphat gewonnen, indem dieses mit Schwefelsäure aufgeschlossen wird. Es entsteht das sogenannte Superphosphat. Hierzu werden etwa 60 % der weltweiten Schwefelsäureerzeugung benötigt.
Roter und weißer Phosphor werden auch für militärische Zwecke genutzt. Der sehr giftige und selbstentzündliche weiße Phosphor wird in Brandmunition wie etwa Phosphorbomben verwendet und wurde früher auch in Nebelmunition eingesetzt. In moderner Nebelmunition wird jedoch der ungiftige rote Phosphor in Mischungen mit Oxidationsmitteln und metallischen Brennstoffen verwendet.Bis in die 1980er-Jahre wurde mit weißem Phosphor auch in Schulen experimentiert, was aus gesundheitlichen Gründen verboten wurde. Nun darf nur noch roter Phosphor in Experimenten eingesetzt werden. 
Das radioaktive Phosphorisotop 32P wird in Medizin und Forschung als Tracer benutzt, um Stoffwechselprozesse zu beobachten (beispielsweise beim 32P-Postlabeling) oder Krankheiten zu behandeln, wie bei der nuklearmedizinischen Therapie der Polycythaemia vera. Ein veraltetes Verfahren zur Diagnostik des Aderhautmelanoms war der Radiophosphortest.
Auf natürlichem Wege gelangt Phosphor einerseits über die Apatit-Verwitterung in den Boden oder aber aus zersetzter organischer Materie. Die atmosphärische Deposition spielt bei Phosphor nur eine untergeordnete Rolle. Durch Kunstdünger erhöht der Mensch den Phosphorgehalt im Boden.
Als Hauptfaktoren der Verluste kann die Erosion betrachtet werden. Die direkte Auswaschung in das Grundwasser ist sehr gering und abgesehen von vernachlässigbaren Mengen von Phosphin-Gas kommt es zu keiner Ausgasung aus dem Boden.
Phosphat besitzt eine sehr schlechte Löslichkeit. So führt zum Beispiel eine Adsorption an Fe- und Al-Hydroxide in sauren Böden zu einer Phosphatfixierung. In basischen Böden kommt es zu einer Ausfällung mit Calcium.
Generell können Phosphatfraktionen im Boden auf verschiedene Art und Weise eingeteilt werden. Zwei häufig verwendete Einteilungen sind die Gliederung nach der Löslichkeit und die Gliederung nach Phosphattypen.
In der Bodenlösung verfügbares Phosphat ist direkt pflanzenverfügbar. Jedoch ist diese mit 1–2 kg/ha die kleinste Fraktion.
Labiles Phosphat ist durch spezifische Sorption an Eisen- und Aluminium-Oxide oder an Tonminerale locker gebunden. 450–900 kg/ha können so im Boden vorliegen. Durch Resorption kann aus dieser Fraktion pflanzenverfügbares Phosphat gebildet werden.
Stabiles Phosphat hat praktisch keine Bedeutung für die Pflanzenernährung, obwohl es mit 3000–6000 kg/ha die größte der drei Fraktionen ist. Als wichtigste Vertreter seien hier Apatite und Calciumphosphate genannt.Diese Fraktionen stehen zueinander in einem dynamischen Gleichgewicht und können über teilweise sehr lange Zeiträume ineinander übergehen.
Anorganisches Phosphat ist jener Anteil, der in primären Phosphormineralien (z. B.: Apatit), in sekundären Phosphormineralien (Fe-, Al- oder Ca-Mineralien) oder adsorbiert an Fe- und Al-Hydroxiden vorliegt.
Gelöstes Phosphat ist jener Anteil der in gelöster Form in der Bodenlösung als H2PO4− oder als HPO42− vorliegt. Gelöstes Phosphat ist direkt pflanzenverfügbar.
Organisches Phosphat ist ein Sammelbegriff für alle weiteren organischen Verbindungen, die im Boden vorliegen. Dies schließt Phosphor im Humus, an organische Moleküle adsorbierten Phosphor, mikrobiellen Phosphor und Phosphor in Pflanzenrückständen mit ein.Der Zeitpunkt, zu dem die maximale globale Phosphatproduktion erreicht wird, wird als Peak Phosphorus bezeichnet.
Phosphor ist für alle biologischen Organismen essenziell. Phosphorverbindungen sind Bestandteil der DNA- und RNA-Moleküle, der Trägersubstanz der Erbinformationen aller Lebewesen. Die stark phosphorhaltige Verbindung Adenosintriphosphat spielt eine entscheidende Rolle beim Energiestoffwechsel (aktivierte Zucker) der Zellen. Phosphor ist weiterhin in Zuckerphosphaten, Phospholipiden und Coenzymen enthalten. Die Phosphorylierung ist einer der wichtigsten Regulationsmechanismen in Organismen. Phosphate sind auch ein elementarer Bestandteil des pH-Puffersystems im Blut.
Die Trockenmasse von terrestrischen Pflanzen enthält ca. 0,2 % Phosphor, die von Säugetieren wie Menschen ca. 4 %. Die Gerüstsubstanz von Knochen und Zähnen besteht hauptsächlich aus Hydroxylapatit (Ca5(PO4)3OH). Der Körper eines Menschen von 70 kg Gewicht enthält etwa 700 Gramm Phosphor, wovon 600 g fest im Knochensystem gebunden sind.
Der Tagesbedarf eines erwachsenen Menschen beträgt ca. 0,75 Gramm Phosphor; vor allem in Milchprodukten, Fleisch, Fisch und Brot ist er reichhaltig vorhanden. Die Phosphatverfügbarkeit wirkt für Pflanzen vielfach als limitierender Wachstumsfaktor, weswegen in der Landwirtschaft große Mengen phosphathaltigen Düngers ausgebracht werden müssen.Weißer Phosphor und Phosphorverbindungen wie Phosphan sowie zahlreiche Phosphorsäureester sind sehr giftig.
In Pflanzen erfüllt Phosphor verschiedene essenzielle Funktionen. Er ist Bestandteil von Lipiden und somit Strukturelement. In der DNA und RNA ist er die Brücke zwischen zwei Ribosen. Kovalent an Adenosin gebunden dient er als universelle Form des Energietransfers in Zellen. Des Weiteren hat Phosphor Einfluss auf den Kohlenhydrathaushalt, die Photosynthese und den Wasserhaushalt von Pflanzen.
Um den im Boden vorkommenden Phosphor für den Stoffwechsel verfügbar zu machen, müssen Pflanzen organisch oder anorganisch gebundenes Phosphor freisetzen, den sie als H2PO4− aufnehmen können. Dasselbe gilt für Mikroorganismen und Pilze, die im Boden leben. Viele Mikroorganismen, Pilze und Pflanzen geben Enzyme in den Boden ab, die die organischen Phosphorsäureester hydrolysieren und somit anorganisches Phosphat freisetzen, welches von den Organismen aufgenommen und metabolisiert werden kann. Diese Enzyme heißen Phosphatasen. Man unterscheidet je nach optimalem pH-Bereich der Phosphatase zwischen sauren (pH 4–5) und basischen Phosphatasen.
Nimmt die Pflanze mehr Phosphat auf als sie in Lipiden, Nucleinsäuren und an Adenosin gebunden gebrauchen kann, speichert sie den Überschuss als organisch gebundene Form in den Vakuolen. Phosphatasen helfen auch an dieser Stelle, das Phosphat wieder in die anorganische freie Form zu überführen.
Leiden Pflanzen unter Phosphatmangel, zeigen sie verschiedene Symptome. Die Blattflächen sind verkleinert und der Habitus ist insgesamt reduziert; es kann zu einer Anthocyan-Verfärbung kommen, Nekrosen können sich entwickeln. Durch die Akkumulation von Stärke in den Chloroplasten kommt es zur „Starrtracht“, eine starre Haltung der Blätter. Die Entwicklung von Blüten, Samen und Früchten ist reduziert bzw. verzögert. Da die Chlorophyllsynthese durch Phosphatmangel nicht so stark reduziert wird, wie im Verhältnis die Blattfläche abnimmt, kommt es zu einer Hyperchlorophyllierung in den Blättern, was sich durch eine tiefgrüne Färbung ausdrückt.
Da in der Rhizosphäre, gerade im Bereich von ein bis zwei mm um die Wurzel herum, die Phosphatkonzentration stark reduziert ist, reagieren manche Pflanzen auf Phosphatmangel mit einem verstärkten Wurzelwachstum.
Der Phosphorkreislauf oder Phosphorzyklus ist die stetige Wanderung und biogeochemische Umsetzung des Bioelementes Phosphor in Gewässern, in Böden und in Biomasse.
Wegen der ökologisch zentralen Bedeutung des Phosphats spielt auch die quantitative Phosphoranalytik eine wichtige Rolle in der Praxis der chemischen Gewässer- und Bodenüberwachung.
Die Methode der Wahl für den Nachweis von Phosphorverbindungen ist die 31P-NMR-Spektroskopie. 31P ist das einzige natürlich vorkommende Phosphor-Isotop und hat eine Kernspin-Quantenzahl von 1/2. Im Vergleich zum Wasserstoff beträgt die relative Empfindlichkeit nur 6,6 %. Der Resonanzbereich beträgt ca. 700 ppm (P4 hat beispielsweise eine Verschiebung von −520 ppm). Als Standard wird im Allgemeinen 85%ige Phosphorsäure verwendet. Da Phosphor ein Spin-1/2-Kern ist, sind die Spektren sehr gut auszuwerten. Wenn zusätzlich der Wasserstoff entkoppelt wird, resultiert meist ein scharfes Signal. Die Phosphorverschiebung ist stark abhängig von seinen Bindungspartner, er ist also sehr gut für die Identifikation von bekannten Verbindungen geeignet. Bei unbekannten Verbindungen ist die Aussagekraft oft beschränkt, weil einem Spektrenbereich nur selten eine Verbindungsklasse exklusiv zuzuordnen ist.
Die quantitative und qualitative Bestimmung von Phosphor erfolgt über das Phosphat (genauer Orthophosphat PO43−). Gebundener Phosphor wird hierzu gegebenenfalls durch oxidierenden Aufschluss in Phosphat überführt.
Bei der Nachweisreaktion mit Natriummolybdat erhält man in saurer Lösung eine gelbe Lösung von Natriummolybdophosphat, der Lösung wird ein Farbreagens aus gelöster Ascorbinsäure hinzugegeben und im Wasserbad erhitzt. Daraus ergibt sich Molybdänblau, welches quantitativ, fotometrisch bestimmt werden kann.
Bei der Nachweisreaktion mit Ammoniumheptamolybdat erhält man in saurer Lösung einen gelben Niederschlag von Ammoniummolybdophosphat. Unter Berücksichtigung, dass das Heptamolybdat in wässriger Lösung ein Gleichgewicht eingeht:
    {\displaystyle \mathrm {Mo_{7}O_{24}^{6-}+4\ H_{2}O\rightleftharpoons 7\ MoO_{4}^{2-}+8\ H^{+}} }
    {\displaystyle \mathrm {\ PO_{4}^{3-}+12\ MoO_{4}^{2-}+24\ H^{+}+3\ NH_{4}^{+}\longrightarrow (NH_{4})_{3}[P(Mo_{3}O_{10})_{4}]+12\ H_{2}O} }
  In alkalischer Ammoniaklösung fällt Phosphat bei Anwesenheit von Magnesium-Ionen als Magnesiumammoniumphosphat aus:
    {\displaystyle \mathrm {PO_{4}^{3-}+Mg^{2+}+NH_{3}+H_{2}O\longrightarrow MgNH_{4}PO_{4}+OH^{-}} }
    {\displaystyle \mathrm {2\ H_{3}PO_{4}+ZrOCl_{2}\longrightarrow Zr(HPO_{4})_{2}\cdot H_{2}O+2\ HCl} }
  Nicht korrekt ist, wie in vielen Lehrbüchern angegeben, die Form Zr3(PO4)4, in wässrigen Lösungen bildet sich diese Verbindung nicht!
Historisch ist die Mitscherlich-Probe zum Nachweis von weißem Phosphor interessant, die allem voran bei vermuteten Phosphorvergiftungen eingesetzt wurde. Hierbei wird der Mageninhalt mit Wasser erhitzt, wobei der weiße Phosphor, der mit dem Wasserdampf flüchtig ist, anschließend kondensiert und bei Berührung mit Luftsauerstoff durch ein Leuchten (Chemolumineszenz) in Erscheinung tritt.
Bei Strukturuntersuchungen von Verbindungen, in denen Phosphor enthalten ist, eignet sich die 31P-Kernresonanzspektroskopie.
Für eine gravimetrische Bestimmung kann aus Phosphat und Molybdationen in stark salzsaurer Lösung ein gelbes Molybdophosphation gebildet werden:
    {\displaystyle \mathrm {H_{2}PO_{4}^{-}+12\ [MoO_{2}Cl_{3}(H_{2}O)]^{-}\longrightarrow [P(Mo_{3}O_{10})_{4}]^{3-}+26\ H^{+}+36\ Cl^{-}} }
  Mit 8-Hydroxychinolin (kurz HOx oder Oxin genannt) bildet sich ein schwer löslicher Niederschlag von Oxin-12-molybdo-1-phosphat, der anschließend bei 160 °C getrocknet und in wasserfreier Form gewogen wird.
    {\displaystyle \mathrm {[P(Mo_{3}O_{10})_{4}]^{3-}+3\ HOx+3\ H^{+}\longrightarrow (H_{2}Ox)_{3}[P(Mo_{3}O_{10})_{4}]} }
   (Farbe: dunkelorange)Der grobkristalline Niederschlag enthält nur 1,37 % Phosphor. Somit sind vor allem kleinere Phosphatmengen gut bestimmbar (siehe Mikromol-Verfahren).
Volumetrische Phosphatbestimmungen werden durch Fällung mit La3+ oder mit Bi3+-Maßlösungen und anschließender Rücktitration mit EDTA durchgeführt.
Für die Bestimmung geringer Konzentrationen an Phosphat in Süßwasserproben wird ein tiefblauer Antimon-Phosphormolybdat-Komplex gebildet, der seine intensive Färbung erst durch ein Reduktionsmittel, meist Ascorbinsäure, erhält. Damit sind empfindliche Nachweise bis in den Bereich von ca. 0,6 mg PO4 /l (ca. 0,2 mg P/l) möglich.
Weißer Phosphor kann sich an der Luft entzünden, wenn er fein verteilt vorliegt. Die Selbstentzündungstemperatur liegt bei rund 34 °C, also relativ nahe bei Raumtemperatur. Die Reaktion zu Phosphorpentoxid ist stark exotherm. Mit Wasser und Alkalihydroxiden können giftige Phosphane entstehen. Starke Oxidationsmittel reagieren meist explosionsartig.
Die Entsorgung phosphorhaltiger Munition nach dem Zweiten Weltkrieg in flachen Ostseeabschnitten führt immer wieder zu schweren Verletzungen und Todesfällen. Die bernsteinfarbenen Phosphorklumpen werden angespült und gefährden damit vor allem Fischer oder Touristen. Statistiken zufolge starben nach dem Zweiten Weltkrieg 168 Menschen durch Munitionsreste in der Ostsee, 250 Menschen wurden zum Teil schwer verletzt. Mittlerweile gehen Experten sogar davon aus, dass die Zahlen deutlich höher liegen.Akute Vergiftungen äußern sich durch gastrointestinale Störungen, Leberschädigung mit schweren Stoffwechselstörungen sowie Schädigung von Herz und Nieren. Chronische Vergiftungen führen auch in geringen Mengen zu Störung des Allgemeinbefindens und Schädigung von Blut und der Knochen (Osteoporose), besonders am Kiefer.
Dosen ab 15 mg weißem Phosphor können schwere toxische Wirkungen auslösen. Mengen ab 50 mg (~1 mg/kg Körpergewicht) können bereits letal wirken.Schulversuche mit weißem Phosphor, wie zum Beispiel der Phosphorglockenversuch, sind nach neueren Regelungen nicht zulässig, weißer Phosphor darf aufgrund seiner Gefährlichkeit an Schulen nicht gelagert werden.
Die anderen bekannten Modifikationen von Phosphor sind wegen ihrer Wasserunlöslichkeit und geringeren Reaktivität in reiner Form ungiftig. Auch entzünden sie sich erst bei höherer Temperatur (roter Phosphor erst bei 260 °C).
Phosphor ist sehr reaktiv und bildet mit sehr vielen Nichtmetallen kovalente Verbindungen. Dabei kommt er in allen Oxidationsstufen zwischen –3 und +5 und den Koordinationszahlen 1 bis 6, meist 3 bis 4, vor. Die Oxidationszahlen –3 und +5 sind dabei bevorzugt.
Phosphane (die alte Bezeichnung Phosphine ist nicht mehr IUPAC-konform, wird aber in der chemischen Literatur, v. a. in der angelsächsischen, fast ausschließlich verwendet) bezeichnen Verbindungen des dreibindigen Phosphors mit Wasserstoff oder Ersatz einer oder mehrerer Wasserstoffatome durch organische Gruppen als Bindungspartner. Die organische Gruppe muss über die Kohlenstoffatome des Grundgerüstes direkt mit dem Phosphoratom verbunden sein. Wird die organische Gruppe durch ein Sauerstoffatom an das Phosphoratom gebunden (also Einheit P-O-C, z. B. im P(OPh)3), spricht man von Phosphorigsäureestern oder Phosphiten.
Mit Sauerstoff bildet Phosphor verschiedene Verbindungen, da Phosphor in mehreren Oxidationsstufen vorliegen kann. Dabei sind sowohl Phosphor-Sauerstoff-Einfachbindungen als auch Doppelbindungen sowie verbrückende Phosphor-Sauerstoff-Phosphor-Bindungen möglich.
Phosphortrioxid P4O6 ist eine weiße, weiche Verbindung, die sehr giftig und reaktiv ist und schnell zu Phosphorpentoxid weiterreagiert.
Phosphortetraoxid P2O4 ist ein Mischoxid. Man kann es durch Oxidation von Phosphortrioxid in Tetrachlorkohlenstoff gewinnen.
Phosphorpentoxid P4O10 ist das wichtigste Phosphoroxid. Es ist sehr hygroskopisch und wird als Trocknungsmittel verwendet.Von diesen Oxiden können eine große Zahl von Phosphor-Sauerstoff-Säuren und ihre entsprechenden Salze mit einem oder mehreren Phosphoratomen abgeleitet werden:
Es existieren auch schwefelhaltige Derivate dieser Säuren, z. B. die Thiophosphorsäure, deren Salze Thiophosphate heißen.
Es gibt außerdem eine Reihe von phosphorhaltigen Mineralien, die wichtigsten darunter sind Hydroxylapatit und Fluorapatit. Weitere Phosphormineralien findet man in der Kategorie:Phosphormineral.
Phosphor bildet eine große Zahl von Verbindungen mit den Halogeniden Fluor, Chlor, Brom und Iod. Die wichtigsten Verbindungentypen sind dabei PX3, P2X4 und PX5. Die Fluorverbindungen sind gasförmig, die Chlorverbindungen meist flüssig, Brom- und Iodverbindungen fest. Viele Phosphorhalogenverbindungen sind giftig. Alle Verbindungen sind hydrolyseempfindlich und müssen bei der Lagerung vor Luftfeuchtigkeit geschützt werden.
Beispiele für diese Verbindungsklasse sind Phosphortrichlorid, Phosphorpentachlorid, Diphosphortetrafluorid und Phosphortriiodid. Außerdem kennt man noch Sauerstoff- und Schwefelhalogenverbindungen des Typs POX3 (z. B. Phosphoroxychlorid) und PSX3, sowie polymere Oxidhalogenide des Typs (POX)n. Die Halogenide des Phosphors gehören zu den ersten nichtmetallischen Halogeniden, die bereits zu Beginn des 19. Jahrhunderts von Forschern wie Joseph Louis Gay-Lussac, Humphry Davy und Pierre Louis Dulong untersucht wurden.
Phosphor bildet mit Schwefel eine Reihe von Phosphorsulfiden, die in ihrer Struktur z. T. den Phosphor-Sauerstoff-Verbindungen ähneln. Der Struktur liegt ein P4-Tetraeder zugrunde, die Tetraederkanten und -spitzen sind unterschiedlich mit Schwefelatomen besetzt. Sie haben die allgemeine Formel P4Sx (x = 3–10). Hergestellt werden sie durch Erhitzen von rotem Phosphor und Schwefel in den entsprechenden Mengenverhältnissen. Phosphorpentasulfid (P4S10) ist hiervon die bedeutendste Verbindung. Tetraphosphortrisulfid (P4S3) wird teilweise noch für die Zündmasse von Streichhölzern benutzt. Auch Verbindungen mit Selen sind bekannt.
Stickstoff bildet mit Phosphor Nitride der Zusammensetzung PN und P3N5. Phosphornitridchloride (Phosphornitrildichloride) sind im monomeren Zustand nicht bekannt. Sie haben die allgemeine Formel (PNCl2)x mit einer ring- oder kettenförmigen Struktur. Sie entstehen durch Reaktion von Ammoniumchlorid mit Phosphorpentachlorid und gehören zur Gruppe der Phosphazene, Verbindungen der allgemeinen Formel (PNH2)x. Polydichlorphosphazen hat Eigenschaften wie synthetischer Kautschuk, ist aber unbeständig. Durch Ersatz der Chloratome mit Alkoxygruppen oder Perfluoralkoxygruppen erhält man aber chemisch und thermisch beständige Polymere mit elastomeren Eigenschaften.
Unter den organischen Phosphorverbindungen kann man unterscheiden in solche mit einer Phosphor-Kohlenstoff-Bindung und ohne Phosphor-Kohlenstoff-Bindung. Unter den ersten gehören Derivate der Phosphine, bei denen Wasserstoffatome durch einen oder mehrere organische Reste ersetzt sind. Ebenso gehören in diese Gruppe Phosphinoxide (R3PO), Alkylphosphinsäuren (R2PO(OH)) und Alkylphosphonsäuren (R-PO(OH)2) bzw. deren Salze. Beispiele für die zweite Gruppe sind Ester der Phosphinsäure, der Phosphonsäure oder der Phosphorsäure, die man als Phosphite, Phosphonate bzw. Phosphate bezeichnet.
Organische Phosphorverbindungen − beispielsweise Triphenylphosphin, Phenyldichlorphosphin oder Phosphorylide − spielen in vielen organischen Reaktionen, z. B. der Wittig-Reaktion eine wichtige Rolle.
In der Biochemie sind vor allem die Phosphorsäureester relevant. Sie sind lebenswichtiger Teil von vielen Stoffwechselprozessen und Teil der DNA. Wichtige Moleküle sind:
Harry H. Binder: Lexikon der chemischen Elemente – das Periodensystem in Fakten, Zahlen und Daten. Hirzel, Stuttgart 1999, ISBN 3-7776-0736-3.
F. Krafft: Phosphor. Von der Lichtmaterie zum chemischen Element. In: Angewandte Chemie. 81 (17/18), 1969, S. 634–645; doi:10.1002/ange.19690811703.
Ludwig Maier: Phosphorverbindungen und ihre technische Bedeutung. In: Chemie in unserer Zeit. 9. Jahrg. Nr. 4, 1975, S. 109–116; doi:10.1002/ciuz.19750090403.
Jochen Metzger: Zeitbombe Phosphor. Wenn dieser Rohstoff ausgeht, droht die Apokalypse. In: P.M.-Welt des Wissens. Nr. 8, 2010, ISSN 1863-9313, S. 58–64.
Die Phosphor-Krise - Das Ende der Menschheit? TV-Dokumentation bei arte, Mai 2013, Regie Christiane Schwarz und Marcel Weingärtner
Phosphat-Reserven Vortrag über die weltweiten Reserven, Abbau, Verbrauch und Preisentwicklung (PDF; 3,3 MB)
Die Photorespiration (griechisch φῶς phōs, Licht; lat.: Respiratio, Atmung), auch oxidativer photosynthetischer Kohlenstoffzyklus bzw. (oxidativer) C2-Zyklus, ist ein Stoffwechselweg in Organismen, die eine oxygene Photosynthese betreiben (Pflanzen, Algen, Cyanobakterien). Hierbei wird Kohlenstoffdioxid in einer lichtabhängigen Reaktion freigesetzt und Sauerstoff wie in der Atmung verbraucht. Daher bezeichnet man den Stoffwechselweg auch als „Lichtatmung“. Diese Bezeichnung lehnt an die der Zellatmung („Dunkelatmung“) an, da dort ebenso Kohlenstoffdioxid entsteht und Sauerstoff verbraucht wird. Jedoch haben beide Vorgänge nichts miteinander zu tun.
Die Photorespiration kann im Zuge der Kohlenstoffdioxidfixierung im Calvin-Zyklus während der Photosynthese auftreten. Normalerweise nutzt das beteiligte Schlüsselenzym RuBisCO als Substrat Kohlenstoffdioxid, alternativ akzeptiert es aber auch Sauerstoff. Dadurch entsteht das toxische Stoffwechselprodukt 2-Phosphoglycolat, das nicht mehr im Calvin-Zyklus verwendet werden kann und daher durch andere biochemische Reaktionen umgewandelt werden muss. In höheren Pflanzen finden diese Reaktionen in drei eng benachbarten Zellkompartimenten statt: dem Chloroplasten, dem Peroxisom und dem Mitochondrium. Es handelt sich im Wesentlichen um einen Rückgewinnungsprozess.
Der photorespiratorische Stoffwechselweg gilt als einer der verschwenderischsten Prozesse auf der Erde.
Die ersten Aufzeichnungen über die Auswirkung der Photorespiration stammen von Otto Warburg. Er beobachtete 1920 in der Süßwasseralge Chlorella, dass die Kohlenstoffdioxidaufnahme durch Sauerstoff gehemmt werden kann. Der Wissenschaftler John P. Decker konnte hierbei nachweisen, dass bei Anwesenheit von Licht und Sauerstoff vermehrt Kohlenstoffdioxid freigesetzt wird. Ohne die biochemischen Prozesse zu kennen, konnten die beiden Wissenschaftler damit auf die Bedeutung von Sauerstoff in der Photorespiration schließen.
Weitere Schritte in der Aufklärung beschäftigten sich mit der Rolle von Glycolat als eines der ersten Stoffwechselprodukte der Photorespiration und behandelten den Einfluss von Sauerstoff und Kohlenstoffdioxid auf diesen Prozess.
So konnten Warburg und Günter Krippahl 1960 zeigen, dass hohe Sauerstoffkonzentrationen die Bildung von Glycolat verursachen. Dies wurde zwei Jahre später von James A. Bassham und Martha Kirk in Chlorella bestätigt, die ebenfalls einen sauerstoffabhängigen Anstieg an Glycolat bzw. 2-Phosphoglycolat messen konnten. Israel Zelitch vermutete 1964, dass Glycolat ein wichtiges Intermediat bei der Photorespiration darstelle. Außerdem beobachteten Bassham und Kirk, dass Sauerstoff die Photosynthese hemmen (inhibieren) kann.
Die durch Sauerstoff hervorgerufene Bildung von Glycolat wird durch hohe Kohlenstoffdioxidkonzentrationen umgekehrt, wie im Folgejahr durch Bermingham und Mitarbeiter demonstriert wurde. Das zeigt, dass Sauerstoff und Kohlenstoffdioxid miteinander konkurrieren. Im Jahr 1966 wurden diese Ergebnisse durch die Arbeitsgruppe um Gleb Krotkov validiert: Die sauerstoffabhängige Inhibition der Photosynthese verringert sich durch steigende CO2-Konzentrationen.Die erste Theorie über den photorespiratorischen Stoffwechselweg wurde 1971 von Nathan E. Tolbert vorgeschlagen.Basierend auf den vorausgegangenen Beobachtungen und eigenen Untersuchungen konnten George E. Bowes und William L. Ogren im selben Jahr mit dem aus Sojabohnen isolierten Enzym RuBisCO (Ribulose 1,5-Bisphosphat Carboxylase/Oxygenase) demonstrieren, dass sowohl Kohlenstoffdioxid als auch Sauerstoff als Substrate für RuBisCO dienen. Zu diesem Zeitpunkt nannte man RuBisCO noch „Ribulosebisphosphatcarboxylase“, da nur ihre carboxylierende, also kohlenstoffassimilierende Funktion bekannt war. Reagiert RuBisCO mit Sauerstoff anstatt mit Kohlenstoffdioxid, wird 2-Phosphoglycolat gebildet. Damit hat das Enzym sowohl eine Carboxylase-, als auch eine Oxygenasefunktion, wodurch der heute verwendete Name zustande kommt. Die Abkürzung RuBisCO für das Enzym wurde 1979 von David Eisenberg bei einem Seminar eingeführt.Diese Schlussfolgerungen wurden zunächst nur zögerlich akzeptiert. Die Arbeitsgruppe um Tolbert konnte 1973 jedoch mit isotopenmarkierten Substraten (14C-Ribulose-1,5-bisphosphat und 18O2) den Nachweis für die Oxygenasereaktion von RuBisCO zweifelsfrei belegen. Durch diese Ergebnisse und den vorausgegangenen Arbeiten und Theorien wird in der Literatur Tolbert als der Entdecker der Photorespiration geführt.
Weitere Untersuchungen in den Folgejahren behandelten die Messungen der Reaktionskinetiken von RuBisCO, den Einfluss der Temperatur auf die Photorespiration sowie die Charakterisierung aller beteiligten Enzyme. Kenntnisse über die Translokatoren für den Austausch der Metabolite zwischen den Organellen sind dagegen noch begrenzt und bleiben weiterhin Gegenstand der Forschung.
Grüne Pflanzen, Algen sowie Cyanobakterien („Blaualgen“) nehmen Kohlenstoffdioxid auf, um daraus im Calvin-Zyklus Kohlenhydrate aufzubauen. Der erste Schritt erfolgt durch das Enzym Ribulose-1,5-bisphosphat-Carboxylase/-Oxygenase (RuBisCO), das die Addition von CO2 an Ribulose-1,5-bisphosphat (1, vgl. Abbildung oberer Zweig) katalysiert. Dadurch werden zwei Moleküle 3-Phosphoglycerat (3, obere Abbildung) gebildet und im Calvin-Zyklus weiter prozessiert.
Als Nebenreaktion akzeptiert RuBisCO auch Sauerstoff („Oxygenasereaktion“), wodurch neben 3-Phosphoglycerat (3) das 2-Phosphoglycolat (4) entsteht (vgl. Abbildung unterer Zweig). 3-Phosphoglycerat fließt regulär in den Calvin-Zyklus ein. Jedoch kann 2-Phosphoglycolat weder direkt zu einem Kohlenhydrat aufgebaut werden, noch wird es für den Metabolismus in irgendeiner Form benötigt. Grünalgen beispielsweise scheiden dessen dephosphorylierte Form, Glycolat, bei guter CO2-Versorgung aus (photosynthetische Glycolatexkretion).Die Photorespiration ist ein Stoffwechselweg, der 2-Phosphoglycolat durch eine Reihe von Reaktionen in 3-Phosphoglycerat überführt und damit dem Kohlenstoffverlust entgegenwirkt. Für diese Regeneration werden neun Enzyme benötigt; in höheren Pflanzen findet sie unter Beteiligung des Cytosols im Chloroplast, im Peroxisom sowie im Mitochondrium statt.
Die Bildung von 2-Phosphoglycolat im Chloroplasten erfolgt durch RuBisCO ausschließlich im Licht, da das Enzym im Dunkeln nicht aktiv ist. So erklärt sich der erste Teil im Namen Photorespiration. Damit läuft die Photorespiration immer parallel zum Calvin-Zyklus ab.
Die Nebenreaktion des Enzyms RuBisCO und das damit verbundene Auftreten des photorespiratorischen Stoffwechselweges liegt daran, dass RuBisCO sowohl CO2 wie auch O2 als Substrat umsetzt. Zwar ist die Affinität von RuBisCO zu CO2 höher als zu O2, der KM-Wert beträgt für CO2 9 µMol/l, für O2 350 µMol/l und damit wird CO2 gegenüber O2 bevorzugt, jedoch ist die Konzentration von Sauerstoff im Wasser 20-mal höher als die von CO2. Dadurch wird jedes vierte bis jedes zweite Molekül Ribulose-1,5-bisphosphat mit Sauerstoff anstatt Kohlenstoffdioxid umgesetzt.
Da RuBisCO sowohl Kohlenstoffdioxid als auch Sauerstoff als Substrat verwenden kann, tritt die Oxygenasereaktion von RuBisCO umso häufiger auf, je höher die Sauerstoffkonzentration im Verhältnis zur Kohlenstoffdioxidkonzentration ist. Dieses Verhältnis steigt mit der Temperatur. Die Löslichkeit eines Gases fällt mit steigender Temperatur, bei CO2 jedoch stärker als bei O2 (vgl. Tabelle). Bei gleichem Verhältnis der Partialdrucke beider Gase verringert sich deshalb das Verhältnis von gelöstem CO2 zu gelöstem O2 mit steigender Temperatur. Für eine CO2-Fixierung wird es damit ungünstiger. Außerdem werden bei höheren Temperaturen die Spaltöffnungen des Blattes geschlossen, um den Wasserverlust der Pflanze zu verringern. Dies bedeutet, dass auch weniger CO2 in die Zelle gelangt, während der lokale O2-Gehalt durch Photolyse ansteigt. Hohe Temperaturen begünstigen infolgedessen die Photorespiration.
Das im Chloroplasten gebildete 2-Phosphoglycolat wird zunächst durch eine 2-Phosphoglycolat-Phosphatase (PGP, EC 3.1.3.18) zu Glycolat umgesetzt. Die Enzymaktivität ist für Pflanzen essentiell, falls das Enzym beispielsweise fehlt, können diese unter natürlichen CO2-Konzentrationen nicht wachsen. Obwohl Pflanzen auch über eine cytosolische PGP verfügen, spielt nur das plastidäre Isoenzym eine Rolle in der Photorespiration.Glycolat wird durch einen Glycolat-Glycerat-Antiporter aus dem Chloroplasten transportiert und gelangt durch Porin-ähnliche Kanäle in das Peroxisom. In assimilierenden Blattzellen höherer Pflanzen liegt ein besonderer Typ von Peroxisom vor, weswegen es als Blattperoxisom bezeichnet wird.Im Peroxisom wird Glycolat durch eine Flavinmononukleotid (FMN)-abhängige Glycolat-Oxidase (EC 1.1.3.15) zu Glyoxylat oxidiert. Das Enzym liegt als Tetra- oder Oktamer identischer Untereinheiten vor. Während Mais nur über eine Genkopie dieses Enzyms verfügt, wurden in der Ackerschmalwand fünf Kopien identifiziert. Falls diese Genkopien entfernt werden, können diese Pflanzen nur unter hohen CO2-Konzentrationen wachsen. Bei der Oxidation zu Glyoxylat wird Sauerstoff verbraucht, was auf den zweiten Teil des Begriffs Photorespiration hinweist: Wie allgemein in der aeroben Atmung wird Sauerstoff konsumiert, und später Kohlenstoffdioxid freigesetzt (siehe weiter unten).
Bei dem Schritt entsteht Wasserstoffperoxid (H2O2), welches für die Zelle giftig ist. Daher wird H2O2 durch eine Katalase zu Wasser und Sauerstoff (O2) abgebaut.
als α-Ketosäure wird Glyoxylat durch die Serin-Glyoxylat-Transaminase (EC 2.6.1.45), ein Homodimer, zu Glycin transaminiert; der Donor der NH2-Gruppe ist das erst nachfolgend entstehende L-Serin. Das Enzym bevorzugt als Stickstoffdonor L-Serin; für den photorespiratorischen Weg ist es essentiell.
ein weiteres Molekül Glyoxylat wird durch eine Glutamat-Glyoxylat-Aminotransferase (EC 2.6.1.4) zu Glycin umgesetzt, wobei als Aminogruppendonor L-Glutamat (Glu) dient. Dabei entsteht α-Ketoglutarat. Diese Aminotransferase kann neben L-Glutamat auch L-Alanin als N-Donor verwenden.Die beiden erzeugten Moleküle Glycin werden schließlich ins Mitochondrium transportiert. Dort vereinigen sie sich in einer Tetrahydrofolsäure (THF)-abhängigen Reaktion zu einem Molekül L-Serin. Hierbei sind sowohl ein Glycin-Decarboxylase-Komplex (GDC) als auch eine Serin-Hydroxymethyltransferase (SHMT, EC 2.1.2.1) beteiligt (vgl. Abbildung oben). GDC besteht funktionell aus drei Enzymen, einer decarboxylierenden Glycindehydrogenase (EC 1.4.4.2), einer Aminomethyltransferase (EC 2.1.2.10) und einer Dihydrolipoyldehydrogenase (EC 1.8.1.4). GDC desaminiert und decarboxyliert Glycin unter Verbrauch von NAD+. Das bei diesem Schritt entstehende CO2 gelangt möglicherweise in Form von Bicarbonat aus dem Mitochondrium. In C3-Pflanzen werden 30–50 % des freigesetzten Kohlenstoffdioxids wieder durch RuBisCO refixiert, der Rest entweicht. SHMT verknüpft schließlich die Methylengruppe der ersten Glycins, Wasser und ein weiteres Molekül Glycin zu L-Serin.
Beide Enzymkomplexe, GDC und SHMT, liegen hochkonzentriert in der Matrix von Pflanzenzellenmitochondrien vor und sind oxidationsempfindlich. Das freigesetzte Ammonium (NH4+) geht nicht verloren und wird noch im photorespiratorischen Stickstoffkreislauf regeneriert (vgl. Abschnitt unten).
L-Serin wird nach Transport ins Peroxisom durch die oben beschriebene Serin-Glyoxylat-Transaminase zu Hydroxypyruvat desaminiert. Dieses wird unter Verbrauch von NADH zu D-Glycerat reduziert, was eine NAD+-abhängige Hydroxypyruvat-Reduktase (EC 1.1.1.81) katalysiert. Zurück im Chloroplasten wird D-Glycerat zu 3-Phosphoglycerat durch eine Glyceratkinase (GKK, EC 2.7.1.31) umgesetzt, dabei wird ein Molekül ATP investiert. 3-Phosphoglycerat tritt dann regulär in den Calvin-Zyklus ein. Interessanterweise ist die GKK das einzig bekannte Enzym, das 3-Phosphoglycerat bildet; Bakterien verwenden dagegen eine Kinase, bei der 2-Phosphoglycerat entsteht.
Der Austausch der beteiligten Metabolite erfolgt entweder durch Translokatoren oder durch Porine (in Peroxisomen).
Im photorespiratorischen Weg wird Glutamat zu α-Ketoglutarat im Peroxisom umgesetzt. Die Aminogruppe wird aber später im Mitochondrium durch den Glycin-Decarboxylasekomplex in Form von NH4+ (Ammonium) abgespalten. Ammonium selbst wirkt in höheren Konzentrationen cytotoxisch, darf aber nicht einfach ausgeschieden werden. Denn das Pflanzenwachstum wird häufig durch die Verfügbarkeit an Stickstoff limitiert.Damit Ammonium als wertvolle Stickstoffquelle nicht verloren geht und Glutamat regeneriert wird, folgen weitere Reaktionen im Chloroplasten. Dorthin gelangt NH4+ durch einen Ammoniumtransporter, möglicherweise auch durch einfache Diffusion. L-Glutamat (3, vgl. Abbildung) und NH4+ werden dann unter ATP-Verbrauch durch die Glutamin-Synthetase (GS, EC 6.3.1.2) zu L-Glutamin (2) umgesetzt. Letzteres wird mit α-Ketoglutarat (1) durch eine Ferredoxin-abhängige Glutamin-Oxoglutarat-Aminotransferase (GOGAT, auch Glutamat-Synthase, EC 1.4.7.1) zu zwei Molekülen L-Glutamat umgesetzt. Gleichzeitig werden zwei Moleküle Ferredoxin oxidiert (Fdox). α-Ketoglutarat gelangt im Austausch gegen Malat in den Chloroplasten (DiT1-Translokator), während Glutamat durch einen Malat-Glutamat-Translokator (DiT2) wieder zurück in das Peroxisom transportiert wird. Dort steht es wieder zur Transaminierung von Glyoxylat zur Verfügung.
Nahezu alles freigesetzte Ammonium wird durch diesen Zyklus refixiert, nur etwa 0,1 ‰ gehen verloren. Diese Regenerierung verbraucht insgesamt zwei Moleküle Ferredoxin und ein Molekül ATP:
    {\displaystyle \mathrm {NH_{4}^{+}+\alpha {\text{-}}Ketoglutarat^{-}+ATP+2\ Fd_{red}\rightarrow } }
Cyanobakterien (Blaualgen) sind die einzig bekannten Bakterien, die eine oxygene Photosynthese betreiben. Sie nutzen den Calvin-Zyklus zur Fixierung von Kohlenstoffdioxid. Lange Zeit wurde aus zwei Gründen angenommen, dass die Photorespiration in Cyanobakterien nicht auftritt. Erstens reichern Cyanobakterien Kohlenstoffdioxid aktiv durch Carboxysomen an, so dass RuBisCO kaum mit Sauerstoff reagiert und die Photorespiration daher ohnehin nicht in nennenswerten Ausmaß auftritt. Zweitens glaubte man, dass wenn sich geringe Mengen an Glycolat bilden sollten, dieses wie in Grünalgen ausgeschieden werde und nicht in irgendeiner Form regeneriert werden müsste.Nun ist bekannt, dass Cyanobakterien ebenfalls über einen 2-Phosphoglycolat-Stoffwechselweg verfügen. Dieser beginnt analog wie bei Pflanzen mit der Umsetzung von 2-Phosphoglycolat über Glycolat zu Glyoxylat. Für den zweiten Schritt verwenden das filamentöse, stickstofffixierende Cyanobakterium Anabaena sowie der im Meer vorkommende Prochlorococcus marinus bei der Oxidation von Glycolat zu Glyoxylat eine pflanzenähnliche Glycolatoxidase. Dagegen nutzt Synechocystis eine Glycolatdehydrogenase, die NADH verbraucht und bei der kein Wasserstoffperoxid entsteht.
Glyoxylat kann – je nach Art des Cyanobakteriums – unterschiedlich verstoffwechselt werden; es wurden drei sich zum Teil überlappende Stoffwechselwege identifiziert. So wird es in manchen wenigen Cyanobakterien durch eine Glyoxylatoxidase unter Sauerstoffverbrauch zu Oxalat oxidiert. Oxalat wird anschließend durch eine Oxalatdecarboxylase und eine Formatdehydrogenase zu zwei Molekülen Kohlenstoffdioxid umgesetzt, dabei wird auch ein Molekül NADH gebildet (Decarboxylierungsweg). Dieser Weg dient damit nicht der Rückführung von Kohlenstoff, im Gegenteil, er wird hierdurch freigesetzt.
Andere Cyanobakterien bilden Hydroxypyruvat aus Glyoxylat. Dies erfolgt entweder über einen pflanzenähnlichen Mechanismus (pflanzenähnlicher Stoffwechselweg, vgl. Abschnitt oben). Alternativ können manche Cyanobakterien zwei Moleküle Glyoxylat durch eine Glyoxylatcarboligase und eine Tartronsäuresemialdehydreduktase unter NADH-Verbrauch zu Hydroxypyruvat umformen, dabei entsteht auch Kohlenstoffdioxid und als Zwischenprodukt Tartronatsemialdehyd (Glyceratweg).
In Synechocystis und Anabaena wird Hydroxypyruvat – wie auch in Pflanzen – durch eine pflanzenähnliche Glyceratkinase zu 3-Phosphoglycerat unter ATP-Verbrauch phosphoryliert. Andere Cyanobakterien bilden aber zuerst 2-Phosphoglycerat, das anschließend zu 3-Phosphoglycerat isomerisiert wird.
In Synechocystis treten diese drei sich überlappenden Stoffwechselwege sogar gemeinsam auf. Nur wenn alle drei Wege unterbrochen werden, benötigt Synechocystis hohe Kohlenstoffdioxidkonzentrationen zum Überleben – analog wie in Pflanzen, bei denen der photorespiratorische Weg unterbrochen wird.
Die Photorespiration ist ein kostspieliger Prozess, in dem vermehrt ATP und Reduktionsmittel investiert werden. Ohne Photorespiration würden pro fixiertem mol CO2 3 mol ATP und 2 mol NADPH verstoffwechselt. Für den Fall, dass das Verhältnis von Carboxylierung zu Oxygenierung 1 zu 0,25 beträgt, erhöht sich der Verbrauch pro fixiertem mol CO2 auf 5,375 mol ATP und 3,5 mol NADPH.
Dieser Mehrverbrauch reduziert die Effizienz der Photosynthese. Nur unter ausreichend hohen CO2-Partialdrücken (z. B. 1 % CO2) findet keine Oxygenasereaktion und damit kein Effizienzverlust der Photosynthese statt. Somit stellt die Photorespiration per se eine energetisch ungünstige Mehrinvestition für die C3-Pflanze dar. Man schätzt, dass der Kohlenstoffgewinn im Calvin-Zyklus ohne Photorespiration um etwa 30 % höher sein könnte. Dadurch, dass RuBisCO das häufigste Protein auf der Erde ist, wird die Photorespiration sogar als einer der verschwenderischsten Prozesse auf der Erde eingestuft.
Im Laufe der Evolution haben sich verschiedene Mechanismen entwickelt, um die kostspielige Nebenreaktion von RuBisCO insbesondere in Hinblick auf gesunkene CO2-Konzentrationen zu vermeiden. So verfügen die im Wasser lebenden Grünalgen und Cyanobakterien über kohlenstoffdioxidkonzentrierende Mechanismen wie Pyrenoide bzw. Carboxysomen. Diese haben die Funktion, Kohlenstoffdioxid um das RuBisCO-Molekül herum anzureichern. Dadurch entsteht eine hohe lokale CO2-Konzentrationen, bei der RuBisCO kaum noch mit Sauerstoff reagiert.
In Landpflanzen entstanden aufgrund geänderter Klimabedingungen der C4− und CAM-Stoffwechsel. Diesen liegt eine ATP-getriebene CO2-Pumpe zu Grunde, mit der sie die CO2-Konzentration im Gewebe aktiv erhöhen und damit RuBisCO mit Kohlenstoffdioxid sättigen. Sie erleiden bei einer Temperaturerhöhung kaum Einbußen der Photosyntheseeffizienz, da die Photorespiration nur in geringen Maßen auftritt. Sie haben infolgedessen eine höhere Nettofixierungsrate als C3-Pflanzen. Zu C4-Pflanzen zählen beispielsweise Zuckerrohr, Sorghum, Mais und viele Unkräuter, welche an heißen Standorten anzutreffen sind.
Durch den photorespiratorischen Weg verfügen alle Organismen, die eine oxygene Photosynthese betreiben (Pflanzen, Algen, Cyanobakterien), über einen Stoffwechselweg, um den Kohlenstoffverlust infolge der Oxygenasereaktion von RuBisCO so gering wie möglich zu halten.
In dem mehrstufigen Prozess werden aus zwei Molekülen 2-Phosphoglycolat drei C-Atome für den Calvin-Zyklus wieder bereitgestellt und ein Molekül CO2 freigesetzt. Falls dieses CO2-Molekül im Calvin-Zyklus nicht refixiert wird, liegt der Verlust an Kohlenstoffatomen durch die Photorespiration bei 25 %.
Damit liegt die Primärfunktion der Photorespiration in der Rückgewinnung des Kohlenstoffes. In den meisten grünen C3-Pflanzen, auch C4-Pflanzen wie Mais, sowie in Cyanobakterien ist der Stoffwechselweg sogar essentiell, also unverzichtbar.C4-Pflanzen sowie Cyanobakterien reichern Kohlenstoffdioxid zwar aktiv an, so dass die Photorespiration nicht so stark auftritt wie in C3-Pflanzen. Dennoch kann man auch dort den photorespiratorischen Weg beobachten. Dies bedeutet, dass die Photorespiration im Laufe der Evolution trotz kohlenstoffdioxidkonzentrierender Mechanismen nicht verschwunden ist und daher einige weitere Vorteile bieten muss:
Hohe Konzentrationen an 2-Phosphoglycolat, Glyoxylat oder Glycin wirken metabolisch toxisch. So hemmt 2-Phosphoglycoat die Triosephosphatisomerasen und Glyoxylat die RuBisCO. Landpflanzen können diese Metabolite nicht wie Grünalgen ausscheiden. Durch die Photorespiration bleiben die Konzentrationen aber unterhalb schädlicher Grenzwerte.
Während der Photorespiration werden Aminosäuren wie Glycin und L-Serin gebildet, in höheren Pflanzen ist sie die Hauptquelle dieser Aminosäuren. Jedoch könnten diese Aminosäuren auch auf anderen Stoffwechselwegen synthetisiert werden, insbesondere wenn die Photorespiration unterdrückt wird.
In Acker-Schmalwand und im Weichweizen wurde gezeigt, dass bei unterdrückter Photorespiration (2 % atmosphärische Sauerstoffkonzentration) auch die Nitratassimilation inhibiert wurde.
Ein in der Literatur häufig diskutierter Vorteil liegt in der Bewältigung gewisser Stresssituationen. Bei hohen Lichtintensitäten, geringen bzw. hohen Temperaturen und insbesondere Wassermangel kommt es vermehrt zu photooxidativen Schäden des Photosyntheseapparates. Dies liegt daran, dass die photosynthetischen Reaktionszentren überlastet sind, weil die bereitgestellten Elektronen nicht schnell genug im Calvin-Zyklus (in der „Dunkelreaktion“) verbraucht werden können – der Elektronentransport „stockt“. Durch den Mehrverbrauch an Reduktantien während der Photorespiration, besonders unter niedrigen CO2-Partialdrücken, könnte dieser Stoffwechselweg als eine Art „Schutzventil“ gedeutet werden. So dient der Decarboxylierungsweg weniger Cyanobakterien ausschließlich der Beseitigung überschüssiger Energie, da 2-Phosphoglycerat nicht wiederverwertet wird. Für Landpflanzen muss aber angemerkt werden, dass der Hauptteil dieser überschüssigen Energie (50–70 % aller absorbierten Photonen) im sogenannten Xanthophyllzyklus beseitigt wird.
Bei einer seit kurzem diskutierten Möglichkeit nimmt man an, dass das während der Photorespiration erzeugte Wasserstoffperoxid (H2O2) für Signalprozesse wichtig ist. H2O2 wird als wichtiges Signalmolekül betrachtet, da es unter anderem andere Redoxsignale beeinflusst. Damit werden beispielsweise Prozesse des Pflanzenwachstums und Stressantworten (Schädlingsbefall) gesteuert. Da H2O2 in photosynthetisch aktiven Zellen durch Photorespiration am schnellsten gebildet wird, könnte das Molekül beispielsweise das pflanzliche Verteidigungssystem aktivieren.
Vorläufer der heutigen Cyanobakterien waren die ersten Lebewesen mit einer oxygenen Photosynthese. Damit war bei ihnen RuBisCO auch Sauerstoff ausgesetzt. Wahrscheinlich wurde auch dort 2-Phosphoglycolat erzeugt, da die CO2-konzentrierenden Mechanismen, wie z. B. das Carboxysom, in der Evolution erst viel später auftraten (vermutlich vor 360–300 Millionen Jahren, in der die Sauerstoffkonzentration in der Atmosphäre anstieg). Pflanzen haben im Laufe der Zeit Enzyme für den Glyceratweg verloren, der heute in vielen Cyanobakterien noch vorkommt. Die Photorespiration ist aber erhalten geblieben. Selbst in Picoplankton, deren Genom stark verkleinert ist (z. B. Prochlorococcus oder Synechococcus), sind die Gene für die Photorespiration erhalten geblieben. Der C2-Zyklus der heutigen Cyanobakterien war entweder bereits zu Beginn vorhanden, oder entwickelte sich recht früh in den ersten Protocyanobakterien.
Nach der Endosymbiontentheorie gehen die heutigen Pflanzen und Algen auf Vorläufer der Cyanobakterien zurück, so dass auch RuBisCO in diese Organismen gelangt ist. RuBisCO aller Organismen (Bakterien, Algen, Pflanzen) ist gemeinsam, dass sie sowohl Kohlenstoffdioxid als auch Sauerstoff als Substrat akzeptieren. Durch eine Spezifitätskonstante kann man angeben, wie sehr RuBisCO CO2 als Substrat gegenüber O2 bevorzugt. Diese Konstante ist das Produkt aus zwei Verhältnissen: den Michaeliskonstanten KM und den maximalen Geschwindigkeitskonstanten vmax (vgl. Tabelle).
Im Laufe der Evolution wurde die Affinität der RuBisCO gegenüber CO2 nur etwas verbessert. Wahrscheinlich wurde das katalytische Zentrum des Enzyms in der Zeit optimiert, als die atmosphärische O2-Konzentration noch sehr gering war und damit keinen selektiven Druck ausüben konnte. Infolgedessen konnte RuBisCO durch den späteren Anstieg der Sauerstoffkonzentration nicht mehr signifikant verbessert werden.
In C3-Pflanzen tritt die Photorespiration besonders unter warmen und trockenen Umweltbedingungen auf, was die Ernteerträge in jenen Regionen – besonders in Hinblick auf die Klimaerwärmung und die wachsende Weltbevölkerung – mindert. Daher orientiert sich ein Teil der Forschung auf eine gentechnische Reduzierung der Photorespiration oder auf eine Einführung neuer Stoffwechselwege, wodurch die Ernteerträge gesteigert werden könnten. Hierbei konnte durch einen Abbau des 2-Phosphoglycolat direkt im Chloroplasten die Effizienz der Lichtausnutzung in Tabakpflanzen um 17 % gesteigert und Ernteerträge um mehr als 40 % gesteigert werden.Verschiedene Versuche, um die Spezifität von RuBisCO gegenüber Kohlenstoffdioxid zu erhöhen, führten zu niedrigeren Umsatzraten. Damit verschlechterte sich die Photosyntheserate. Eine weitere Strategie verfolgt das Ziel, andere RuBisCO-Arten, wie das bakterielle Typ II-RuBisCO, in C3-Pflanzen einzubringen. Dies scheiterte aber deshalb, da sich das neueingebrachte RuBisCO nicht zu einem funktionellen Enzym zusammensetzt.
Ein anderer Teil der Forschung versucht daher, nicht die Photorespiration in C3-Pflanzen zu unterdrücken. Stattdessen folgt sie dem Ziel, C3-Pflanzen in C4-Pflanzen umzuwandeln, da dort die Photorespiration kaum auftritt und C4-Pflanzen bei Wasser- und Stickstoffmangel C3-Pflanzen übervorteilen, besonders bei steigenden Temperaturen. Eines dieser Projekte ist der sogenannte C4-Reis, bei dem in handelsüblichen Reis, eine C3-Pflanze, die C4-Photosynthese eingebracht werden soll.
Bauwe H., Hagemann M. und Fernie AR. (2010): Photorespiration: players, partners and origin. In: Trends Plant Sci. 15(6); 330–336; PMID 20403720; doi:10.1016/j.tplants.2010.03.006
Reumann, S. und Weber, AP. (2006): Plant peroxisomes respire in the light: some gaps of the photorespiratory C2 cycle have become filled – others remain. In: Biochim Biophys Acta 1763(12); 1496–1510; PMID 17046077; doi:10.1016/j.bbamcr.2006.09.008
Foyer, CH. et al. (2009): Photorespiratory metabolism: genes, mutants, energetics, and redox signaling. In: Annu Rev Plant Biol. 60; 455–484; PMID 19575589; doi:10.1146/annurev.arplant.043008.091948
Bauwe, H. (2010): Recent developments in photorespiration research. In: Biochem Soc Trans. 38(2); 677–682; PMID 20298242; doi:10.1042/BST0380677
Hans W. Heldt, Birgit Piechulla: Pflanzenbiochemie. 4. Auflage. Spektrum Akademischer Verlag, Heidelberg 2008; ISBN 978-3-8274-1961-3
Caroline Bowsher, Martin W. Steer, Alyson K. Tobin: Plant Biochemistry. Garland Pub, New York, NY 2008, ISBN 978-0-8153-4121-5
Nelson, David L., Cox, Michael M., Lehninger, Albert L. [Begr.]: Lehninger Biochemie. Springer, Berlin; 4., vollst. überarb. u. erw. Auflage 2009; ISBN 978-3-540-68637-8
Andreas Bresinsky, Christian Körner, Joachim W. Kadereit, G. Neuhaus, Uwe Sonnewald: Strasburger – Lehrbuch der Botanik. 36. Auflage. Spektrum Akademischer Verlag, Heidelberg 2008, ISBN 978-3-8274-1455-7
Ulrich Lüttge, Manfred Kluge, Gabriela Bauer: Botanik. 5. vollst. überarb. Auflage. Wiley-VCH, Weinheim 2005; ISBN 978-3-527-31179-8

Eine physikalische Größe ist eine an einem Objekt der Physik quantitativ bestimmbare Eigenschaft eines Vorgangs oder Zustands. Beispiele solcher Größen sind Länge, Masse, Zeit, Stromstärke. Jeder spezielle Wert einer physikalischen Größe (Größenwert) wird als Produkt aus einem Zahlenwert (auch Maßzahl) und einer Maßeinheit angegeben. Vektorielle Größen werden durch Größenwert und Richtung angegeben.Der Begriff physikalische Größe im heutigen Verständnis wurde von Julius Wallot eingeführt und setzte sich ab 1930 langsam durch. Das führte zu einer begrifflich klaren Unterscheidung zwischen Größengleichungen, Zahlenwertgleichungen und zugeschnittenen Größengleichungen (siehe Zahlenwertgleichung). Eine Größengleichung ist die mathematische Darstellung eines physikalischen Gesetzes, das Zustände eines physikalischen Systems und deren Änderungen beschreibt. Sie stellt den dabei geltenden Zusammenhang zwischen verschiedenen physikalischen Größen dar, wobei in der Regel für jede dieser Größen ein Formelzeichen steht. Größengleichungen gelten unabhängig von den gewählten Maßeinheiten.
Diejenigen physikalischen Größen, die als Basis eines Größensystems festgelegt sind, heißen Basisgrößen.
Ein Vergleich von zwei Dingen erfordert stets ein Kriterium, anhand dessen der Vergleich stattfindet (tertium comparationis). Dies muss ein Merkmal (oder Eigenschaft) sein, das beiden Dingen zu eigen ist. Als physikalische Größe bezeichnet man ein Merkmal dann, wenn dieses einen Wert besitzt, sodass das Verhältnis zweier Merkmalswerte ein reeller Zahlenfaktor (Verhältnisgröße) ist. Ein Vergleich anhand einer Größe ist somit quantifizierbar. Den Vergleichsvorgang zur Bestimmung des Zahlenfaktors bezeichnet man als Messung. Die Messbarkeit eines Merkmals, d. h. die Angabe einer eindeutigen und reproduzierbaren Messvorschrift für einen Vergleich, ist gleichwertig mit der Definition einer physikalischen Größe.
Alle Merkmale eines Objektes fallen in zwei Klassen, physikalische Größen und alle übrigen. Die Physik beschäftigt sich ausschließlich mit der erstgenannten Klasse. Sie stellt allgemeine Zusammenhänge zwischen Größenwerten auf, also Zusammenhänge, die für alle Träger dieser Größe gelten. Als Träger bezeichnet man hierbei alle Objekte, die die betrachtete Größe als Merkmal besitzen. Physikalische Zusammenhänge sind somit unabhängig von der konkreten Beschaffenheit eines Trägers.
Die folgenden Abschnitte gehen auf einzelne Begriffe ein, die im Zusammenhang mit physikalischen Größen verwendet werden.
Wenn der Quotient zweier Größenwerte verschiedener physikalischer Größen eine reelle Zahl ist, dann handelt es sich um physikalische Größen gleicher Dimension. In jeder Gleichung zwischen physikalischen Größen müssen beide Seiten von gleicher Dimension sein (Dimensionsbetrachtung).
Der Begriff Dimension ist in Verbindung mit einem Größensystem zu betrachten. Die Dimension stellt die jeweilige physikalische Größe qualitativ im Größensystem dar. Die Dimension einer abgeleiteten physikalischen Größe wird als Potenzprodukt von Dimensionen der Basisgrößen definiert. Dieses Potenzprodukt stützt sich auf die zugrundeliegenden Größengleichungen; eventuelle Zahlenfaktoren, mathematische Operationen wie Skalar- oder Vektorprodukt, Differenzialquotient, Integral, Stufe der zu den Größen gehörenden Tensoren bleiben unberücksichtigt. Auf diese Weise lässt sich eine qualitative Abhängigkeit der abgeleiteten Größe von den Basisgrößen darstellen.
Im Internationalen Größensystem (ISQ) ist die abgeleitete physikalische Größe mechanische Arbeit als
  definiert. Die Dimension der mechanischen Arbeit lässt sich aus den Dimensionen der in dieser Größengleichung beteiligten Größen herleiten.
    {\displaystyle \mathrm {dim} \ W\equiv \mathrm {dim} \ {\vec {F}}\cdot \mathrm {dim} \ {\vec {r}}\equiv {\mathsf {MLT^{-2}}}\cdot {\mathsf {L}}\equiv {\mathsf {ML^{2}T^{-2}}}}
Mit der Größenart wird die Menge der Größen einer gegebenen Dimension unterteilt. Nach dem Internationalen Wörterbuch der Metrologie (VIM), 3. Auflage 2010, ist Größenart oder Art einer Größe der „Aspekt, der untereinander vergleichbaren Größen gemeinsam ist“, und in einer Anmerkung heißt es: „Die Unterteilung des Oberbegriffs ‚Größe‘ nach der Größenart ist […] willkürlich“. Größen gleicher Art lassen sich in sinnvoller Weise durch Addition und Subtraktion verknüpfen. Außerdem gelten für Größen gleicher Art die Ordnungsrelationen „größer“, „kleiner“ und „gleich“.
Beispielsweise sind Breite, Höhe und Länge eines Quaders, Durchmesser eines Rohrs, Spannweite eines Vogels, Wellenlänge alles Größen der Größenart „Länge“; sie können mit der Länge eines Gliedermaßstabs verglichen werden. Ob auch noch die Niederschlagshöhe, angegeben als Volumen/Fläche, als hiermit gleichartig betrachtet wird, bleibt dem Anwender überlassen, obwohl auch sie leicht mit dem Metermaß messbar ist. Der Verbrauchsangabe bei Kraftfahrzeugen in „Liter pro 100 Kilometer“ wird man jedoch kaum die Größenart Fläche zusprechen, obwohl sie die Dimension einer Fläche hat.
Der Wert einer physikalischen Größe (Größenwert) ist nach allgemein verbreiteter Auffassung das Produkt aus einer Zahl und der physikalischen Einheit, die der betreffenden Größenart zugeordnet ist. Das Verhältnis von zwei Größenwerten gleichartiger Größen ist eine reelle Zahl.
Vorsichtiger wurde dies innerhalb des deutschen Normenwerkes in der ersten Ausgabe „Schreibweise physikalischer Gleichungen“ der Norm DIN 1313 vom November 1931 dargestellt: Mit den in den physikalischen Gleichungen vorkommenden Formelzeichen kann so gerechnet werden, als ob sie die physikalischen „Größen“, d. h. benannte Zahlen bedeuteten. Sie werden dann zweckmäßigerweise als symbolische „Produkte“ aus den Zahlenwerten (Maßzahlen) und den Einheiten aufgefasst gemäß der Gleichung
Physikalische Größe = Zahlenwert „mal“ Einheit.Man bezeichnet einen Unterschied um den Faktor 10 zwischen Werten derselben Größe als eine Größenordnung. 
Es gibt eine Reihe von Größen, deren Größenwerte unveränderlich feststehen. Diese nennt man Naturkonstante, Universalkonstante oder auch physikalische Konstante (Beispiele: Lichtgeschwindigkeit im Vakuum, Elementarladung, Plancksche Konstante, Feinstrukturkonstante).
Es ist zweckmäßig, das Verhältnis eines Größenwerts zu dem Wert einer gleichartigen, feststehenden und wohldefinierten Vergleichsgröße zu ermitteln. Den Vergleichsgrößenwert bezeichnet man als Maßeinheit oder kurz Einheit, das gemessene Verhältnis als Maßzahl oder Zahlenwert. Der Größenwert kann dann als Produkt aus Zahlenwert und Einheit dargestellt werden (siehe auch Abschnitt Schreibweise). Der Zahlenwert ist je nach Definition der Größe eine reelle Zahl – bei manchen Größen auf nicht negative Werte beschränkt – oder komplex; bei einigen Größen der Dimension Zahl wie z. B. manchen Quantenzahlen ist er immer ganzzahlig.
Die Definition einer Einheit unterliegt der menschlichen Willkür. Eine Möglichkeit besteht in der Wahl eines bestimmten Objekts – eines sogenannten Normals – als Träger der Größe, dessen Größenwert als Einheit dient. Auch ein berechneter Größenwert kann gewählt werden, wofür allerdings ein geeigneter physikalischer Zusammenhang mit anderen Größenwerten bekannt sein muss (siehe auch Abschnitt Größengleichungen). Eine dritte Möglichkeit ist, den Wert einer physikalischen Konstanten als Einheit zu verwenden, sofern eine solche für die gewünschte Größe existiert.
Theoretisch genügt es, für eine Größenart eine einzige Einheit zu definieren. Historisch bedingt hat sich aber häufig eine Vielzahl verschiedener Einheiten für die gleiche Größenart gebildet. Sie unterscheiden sich wie alle gleichartigen Größenwerte lediglich um einen reinen Zahlenfaktor.
Bestimmte physikalische Größen besitzen eine Orientierung im physikalischen Raum, der Größenwert hängt also von der Messrichtung ab. Beispielsweise ist die Geschwindigkeit eines Fahrzeugs typischerweise entlang einer Straße gerichtet; die gemessene Geschwindigkeit senkrecht zu dieser ist null – es handelt sich um eine vektorielle Größe. Die mechanische Spannung in einem Werkstück hängt stark von der betrachteten Schnittfläche ab – es gibt hier mehr als eine zu betrachtende Richtung, also ist zur Beschreibung ein Tensor (zweiter Stufe) nötig.
   Elementen beschreiben und hat dabei bestimmte einfache Eigenschaften bei Koordinatentranslation bzw. -transformation. Dementsprechend kann er eine bestimmte Klasse physikalischer Größen beschreiben:
Ein Tensor 0. Stufe ist ein Skalar. Er beschreibt eine Größe, die richtungsunabhängig ist und einzig durch ihren Größenwert (als Zahl) bestimmt ist.
Ein Tensor 2. Stufe ist durch neun Komponenten bestimmt. Er wird meist durch eine 3×3-Matrix dargestellt. Mit „Tensor“ ohne Zusatz ist in der Praxis meist ein Tensor 2. Stufe gemeint.
Die Physik soll die beobachtete Natur beschreiben, unabhängig von einer speziellen mathematischen Darstellung. Daher muss eine physikalische Größe in jedem Fall unter Koordinatentransformationen invariant (unveränderlich) sein. So wie das System ihrer Größenwerte unabhängig von der Einheit ist, so sind auch die jeweiligen Richtungen unabhängig von der Wahl des Koordinatensystems.
Tensoren haben unter Punktspiegelung ein für ihre Stufe charakteristisches Verhalten. So ändert sich eine skalarwertige Größe eines Objekts nicht, wenn man dieses Objekt an einem Punkt spiegelt. Eine vektorwertige Größe, wie etwa die Geschwindigkeit, zeigt nach der Punktspiegelung hingegen in die entgegengesetzte Richtung. Manche Größen verhalten sich zwar bei Drehung und Verschiebung wie Tensoren, weichen jedoch unter Punktspiegelung hiervon ab. Derartige Größen bezeichnet man als Pseudotensoren. Bei Pseudoskalaren ändert der Größenwert sein Vorzeichen. Bei Pseudovektoren wie etwa dem Drehimpuls dreht sich die Richtung durch eine Punktspiegelung des Objekts nicht um.
Die folgenden Erläuterungen orientieren sich an den nationalen und internationalen Regelungen von Normungsorganisationen und Fachgesellschaften [z. B. DIN 1338, EN ISO 80000-1, Empfehlungen der International Union of Pure and Applied Physics (IUPAP)].
Einer physikalischen Größe wird in mathematischen Gleichungen ein Schriftzeichen, das Formelzeichen zugeordnet. Dieses ist grundsätzlich willkürlich, jedoch existieren Konventionen (z. B. SI, DIN 1304, ÖNORM A 6438, ÖNORM A 6401, etc.) zur Bezeichnung bestimmter Größen. Häufig wird als Formelzeichen der Anfangsbuchstabe des lateinischen Namens einer Größe genommen. Auch Buchstaben aus dem griechischen Alphabet werden oft verwendet. Üblicherweise besteht ein Formelzeichen nur aus einem einzigen Buchstaben, der zur weiteren Unterscheidung mit einem oder mehreren Indizes versehen werden kann.
Für Einheiten gibt es festgelegte Schriftzeichen, die Einheitenzeichen. Sie bestehen meistens aus einem oder mehreren lateinischen Buchstaben oder seltener aus einem Sonderzeichen wie z. B. einem Gradzeichen oder griechischen Buchstaben wie das Ω (großes Omega) für die Einheit Ohm. Bei Einheiten, die nach Personen benannt sind, wird der erste Buchstabe des Einheitenzeichens üblicherweise groß geschrieben.
Ein Größenwert wird immer als Produkt aus Zahlenwert und Einheit angegeben. Will man nur den Zahlenwert angeben, so setzt man das Formelzeichen in geschweifte Klammern. Will man nur die Einheit angeben, so setzt man das Formelzeichen in eckige Klammern. Formal lässt sich ein Größenwert also wie folgt schreiben:
Da der Zahlenwert von der gewählten Maßeinheit abhängt, ist die alleinige Darstellung des Formelzeichens in geschweiften Klammern nicht eindeutig. Deshalb ist für die Beschriftung von Tabellen und Koordinatenachsen die Darstellung „G/[G]“ (z. B. „m/kg“) oder „G in [G]“ (z. B. „m in kg“) üblich. Die Darstellung von Einheiten in eckigen Klammern (z. B. „m [kg]“) oder auch in runden Klammern (z. B. „m (kg)“) entspricht hingegen nicht der Norm DIN 1313 und wird in den Empfehlungen zum Einheitensystem SI nicht empfohlen.Da die verwendeten Einheiten abhängig vom Einheitensystem sind, muss das Einheitensystem mit angegeben werden:
    {\displaystyle {\begin{aligned}\left[U\right]_{\text{SI}}&=\mathrm {V} \\\left[U\right]_{\text{CGS-ESU}}&=\mathrm {StatV} \end{aligned}}}
Die Formatierung ist durch DIN 1338 geregelt. Demnach wird das Formelzeichen kursiv geschrieben, während das Einheitenzeichen mit aufrechter Schrift geschrieben wird, um es von Formelzeichen zu unterscheiden. Beispielsweise bezeichnet „m“ das Formelzeichen für die Größe „Masse“ und „m“ das Einheitenzeichen für die Maßeinheit „Meter“.
Zwischen der Maßzahl und dem Einheitenzeichen wird ein Leerzeichen geschrieben. Eine Ausnahme von dieser Regel stellen die Gradzeichen dar, die ohne Zwischenraum direkt hinter die Maßzahl geschrieben werden („ein Winkel von 180°“), sofern keine weiteren Einheitenzeichen folgen („die Außentemperatur beträgt 23 °C“). Im Schriftsatz empfiehlt sich hierfür ein schmales Leerzeichen, das zusätzlich vor einem Zeilenumbruch geschützt werden sollte, damit Zahlenwert und Einheit nicht getrennt werden.
In Formeln werden Vektoren häufig durch eine besondere Schreibweise gekennzeichnet. Dabei gibt es unterschiedliche Konventionen. Üblich sind Vektorpfeile über dem Buchstaben (
  ) verwendet. Welche Schreibweise gewählt wird, hängt auch davon ab, ob von Hand oder maschinell geschrieben wird, da sich Merkmale wie Fettdruck oder Serifen mit einer Handschrift nicht zuverlässig wiedergeben lassen.
Es gibt von der Sprache und vom Fach abhängig unterschiedliche Traditionen zur Aufrecht- und Kursivschreibung im Zusammenhang mit Formeln. In modernerer Fachliteratur hat sich jedoch die Konvention durchgesetzt, nicht nur Größensymbole, sondern alles, was veränderlich ist, kursiv zu setzen; Einheitenzeichen, Elementsymbole, Erläuterungen usw. werden hingegen aufrecht gesetzt. Formelzeichen sowie veränderliche Indizes erscheinen also kursiv. Beispiel:
Bei fehlerbehafteten Größenwerten wird der Zahlenwert mit seiner Messunsicherheit angegeben oder – je nach den Umständen – mit seinen Fehlergrenzen, siehe auch Messabweichung. Das Kenntlichmachen geschieht meistens durch ein „±“ nach dem fehlerbehafteten Zahlenwert, gefolgt von dem Fehlerwert (wobei Klammern erforderlich sind, sofern eine Einheit folgt, damit diese sich auf beide Werte bezieht). Aber auch Kurzformen wie eine geklammerte Fehlerangabe oder Fettdruck der unsicheren Ziffer des Zahlenwerts sind üblich.
Die Anzahl der anzugebenden unsicheren Dezimalstellen des Zahlenwerts richtet sich nach dem Fehlerwert. Beginnt dieser mit einer 1 oder 2, so werden zwei Stellen notiert, ansonsten nur eine. Gegebenenfalls ist der Zahlenwert wie üblich zu runden, siehe DIN 1333; eine Fehlergrenze wird hingegen immer aufgerundet.
Zusätzliche Bezeichnungen oder Informationen dürfen grundsätzlich nicht im Größenwert einer physikalischen Größe (also weder in der Einheit noch beim Zahlenwert) auftauchen bzw. diesem hinzugefügt werden, da dies unsinnig wäre; sie dürfen nur in der Benennung oder Bezeichnung der physikalischen Größe, also im Formelzeichen, zum Ausdruck gebracht werden.
   als Subskript ergänzen, um darauf hinzuweisen, dass eine Umdrehungsfrequenz (Drehzahl) gemeint ist:
   („Die Drehzahl des Motors beträgt 2000 pro Minute.“)Es kann auch ein eigenes, klar definiertes Formelzeichen eingesetzt werden. Um z. B. auf den doppelten Index im obigen Beispiel zugunsten einer leichteren Lesart zu verzichten, könnte man das ggf. einprägsamere Symbol 
   („Die Drehzahl des Motors beträgt 2000 pro Minute.“)Ohne weitere Erläuterung könnte man in der Regel z. B. auch
   („Die Höhe des Autos beträgt 1,5 Meter, die Breite des Autos beträgt 2,2 Meter.“)verwenden, da die Symbole für die zwei Spezialfälle Höhe und Breite eines Längenmaßes gemeinhin üblich sind.
In der Praxis findet nicht immer eine saubere Unterscheidung zwischen Größenwert bzw. Einheit einer physikalischen Größe einerseits und bloßen Zusatzangaben andererseits statt, sodass es zu Vermischungen kommt. Die aufgeführte Umdrehungszahl ist ein häufiges Beispiel dafür. „Umdrehung“ ist dort keine Einheit, sondern beschreibt lediglich den die Frequenz hervorrufenden Prozess näher. Nicht zulässig, jedoch häufig vorkommend, ist deshalb etwa
   („Die Drehzahl des Motors beträgt 2000 Umdrehungen pro Minute“).Weitere Beispiele für häufig vorkommende falsche Schreib- bzw. Sprechweisen sind:
   bzw. „Die Neutronen-Flussdichte beträgt 1000 pro Quadratzentimeter und Sekunde.“Massekonzentration von Blei:Falsch: 
   bzw. „Die Blei-Massekonzentration beträgt 20 Nanogramm pro Kubikmeter.“Durch eine Spule verursachte magnetische Feldstärke:Falsch: 
Die Darstellung von Naturgesetzen und technischen Zusammenhängen in mathematischen Gleichungen nennt man Größengleichungen. Die Formelzeichen einer Größengleichung haben die Bedeutung physikalischer Größen, sofern sie nicht als Symbole für mathematische Funktionen oder Operatoren gemeint sind. Größengleichungen gelten unabhängig von der Wahl der Einheiten. Trotzdem kann es vorkommen, dass die Gleichungen in verschiedenen Einheitensystemen unterschiedlich geschrieben werden. Beispielsweise hat die Vakuumlichtgeschwindigkeit in manchen Einheitensystemen definitionsgemäß den Wert 
Größengleichungen verknüpfen verschiedene physikalische Größen und deren Größenwerte miteinander. Zur Auswertung muss man die Formelzeichen durch das Produkt aus Zahlenwert und Einheit ersetzen. Die verwendeten Einheiten sind dabei unerheblich.
Für physikalische Größen sind nicht alle Rechenoperationen, die mit reinen Zahlen möglich wären, sinnvoll. Es hat sich erwiesen, dass eine geringe Anzahl Rechenoperationen ausreicht, um alle bekannten Naturgeschehen zu beschreiben.
Addition und Subtraktion sind nur zwischen Größen der gleichen Größenart möglich. Die Dimension und damit auch die Einheit der Größe(n) bleiben dabei unverändert, die Maßzahlen werden addiert bzw. subtrahiert.Bsp.: 
Dies funktioniert jedoch nur dann, wenn die beiden Größen in der gleichen Einheit gemessen werden. Ist dies nicht der Fall, müssen beide vor der Addition bzw. Subtraktion noch auf dieselbe Einheit umgerechnet werden.
    {\displaystyle l_{1}+l_{2}=2\,\mathrm {km} +300\,\mathrm {m} =2000\,\mathrm {m} +300\,\mathrm {m} =2300\,\mathrm {m} }
  Multiplikation und Division sind uneingeschränkt möglich. Die beiden Größen werden multipliziert, indem ihre Maßzahlen multipliziert und das Produkt der Einheiten gebildet wird. Für die Division gilt Entsprechendes. Das Ergebnis gehört also in aller Regel zu einer anderen Größenart als die beiden Faktoren, es sei denn, einer der Faktoren ist lediglich eine dimensionslose Zahl.Bsp.: 
    {\displaystyle v={\frac {s}{t}}={\frac {3\,\mathrm {m} }{2\,\mathrm {s} }}=1{,}5\,{\frac {\mathrm {m} }{\mathrm {s} }}}
  Potenzen können daher ebenso gebildet werden. Dies gilt sowohl für positive ganzzahlige als auch für negative und gebrochene Exponenten (also auch für Brüche und Wurzeln).Bsp.: 
Wird eine Größe potenziert, deren Einheit einen Vorsatz für dezimale Teile und Vielfache enthält, so muss der Exponent auf die gesamte Einheit (also auf das Produkt aus Vorfaktor und Einheit) angewendet werden. Beispielsweise ist ein Quadratkilometer nicht etwa 1000 Quadratmeter, sondern
    {\displaystyle 1\,\mathrm {km} ^{2}=1\cdot 1000^{2}\cdot \mathrm {m} ^{2}=1\,000\,000\,\mathrm {m} ^{2}}
   usw. sind nur für reine Zahlen als Argument definiert. Sie können daher nur auf dimensionslose Größen angewendet werden. Der Funktionswert ist ebenfalls eine dimensionslose Zahl.Bsp.: 
  Das Differential einer Größe ist von der gleichen Größenart wie die Größe selbst. Differential- und Integralrechnung ist uneingeschränkt möglich.Bsp.: 
    {\displaystyle v=\int _{t_{1}}^{t_{2}}a\cdot \mathrm {d} t=\int _{0}^{2\,\mathrm {s} }3\,{\frac {\mathrm {m} }{{\mathrm {s} }^{2}}}\cdot \mathrm {d} t=6\,{\frac {\mathrm {m} }{\mathrm {s} }}}
  Ein Sachverhalt ist falsch dargestellt, wenn diese Rechenoperationen in unsinniger Weise auszuführen wären. Die entsprechende Kontrolle wird in der Dimensionsanalyse durchgeführt, um die Existenz einer noch unbekannten Gesetzmäßigkeit zu überprüfen.
In Zahlenwertgleichungen haben die Formelzeichen ausschließlich die Bedeutung von Zahlenwerten, d. h. von Maßzahlen bzgl. gewisser Maßeinheiten. Eine Zahlenwertgleichung ist nur bei Benutzung der dafür gewählten Einheiten gültig. Bei Benutzung von Größenwerten in anderen Einheiten ergeben sich meist Fehler. Es empfiehlt sich daher, Berechnungen grundsätzlich mit Größengleichungen durchzuführen und diese erst im letzten Schritt zahlenmäßig auszuwerten.
Formeln in historischen Texten, „Faustformeln“ und empirische Formeln sind oft in Form von Zahlenwertgleichungen angegeben. In einigen Fällen stehen die Symbole für die zu benutzenden Einheiten mit in der Gleichung. Die dabei manchmal anzutreffende Verwendung von eckigen Klammern um die Einheitenzeichen, wie etwa 
  , ist nicht normgerecht: DIN 1313:1998-12, Kapitel 4.3 sieht für die Darstellung von Maßzahlen Formelzeichen in geschweiften Klammern oder die Division der Größen durch die jeweils gewünschte Maßeinheit vor. Mit Letzterem geht z. B.die obige Zahlenwertgleichung über in die zugeschnittene Größengleichung
    {\displaystyle {\frac {\mathrm {WCT} }{^{\circ }\mathrm {C} }}=13{,}12+0{,}6215\,{\frac {T}{^{\circ }\mathrm {C} }}-11{,}37\,\left({\frac {v}{\mathrm {km/h} }}\right)^{0{,}16}+0{,}3965\,{\frac {T}{^{\circ }\mathrm {C} }}\,\left({\frac {v}{\mathrm {km/h} }}\right)^{0{,}16},}
Jedes Wissensgebiet der Technik und Naturwissenschaften verwendet einen beschränkten Satz an physikalischen Größen, die über Naturgesetze miteinander verknüpft sind. Wählt man aus diesen Größen wenige Basisgrößen aus, sodass sich alle anderen des betrachteten Gebietes als Potenzprodukte der Basisgrößen darstellen lassen, dann bilden alle Größen zusammen ein Größensystem, sofern außerdem keine Basisgröße aus den anderen Basisgrößen dargestellt werden kann. Die aus den Basisgrößen darstellbaren Größen heißen abgeleitete Größen, das jeweilige Potenzprodukt ihrer Dimensionen bezeichnet man als Dimensionsprodukt. Welche Größen man für die Basis wählt, ist grundsätzlich willkürlich und geschieht meistens nach praktischen Gesichtspunkten. Die Anzahl der Basisgrößen bestimmt den Grad des Größensystems. Beispielsweise ist das internationale Größensystem mit seinen sieben Basisgrößen ein Größensystem siebten Grades.
Man benötigt für jede Größe eine Einheit, um Größenwerte angeben zu können. Daher entspricht jedem Größensystem ein Einheitensystem gleichen Grades, das sich analog aus voneinander unabhängigen Basiseinheiten und den aus diesen darstellbaren abgeleiteten Einheiten zusammensetzt. Die abgeleiteten Einheiten werden aus den Basiseinheiten durch Produkte von Potenzen dargestellt – im Unterschied zu Größensystemen eventuell ergänzt durch einen Zahlenfaktor. Man bezeichnet das Einheitensystem als kohärent, wenn alle Einheiten ohne diesen zusätzlichen Faktor gebildet werden können. In derartigen Systemen können alle Größengleichungen als Zahlenwertgleichungen aufgefasst und dementsprechend schnell ausgewertet werden.
Das in fast allen Ländern der Welt benutzte internationale Einheitensystem (SI) ist ein kohärentes Einheitensystem siebten Grades, das auf dem internationalen Größensystem fußt; jedoch ist das Internationale Größensystem später entwickelt worden als das SI. Das SI definiert zudem standardisierte Vorsätze für Maßeinheiten, allerdings sind die so gebildeten Vielfachen oder Teile einer SI-Einheit selbst nicht Teil des eigentlichen Einheitensystems, da dies der Kohärenz widerspräche. Beispielsweise ist ein fiktives Einheitensystem, das die Basiseinheiten Zentimeter (
(Zu weiteren konkurrierenden Einheitensystemen siehe unten im Abschnitt Praktisch verwendete Maßsysteme.)
Der Quotient zweier Größen ist eine neue Größe. Eine solche Größe bezeichnet man als Verhältnisgröße (oder Größenverhältnis), wenn die Ausgangsgrößen von der gleichen Größenart sind, ansonsten als Quotientengröße. Allgemeiner ist die Quotientengröße in der DIN-Norm 1313 vom Dezember 1998 definiert; danach wird nur verlangt, dass der Bruch aus Zählergröße und Nennergröße konstant ist. Von April 1978 bis November 1998 hingegen hatte das DIN in der Normausgabe vom April 1978 den Begriff Größenquotient spezieller nur für Brüche aus zwei Größen verschiedener Dimension empfohlen und von einem Größenverhältnis (einer Verhältnisgröße) lediglich verlangt, dass die Ausgangsgrößen von gleicher Dimension, aber nicht unbedingt gleicher Größenart sind. (Beispielsweise sind die elektrische Stromstärke und die magnetische Durchflutung von gleicher Dimension, aber verschiedener Größenart.)
Häufig werden Quotientengrößen umgangssprachlich ungenau umschrieben. Beispielsweise ist eine Definition der Fahrtgeschwindigkeit als „zurückgelegter Weg je Zeiteinheit“ oder „zurückgelegter Weg je vergangener Zeit“ oder „Weg je Zeit“ nicht korrekt, denn die Geschwindigkeit hat nicht die Dimension eines Weges (Länge). Korrekt wäre „in einer Zeitspanne zurückgelegter Weg, geteilt durch diese Zeitspanne“. Die genannte verkürzte Ausdrucksweise ist zwar üblich und genügt, um einen anschaulichen Begriff von der jeweiligen Quotientengröße zu geben, aber die genaue Definition als Quotient sollte außerdem immer angegeben werden.
Falls zwei Größen sich auf eine Eigenschaft des gleichen Objektes beziehen, nennt man die Quotientengröße auch bezogene Größe. Hierbei ist die Nennergröße die Bezugsgröße, während die Zählergröße den Schwerpunkt in der Namensgebung setzt. Insbesondere bezeichnet man eine bezogene Größe als …
… -dichte, wenn sie sich auf das Volumen (oder als -flächendichte auf die Fläche bzw. als -längendichte auf die Länge) bezieht. (Einheit: z. B. „… pro Liter“, „… pro Quadratkilometer“ bzw. „… pro Zentimeter“)
… -rate oder -geschwindigkeit, wenn sie sich auf eine Zeitspanne bezieht. (Einheit: z. B. „… pro Stunde“)Verhältnisgrößen sind grundsätzlich dimensionslos. Sie können daher nach obigen Rechenregeln als Argumente von transzendenten Funktionen auftreten. Der Name einer Verhältnisgröße enthält meistens ein Adjektiv wie relativ oder normiert oder er endet auf -zahl oder -wert. Beispiele sind die Reynolds-Zahl und der Strömungswiderstandskoeffizient.
Verschiedene Verhältnisgrößen gehören nur in seltenen Fällen zur gleichen Größenart; manchmal werden daher zur besseren Trennung bei der Angabe ihres Größenwerts die Einheitenzeichen nicht gekürzt. Häufig werden Verhältnisgrößen in den Einheiten %, ‰ oder ppm angegeben.
Eine besondere Stellung haben Verhältniseinheiten, wenn sie das Verhältnis gleicher Einheiten sind. Diese sind immer 1 und damit idempotent, d. h., sie können beliebig oft mit sich selbst multipliziert werden, ohne ihren Wert zu ändern. Einige idempotente Verhältniseinheiten tragen besondere Namen, wie beispielsweise die Winkeleinheit Radiant (rad). In kohärenten Einheitensystemen sind die Verhältniseinheiten immer 1, also idempotent. Bei idempotenten Verhältniseinheiten kann man die Zahlenwerte einfach multiplizieren. Beispiel: Aus den Angaben, dass 30 % der Erdoberfläche Landfläche sind und Asien 30 % der Landfläche darstellt, folgt nicht, dass 900 % der Erdoberfläche vom Kontinent Asien bedeckt sind, weil % nicht idempotent ist, also %2 nicht dasselbe wie % ist. Sagt man aber, dass ein Anteil von 0,3 der Erdoberfläche Landfläche ist und Asien einen Anteil von 0,3 der Landfläche einnimmt, kann man folgern, dass Asien 0,09 der Erdoberfläche ausmacht, weil hier die idempotente Einheit 1 verwendet wird.
Feldgrößen dienen der Beschreibung von physikalischen Feldern. Das Quadrat einer Feldgröße ist in linearen Systemen proportional zu dessen energetischem Zustand, der über eine Leistungsgröße erfasst wird. Ohne die genaue Gesetzmäßigkeit kennen zu müssen, folgt daraus unmittelbar, dass das Verhältnis zweier Leistungsgrößen gleich dem Quadrat des Verhältnisses der zugehörigen Feldgrößen ist. Dabei ist unerheblich, ob beide Leistungsgrößen unmittelbar für Leistung stehen oder damit verbundene Größen wie Energie, Intensität oder Leistungsdichte.
In vielen technischen Bereichen sind die logarithmierten Verhältnisse von besonderem Interesse. Derartige Größen werden als Pegel oder Maß bezeichnet. Wird bei der Bildung der natürliche Logarithmus verwendet, so kennzeichnet man dieses durch die Einheit Neper (Np), ist es der dekadische Logarithmus, so nutzt man das Bel (B) oder häufiger sein Zehntel, das Dezibel (dB).
Zustandsgrößen sind dabei physikalische Größen, die eine Eigenschaft eines Systemzustands repräsentieren. Man unterscheidet weiterhin zwischen extensiven und intensiven Größen. Extensive Größen wie Masse und Stoffmenge verdoppeln ihren Größenwert bei Systemverdopplung, intensive Größen wie Temperatur und Druck bleiben dabei konstant. Ebenfalls gebräuchlich ist die Unterscheidung zwischen stoffeigenen und systemeigenen Zustandsgrößen.
Prozessgrößen hingegen beschreiben einen Vorgang, nämlich den Übergang zwischen Systemzuständen. Zu ihnen gehören insbesondere die Größen „Arbeit“ (
  ). Um ihren Charakter als reine Vorgangsgrößen zum Ausdruck zu bringen, werden sie vielerorts ausschließlich als Differentiale angegeben, wobei ihnen häufig kein 
cgs-System:vor allem von Theoretikern und in den USA benutzt, mit drei Grundgrößen, in welchem alle Längen in Zentimetern und elektrische Spannungen in Potenzen der Grund-Einheiten cm, g (= Gramm) und s (= Sekunde) angegeben werdenmksA-System:in der praktischen Elektrotechnik eingeführtes System mit vier Grundeinheiten, Vorläufer des Internationalen Einheitensystems, enthält neben Meter (= m), Kilogramm (= kg) und Sekunde (= s) das Ampere (= A) als Einheit der Stromstärke; das Volt (= V) als Spannungseinheit ergibt sich über die definierte Gleichheit der elektrischen und mechanischen Energieeinheiten Wattsekunde und Newtonmeter (1 Ws = 1 V·A·s = 1 N·m = 1 kg·m2·s−2)Hochenergie-System (siehe bei Planck-Einheiten):alle Größen werden in Potenzen nur einer einzigen Einheit, der Energieeinheit eV, angegeben, z. B. Längen als reziproke Energien, genauer: in Einheiten von 
   (reduzierte Plancksche Konstante) werden dabei durch Eins ersetzt.In den verschiedenen Maßsystemen sehen Naturgesetze, z. B. die Maxwellschen Gleichungen, formelmäßig verschieden aus; aber wie erwähnt sind die physikalischen Gesetze invariant gegen solche Änderungen. Insbesondere kann man jederzeit von einem Maßsystem in ein anderes umrechnen, auch wenn die dabei benutzten Zusammenhänge kompliziert sein können.
Horst Teichmann: Physikalische Anwendungen der Vektor- und Tensorrechnung. (= BI-Hochschultaschenbücher. 39). 3. Auflage. Bibliographisches Institut, Mannheim u. a. 1973, ISBN 3-411-00039-2 (Speziell zum Absatz über Skalare, Vektoren und Tensoren).
Friedrich Kohlrausch: Allgemeines über Messungen und ihre Auswertung. In: Volkmar Kose, Siegfried Wagner (Hrsg.): Praktische Physik. 24. neubearb. und erw. Auflage. Band 3. B. G. Teubner, Stuttgart 1996, ISBN 3-519-23000-3, 9.1 Begriffs- und Einheitensysteme, S. 3–19 (ptb.de [PDF; 3,9 MB; abgerufen am 24. November 2018] veröffentlicht durch die Physikalisch-Technische Bundesanstalt). 
H. Fischer, H. Kaul: Mathematik für Physiker. Band 1, 7. Aufl., Vieweg u. Teubner 2011, ISBN 978-3-8348-1220-9.
Hans Dieter Baehr: Physikalische Größen und ihre Einheiten – Eine Einführung für Studenten, Naturwissenschaftler und Ingenieure. (= Studienbücher Naturwissenschaft und Technik. Band 19) Bertelsmann Universitätsverlag, Düsseldorf 1974, ISBN 3-571-19233-8.
Hans Rupp: Physikalische Größen, Formeln, Gesetze und Definitionen. 2. Auflage, Oldenbourg Schulbuchverlag, 1995, ISBN 3-486-87093-9.
Paul A. Tipler: Physik. 3. korrigierter Nachdruck der 1. Auflage 1994, Spektrum Akademischer Verlag, Heidelberg/Berlin 2000, ISBN 3-86025-122-8.Speziell zur physikalischen Größenart
Alfred Böge: Handbuch Maschinenbau. Vieweg+Teubner, 2011, ISBN 978-3-8348-1025-0 (eingeschränkte Vorschau in der Google-Buchsuche).
DIN Deutsches Institut für Normung e. V. (Hrsg.): Klein: Einführung in die DIN-Normen. B.G. Teubner, 2001, ISBN 978-3-519-26301-2 (eingeschränkte Vorschau in der Google-Buchsuche).
Physikalische Größen- und Einheiten (PDF) – ausführliche Beschreibung zur Formatierung und Angabe von Größenwerten bei physikalischen Versuchen (210 kB).

Der Physikalische Verein – Gesellschaft für Bildung und Wissenschaft – ist ein am 24. Oktober 1824 gegründeter wissenschaftlicher Verein in Frankfurt am Main, der seine Gründung auf eine Anregung Johann Wolfgang von Goethes zurückführt. Bis 1834 wurden unter dem Namen Physikalisches Museum zusätzlich zu Vorträgen auch Besichtigungen der Sammlung von naturwissenschaftlichen Apparaten angeboten. Im Verlauf des 19. Jahrhunderts entwickelte sich der Verein zu einer Art technischem Überwachungsverein für Frankfurt und einer naturwissenschaftlichen Akademie.
Bei der Gründung der Stiftungsuniversität Frankfurt 1914 war er einer der Stifter und brachte seine naturwissenschaftlichen Institute und Gebäude ein.
Die wissenschaftliche Breitenbildung, die von Anfang an ein weiteres Ziel gewesen war, ist seit Bestehen der Universität Schwerpunkt der Tätigkeiten.
Bis 2005 war im Gebäude des Vereins der Fachbereich Physik der Universität untergebracht, seit 2010 ist es im Besitz der Senckenberg Gesellschaft für Naturforschung. Zwischen Dezember 2013 und Juni 2017 wurde das Gebäude renoviert und heißt seitdem Arthur-von-Weinberg-Haus. Seit 2017 steht es dem Verein wieder zur Verfügung, die  Sternwarte wird voraussichtlich 2019 wieder eröffnen.Zum wissenschaftlichen Angebot gehören Vorträge, Seminare und astronomische Beobachtungen. Der Verein veranstaltet darüber hinaus die größten Science-Slams Deutschlands und betreibt die Hans-Ludwig-Neumann-Sternwarte auf dem Kleinen Feldberg.
Aufgrund dieser Anregung riefen am 24. Oktober 1824 elf Frankfurter Bürger unter der Führung von Christian Ernst Neeff und Johann Valentin Albert das Physikalische Museum ins Leben. Weitere Gründer waren Johann Jacob Casimir Buch, Joseph Aschbach, Johann Michael Mappes und Johann Georg Neuburg. Einige von ihnen hatten bei der Konstituierung der Senckenbergischen Naturforschenden Gesellschaft mitgewirkt, die sich nicht wie gewünscht mit Physik und Chemie beschäftigte. Albert besaß eine umfangreiche Sammlung naturwissenschaftlicher Apparaturen, die er samt Räumlichkeiten in der Schäfergasse zur Verfügung stellte. Ab dem 29. Oktober war dort das Museum für die Öffentlichkeit geöffnet. Für Mitglieder fanden Vorlesungen statt. Der Philosoph Arthur Schopenhauer lobte das „physikalische Kabinett“ und pries es als einen der Vorteile gegenüber Städten wie Berlin und Mannheim an.Am 24. November desselben Jahres hielt Neeff die Eröffnungsrede in der ersten Versammlung der Gründer und weiterer Besucher. Bei dieser Versammlung wurden die ersten Statuten verabschiedet. Ziel war nach § 1 der Satzung „[…] sich gegenseitig zu belehren, um Kenntnisse in der Physik und Chemie allgemeiner zu verbreiten, und diese Wissenschaften selbst so viel als möglich zu fördern und zu bereichern […]“
Im Dezember begannen unregelmäßig öffentliche Vorträge. Den ersten dieser Vorträge hielt am 10. Dezember der Sohn des Mitbegründers Johann Valentin Albert über Die Einrichtung und Gebrauch des Woltmann’schen hydrodynamischen Flügels oder Strommessers. Besondere Aufmerksamkeit bekam das Museum, als 1825 die Gesellschaft Deutscher Naturforscher und Ärzte im Rahmen ihrer vierten Versammlung das Museum besuchte. 1826 war einer der Gastredner der bekannte Wissenschaftler Ernst Chladni. Schnell war im Haus in der Schäfergasse zu wenig Platz für Besucher und Apparate. Albert verkaufte sein privates Wohnhaus und erwarb mit dem Erlös ein Haus in der Töngesgasse, in welches das Museum zog.
1828 und 1829 hielt Beat Friedrich von Tscharner zwei erfolgreiche Vortragsreihen in Frankfurt ab. Diese Vorträge ließen das Interesse an Physik und Naturwissenschaften in Frankfurt wachsen. Daraufhin organisierte der Verein Vorträge zu ähnlichen Themen und stellte für das Wintersemester 1828/29 ein eigenes Vortragsverzeichnis auf. Regelmäßige Veranstaltungen wie die von Tscharner fanden allerdings nicht statt, weil die Arbeit der Referenten unentgeltlich war. Es blieb bei gelegentlichen Vorträgen, die im Frankfurter Intelligenzblatt angekündigt wurden. Nach der Generalversammlung 1833 stellte der Vorsitzende Johann Karl Passavant Karl Werner Maximilian Wiebel als ständigen Lehrer für Physik und Chemie ein. Seitdem konnte endlich ein regelmäßiges Vortragsprogramm gestaltet werden. Passavant veranlasste, dass der Verein sich 1834 von Albert trennte. Da durch die Dr. Senckenbergische Stiftung kostenfrei Räumlichkeiten zur Verfügung gestellt wurden, musste man nicht mehr auf dessen Räume und finanzielle Mittel zurückgreifen.
Seit 1826 sammelte der Verein Wetterdaten in Frankfurt und anderen hessischen Städten und übergab diese dem Senat der Freien Stadt Frankfurt. Den regelmäßig erstellten Wetterbericht ließ sich Goethe bis nach Weimar schicken. Er wurde außerdem öffentlich ausgehängt und in Zeitschriften veröffentlicht. Als man 1835 an den Senat herantrat, erhoffte man sich daher eine finanzielle Förderung, die für die Bezahlung der Lehrkraft benötigt wurde. Wiebel hatte den Verein 1835 verlassen, Nachfolger wurde Rudolf Christian Böttger. Als Gegenleistung für die finanzielle Förderung wurde der Verein verpflichtet, Vorlesungen zur Physik und Chemie speziell für die Schüler der höheren Lehranstalten abzuhalten. Außerdem sollten auf Anfrage der städtischen Behörden Gutachten erstellt werden. In den nachfolgenden Jahren erarbeiteten Böttger und Johann Philipp Wagner Gutachten zu Patentanträgen Frankfurter Bürger.Am 25. Februar 1837 stellte Wagner dem Verein seine Erfindung eines elektrischen Hammers, einen elektromechanischen Unterbrecherkontakt, vor. 1838 wurde im Turm der Paulskirche eine Sternwarte eingerichtet, die im Auftrag des Senats für die genaue Zeitbestimmung der öffentlichen Turmuhren sorgen sollte. Auch astronomische Beobachtungen waren möglich.
1851 trat Johann Philipp Reis dem Verein bei. Am 26. Oktober 1861 stellte er sein Telephon bei einem öffentlichen Vortrag vor. Am 16. November folgte ein weiterer öffentlicher Vortrag. Die Vorführung sorgte bei einigen Mitgliedern für Unverständnis, bei anderen aber auch für Begeisterung. Zum wirtschaftlichen Durchbruch seiner Erfindung kam es nicht. Reis, der sich eine aktive Vermarktung seines Telefons durch den Vorstand erhofft hatte, legte seine Mitgliedschaft 1867 nieder. Er starb 1874 in Friedrichsdorf. Nach der Inbetriebnahme des ersten Telefonnetzes in Deutschland ließ der Physikalische Verein 1878 einen Obelisken auf seinem Grab errichten.
Weitere Dozenten bis 1864 waren unter anderem Friedrich Eisenlohr, Ernst Abbe und Friedrich Kohlrausch.
Nach der Annexion Frankfurts durch Preußen 1866 war die finanzielle und politische Position des Vereins nicht mehr sicher. Der Senat der Freien Stadt Frankfurt fiel als Auftraggeber aus. Außerdem war im gleichen Jahr das Stifthaus abgerissen worden. Es sollte keine weitere Lehrkraft eingestellt werden. Aber es fanden weiterhin Vorträge von ehrenamtlichen Lehrern und Professoren statt, wie durch Karl Zöppritz. Erst 1868 wurde die Stelle eines Dozenten für Physik durch Wilhelm August Nippoldt und anschließend Georg Krebs wieder besetzt. Nach Böttgers Tod 1881 nahm Bernhard Lepsius dessen Lehrstelle für Chemie neu an. Die Lehrkräfte erarbeiteten 1885 ein Testgerät für Blitzableiter, das weithin Beachtung fand.Am 19. Oktober 1887 eröffnete man in der Stiftsstraße 32 ein neues Gebäude. Das Grundstück gehörte der Dr. Senckenbergische Stiftung und wurde dem Verein in Erbpacht übergeben. Das Gebäude besaß einen Hörsaal für 200 Personen, ein chemisches Laboratorium für 24 Personen, ein physikalisches Kabinett, ein Observatorium für meteorologische Beobachtungen und eine Reihe weiterer Räume. Zum Bau hatten der Vorsitzende Theodor Petersen und der Schatzmeister Heinrich Roessler finanziell beigetragen.
Durch Spenden finanziert konnte 1888 eine Elektrotechnische Lehr- und Untersuchungsanstalt eröffnet werden. Sie teilte sich bald in die Elektrotechnische Lehranstalt und die Elektrotechnische Untersuchungsanstalt. Beide gingen später in das Institut für Angewandte Physik der Frankfurter Universität über. Auf der Internationalen Elektrotechnischen Ausstellung von 1891 in Frankfurt stellte der Verein neben den Büsten von Reis und Soemmerring deren Telefon beziehungsweise Telegraf im Original aus. 1896 bauten Walter König und weitere Mitglieder des Vereins einen Röntgenapparat, der Röntgenstrahlen genügender Stärke erzeugen konnte, um damit Menschen zu röntgen. Dieses Gerät gehörte zu den ersten seiner Art. Die Röntgenstrahlung war erst 1895 von Wilhelm Conrad Röntgen entdeckt worden. Einige Jahre später wurde die Apparatur ins Bürgerhospital gebracht.
Zu den weiteren Dozenten bis 1908 gehörten Hermann Theodor Simon, dessen Assistent Max Reich, sowie Martin Freund. Einer der zahlreichen Assistenten war James Franck.
1897 erwog der Vorstand erneut einen Standortwechsel. Die Pläne von Franz von Hoven und Richard Dielmann, nach denen das neue Gebäude auf dem Eckgrundstück zwischen Bleichstraße und Brönnerstraße entstehen sollte, wurden jedoch nicht realisiert. Zuvor hatte Franz von Hoven bereits Pläne zur Erweiterung des bestehenden Gebäudes in der Stiftstraße vorgelegt, womit der vorhandene Raum verdoppelt worden wäre. Die Pläne wurden verworfen als bekannt wurde, dass durch die Stiftstraße eine Straßenbahn geführt werden sollte, die die physikalischen Geräte gestört hätte. 1899 kamen die Dr. Senckenbergische Stiftung und der Verein überein, außerhalb der Innenstadt neue Gebäude zu errichten. Als neuer Standort wurde die Viktoria-Allee (heute Senckenberganlage) gewählt. Nach dem 1906 abgeschlossenen Vertrag erhielt der Verein eine Abfindung von der Dr. Senckenbergischen Stiftung für das bestehende Gebäude in der Stiftsstraße. Das Gelände für den Neubau wurde dem Verein abermals in Erbpacht überlassen.
Beim Bau des Gebäudes 1906 kam es zu Behinderungen, da sich herausstellte, dass das alte Bett des Kettenhofbaches unter dem geplanten Gebäude lag. Aus diesem Grund konnte kein Grundstein gelegt werden, stattdessen wurde am 13. Mai 1906 im Dachgeschoss ein Schlussstein gesetzt. Finanziert wurde das Gebäude hauptsächlich durch Spenden, die Baukosten betrugen mehr als 1,5 Millionen Mark. Treibende Kräfte beim Neubau des Gebäudes waren Eugen Hartmann und Leo Gans, die beide Vorstandsmitglieder waren und selbst namhafte Geldbeträge spendeten.Bereits 1907 bezog man das Gebäude, die feierliche Einweihung fand aber erst 1908 statt. Zu den Gästen zählte neben verschiedenen Vertretern der umliegenden Universitäten und wissenschaftlichen Akademien auch Friedrich Kohlrausch als ältester noch lebender ehemaliger Dozent des Vereins. Auch Ferdinand von Zeppelin, seit 1907 Ehrenmitglied, nahm an der Feier teil.
Das noch heute bestehende neobarocke Gebäude mit einem Mittel- und zwei Eckrisaliten hatte eine Länge von fast 100 Metern und vier (heute fünf) Etagen. Neben einem großen Hörsaal gab es zwei kleinere mit 140 beziehungsweise 160 Sitzplätzen. Ein vierter Hörsaal mit 180 Sitzplätzen war für Vorlesungen der Elektrotechnik gedacht. Im Dachgeschoss lagen Personalwohnungen für Hausmeister, Glasbläser, Laboranten und Assistenten. Ein Aufzug verband die Stockwerke, die Sternwarte war nur über eine Treppe erreichbar. Von der Plattform auf dem Dach aus konnten kleine Wetterballons gestartet werden, außerdem standen dort Antennen für die drahtlose Telegraphie.
Im linken westlichen Flügel des Gebäudes lag das Chemische Institut mit Laboren, Werkstätten, sowie einer Apparaturen- und Chemikaliensammlung. Im zweiten Geschoss arbeitete das Physikalisch-Chemische Institut. Der rechte Flügel beherbergte das Elektrotechnische, das Physikalische und das Meteorologische Institut sowie die Sternwarte. Neben Mess- und Maschinenräumen für das Elektrotechnische Institut befanden sich hier auch gesammelte physikalische Apparate, Übungssäle und eine Wetterstation. Die Sternwarte auf dem östlichen Risalit verfügte über einen zehnzölligen Äquatorial von Carl Zeiss.
In einem Pavillon im Garten standen weitere Apparate, unter anderem zur Wetterbeobachtung. Im Palmengarten Frankfurt und auf dem Kleinen Feldberg befanden sich meteorologische Beobachtungsstationen. In Offenbach besaß der Verein ein Lagerhaus für Ballons.
Zu den Dozenten bis 1914 zählten Richard Wachsmuth, Kurt Wegener und Franz Linke. Linke war der letzte Dozent, der unmittelbar beim Physikalischen Verein angestellt war, alle weiteren Dozenten wurden von der Frankfurter Universität berufen.
Anfang des 20. Jahrhunderts wurde in Frankfurter Zeitungen vermehrt diskutiert, ob eine Universität in Frankfurt wünschenswert sei oder nicht. Es bestand der Wunsch nach einer Stiftungsuniversität. Den Stiftern, zu denen auch der Verein gehörte, schwebte eine Privatuniversität nach amerikanischem Vorbild vor. Widerstände gegen eine weitere hessische Universität kamen unter anderem aus Marburg. Am 10. Juni 1914 bewilligte Wilhelm II. die Einrichtung einer Universität unter der Voraussetzung, dass keine zusätzlichen Gelder aus staatlicher Hand zur Finanzierung erforderlich waren.
Der Physikalische Verein stellte der Universität seine Institute für Physik, Chemie, Elektrotechnik, physikalische Chemie und Astronomie im Vereinsgebäude zur Mitbenutzung zur Verfügung. Zur Verfügung gestellt wurden außerdem die Einrichtungen zur Meteorologie und Geophysik im Taunusobservatorium, das 1913 auf dem Kleinen Feldberg gegründet worden war.
Der Erste Weltkrieg und die Deutsche Inflation 1914 bis 1923 bereiteten sowohl der Universität als auch dem Physikalischen Verein große finanzielle Schwierigkeiten. Zwar mussten seit Gründung der Universität keine Gehälter mehr für Dozenten bezahlt werden, der Verein hatte sich aber verpflichtet, die Gehälter der Assistenten zu übernehmen und den Unterhalt des Gebäudes zu tragen. Erst ab 1923 kam die Universität auch für diese Kosten auf. Zu den finanziellen Sorgen kam ein großer Mitgliederschwund. Von den 1100 Mitgliedern vor dem Ersten Weltkrieg traten 1925 circa 400 aus.
Nach 1914 war die physikalische Forschung Sache der Universität. Der Verein veranstaltete nur noch Vorträge, die zur allgemeinen Weiterbildung beitrugen. Neben Themen der Physik wurden Fragen der Astronomie diskutiert. Ab 1836 fanden ununterbrochen Vorlesungen für Schüler statt, die beibehalten wurden.
Den bedeutenden Stern-Gerlach-Versuch zur damals neuen Quantenphysik unternahmen 1922 die Physiker Otto Stern und Walther Gerlach im Institutsgebäude des Vereins. Auf den Ergebnissen des Versuchs zur Richtungsquantelung von Drehimpulsen bei Atomen beruhen Atomuhren und Laser. Heute erinnert eine am südlichen Eingang des Gebäudes angebrachte Tafel mit grafischer Darstellung des Versuchsaufbaus an diese wissenschaftlichen Leistungen.
1926 erwarb der Verein die Villa von August Albert, dem Enkel des Mitbegründers Johann Valentin Albert, in der Feldbergstraße. Diese Investition wurde durch Kredite finanziert. Das Meteorologische Institut mit seinem regionalen Wetterdienst übernahm das Gebäude. Das Institut für Allgemeine Chemie hatte zwar in den Jahren 1913 bis 1919 vom Preußischen Staat ein eigenes Gebäude bekommen, die Physikalische Chemie war allerdings weiterhin im Hauptgebäude untergebracht. In der Nachbarschaft des Gebäudes errichtete man für das Institut für Physikalische Chemie einen Erweiterungsbau. Am 11. Mai 1931 fand die Einweihung des Neubaus statt. Die Eröffnungsrede hielt Fritz Haber. Der Kettenhofweg auf Höhe des Gebäudes war zwischenzeitlich auf Anregung des Vereins nach ihrem Ehrenmitglied in Robert-Mayer-Straße umbenannt worden.
Der große Hörsaal wurde 1932 für die von Oberstudiendirektor Hofmann durchgeführte Filmvorführungsreihe Über die Lage der deutschen Ostprovinzen zur Verfügung gestellt. Ab 1933 fanden unregelmäßig Vorträge verschiedener Regierungsämter im Gebäude des Vereins statt. Ab 1939 veranstaltete die NS Gemeinschaft Kraft durch Freude hin und wieder astronomische Beobachtungen und Vorträge in der Sternwarte.
Da die Universität einen „jüdisch-marxistischen“ Ruf hatte, drohte deren Auflösung. Der Verein wollte es sich im Fall der Auflösung zur Aufgabe machen finanzielle Mittel „[…] zu beschaffen, damit er seine ursprüngliche, satzungsgemäße Aufgabe weiter erfüllen kann, als Forschungsinstitut der Verbreitung naturwissenschaftlicher Kenntnisse in allen Kreisen der Frankfurter Bevölkerung […] zu dienen“.Im Januar 1939 war ein Anschluss an das Hauptamt für Technik in der NSDAP im Gespräch. Anschluss und Regulierungen durch das Amt lehnte man aber ab, mit der Begründung „[…], dass es sich bei den Vorträgen des physikalischen Vereins um wissenschaftliche, nicht aber um technische Vorträge handelt, die nicht der Kompetenz des Amts für Technik unterstehen.“Die Verordnungen zum Reichsbürgergesetz von 1935 wurden ab 1939 umgesetzt. Mitglieder „nichtarischer“ Abstammung wurden aus dem Mitgliederverzeichnis gestrichen, davon waren etwa 50 Personen betroffen. Auch eine Marmortafel, die im Gebäude angebracht war und die Namen aller ewigen Mitglieder beinhaltete, sollte auf Verlangen der Stadtverwaltung entfernt werden. Der Vorstand des Vereins befand „dass die Übertapezierung den angestrebten Zweck erfüllt und zur Zeit kein Bedürfnis besteht, die Tafeln entfernen zu lassen.“ Die Tafeln befinden sich noch heute im Eingangsbereich des Gebäudes.
Während des Zweiten Weltkriegs konnte der Verein zwar Vorträge ungestört durchführen, Mitgliederversammlungen waren aber 1943 verboten worden. Die Elektrotechnische Lehranstalt musste das Gebäude in der Robert-Mayer-Straße verlassen, um dem Institut für Angewandte Physik, das „kriegswichtige Forschungen“ leistete, mehr Platz zu schaffen.Bei den Luftangriffen am 18. März und am 22. März 1944 trafen mehrere Brandbomben das Gebäude. Das unbeschädigte Teleskop der Sternwarte wurde daraufhin in Sicherheit gebracht. In der Nacht vom 12. auf den 13. September zündete eine Luftmine in der Robert-Mayer-Straße direkt vor dem Eingang des Vereinsgebäudes. Die Räume des Erdgeschosses wurden beschädigt, das Institut für Physikalische Chemie in der gleichen Nacht von einer Sprengbombe vollständig zerstört. Am 5. März 1945 traf eine Bombe einen Stahlträger in der Decke des großen Hörsaals und richtete dort großen Schaden an. Die beiden kleinen Hörsäle im zweiten Obergeschoss brannten im September 1944 aus, es blieb nur noch der kleine Hörsaal des Instituts für Angewandte Physik im Erdgeschoss.
Seine erste Mitgliederversammlung nach dem Zweiten Weltkrieg hielt der Verein am 10. Juni 1946 ab. Am 9. Juli 1946 erreichte er die Lizenzierung durch das Kultusministerium und die Militärregierung der amerikanischen Besatzungszone. Er konnte seine Tätigkeit wieder aufnehmen. Bis zum 125-jährigen Jubiläum im Jahr 1949 war das Gebäude teilweise instand gesetzt. Im unbeschädigten kleinen Hörsaal des Erdgeschosses fanden wieder regelmäßige Vorträge statt. Auch die Institute der Universität konnten ab 1949 wieder arbeiten. Die Besucherzahl der Schülervorlesungen und anderer öffentlicher Vorträge des Vereins ging gegenüber der Vorkriegszeit jedoch stark zurück.
Am 28. Oktober 1951 wurde das Richtfest für den Wiederaufbau gefeiert. Auf das Gebäude, das im Geschmack der Zeit und aus Kostengründen einfach gehalten war, setzte man eine weitere Etage. Damit entfielen die Plattform auf dem Dach und ihre Einrichtungen. Ende 1954 waren die finanziellen Mittel des Vereins erschöpft. Die Bauarbeiten gingen erst im Frühjahr 1955 weiter, nachdem ein weiterer Kredit bewilligt worden war. Der große Hörsaal feierte am 28. Mai 1956 Einweihung. Erst 1960 war auch die im März 1945 komplett ausgebrannte Sternwarte einsatzbereit.
Im Juli 1998 errichtete man auf dem Gelände des Taunusobservatoriums auf dem Kleinen Feldberg eine weitere Sternwarte. Die Hans-Ludwig-Neumann-Sternwarte erhielt ihren Namen nach dem früheren Vorsitzenden und Ehrenmitglied Hans-Ludwig Neumann. Die technische Ausstattung der Sternwarte eignet sich zur wissenschaftlichen amateur-astronomischen Forschung. Auch Studierende der Astronomie und Astrophysik werden hier ausgebildet.
Bis 1996 war das Institut für Meteorologie im Gebäude in der Feldbergstraße untergebracht. Nach dem Umzug des Instituts auf den Campus Riedberg wurde das Gebäude aufgegeben.
Das Gebäude in der Robert-Mayer-Straße wurde zwischen Dezember 2013 und Juni 2017 von der Senckenberg Gesellschaft für Naturforschung renoviert. Der Umzug zurück in das Gebäude fand im Juni 2017 statt.  Verantwortlicher Architekt war Peter Kulka. Außer dem Gebäude des Physikalischen Vereins wurden zeitgleich das Senckenbergmuseum und das Jügelhaus umgebaut. Vor seiner Zerstörung bildete ein Uhrturm auf dem Jügelhaus ein symmetrisches Gegenbild zur Sternwarte auf dem Dach des Vereinsgebäudes. Heute besteht diese Symmetrie nicht mehr, weil der Uhrturm zerstört wurde. Aber die Gebäude haben ein einheitliches Erscheinungsbild: Roter Mainsandstein wird durch helle Wandnutzflächen verbunden und die Dächer bestehen aus Schiefer. Arkaden fügen die Gebäude aneinander.
Ziel des Umbaus war es die drei Gebäude besser zu vereinen. Nach der Auffassung von Peter Kulka würden die Gebäude zwar von außen einen einheitlichen Eindruck machen, „im Inneren [seien sie aber] nie logisch rational zusammengebracht worden“. Um die Gebäude innerlich weiter zu verbinden wurden transparente Brücken zwischen den Gebäuden errichtet. Alle drei Baukörper sind damit durch eine zentrale Achse miteinander verbunden. Der Gebäudekomplex ist wie ein „H“ geformt. Das Gebäude des Physikalischen Vereins und das Jügelhaus verkörpern jeweils eine Seite des Komplexes. Die neuen Brücken bilden gemeinsam mit dem Senckenbergmuseum den Mittelbalken. Kulka meint, die Gebäude wären mit langen Gängen und vielen Fenstern nicht für die Forschung geeignet. Dieses Problem sollte behoben werden, ohne den historischen Eindruck der Gebäude zu beeinträchtigen. Räume wie die Aula im Jügelbau behielten ihre historische Gestalt. Der Hörsaal des Physikalischen Vereins wurde jedoch zu einem modernen Vorlesungssaal umgebaut. Die Dächer wurden energetisch sinnvoll aus Aluminium gebaut.Die drehbare Kuppel der Sternwarte wurde während des Umbaus nicht bearbeitet. Hier dauern die Umbauarbeiten noch an, weshalb die Sternwarte noch nicht zugänglich ist. Dreh- und Öffnungsmechanismus überholt werden, die abmontierten Fernrohre der Sternwarte sollen modernisiert werden. Das Hauptteleskop soll eine neue Linse erhalten. Die Plattform auf dem Dach wurde bereits erweitert, um Platz für weitere mobile Teleskope zu bieten.Besonders kritisiert wurden die Pläne für das neu gestaltete Aluminiumdach.Im Rahmen des Umbaus wurde das Gebäude nach dem Förderer des Physikalischen Vereins und der Senckenberg Gesellschaft in Arthur-von-Weinberg-Haus umbenannt.
Wöchentlich findet die Vortragsreihe Astronomie am Freitag statt, die nur in den hessischen Sommer- und Winterferien unterbrochen wird. Diese Vortragsreihe behandelt Themen der Astronomie und Astrophysik. Unregelmäßig werden in der Vortragsreihe NaturWissenschaft und Technik Vorträge von Wissenschaftlern und Ingenieuren gehalten, die ihre Forschungsergebnisse und Entwicklungen präsentieren. Die seit 1836 angebotenen Schülervorlesungen werden zurzeit aufgrund des Umbaus nicht angeboten. Der Physikalische Verein bietet außerdem Seminare zur praktischen Astronomie und Lehrerfortbildungen an. Der Verein nahm bis zu seinem Umzug regelmäßig an der Nacht der Museen in Frankfurt teil.
Seit 2010 veranstaltet der Physikalische Verein Science-Slams in Frankfurt. Heute sind diese mit bis zu 1300 Besuchern die größten Veranstaltungen dieser Art in Deutschland. Hauptpreis des Frankfurter Slams ist der Bembel der Weisheit. Thomas Ranft war bisher bei verschiedenen Slams Moderator.Nach Fertigstellung des Umbaus 2019 soll die Volkssternwarte, wie vorher, der Öffentlichkeit zur astronomischen Beobachtung zur Verfügung gestellt werden. Dort befindet sich ein Fernrohr mit einem Durchmesser von 21 cm und einer Brennweite von 310 cm. Die historische Glaslinse des Teleskops wurde vom Optiker Max Pauly hergestellt. Darüber hinaus gibt es einen zusätzlichen speziellen Refraktor, der sich zur Sonnenbeobachtung eignet.
Der bietet der Verein Sonnenbeobachtungen im Palmengarten Frankfurt in den hessischen Sommerferien an. Außerdem kann monatlich an der Hans-Ludwig-Neumann-Sternwarte beobachtet werden. Weitere Beobachtungsmöglichkeiten bietet der Verein beispielsweise bei Veranstaltungen in Zusammenarbeit mit der Keltenwelt am Glauberg, der Goethe-Universität und anderen Institutionen.An der vom Verein betriebenen Hans-Ludwig-Neumann-Sternwarte entdeckten Erwin Schwab, Rainer Kling, Ute Zimmer und Stefan Karge mehr als 150 Asteroiden, darunter (204852) Frankfurt und (207687) Senckenberg. Weitere Projekte an der Sternwarte sind Beobachtung von Quasaren und Nachbeobachtung von Exoplaneten.
Der Physikalische Verein vergibt insgesamt vier Förderpreise. Diese Preise werden für verschiedene wissenschaftliche Disziplinen verliehen.
Der Philipp Siedler-Wissenschaftspreis soll an den Vorsitzenden in den Jahren 1956 bis 1964 erinnern, der zum Wiederaufbau des Vereins und der Sternwarte nach dem Zweiten Weltkrieg maßgeblich beitrug. Dieser Preis wird für herausragende Studienabschlussarbeiten in den Fachbereichen der Physik der Goethe-Universität verliehen. Die betreuenden Hochschullehrer müssen die Arbeiten für eine Teilnahme vorschlagen. Jährlich werden bis zu drei Preise vergeben. Erstmals wurde der Preis 1996 verliehen.
Mit dem Eugen-Hartmann-Didaktikpreis werden seit 1998 Staatsexamensarbeiten aus dem Institut für Didaktik der Physik der Goethe-Universität geehrt. Dabei werden jedes Jahr bis zu drei Preise verliehen. Auch bei diesem Preis muss der betreuende Hochschullehrer Arbeiten für die Teilnahme vorschlagen.
Der Christian-Ernst-Neeff-Umweltpreis wird für Arbeiten mit interdisziplinärem Charakter über Umweltschutz und Umwelttechnik verliehen. Dieser Preis wird seit 1996 verliehen. Jährlich können bis zu drei Arbeiten ausgezeichnet werden. Bewerber müssen nicht vorgeschlagen werden, sondern können auf eigene Initiative Arbeiten einreichen. Der Preis richtet sich an Amateurforscher, vor allem an Schüler.
Der Samuel-Thomas-von-Soemmerring-Astronomiepreis wird jährlich an maximal drei Amateurastronomen, vornehmlich aus der Rhein-Main-Region, vergeben. Die Arbeiten können auf eigene Initiative eingereicht werden. Der 1996 erstmals verliehene Preis würdigt Samuel Thomas von Soemmerring, der selbst Amateurastronom war.
Die Mitgliedschaft im Verein wird in der Satzung geregelt. Grundsätzlich kann jede natürliche und juristische Person Mitglied werden.
Seit 1838 werden die Mitgliedszahlen in den jährlich erscheinenden Jahresberichten veröffentlicht. 1898 wurde es auf Anregung des Vorstands auch für Frauen möglich dem Verein beizutreten. Diese Möglichkeit nahmen von 1898 bis 1899 zwei Frauen wahr. Heute hat der Verein circa 1700 Mitglieder.
Die Anzahl der Mitglieder stieg bis 1911 kontinuierlich an und erreichte kurz nach der Eröffnung des neuen Vereinsgebäudes einen Höhepunkt von 1084 Mitgliedern. Während des Ersten Weltkriegs sank die Zahl der Mitglieder, stieg allerdings 1918 wieder. Durch die Inflation ab 1919 und die Weltwirtschaftskrise sank die Mitgliedszahl drastisch. 1940 erreichte sie ihren Tiefstand von 249 Mitgliedern. 1945 hatte der Verein etwa 300 Mitglieder. Erst ab 1975 stieg die Mitgliedszahl wieder in größerem Maße an.
Die Grafik zeigt die Anzahl der Mitglieder in Abhängigkeit vom Jahr an. Die Daten wurden aus den jeweiligen Jahresberichten entnommen. Für die Jahre 1920 und 1950 liegen keine veröffentlichten Daten vor, es wurde stattdessen die Anzahl der Mitglieder im jeweils nächstgelegenen Jahr angegeben.
Eine ewige Mitgliedschaft kann laut der Satzung von jedem beitragspflichtigen Mitglied erworben werden. Dafür muss einmalig ein Betrag gezahlt werden, der mindestens das Hundertfache des normalen Beitrags betragen muss. Bei einem aktuellen Jahresbeitrag von 50 € also 5000 €. Die Namen der ewigen Mitglieder werden im Eingangsbereich des Vereinsgebäudes auf den historischen Marmortafeln eingraviert.
Eine Ehrenmitgliedschaft wird auf Vorschlag des Präsidiums durch den Verwaltungsrat verliehen. Mit der Ehrenmitgliedschaft sind dieselben Rechte wie mit einer normalen Mitgliedschaft verbunden, es muss allerdings kein Mitgliedsbeitrag gezahlt werden. Seit Gründung hat der Physikalische Verein mehr als 300 Ehrenmitglieder ernannt. Die meisten Ehrenmitglieder wie Albert Einstein oder Otto Hahn zeichnen sich durch herausragende Leistungen auf naturwissenschaftlichen Gebieten aus. Andere Ehrenmitglieder wie Harald Lesch setzen sich für die Vermittlung der Naturwissenschaften ein. Ehrenmitglieder wie Hans-Ludwig Neumann förderten die Entwicklung des Vereins. Das neuste Ehrenmitglied ist Johanna Stachel, die die Ehrung am 28. März 2014 erhielt. Sie ist gleichzeitig die erste Frau, die die Ehrenmitgliedschaft verliehen bekam.
Rechtsform ist ein altrechtlicher Verein. Seine Rechtsfähigkeit als juristische Person gründet auf einer königlichen Kabinettsorder der Preußischen Krone vom Juni 1876. Mit Inkrafttreten der seit 2008 gültigen Satzung wurde der Vorstand des Vereins in Präsidium umbenannt. Das Präsidium besteht aus vier bis sieben vom Verwaltungsrat gewählten Mitgliedern, sowie dem Ehrenpräsidenten, der seit 2007 Gerd Sandstede ist. Das Präsidium hat die Leitung aller Geschäfte wahrzunehmen. Aus seinen Reihen wählt das Präsidium den Präsidenten, den Vizepräsidenten, den Schatzmeister und Schriftführer sowie einen wissenschaftlichen Direktor.
Im Verwaltungsrat sitzen zwölf bis zwanzig von der Mitgliederversammlung auf drei Jahre gewählte Personen. Hinzu kommt der Präsident des Vereins, der Präsident der Goethe-Universität und die geschäftsführenden Direktoren der physikalischen Institute der Universität. Der Verwaltungsrat ernennt Ewige Mitglieder, Ehrenmitglieder sowie den Ehrenpräsidenten.
Physikalischer Verein (Hrsg.): Der Neubau des Physikalischen Vereins und seine Eröffnungsfeier am 11. Januar 1908. 1. Auflage. Frankfurt 1908. 
Physikalischer Verein (Hrsg.): Festschrift zur Jahrhundertfeier des Physikalischen Vereins dargeboten von den Dozenten seiner Institute. 1. Auflage. Frankfurt 1924. 
Heinz Fricke (Hrsg.): 150 Jahre Physikalischer Verein Frankfurt a. M. 1. Auflage. Physikalischer Verein, Frankfurt 1974, DNB 750868783. 
Ludwig Heilbronn: Die Gründung der Universität Frankfurt a. M. Josef Baer & Co., Frankfurt am Main Juni 1915 (Online im Internetarchiv archive.org [abgerufen am 2. September 2015] Überblick über die Gründer der Goethe-Universität mit geschichtlichem Überblick zum Physikalischen Verein). 
Panagiotis Kitmeridis: Popularisierung der Naturwissenschaften am Beispiel des Physikalischen Vereins Frankfurt. Staats- und Universitätsbibliothek Hamburg, Hamburg 2015, DNB 1080721185, urn:nbn:de:gbv:18-76587.
Landesamt für Denkmalpflege Hessen (Hrsg.):  Physikalischer Verein. In: DenkXweb, Online-Ausgabe von Kulturdenkmäler in Hessen@1@2Vorlage:Toter Link/denkxweb.denkmalpflege-hessen.de(Seite nicht mehr abrufbar, Suche in Webarchiven:  Physikalischer Verein)
Dokumente aus 180 Jahren Vereinsgeschichte auf der Website des Instituts für Stadtgeschichte Frankfurt. Abgerufen am 18. Juni 2015. 

Der Physikalismus ist in der Philosophie die metaphysische These, dass alles, was existiert, physisch sei, oder dass zwischen den Eigenschaften aller real existierenden Objekte und deren physikalischen Eigenschaften eine Supervenienz-Beziehung herrsche. Der Physikalismus ist damit eine monistische Position, die im Gegensatz zu dualistischen, pluralistischen und idealistischen Positionen steht.
Sowohl zur Definition des Physikalischen wie auch zur Explikation des Physikalismus gibt es verschiedene Varianten. Gemäß einer häufig verwendeten Definition gelten alle Objekte, Eigenschaften oder Ereignisse (alle Entitäten) als physisch, die in den Theorien der Physik beschrieben werden können.
Physikalistische Positionen werden von vielen Gegenwartsphilosophen und Naturwissenschaftlern vertreten, jedoch ist der Physikalismus auch Gegenstand einer kontroversen Diskussion.
Eine besondere Rolle spielt der Physikalismus in der Philosophie des Geistes, da mit ihm die Ablehnung der Idee eines immateriellen Bewusstseins verbunden ist. Viele Vertreter des modernen Physikalismus vertreten etwa die These, dass die Annahme, Geistiges sei nicht determiniert von physischen Ursachen, falsch ist, da es nach naturwissenschaftlicher Konzeption keine hinreichenden Anhaltspunkte dafür gebe, daran zu zweifeln, dass geistige Phänomene auf physische Ursachen zurückgehen.
Der Physikalismus ist eng verwandt zum Materialismus. In heutigen systematischen Debatten wird eher von Physikalismus als von Materialismus gesprochen, weil viele Konnotationen an „materialistische“ klassische Positionen nicht dem heutigen, engeren Begriff von Physikalismus zugehören.
Der Begriff des Physikalismus wurde insbesondere durch Otto Neurath und Rudolf Carnap in einer Reihe von Aufsätzen in der ersten Hälfte des 20. Jahrhunderts geprägt. Der Physikalismus war Teil eines wichtigen metaphysikkritischen Programms (Einheitswissenschaft) des Logischen Empirismus, welches zum Ziel hatte, eine einheitliche Sprache zu entwickeln, in welcher der empirische Gehalt aller Erfahrungswissenschaften ausgedrückt werden könnte. Eine Motivation für dieses Programm war es, dass der Logische Empirismus annahm, so die Intersubjektivität der Wissenschaften sicherzustellen und außerdem die Trennung zwischen Geisteswissenschaften und Naturwissenschaften zu überwinden.
Wegen des vom Logischen Empirismus vertretenen Methodischen Neutralismus war mit der Annahme einer physikalistischen Sprache keine ontologische Aussage verbunden; ontologische Fragestellungen wurden wie alle metaphysischen Aussagen als Scheinprobleme angesehen, von der die Wissenschaft möglichst weitgehend befreit werden muss. Prinzipiell könnte man nach Carnap z. B. auch eine phänomenalistische Sprache als Grundlage einer Einheitswissenschaft verwenden, solange der Sprachaufbau genau angegeben ist, so dass eine Übersetzbarkeit gegeben ist. Die Wahl einer physikalistischen Sprache hatte praktische Gründe, da in einer solchen Sprache bereits Intersubjektivität und vor allem auch Intersensualität vorausgesetzt sind. Die Wahl einer physikalistischen Sprache beinhaltete nicht die Forderung nach Reduzierbarkeit der Gesetze aller Einzelwissenschaften auf die physikalischen Gesetze, sondern nur die Ausdrückbarkeit aller Aussagen aller Einzelwissenschaften in der physikalistischen Sprache.
Die Metaphysik behandelt die zentralen Probleme der theoretischen Philosophie: die Fundamente (Voraussetzungen, Ursachen oder „ersten Gründe“) und allgemeinsten Strukturen (Gesetzlichkeiten, Prinzipien) sowie den Sinn und Zweck der gesamten Wirklichkeit beziehungsweise allen Seins.
Die Ontologie wird auch als „allgemeine Metaphysik“ bezeichnet. Sie ist die philosophische Grundlagendisziplin, die danach fragt, was existiert. Die zentrale ontologische Frage lautet also: „Was gibt es?“ Hierauf antwortet der Physikalist, dass in Wirklichkeit nur physische Entitäten existieren. „Entität“ ist dabei ein Sammelbegriff für Objekte, Eigenschaften, Ereignisse usw.
Mit dieser Antwort erweist sich der Physikalismus als eine Variante des Monismus. Monisten erklären, dass nur eine Sorte von Entitäten existiert. Allerdings gibt es nicht nur den physikalistischen Monismus, sondern auch den idealistischen und den neutralen Monismus. Idealistische Monisten stimmen den Physikalisten darin zu, dass es nur eine Sorte von Entitäten gibt – sie erklären allerdings, dass nur geistige Entitäten existieren. Das, was als physische Außenwelt erscheint, sei in Wirklichkeit ein Produkt des Geistes. Neutrale Monisten behaupten, dass es nur eine Sorte von neutralen Entitäten gebe. Diese Entitäten sollen physische und mentale Aspekte enthalten, selbst aber weder physischer noch mentaler Natur sein.
Der klassische Kontrahent des Physikalismus ist der Dualismus. Dualisten vertreten die These, dass es zwei grundverschiedene Sorten von Entitäten gibt: physische und geistige. In der Geschichte der Philosophie haben sich verschiedene Varianten des Dualismus entwickelt. Während der klassische Dualismus in der Tradition von René Descartes von einer Interaktion zwischen dem Geist und der physischen Welt (etwa dem Gehirn) ausgeht, bestreiten andere Theorien eine derartige gegenseitige Beeinflussung. Der Epiphänomenalismus behauptet, dass die physische Welt auf den Geist einwirkt, aber nicht umgekehrt. Der auf Gottfried Wilhelm Leibniz zurückgehende psychophysische Parallelismus bestreitet jede ursächliche Interaktion zwischen der geistigen und der physischen Welt.
Eine dritte Klasse von ontologischen Positionen kann „Pluralismus“ genannt werden. Pluralisten erklären, dass es viele verschiedene Sorten von Entitäten gebe. Schließlich gibt es noch Positionen, die die ontologische Frage „Was gibt es?“ ablehnen. Sie erklären, dass diese Frage keine allgemeine Antwort habe, sondern davon abhängig sei, wie wir die Welt beschreiben. Solche Positionen werden oft „relativistischer“ oder „pragmatistischer Pluralismus“ genannt. Wenn der Physikalist seine Position plausibel machen will, muss er sich allen vorgenannten Alternativen (idealistischer und neutraler Monismus, Formen des Dualismus und des Pluralismus) argumentativ stellen.
Der Begriff „Physikalismus“ wird oft gleichbedeutend mit dem Begriff des Materialismus verwendet. In den aktuellen Debatten der Wissenschaftstheorie und Philosophie des Geistes ist dabei der Begriff „Physikalismus“ üblich, während man im Zusammenhang philosophiehistorischer Darstellungen meist vom „Materialismus“ spricht. Allerdings gibt es auch gewisse inhaltliche Unterschiede: Während der traditionelle Materialismus auf die These festgelegt ist, dass alle Entitäten aus kleinsten Materieteilchen zusammengesetzt sind, möchte der Physikalismus der Physik nicht vorschreiben, welche Entitäten sie letztlich als grundlegend postuliert. So wäre der Physikalismus auch mit dem Ergebnis vereinbar, dass die bestbestätigten physikalischen Theorien Entitäten fordern, die nicht als Materie beschrieben werden können – etwa Gravitationskräfte.
Physikalisten erklären in der Regel, dass die Welt in einem wichtigen Sinne nur aus Elementarteilchen bestehe. Zwar gebe es auch viele andere Objekte, wie Bäume, Steine oder Kaninchen, doch all diese Objekte seien letztlich nichts anderes als Anordnungen von Elementarteilchen. Dies ist die zentrale Idee des „Schichtenmodells der Realität“ („layered model of reality“), in dem jedes Objekt durch Objekte der nächstniedrigeren Schicht zusammengesetzt ist (siehe schematische Darstellung).
Eine präzisere Formulierung des Schichtenmodells bietet die Unterscheidung zwischen grundlegenden und komplexen physischen Entitäten. Als grundlegende physische Entitäten gelten die durch die Mikrophysik beschriebenen, kleinsten physischen Objekte, Prozesse oder Eigenschaften. Meist werden die grundlegenden physischen Entitäten als die Elementarteilchen und deren Eigenschaften vorgestellt. Zu den komplexen physischen Entitäten zählt hingegen alles, was aus den grundlegenden physischen Entitäten zusammengesetzt ist oder sich aus deren Zusammensetzung ergibt. So gelten dem Physikalisten etwa Moleküle, Neuronen, Menschen oder Planeten als physische Gegenstände, da sie aus Elementarteilchen zusammengesetzt sind. Im Rahmen des Schichtenmodells lautet die These des Physikalismus, dass sich alles aus der Zusammensetzung der grundlegenden physischen Entitäten ergebe. Ein Dualist würde hingegen erklären, dass sich das menschliche Bewusstsein eben nicht aus einer derartigen, physischen Konstellation ergibt.
Oft wird angenommen, dass der Physikalismus mit dem Schichtenmodell der Welt einen generellen Reduktionismus zur Folge hat: Wenn alle Objekte aus Elementarteilchen (also den Objekten der letzten Schicht) zusammengesetzt sind und sich alle Eigenschaften aus den Eigenschaften der Elementarteilchen ergeben, so sollte es im Prinzip möglich sein, alles auf der Ebene der Mikrophysik zu erklären und somit alle wahren, wissenschaftlichen Theorien auf die Mikrophysik zurückzuführen (zu reduzieren).
Allerdings können Physikalismus und ein solcher Reduktionismus nicht miteinander gleichgesetzt werden, da es auch Versuche gibt, einen nichtreduktiven Physikalismus zu formulieren. Solche Theorien nehmen an, dass alle Objekte aus grundlegenden physischen Teilchen zusammengesetzt sind, bestreiten jedoch entweder, dass sich daher auch alle wissenschaftlichen Theorien reduzieren lassen oder behaupten im Sinne der Emergenzhypothese die Existenz von irreduziblen Eigenschaften.
Da Physikalismus und Reduktionismus nicht miteinander identifiziert werden können, wird in der Philosophie eine intensive Debatte über die korrekte Definition des Physikalismus geführt. Der Physikalismus ist zwar durch die These bestimmt, dass alles, was existiert, physisch ist. Allerdings bleibt ein Problem, solange nicht hinreichend geklärt ist, wie die genannte These zu verstehen ist. So kann man etwa fragen, was es heißt, dass der Mensch oder das Bewusstsein physisch ist, wenn man nicht zugleich sagen will, dass sie auf das Physische reduziert werden können.
Ein populärer Vorschlag versucht, den Physikalismus durch das Konzept der Supervenienz zu definieren. Der Begriff der Supervenienz beschreibt die folgende Beziehung: A superveniert über B genau dann, wenn A nicht geändert werden kann, ohne dass B geändert wird. Ein Beispiel ist das Verhältnis von darstellenden und physischen Eigenschaften eines Kunstwerks. Man kann nicht die Landschaft, die das Bild darstellt, verändern, ohne gleichzeitig die physische Struktur des Bildes zu verändern. In diesem Sinne supervenieren die darstellenden Eigenschaften des Bildes über den physischen Eigenschaften. David Lewis beschreibt dieses Verhältnis wie folgt:
Nun bietet es sich an, den Physikalismus mit Hilfe der Supervenienzthese zu definieren: Alle Entitäten supervenieren über den grundlegenden physischen Entitäten. Eine solche Definition hat u. a. den Vorteil, gegenüber der Reduktionsfrage neutral zu sein. Supervenienzverhältnisse sind mit Reduktionen vereinbar, setzen sie jedoch nicht voraus.
Bei genauerer Betrachtung zeigt sich allerdings, dass Supervenienz alleine nicht hinreichend für den Physikalismus ist. So gibt es dualistische Positionen, die mit der Supervenienzthese vereinbar sind, schließlich könnte es immaterielle Entitäten geben, die sich nur dann verändern, wenn sich auch etwas Physisches verändert – mehr wird durch die Supervenienzthese nicht verlangt. Der Epiphänomenalismus und der Psychophysische Parallelismus sind etwa als derartige Dualismen anzusehen. Die Supervenienzthese muss also um eine zusätzlich Annahme ergänzt werden, um eine Definition des Physikalismus darzustellen.Der Linguist Noam Chomsky vertritt die Ansicht, dass seit den revolutionären Denkmodellen von Isaac Newton und René Descartes eine zufriedenstellende Definition des Physikalismus ausbleibt. Es ist stets unklar, ob mit Physikalismus lediglich Materie, oder aber auch Funktionen, Strukturen und Dispositionen gemeint sind. Davon abgesehen ist es keineswegs klar, wo zwischen den genannten Kandidaten eine Trennlinie zu setzen ist – diese Schwierigkeit offenbart sich gerade bei komplexeren Phänomenen wie etwa Sprache, Bewusstsein, kybernetischen Systemen und so weiter. Bis dies aber der Fall ist, hat es Chomsky zufolge wenig Sinn, das Leib-Seele-Problem oder verwandte Themen zu diskutieren.
Viele Wissenschaftler und Philosophen sehen die Wahrheit des Physikalismus durch den Fortschritt der Naturwissenschaften belegt. Sie weisen zum einen darauf hin, dass die (Natur-)Wissenschaften an keiner Stelle auf immaterielle Ursachen zurückgreifen müssten. Dort, wo man dachte, dass nur eine immaterielle Ursache Erklärung für ein Phänomen sein könne, habe man schließlich doch eine physische Ursache gefunden. Ein typisches Beispiel ist der Niedergang des physiologischen Vitalismus des 18. und frühen 19. Jahrhunderts, der einen immateriellen élan vital postulierte, um das Phänomen des Lebens zu erklären. Schließlich wurde diese Annahme jedoch durch eine Reihe wissenschaftlicher Entwicklungen wie die erste Synthese eines organischen Materials durch Friedrich Wöhler und die Entwicklung der Evolutionstheorie in vielerlei Hinsicht überflüssig.
Zudem weisen Physikalisten darauf hin, dass das Schichtenmodell der Welt empirisch gut bestätigt sei. Man finde nun einmal keine Objekte in der Welt, die nicht komplett aus kleineren Objekten zusammengesetzt seien, und auch die Naturwissenschaften zeigten, wie sich die Eigenschaften der Objekte aus Eigenschaften der grundlegenderen Objekte ergäben. Diese empirischen Ergebnisse führen nach der Meinung vieler Physikalisten durch einen Schluss auf die beste Erklärung zum Physikalismus.
Antiphysikalisten reagieren auf diesen Einwand in der Regel, indem sie zu zeigen versuchen, dass es Phänomene gebe, die sich hartnäckig der Einordnung in das physikalistische Schichtenmodell widersetzten. So wird etwa darauf verwiesen, dass Zahlen reale Entitäten seien, die nicht aus grundlegenderen physischen Objekten zusammengesetzt seien oder es wird argumentiert, dass Eigenschaften des Bewusstseins wie Qualia oder Intentionalität sich nicht aus den biologischen Eigenschaften der Lebewesen ergeben. Zudem wird von Antiphysikalisten oft argumentiert, dass die Physikalisten den tatsächlichen Stand der Naturwissenschaften falsch wiedergäben. So zeichne sich die aktuelle Naturwissenschaft durch eine zunehmende Spezialisierung aus, in der immer mehr Entitäten postuliert würden, ohne dass dabei immer gezeigt werde, wie sich diese Entitäten aus der grundlegenderen, ontologischen Schicht ergäben.
Die meisten Physikalisten sehen in den empirischen wissenschaftlichen Ergebnissen allerdings auch nicht einen Beweis des Physikalismus, sondern einen Hinweis für die Plausibilität ihrer Position, die einen gegenüber antiphysikalistischen Behauptungen skeptisch stimmen solle. Die klassischen Argumente für den Physikalismus beziehen sich vielmehr auf Überlegungen zur Kausalität.
Antiphysikalisten argumentieren für die Existenz von nichtphysischen Entitäten, etwa von nichtphysischen mentalen Zuständen oder Substanzen. Nun wird von Physikalisten immer wieder eingewandt, dass solche Positionen nicht die kausale Wirksamkeit der angeblich nichtphysischen Entitäten erklären könnten. Mentale Zustände hätten etwa offensichtliche kausale Kräfte. Kopfschmerzen mögen die Ursache für das Schlucken einer Aspirintablette sein, die Sehnsucht nach einer Freundin möge zu einer längeren Reise führen. Nun argumentieren Physikalisten, dass es für jede Handlung auch eine physische bzw. biologische Ursache gebe. Für das Schlucken einer Aspirintablette gebe es in etwa folgende Ursache: Im Gehirn liefen neuronale Prozesse ab, die zu Erregungsweiterleitungen in die Muskeln führten, die wiederum das Schlucken der Tablette verursachten.
Es scheint also, als gebe es für Handlungen gleichzeitig zwei Ursachen: Zum einen die mentale Ursache (etwa Kopfschmerzen) und zum anderen die physische Ursache. Doch nun argumentieren Physikalisten, dass eine solche generelle Überdetermination bzw. Mehrfachverursachung durch zwei oder mehr Ursachen höchst unplausibel sei. Man könne dies einsehen, wenn man sich auf reale Beispiele von Überdetermination konzentriere, wie etwa ein Haus, das durch Blitzeinschlag und Brandstiftung in Flammen gesetzt werde. Natürlich können derartige Fälle vorkommen, doch eine generelle Überdetermination ist auszuschließen. Genau dies wird aber von Dualisten gefordert, wenn sie annehmen, dass es für einige Handlungen immer eine mentale und eine physische (Instrumental- bzw. Sekundär-)Ursache gibt. Man kann das Argument für den Physikalismus wie folgt formulieren:Prämisse 1: Mentale Zustände verursachen physische Ereignisse.
Prämisse 4: Wenn Prämisse 1–3 wahr sind, dann sind mentale Ereignisse nichts anderes als physische Ereignisse.
Nach Ansicht von Physikalisten zeigt dieses Argument nicht nur, dass mentale Zustände physische Zustände sind. Das Argument lasse sich auch auf andere Entitäten übertragen, von denen ein Dualist behaupten könnte, dass sie nicht physisch seien, wie etwa ästhetische und ethische Eigenschaften. Nach Ansicht des Physikalisten zeigen also Überlegungen zur Kausalität die Wahrheit des Physikalismus. Nun sind von Dualisten selbstverständlich verschiedene Antworten entwickelt worden.
Während Epiphänomenalisten behaupten, dass mentale Zustände gar keine Wirkungen hätten, erklären interaktionistische Dualisten mit Verweis auf die Quantenphysik, dass nicht jedes physische Ereignis eine physische Ursache habe oder argumentieren für die Möglichkeit einer generellen Überdetermination bzw. für das Zusammenwirken von Teilursachen. Es werden in der Argumentation also die Prämissen 1–3 in Zweifel gezogen.
Ein grundsätzlicher Einwand gegen den Physikalismus lautet, dass der Begriff des Physischen letztlich unverständlich und der Physikalismus daher bedeutungslos sei. Das Problem wurde zunächst von Carl Gustav Hempel formuliert, weswegen man auch von „Hempels Dilemma“ spricht. Eine neuere, einflussreiche Formulierung ist der Aufsatz There is no Question of Physicalism von Tim Crane und D. H. Mellor.Das Dilemma ergibt sich aus der Frage, wer bestimmt, was als physische Entität gelten soll. Sicherlich die Physik, doch es bleibt die Frage, an welche Physik man sich wenden soll. Ist die aktuelle Physik oder eine zukünftige, idealisiert 'komplette' Physik gemeint? Wenn die aktuelle Physik gemeint ist, so ist der Physikalismus nach Meinung der Kritiker vermutlich falsch. Es sei schließlich höchst unplausibel, dass die aktuelle Physik schon alle physischen Entitäten identifiziert hätte. Doch wenn man sich an eine ideale zukünftige Physik wendet, so ist der Physikalismus nach Ansicht der Kritiker trivial: Eine idealisiert-komplette Physik würde zwangsläufig auf alle grundlegenden Entitäten zurückgreifen, welcher Art sie auch seien. Und wie könnte man da ausschließen, dass sich unter den grundlegenden Entitäten auch Qualia, Zahlen usw. befinden? Wenn man „physisch“ mit Hilfe einer ideal-kompletten Physik definiert, so scheint sogar ein klassischer Dualist zugleich Physikalist sein zu können.
Während manche Philosophen, wie David Lewis, erklären, dass die aktuelle Physik doch in einem wichtigen Sinne schon vollständig sei, versuchen andere Philosophen das Dilemma durch einen dritten Vorschlag aufzulösen. So schlägt etwa Frank Cameron Jackson vor, „physisch“ all die Entitäten zu nennen, die gebraucht werden, um das Geschehen von einer gewissen Größe zu beschreiben. Die Idee ist, dass all das „physisch“ genannt werden soll, was auf der subatomaren Ebene geschieht, während Makroeigenschaften, wie etwa das Schmerzerleben eines Menschen, nicht als grundlegende physische Entität betrachtet werden sollen. Eine solche Trennung könnte vorgenommen werden, wenn man nur die subatomaren Entitäten als grundlegende physische Phänomene bezeichnen dürfte. Diese Strategie mag bei mentalen Zuständen gut funktionieren, hat jedoch ein Problem etwa mit der Annahme von nichtphysischen Zahlen. Zahlen können schließlich nicht nach räumlicher Größe geordnet werden und scheinen auf jeder Ebene anwendbar.
Die Existenz von Qualia – den subjektiven Erlebnisgehalten – wird oft für das schwerwiegendste Problem des Physikalismus gehalten. So haben etwa David Chalmers und Frank Cameron Jackson die Existenz von Qualia als hinreichenden Grund für eine Ablehnung des Physikalismus gesehen. Auch Roger Penrose behauptet Entsprechendes. Die grundlegende Idee ist, dass der qualitative Erlebnisgehalt zwar eine Eigenschaft vieler mentaler Zustände sei, aber nicht auf die Eigenschaften physischer Zustände zurückführbar.
Ein sehr bekanntes qualiabasiertes Argument gegen den Physikalismus ist von Jackson entwickelt worden: Er entwirft ein Gedankenexperiment von der Superwissenschaftlerin Mary: Mary ist eine auf Farbensehen spezialisierte Neurowissenschaftlerin, die seit ihrer Geburt in einem schwarz-weißen Labor gefangen ist und noch nie Farben gesehen hat. Sie kennt alle physischen Fakten über das Sehen von Farben, weiß jedoch nicht, wie Farben aussehen. Jacksons Argument gegen den Physikalismus ist nun recht kurz: Mary kennt alle physischen Fakten über das Sehen von Farben. Sie kennt dennoch nicht alle Fakten über das Sehen von Farben. Also gibt es Fakten, die außerhalb naturwissenschaftlicher Konzeptionen stehen, die somit das Phänomen Farbe nicht hinreichend darlegen können. Also ist der Physikalismus falsch. Gegen dieses Argument sind, wie gegen jedes qualiabasierte Argument, verschiedene physikalistische Repliken vorgebracht worden. So wurde etwa behauptet, dass Mary keine neuen Fakten kennenlernt, sondern allein eine neue Fähigkeit erwerbe. Auch wurde behauptet, dass Mary lediglich einen schon bekannten Fakt auf eine neue Weise kennenlerne.
Der Status qualiabasierter Argumente gegen den Physikalismus ist weiterhin höchst umstritten. Zum einen ist das Konzept der Qualia selbst schwer bestimmbar und sehr umstritten. Zum anderen ist aber auch nicht sicher, welchen Status Qualiaargumente haben. Sind sie metaphysische Argumente, die uns über den ontologischen Status von Mentalem aufklären können, oder sind sie erkenntnistheoretische Argumente, die uns vor allem über die Grenzen unseres Wissens aufklären? Wäre Letzteres der Fall, hätte das Qualiaproblem keine Konsequenzen in Bezug auf die Frage nach der Wahrheit des Physikalismus.
Neben den beschriebenen Problemen wird gelegentlich eine sehr viel grundsätzlichere Kritik am Physikalismus geäußert. Vertreter pluralistischer und ähnlicher Positionen erklären, dass die Konzeption des Physikalismus auf einer vollkommen verkehrten Vorstellung der Rolle der Physik beruhe. Sie argumentieren, dass die Physik zwar eine legitime Form des Wissenserwerbs sei, aber in keiner Weise verabsolutiert werden dürfe. Vielmehr sei die physikalische Beschreibung der Welt eine von vielen Beschreibungsmöglichkeiten, die jedoch in keiner Weise „tiefer“ oder „wirklicher“ als die mentale, ästhetische oder ökonomische Beschreibung sei. Man müsse akzeptieren, dass es eine Pluralität der Perspektiven gebe und nicht die eine, einzig wahre Beschreibung der Welt, die oft in der (Mikro-)Physik vermutet wird. Es gebe also eine Vielzahl von Ebenen, und der Fehler des Physikalismus sei die Annahme, dass sich diese Ebenen in einem Schichtenmodell auf die physische Ebene zurückführen lassen müssten.
Pluralistische Positionen werden aus verschiedenen metaphysischen Perspektiven formuliert. Ein früher Vertreter des Pluralismus war Alfred North Whitehead, der diesen Gedanken in seinem philosophischen Hauptwerk Prozess und Realität entwickelte. Der Wissenschaftstheoretiker John Dupré vertritt etwa einen realistischen Pluralismus, der eine pluralistische Ontologie impliziert. Nelson Goodman argumentiert hingegen für einen relativistischen Pluralismus, der nicht mit einer pluralistische Ontologie, sondern der Abschaffung ontologischer Konzepte einhergeht. Hilary Putnam versucht in Kombination mit dem internen Realismus eine Zwischenposition zu formulieren, in Deutschland vertritt Peter Bieri neuerdings eine vergleichbare Position.
Der Physikalismus ist eine Position, die in der analytischen Philosophie zeitweise eine nahezu unbezweifelte Hintergrundannahme war. Dieser Status des (meistens mit dem Reduktionismus kombinierten) Physikalismus ist durch zwei Entwicklungen ins Wanken geraten: Zum einen wurden von verschiedenen Seiten die metaphysisch realistischen Prämissen des klassischen Physikalismus angegriffen. Die einflussreichsten Beispiele für diese Tendenz sind Goodman und der späte Putnam. Zum anderen ist in der modernen Debatte der Philosophie des Geistes immer deutlicher geworden, dass eine reduktiv physikalistische Interpretation des Bewusstseins zu schweren Problemen führt. Diese Tendenzen haben allerdings oft nicht zurück zu einem klassischen Dualismus geführt, sondern zu der Entwicklung nichtreduktiver Physikalismen und pluralistischer Positionen. Gleichzeitig gibt es eine Reihe von Philosophen, die der Meinung sind, dass sich letztlich keine Alternative zu einem reduktiven Physikalismus finden lasse, ein bekannter Vertreter dieser Position ist etwa David Lewis. Damit bleibt der Ausgang der Debatte um den Physikalismus weiter offen. Erschwerend kommt hinzu, dass die Modelle des Physikalismus oft entsprechend der Klassischen Physik beschrieben sind und keineswegs klar ist, wie eine Formulierung auf Basis der Quantentheorie letztlich aussehen wird.
Ansgar Beckermann: Eigenschafts-Physikalismus. In: Zeitschrift für philosophische Forschung. Bd. 50, Nr. 1/2, 1996, S. 3–25, (JSTOR 20483777; Deutschsprachiger Einführungsartikel).
Jaegwon Kim: Physicalism, or Something Near Enough. Princeton University Press, Princeton NJ u. a. 2005, ISBN 0-691-11375-0 (Einführendes Werk mit Schwerpunkt Philosophie des Geistes).
Marcus Knaup, Tobias Müller, Patrick Spät (Hrsg.): Post-Physikalismus. Alber, Freiburg (Breisgau) u. a. 2011, ISBN 978-3-495-48464-7 (Kurzbeschreibung sowie Inhalt und Einleitung; PDF; 102 kB).
Jan G. Michel: Der qualitative Charakter bewusster Erlebnisse. Physikalismus und phänomenale Eigenschaften in der analytischen Philosophie des Geistes. mentis, Paderborn 2011, ISBN 978-3-89785-742-1 (Umfangreiche Untersuchung des Physikalismus in der Philosophie des Geistes).
Jeffrey Poland: Physicalism. The Philosophical Foundations. Clarendon Press, Oxford 1994, ISBN 0-19-824980-2 (Umfangreiche wissenschaftstheoretische Diskussion).
Daniel Stoljar: Eintrag in Edward N. Zalta (Hrsg.): Stanford Encyclopedia of Philosophy.Vorlage:SEP/Wartung/Parameter 1 und Parameter 3 und nicht Parameter 2
Jochen Fahrenberg: Gehirn und Bewusstsein (PDF; 291 kB) (Darstellung der verschiedenen Positionen im Überblick)
Peter Schulte: Plädoyer für einen physikalistischen Naturalismus (PDF; 165 kB), Zeitschrift für philosophische Forschung, 64 (2010), 165–189

Die Piaggio P.149 ist ein viersitziges, einmotoriges Leichtflugzeug des italienischen Herstellers Piaggio. Sie ist ein Ganzmetallflugzeug und bedingt kunstflugtauglich. Die Piaggio P.149 entstand Anfang der 1950er-Jahre als Weiterentwicklung der P.148 und wurde vornehmlich zivil oder militärisch als Schul-, Verbindungsflugzeug oder Reiseflugzeug eingesetzt.
Größter Nutzer des Flugzeugs war die deutsche Luftwaffe, die über 260 Exemplare des Flugzeugs beschaffte und diese von 1957 bis 1990 einsetzte. Auch die Luftstreitkräfte Österreichs, die israelischen Luftstreitkräfte sowie drei afrikanische Staaten setzten das Muster in ihren Luftwaffen ein. Die Schweizerische Luftverkehrsschule nutzte das Muster als Standardschulflugzeug für die Piloten der Swissair.
Während der militärischen Einsatzzeit in Deutschland zeigten sich teilweise erhebliche Mängel an diesem Flugzeug, die jedoch alle behoben wurden. Es gilt heute als gutmütig im Flugverhalten und technisch als zuverlässig.
Viele Piaggio P.149 gingen nach ihrer kommerziellen oder militärischen Nutzung wie andere Schul- oder Verbindungsflugzeuge in privaten Besitz über. Sie hat in Fliegerkreisen den Spitznamen „Pitschi“.
Das Unternehmen Piaggio entwickelte zu Beginn der 1950er-Jahre ein zweisitziges Spornradflugzeug, das sich zur Anfänger- und Kunstflugschulung eignete. Nach rund sechs Monaten Entwicklungs- und Bauzeit wurde am 12. Februar 1951 der erste Prototyp unter der Bezeichnung P.148 fertiggestellt. Bei der P.148 handelte es sich wie beim Nachfolger um einen freitragenden Tiefdecker, der im Gegensatz zur P.149 über ein starres Spornradfahrwerk verfügte. Angetrieben wurde die P.148 von einem Lycoming O-435. Nach einer Erprobung orderte die italienische Luftwaffe 100 Stück des Musters.Dieser Erfolg regte das Unternehmen Piaggio zu einer Weiterentwicklung der P.148 an. Im Zuge dessen wurde die Anzahl der Sitzplätze durch eine deutliche Vergrößerung der Kabine auf vier erhöht, das starre Spornradfahrwerk wich einem einziehbaren Bugfahrwerk und die Motorleistung wurde durch den Einsatz des GO-480 auf 274 PS erhöht. Durch diese Änderungen entstand ein viersitziges, voll kunstflugtaugliches Reiseflugzeug, das am 19. Juni 1953 zum Erstflug abhob.
Die P.149 absolvierte ihren Jungfernflug am 19. Juni 1953. Wann und wo die letzte P.149 produziert wurde, kann aus Literaturangaben nicht mit Sicherheit nachvollzogen werden. 
Von den insgesamt 265 für die Bundeswehr bestellten Maschinen der Variante P.149D wurden 75 bei Piaggio selbst und 190 Exemplare bei Focke-Wulf in Bremen in Lizenz gefertigt. Letztere erhielten den Zusatzbuchstaben „FW“ für Focke-Wulf vor der Musterbezeichnung  – also FWP.149D. Die erste bei Focke-Wulf gebaute Maschine verließ Ende 1957 die Produktionshallen, das Ende der Lizenzfertigung liegt mit großer Wahrscheinlichkeit zwischen 1960 und 1963. 1965 war die Fertigung sicher beendet, da Jane’s 1965/66 die P.149D nicht mehr aufführt.Die Quellen machen keine Angaben über die Gesamtproduktionszahlen, sind sich aber darüber einig, dass die Bundesluftwaffe mit Abstand der größte Abnehmer des Flugzeugs war, wobei auch hier die Abnahmezahlen zwischen 262, 265 und 266 variieren.
Das Flugzeug ist ein freitragender Tiefdecker und wurde aus Leichtmetall in Ganzmetallbauweise hergestellt. Das Flugzeugmuster ist viersitzig, wobei je zwei nebeneinander liegende Sitze hintereinander in einer geschlossenen Kabine angeordnet sind. Der Führersitz ist vorne links. Das Flugzeug besitzt Doppelsteuer, ist also sowohl vom linken als auch vom rechten Sitz steuerbar. Das Fahrwerk ist als Bugfahrwerkskonstruktion ausgelegt und elektrisch einziehbar. Das Flugzeug verfügt über Landeklappen. Die P.149 ist kunstflugtauglich, sofern ein zulässiges Gesamtgewicht von 1470 kg nicht überschritten wird und das Flugzeug mit maximal zwei Personen besetzt ist.Siehe dazu auch: Technische Daten
Die P.149 ist mit einem Triebwerk des US-amerikanischen Herstellers Lycoming ausgestattet. Es handelt sich um einen Sechszylinder-Boxermotor mit Untersetzungsgetriebe des Typs GO-480. In der Typenbezeichnung des Motors ist die Bauart durch die Kennbuchstaben G für geared (englisch für „mit Getriebe“) und O für opposed (engl. für „gegenüberliegend“, Boxerbauweise) sowie der Hubraum in Kubikzoll dargestellt. Der Motor verfügt somit über 480 Kubikzoll, also rund 7,8 Liter Hubraum und leistet bei 3400/min 274 PS. Die zulässige Dauerleistung des Motors liegt bei 264 PS, wobei der Kraftstoffverbrauch dann bei rund 60 Litern pro Stunde liegt. Dieser Motor wurde auch in der Dornier Do 27 eingesetzt, wodurch die Stückzahlen dieses Motors bei der Bundeswehr anstiegen. Daher wurde der Motor seinerzeit bei BMW in Lizenz gefertigt.
Während des Betriebes der P.149 wurden erhebliche Konstruktionsmängel offensichtlich. Diese betrafen vor allem das Fahrwerk und die Tragflächenaufhängung. Manche Mängel waren so gravierend, dass zeitweise der gesamte Flugzeugbestand mit Startverbot belegt wurde.
Infolge einer Notlandung mit eingezogenem Fahrwerk wurde das betroffene Flugzeug zerlegt und auf Mängel untersucht. Dabei fielen dem zuständigen Personal deformierte vordere Flügelanschlussbolzen auf. Im Anschluss wurde der gesamte Flugzeugbestand auf diesen Mangel hin untersucht und mehrfach die gleiche Beschädigung festgestellt. Durch den Einsatz von Bolzen mit höherer Festigkeit konnte der Mangel 1960 an allen Flugzeugen behoben werden.Im Betrieb des Flugzeugs fanden auffällig oft Bauchlandungen statt, da sich das Fahrwerk häufig nicht ausfahren ließ. Auch die Notvorrichtung zum Ausfahren des Fahrwerks versagte in diesen Fällen. Als Ursache für dieses Schadensbild stellte sich ein Kreuzgelenkbolzen der Fahrwerksspindel heraus. Um das Problem zu beseitigen, wurde der Bolzen größer dimensioniert und an allen Flugzeugen des Typs getauscht.Ein weiterer Schwachpunkt sind die Trudeleigenschaften der P.149. Das Flugzeug ist zwar schwer ins Trudeln zu bringen, muss aber, einmal ins Trudeln gebracht, innerhalb weniger Trudelumdrehungen wieder ausgeleitet werden. Wird das Trudeln nicht zügig beendet, neigt die P.149 dazu, in das Flachtrudeln überzugehen, aus dem sich das Flugzeug kaum wieder herausbringen lässt. Diesem Schwachpunkt wurde mit genauen Symmetrievermessungen und gegebenenfalls Einstellung begegnet, was die Neigung zum Flachtrudeln erheblich verminderte.Der Flugzeugtyp gilt heute als Flugzeug mit einem gutmütigen Flugverhalten und technisch als zuverlässig.
Die Grundversion der P.149 wurde entsprechend den Wünschen der Auftraggeber modifiziert und mit einem zugehörigen Kennbuchstaben versehen. Zu den Versionen gehörten die P.149D als Version für die deutsche Bundeswehr, die P.149E, für die schweizerische Luftverkehrsschule und die P.149U für die ugandische Luftwaffe.
Eine Sonderrolle nimmt die FWP.149D ein, bei der es sich um einen deutschen Lizenzbau der P.149D handelt. Siehe dazu auch Abschnitt: Bauzeit, Produktionsstätten und Stückzahlen.
Im Jahre 1954 gewann Adolf Galland mit seinem Kopiloten Eduard Neumann den italienischen Flugwettbewerb Giro Aereo d’Italia auf einer P.149. Zu diesem Zeitpunkt war Galland gerade aus Argentinien zurückgekehrt und für deutsche Luftfahrtunternehmen tätig geworden. Es ist daher naheliegend, dass der Sieg bei diesem Wettbewerb und Gallands Tätigkeiten einen direkten Einfluss auf die Entscheidung der Bundeswehr hatte, die P.149 als neues Schul- und Verbindungsflugzeug zu wählen.
Die P.149 wurde in ihren verschiedenen Versionen vor allem zur Anfängerschulung und als Verbindungsflugzeug eingesetzt. Dies umfasste sowohl zivile, als auch militärische Nutzung in verschiedenen Nationen.
Die private Nutzung des Flugzeugs war und ist eher selten, da die Betriebskosten der P.149 deutlich über dem Niveau von in Deutschland üblichen Sportflugzeugen, wie zum Beispiel einer Robin DR 400 oder einer Cessna 172, liegen. Dennoch befinden sich heute noch viele P.149 in Deutschland in privater Hand und werden auch geflogen.
Bei der Suche nach einem geeigneten Schulflugzeug für die Bundeswehr setzte sich die P.149 im Jahre 1956/57 in einem Vergleichsfliegen gegen die Saab 91 Safir und die Beechcraft T-34, eine militärische Variante der Beechcraft Bonanza, durch. Es ist heute davon auszugehen, dass die P.149 sich gegenüber den Vergleichsmustern unter anderem wegen des großen Platzangebots durchsetzen konnte, da das Flugzeug bei der Marine und bei der Luftwaffe auch als Verbindungsflugzeug eingesetzt werden sollte. Im Mai 1957 lieferte Piaggio das erste von 72 georderten Flugzeugen an die Luftwaffe aus. Wenigstens 190 Flugzeuge wurden bei Focke-Wulf in Bremen in Lizenz gefertigt.Die Flugzeugführerschule „S“ (FFS„S“), die ab 1978 in das Lufttransportgeschwader 62 überging, war die erste Nutzereinheit der P.149 in der Bundeswehr. Die angehenden Flugzeugführer hatten zum Zeitpunkt des Eintretens in die FFS"S" bereits ein Auswahlverfahren hinter sich gebracht und erhielten nun 120 Flugstunden auf der P.149. Bei den Flugstunden handelte es sich zunächst um eine Einweisung auf das Muster, auf die Kunstflug, Tagnavigationsflüge, Instrumentenflüge, Nachtflüge, Überlandflüge und Schlechtwetterflüge folgten. Danach fanden die Schulungsflüge in einem Prüfungsflug ihren Abschluss.Bis zum März 1959 wurden die Ausbildungsgruppen der FFS"S", die bis dahin auf dem Flugplatz Memmingen stationiert waren, auf verschiedene Flugplätze verteilt, zu denen auch der Fliegerhorst Diepholz gehörte. Dort studierten vier Fluglehrer ein Kunstflugprogramm für die Öffentlichkeit ein. Im Rahmen der Vorführungen fanden zunächst Verbands- und Formationsflüge mit vier P.149 statt, danach eine Solovorführung mit einer metallisch blank polierten P.149 aus der Formation. Nachdem am 19. Juni 1962 vier Starfighter der Bundeswehr bei einer Übung für eine Flugvorführung über Nörvenich abstürzten und dabei vier Todesopfer zu beklagen waren, wurden in der Bundeswehr sämtliche Kunstflugaktivitäten untersagt – auch die mit der P.149.Ein weiterer Einsatzort der P.149 war ab dem 10. Mai 1961 das Fluganwärterregiment (FlAnwRgt) auf dem Fliegerhorst Uetersen. Das Fluganwärterregiment führte die Prüfungen der Fluganwärter bis dahin auf der Piper L18C durch. Hier wurden auch afrikanische Piloten im Zuge von Wirtschaftshilfe auf der P.149D geschult.Im Jahre 1963 tauschte die Flugdienststaffel der Technischen Schule der Luftwaffe 1 ihre bis dahin verwendeten Harvard Mk. IV gegen die Piaggio P.149. Die Aufgabe der P.149 bestand bei dieser Flugdienststaffel darin, Ziele für Trainingszwecke von Fernmeldepersonal darzustellen.
Auch die Marine verwendete zwölf Maschinen des Typs P.149. Diese wurden bei der Marine-Dienst- und Seenotstaffel, beziehungsweise dem Marinefliegergeschwader 2 und Marinefliegergeschwader 3 eingesetzt.Das Flugzeug wurde an vielen weiteren Einsatzorten der Bundeswehr geflogen und zog mit seinen Staffeln regelmäßig um. Da viele Ausbildungsschritte der Bundeswehr in die Vereinigten Staaten verlagert oder anderweitig ausgelagert wurden, wurden die P.149 bereits ab 1972 von der Bundeswehr über die Vebeg GmbH veräußert. Beim Verkauf wurden Sportgruppen der Bundeswehr gegenüber privaten Interessenten bevorzugt behandelt. Im Rahmen von Wirtschaftshilfe erhielten auch Nigeria und Uganda Flugzeuge dieses Typs von der Bundeswehr.Am 31. März 1990 wurde die P.149 bei der Bundeswehr offiziell außer Dienst gestellt. Zu diesem Zeitpunkt war sie das älteste Flugzeug der Luftwaffe.
In den 1960er-Jahren unterstützte Israel mehrere afrikanische Staaten, zu denen auch Uganda gehörte, beim Aufbau ihrer Luftwaffen. Im Jahre 1968 endete die Kooperation mit Uganda, das im Zuge des Aufbaus der Luftwaffe einige P.149 angeschafft hatte. Mit Beendigung der Kooperation wurden vier ugandische P.149 nach Israel verkauft. Dort dienten sie als leichte Transport- und Verbindungsflugzeuge, behielten die ugandische Lackierung, trugen aber israelische Hoheitszeichen. Im Jahre 1971 stellte die israelische Luftwaffe die P.149 außer Dienst. Eines der vier Flugzeuge war zu diesem Zeitpunkt bereits durch einen Unfall zerstört worden, die verbliebenen Exemplare wurden nach Übersee verkauft.
Im Jahre 1962 stimmte die nigerianische Nationalversammlung dem Aufbau einer landeseigenen Luftwaffe zu. Am Aufbau waren diverse Staaten beteiligt, vor allem aber die Bundesrepublik Deutschland, die 1963 den Vertrag zum Aufbau der nigerianischen Luftwaffe unterzeichnete. Neben Personal, Ausbildung und Material gehörten auch 14 Piaggio P.149D für die Anfängerschulung zum Vertragsumfang.
Die Luftwaffe dieses Landes erhielt 1965 im Rahmen eines Kooperationsprogramms mit der Bundesrepublik Deutschland acht Flugzeuge des Typs P.149.
Die Luftwaffe von Uganda erhielt drei Flugzeuge mit der Bezeichnung P.149U, die eine militärische Abwandlung der P.149 war. Außerdem gab es Flugzeuglieferungen der Bundesrepublik Deutschland im Rahmen von Wirtschaftshilfen an Uganda. Wie viele Flugzeuge im Rahmen dieser Wirtschaftshilfe geliefert wurden und ob es sich dabei um die drei Flugzeuge mit der Bezeichnung P.149U handelte, bleibt dabei offen.
Die Schweizerische Luftverkehrsschule (SLS) suchte am Ende der 1950er- bzw. Anfang der 1960er-Jahre nach einem neuen Standardschulflugzeug. Aus der Überprüfung verschiedener Muster durch erfahrene Fluglehrer ging die P.149 als Sieger nach Punkten hervor, woraufhin die SLS bei Piaggio mehrere Flugzeuge bestellte. Am 20. April 1961 wurde die erste von fünf P.149E aus Italien in die Schweiz überführt. Bis zum 23. September 1965 waren alle in Italien bestellten Flugzeuge geliefert. Zwischen 1970 und 1991 wurden sieben weitere Flugzeuge des Musters P.149D von Focke-Wulf an die SLS geliefert. Die SLS setzte das Muster als Standardschulflugzeug für die Piloten der Swissair ein. Die letzten bei der SLS im Betrieb befindlichen P.149 wurden 1997 ausgemustert.
Im Folgenden werden die militärischen Zwischenfälle in der Einsatzzeit der P.149D bei der Bundeswehr gelistet, soweit sie bekannt sind. Dabei sollte es nicht verwirren, wenn in der Auflistung auch zivile Luftfahrzeugkennzeichen erscheinen, da die Schulungsmaschinen teilweise bei der Verkehrsfliegerschule der Lufthansa zugelassen waren.
Am 25. Juli 1958 wurden bei einer Notlandung mit der AS+464 bei Wüstenbruck nahe Ansbach zwei Luftfahrzeugführer leicht verletzt.
Am 5. September 1958 hatte die BA+394 eine folgenschwere Bodenberührung, bei der der Luftfahrzeugführer getötet und drei Passagiere verletzt wurden.
Am 30. Juni 1959 verunglückte die BA+391 im Manyas-See in der Türkei. Dabei wurden drei Personen leicht verletzt.
Am 14. Juli 1960 verunglückte die AS+424 bei Diepholz, wobei zwei Luftfahrzeugführer schwer verletzt wurden.
Am 18. Januar 1962 starben zwei junge Flugzeugführer in der JC+389 infolge einer Baumberührung am Dörenberg bei Bad Iburg.
Am 16. Januar 1968 kollidierte die D-EJCO in der Nähe des Flughafens Bremen mit einer Lockheed C-140. Die beiden Flugzeugführer der P.149D kamen bei dem Unfall ums Leben. Die C-140 konnte in Bremen notlanden.
Am 8. Mai 1968 kollidierten zwei P.149D bei Tutzing. Der Flugzeugführer der 91+06 verunglückte dabei tödlich, während die 91+67 auf einem Feld notlanden konnte und die Insassen verletzt wurden.
Am 9. Mai 1969 kollidierte die 91+97 bei Filmaufnahmen mit einem Lastfallschirm, der bei Forstwiesen aus einer Transall C-160 abgesetzt wurde. Der Luftfahrzeugführer und zwei Kameramänner kamen ums Leben.
Am 19. April 1970 stürzte die 90+61 bei Karlsruhe nach einer Baumberührung ab. Die beiden Luftfahrzeugführer und der Redakteur einer Lokalzeitung kamen dabei ums Leben.
Am 1. Juli 1970 stürzte die 92+26 in Rudingshain im Vogelsberg ab. Ein Insasse wurde getötet, zwei weitere verletzt.
Am 27. April 2008 kamen beide Insassen einer P.149D beim Landeanflug auf den Sonderlandeplatz Torgau-Beilrode ums Leben, nachdem das Flugzeug im Bereich des linken Queranflugs aus geringer Höhe nach links abgekippt war. Zuvor nahmen Zeugen unregelmäßigen Motorlauf des Flugzeugs wahr.
Die bei Focke-Wulf in Bremen in Lizenz gebauten Versionen FWP.149D weisen als eindeutiges Unterscheidungsmerkmal zu den italienischen Originalversionen der P.149 eine spezielle Vernietung am Rumpf auf. Hier wurden die Buchstaben „FWP“ ineinander verschachtelt in den Rumpf genietet. Die Buchstaben stehen für Focke-Wulf Piaggio.
In Pilotenkreisen hat das Flugzeug den Spitznamen „Pitschi“, wobei die Diktion des Spitznamens (Piggi) oft an den Herstellernamen angelehnt ist. Bei der Aussprache von „Pitschi“ wird das „t“ meist weich, und das „sch“ meist stimmhaft gesprochen (Pidji). Je nach Quelle variieren die Schreibweisen teils erheblich.
Mit der Piaggio P.149 lässt sich die Jakowlew Jak-18T vergleichen. Sie ist neben der P.149 eines der wenigen viersitzigen voll kunstflugtauglichen Flugzeuge. Auch das Alter, die Triebwerksleistungen und die Gesamtauslegung mit einziehbarem Bugfahrwerk und Sitzplatzanordnung sind vergleichbar. Ein nennenswerter Unterschied besteht in der Reisegeschwindigkeit, die bei der P.149 deutlich höher liegt. Die Jak-18T weist im Gegenzug eine deutlich kürzere Start- und Landestrecke auf.
Ebenfalls wird die Pilatus P-3 gerne als Vergleichsmuster herangezogen. Die P-3 gleicht der P.149 sowohl im Erscheinungsbild als auch in der Grundkonzeption als freitragender Tiefdecker mit einziehbarem Bugfahrwerk. Signifikantester Unterschied ist die Anzahl und Anordnung der Sitzplätze. Während die Piaggio P.149 durch ihre vier Sitzplätze auch als Verbindungsflugzeug herangezogen wurde, diente die Pilatus P-3 als Zweisitzer mit hintereinander angeordneten Sitzen vor allem als Schulflugzeug für zukünftige Piloten von Kampfflugzeugen mit Strahltriebwerk.

Picket Fences – Tatort Gartenzaun (Originaltitel: Picket Fences, auf deutsch: Lattenzäune) ist eine US-amerikanische dramatische Fernsehserie. Zwischen 1992 und 1996 entstanden in vier Staffeln 88 Episoden, die in den Vereinigten Staaten durch CBS und in Deutschland ab 1995 durch Sat.1 erstausgestrahlt wurden. David E. Kelley hatte die Idee zu der Serie und verfasste auch den Großteil der Drehbücher der ersten drei Staffeln. Auch beeinflusst durch Twin Peaks, spielt sie in einer fiktiven US-Kleinstadt, die als Kulisse für öffentliche und private Probleme des zeitgenössischen Amerika dient. Dabei behandelt sie von Kritikern als provokativ wahrgenommene, ethisch-moralische Fragestellungen bezüglich Sexualität, Religion, gesellschaftlicher Minderheiten und anderer Themen aus konträren Blickwinkeln. Charakteristisch für die Serie sind skurrile Verbrechensarten, vor Gericht ausgefochtene Streitigkeiten und schwarzhumorige Situationen. Die wichtigsten Hauptrollen spielen Tom Skerritt und Kathy Baker. Picket Fences ist eine vor allem hinsichtlich der schauspielerischen Leistungen vielfach preisgekrönte Serie und wurde neben 14 Primetime Emmy Awards mit weiteren renommierten Fernsehpreisen ausgezeichnet. In ihrem Ursprungsland nahmen Einschaltquoten und Zuspruch vonseiten der Kritik im Laufe ihrer Erstausstrahlungszeit zu.
Picket Fences wurde hauptsächlich den Genres Drama, Courtroom Drama (auf Deutsch etwa: „Gerichtssaal-Drama“), Polizei- und Krimiserie, Familienserie und – wegen schwarzhumoriger Elemente – Comedy zugeordnet. Typisch für Serien von David E. Kelley, gibt es überdies etliche Elemente der Krankenhausserie. Für den Journalisten Harald Keller ist die Serie eine „gefällige Verknüpfung von leichthin unterhaltenden Elementen mit Problemthemen in einer Form, die oftmals einer Mischung aus Tragikomödie, Musterprozeß und brechtischem Lehrstück gleicht“.Die meisten Episoden beinhalten einen Haupthandlungsstrang und einen oder zwei thematisch damit verknüpfte Nebenhandlungsstränge. Während es in den ersten beiden Staffeln hauptsächlich Episoden mit abgeschlossenen Geschichten gibt, gibt es in der dritten Staffel zwei wichtige, mehrere Episoden umfassende Handlungsstränge.
Die Serie spielt in der fiktiven Stadt Rome im US-Bundesstaat Wisconsin. Rome ist eine überwiegend von Weißen bewohnte, circa 30.000 Einwohner zählende Kleinstadt. Häufige Schauplätze innerhalb der Stadt sind das Polizeirevier, das Gerichtsgebäude mit dem fiktiven Namen Hogan County Courthouse und das Wohnhaus der Familie Brock.
Am Beginn vieler Episoden steht die Entdeckung eines Verbrechens bzw. die Feststellung eines vermeintlichen Straftatbestandes. Oft folgen die Ermittlungsarbeit der Polizei und die Vernehmung von Beschuldigten und Zeugen. Häufig werfen die thematisierten Fälle ethisch-moralische Fragen auf, die sowohl innerhalb der Familie Brock als auch von der Polizei und vor dem Gericht kontrovers diskutiert bzw. verhandelt werden. Viele Episoden enden mit dem Urteilsspruch des Richters oder der Jury.
Zu den kontroversen Fragestellungen gehört etwa, inwiefern Selbstverteidigung als Selbstjustiz zu beurteilen ist; ob ein verurteilter Triebtäter wieder Teil der Gesellschaft werden darf; ob ein HIV-positiver Arzt weiterhin praktizieren darf; oder inwiefern Kleinwüchsigkeit einen Nachteil für die Persönlichkeitsentwicklung darstellt. Die Rechte anderer gesellschaftlicher Minderheiten, etwa von Obdachlosen, werden auch behandelt. Ebenfalls wird Gewalt verschiedener Arten thematisiert, darunter häusliche und fiktionale Gewalt. Um letztere etwa geht es bei der Frage, inwieweit Gewaltdarstellungen in Medien für eine Schießerei unter Schülern verantwortlich sind.
Wiederholt thematisiert werden medizinethische Fragen. So etwa geht es um die Rechtmäßigkeit der Verwendung von Fötalgewebe zur Lebensrettung, um Abtreibungen oder um die Legalität von Organspenden und von Kryonik. Sterbehilfe ist auch ein Thema mehrerer Episoden. Als etwa Dr. Jill Brock einem todkranken Patienten auf dessen Wunsch medikamentös beim Sterben hilft, wird sie nach einer kontroversen Diskussion und unter Verweis auf das Gesetz gegen Sterbehilfe zunächst für schuldig befunden; nach einer Verfassungsbeschwerde ihrer Rechtsanwälte gegen jenes Gesetz aber wieder freigesprochen.
Nicht selten stehen medizinbezogenene Fragen in der Serie in Zusammenhang mit religiösen Überzeugungen. In der Episode In Gottes Hand (Staffel 2) zum Beispiel wird die Frage aufgeworfen, ob der Mann eines Pärchens, das zu den Christlichen Wissenschaftlern gehört, den Ärzten das Einleiten lebensverlängernder Maßnahmen verbieten darf, wenn diese im Widerspruch zu der Religion stehen. In anderen, religionsbezogenen Episoden geht es um die Trennung von Kirche und Staat, um Stigmatisation oder um eine Geburt trotz Jungfräulichkeit der Mutter.
Die dritte Staffel erzählt auch zwei Geschichten, die sich über mehr als zwei Episoden erstrecken. Dazu gehört eine gerichtliche Auseinandersetzung um einen Mord, die sich auch um die Frage dreht, inwieweit der Angeklagte bei seiner Aussage in Polizeigewahrsam auf sein Recht auf anwaltlichen Beistand verzichtet hat. Im Rahmen dieses Falles wird auch die Berufungsverhandlung vor dem Obersten Bundesgericht geschildert. In dem anderen Handlungsstrang jener Staffel geht es um die Integration farbiger Schüler aus einer von Jugendkriminalität geprägten Großstadt in das schulische Leben von Rome. Die Vertreter Romes wehren sich zunächst gegen jene Schülerverlegung, auch durch Drohung mit Schusswaffen, müssen die entsprechende Anordnung eines schwarzen Bundesrichters dann aber akzeptieren.
In vielen Episoden der vierten, der letzten, Staffel stehen die persönlichen Beziehungen und Liebschaften der Hauptfiguren im Fokus. Gerichtsverhandlungen gibt es seltener; dazu gehört auch ein Mordprozess, in dem Papst Johannes Paul II. als Hauptbelastungszeuge gegen einen homosexuellen Angeklagten aussagt und von der Verteidigung deshalb als voreingenommen beschuldigt wird. Ein anderer Mordprozess, in dem ein Jude des Mordes an einem Nazi-Anhänger angeklagt ist, wird von demonstrierenden Neonazis, die mit Hakenkreuzarmbinden der Verhandlung beiwohnen, und Juden begleitet.
Bestandteile der Geschichten sind oftmals ungewöhnliche Todesarten oder Leichname in außergewöhnlichem Zustand. Zum Beispiel wird ein toter Mensch in einer Geschirrspülmaschine oder erfroren in einer Gefriertruhe aufgefunden. Ein anderes Mal hat eine Frau die obere Hälfte ihres ungeliebten Mannes mit einer Dampfwalze zerquetscht. Es gibt weitere groteske Aspekte, die in der Serie vorkommen. So etwa kommt ein kleinwüchsiger Zirkusmitarbeiter auf einem Zirkuselefanten nach Rome geritten. Bei der Bergung der gefrorenen Leiche des Bürgermeisters bricht der Kopf ab und kullert bis vor die Füße des Sheriffs. Unerwartete Wendungen in der Handlung bzw. der Aufklärung von Kriminalfällen sind nicht selten. Beispielsweise gibt eine Frau, die gegen ihren mordverdächtigen Mann aussagen soll, im Zeugenstand den Mord plötzlich selbst zu.
Der etwa 50 Jahre alte Jimmy Brock ist der Sheriff von Rome und im Gegensatz zu seiner Frau und seinen Kindern Agnostiker. Er ist in zweiter Ehe mit Dr. Jill Brock verheiratet, einer Hausärztin, die manchmal auch als Chirurgin und Notärztin arbeitet. Mitunter sind sie auch im Schulausschuss oder im Stadtrat tätig. Oft sind sie bezüglich der vor Gericht verhandelten Fälle unterschiedlicher Meinung. Zusammen haben sie die pubertierenden Söhne, den älteren Matthew und den jüngeren Zachary. Sie sind oft an jugendlichem Schabernack beteiligt, so etwa am Schießen per Kartoffelkanone auf Menschen. Zachary geht ab der zweiten Staffel seinem Wunsch nach, ebenso wie sein Vorbild, dem Rechtsanwalt Wambaugh, Jude zu werden. Bis zur dritten Staffel mit in ihrem Haus lebt die jugendliche Kimberly Brock, Jimmys Tochter aus erster Ehe. Kimberly ist selbstsicher und direkt, mitunter auch rebellisch. Wenn es um das Erklären von Sachverhalten wie etwa dem religiösen Glauben geht, ist sie für ihre beiden Halbbrüder eine Ersatzmutter. In der zweiten und dritten Staffel arbeitet sie außerschulisch als Assistentin für Wambaugh, in der vierten studiert sie Medizin.
Mit im Polizeirevier arbeiten die Deputys Kenny Lacos und Maxine Stewart. In manchen Nebenhandlungssträngen geht es um ihre Liebschaften, teils zu anderen Partnern, teils zueinander. Ginny Weedon ist eine ältere, nur 1,30 m große Frau, die in den ersten beiden Staffeln im Rezeptionsdienst des Polizeireviers arbeitet. Sie ist sehr neugierig und lauscht gern an geschlossenen Türen. Sie wird früh in der dritten Staffel erfroren in ihrer Tielkühltruhe entdeckt, in die sie wohl beim Griff nach einer Konservendose versehentlich gestürzt ist.
Carter Pike ist der Coroner von Rome und hilft der Polizei öfters auch kriminalistisch, wobei ihn der Sheriff nicht selten als übereifrig empfindet. Unter den Einwohnern von Rome steht er unter dem Verdacht, nekrophil zu sein. Er ist zwischen 35 und 40 Jahren alt und versucht mehrfach, seinem Junggesellendasein ein Ende zu setzen. Wegen mangelnden, diesbezüglichen Erfolges versucht er zu Beginn der vierten Staffel verzweifelt, aber erfolglos, Suizid. Um endlich Vater zu werden, nimmt er in der dritten Staffel eine Leihmutter in Anspruch, die die Schwangerschaft aber trotz seines Widerspruchs wieder abbricht. In der vierten Staffel lernt er seine künftige Ehefrau Sue kennen.
Douglas Wambaugh ist ein jüdischer Rechtsanwalt im Alter von Anfang 70, der oft als Pflichtverteidiger auftritt. Die Frage, ob seine Mandanten schuldig sind, will er von ihnen meist gar nicht beantwortet haben. Er schafft es manchmal, selbst mit absurden Argumenten Prozesse zu gewinnen, und ist Argumenten und Scherzen, die auf Kosten anderer Personen gehen, nicht abgeneigt. In manchen Gerichtsverhandlungen wirft er der Anklagevertretung plötzlich vor, ihm nur zu widersprechen, weil er Jude sei, und wird danach vom Richter gemaßregelt. Den Richter wie auch sich selbst würdigt er gern als „Original“. Bei Trauerfeiern und anderen gesellschaftlichen Veranstaltungen ist Wambaugh oft der einzige, der eine Rede hält, oder der erste, der eine Unterhaltung beginnt. Mit der Begründung, dass er mit geschmacklosen Bemerkungen antisemitische Vorurteile fördere, möchte ihn der Rabbi in der zweiten Staffel sogar aus seiner Gemeinde ausschließen, jedoch erfolglos. In der dritten Staffel erfährt er, dass er an Multipler Sklerose erkrankt ist; anfangs der vierten lässt sich seine Ehefrau von ihm scheiden, weil er seinen ehelichen Pflichten nicht nachgekommen ist. Ein seltener in der Serie auftretender Rechtsanwalt ist Franklin Dell.
Als Staatsanwalt ist zu Beginn der ersten Staffel Barnaby Woods tätig. Bald stellt sich heraus, dass er der geheimnisvolle Gast ist, der in den Badewannen fremder Häuser badet. Als solcher stirbt er schließlich an Streuströmen. Ab der zweiten Staffel tritt als Staatsanwalt und Gegner Wambaughs in vielen Gerichtsprozessen John Littleton auf, der ab der dritten Staffel zu den Hauptfiguren gehört und unter ihnen der einzige Schwarze ist. Nach dem Tod seines Bruders gibt er seinen Job früh in der vierten Staffel auf.
Henry Bone ist der Richter, der die in Rome verhandelten Gerichtsprozesse leitet. Bezüglich mancher Urteile, die er fällt, wird deutlich, wie schwer ihm die Entscheidungsfindung gefallen ist, und dass es für ihn eine Qual der Wahl war. Ansprachen und Diskussionen beendet er wegen der von ihm wahrgenommenen Absurdität mancher Argumente oft genervt mit der Aufforderung „Und jetzt raus hier!“ In der vierten Staffel hat er einen Herzinfarkt.
Teilweise wird auch deutlich, dass Bone bei seinen Urteilen auf Gott vertraut. Deshalb ist er besonders schockiert, als am Ende der dritten Staffel sein Vorbild Gary Barrett, der der Priester der römisch-katholischen Gemeinde Romes ist, stirbt. Barrett wird, im Beichtstuhl sitzend, von einem spielsüchtigen Jugendlichen erschossen, weil er ihm sein Geld nicht aushändigen wollte. Über Barrett wurde in der zweiten Staffel öffentlich bekannt, dass er ein Damenschuh-Fetischist ist. Nach seiner Ankündigung, sich deshalb in psychiatrische Behandlung zu begeben, erlaubte es ihm seine Gemeinde, sein Amt zu behalten. Der andere Pfarrer, der als wiederkehrende Nebenfigur zu sehen ist, ist Henry Novotny, Pfarrer der Episkopalkirche.
Den Serienabschluss bildet die Hochzeit dreier Pärchen: Carter Pike und Sue, Kenny Lacos und Maxine Stewart sowie Douglas Wambaugh und seine Exfrau Myriam.
Etliche, in der Serie erzählte Geschichten werden auch aus der Sicht des Bürgermeisters von Rome betrachtet. Im Amt des Bürgermeisters gibt es häufige Wechsel, welche nicht selten durch den plötzlichen, seltsamen Tod des Amtsinhabers nötig werden.
Zu Serienbeginn ist Bill Pugen Bürgermeister der Stadt. Er gewinnt seine Wiederwahl unter anderem gegen Wambaugh, der ihn im Wahlkampf wegen seines Übergewichts diskreditiert. Kurz nach Beginn der zweiten Staffel stirbt er an einer Todesursache, welche in der Handlung mit spontaner menschlicher Selbstentzündung erklärt wird. Seine Amtsnachfolgerin wird die Dessous-Geschäftsinhaberin Rachel Harris. Als ein Jahrzehnte altes Porno-Video mit ihr öffentlich bekannt wird, verliert sie auf einen Stadtratsbeschluss hin ihr Amt. Dieses erhält noch in derselben Staffel kommissarisch das älteste Ratsmitglied Howard Buss, der in der ersten Staffel erfahren hatte, dass er an Alzheimer erkrankt ist. Während seiner Amtszeit verstärkt sich seine Demenz weiter. Um sich von der Aufregung zu beruhigen, die das Amt mit sich bringt, hat er einen Teddybär und ein Schaukelpferd in seinem Amtszimmer, welche er auch, bekleidet nur mit Indianerschmuck und Windeln, benutzt. Sein Sohn leistet ihm ungebeten Sterbehilfe und schießt auf ihn, um ihn von seiner zunehmenden Entwürdigung zu erlösen. Nach Howards Tod am Ende der zweiten Staffel hat übergangsweise Jill Brock das Amt inne.
Die nächste Bürgermeisterwahl gewinnt der populistische Postbote Ed Lawson äußerst knapp gegen Carter Pike. Lawson wird aber noch in derselben Staffel wegen mangelnder Erfüllung seiner Ehepflichten von seiner Frau ermordet, die trotzdem vom Anklagepunkt wegen Mordes freigesprochen wird. Wegen fehlender anderer, geeigneter Kandidaten und erneut übergangsweise übernimmt daraufhin – gegen Ende der dritten Staffel – Laurie Bey das Amt. Sie ist fast taubstumm und kommuniziert deshalb meist in Gebärdensprache und mit einer Dolmetscherin. Vor ihrem Amtsantritt wurde sie als „Tanzende Diebin“ bekannt und verhaftet, als welche sie – ähnlich wie Robin Hood – von den Reichen stahl, um den Armen zu helfen, und dabei einen Tanz aufführte. In ihrer Amtszeit trägt sie als Leihmutter das Baby zweier homosexueller Männer aus, darunter ihr Bruder. Dabei wird sie als Bürgermeisterin von Maxine Stewart vertreten, die in Folge einer kontroversen Entscheidung prompt angeschossen wird.
Der studierte Rechtsanwalt David E. Kelley gelangte in der Mitte der 1980er Jahre erstmals ins Fernsehgeschäft, als ihn Steven Bochco als Drehbuchautor und Story Editor für die von Bochco erschaffene Anwaltsfernsehserie L.A. Law – Staranwälte, Tricks, Prozesse engagierte. Bei mehr als der Hälfte der Episoden der ersten fünf Staffeln war Kelley maßgeblich am Verfassen des Drehbuchs beteiligt. Kritiker schrieben ihm zu, die Serie, die mehrere Emmys gewann, so erfolgreich gemacht zu haben. Nachdem er die Serie 1991 verlassen hatte, suchte er nach einem Käufer für seine eigene, Picket Fences betitelte Serie und fand ihn im Network CBS. Der daraufhin zwischen den beiden Parteien geschlossene Vertrag beinhaltete auch die Produktion zweier weiterer, von Kelley zu erschaffender Fernsehserien. Picket Fences startete im September 1992.Das Konzept zur Serie gleicht hinsichtlich dem Schauplatz – eine Kleinstadt, in der merkwürdige Dinge geschehen – den Konzepten der bereits 1990 gestarteten US-Fernsehserien Twin Peaks und Ausgerechnet Alaska. Kelley gab zu, dass Picket Fences von diesen Serien beeinflusst wurde.In einem Interview mit der New York Times während der US-Erstausstrahlung der zweiten Staffel äußerte sich Kelley begeistert über die künstlerische Freiheit, die ihm vonseiten CBS bei der Arbeit an Picket Fences gewährt wurde.Bei den meisten Fernsehserien kommen wechselnde Drehbuchautoren bzw. Teams aus Drehbuchautoren zum Einsatz. Bei Picket Fences hingegen schrieb Kelley die Drehbücher nahezu aller Episoden der ersten drei Staffeln alleine oder zusammen mit Koautoren. Nach der zweiten Staffel und dem Drängen von CBS, eine weitere der vereinbarten drei Fernsehserien zu produzieren, widmete sich Kelley zugleich auch der Koordination und den Drehbüchern der von ihm erschaffenen Fernsehserie Chicago Hope – Endstation Hoffnung (produziert von 1994 bis 2000). Die Doppelbelastung war ihm zu hoch, sodass er sich nach der dritten Staffel als Drehbuchautor bei Picket Fences weitgehend zurückzog und selbst nur noch für zwei Episoden der vierten Staffel das Drehbuch lieferte. Bei Picket Fences ersetzte ihn ein Ensemble aus anderen, oft wechselnden Drehbuchautoren, die das Gerichtsformat der Serie zu einem großen Teil verwarfen und den Fokus auf die persönlichen Probleme der Figuren lenkten.Zwischen Picket Fences und Chicago Hope gab es in der Fernsehsaison 1994/95 in jeder der beiden Serien eine Episode, die ein Crossover mit der anderen Serie darstellt. Beide Serien spielen somit im selben fiktiven Universum. Bei den Episoden handelt es sich um Denn sie wissen, was sie tun (Rebels With Cause, Staffel 3) aus Picket Fences und Kleine Opfer (Small Sacrifices, Staffel 1) aus Chicago Hope. Die Figur Wambaugh ist in der ersten Episode als Patient im Krankenhaus Chicago Hope und in der zweiten, etwa zwei Monate später erstausgestrahlten Episode als Anwalt in dem Krankenhaus.
Zu den Produzenten der Serie gehörte auch Robert Breech. Er war – wie schon bei L.A. Law – für die juristischen Aspekte in den Episoden zuständig. Eine weitere Produzentin war Ann Donahue, zumindest in den ersten beiden Staffeln.
Die Kulissen für die Kleinstadt Rome entstanden in einem Filmstudio von 20th Century Fox in Los Angeles.
Die beiden Hauptrollen des Ehepaares Brock wurden auf Kelleys Wunsch hin, dafür zwei etablierte Kinoschauspieler zu gewinnen, mit Tom Skerritt und Kathy Baker besetzt. Die übrigen Rollen gingen überwiegend an weniger bekannte Schauspieler. Dazu gehört auch Don Cheadle, für den seine Rolle als Staatsanwalt Littleton einen Popularitätsschub bedeutete. Er verließ die Serie früh in der vierten Staffel und erhielt danach Rollen in etlichen Kinofilmen. Ebenfalls durch Picket Fences bekannt wurde die damalige Jugendschauspielerin Holly Marie Combs, sie erhielt danach eine Hauptrolle in der Serie Charmed – Zauberhafte Hexen. Für den 1994 bereits 80 Jahre alt gewordenen Ray Walston, Darsteller des Richters Bone, war es hinsichtlich seines Abschneidens bei den Emmy Awards die erfolgreichste Station seiner Laufbahn.
Die deutsche Synchronfassung wurde von der Telesynchron in Berlin hergestellt. Dialogbuchautoren waren Bernd Eichner und Bodo Traber, Dialogregie führten Jürgen Kluckert und ebenfalls Eichner.Die Tabelle nennt die Schauspieler und ihre Rollennamen, ihre Zugehörigkeit zur Hauptbesetzung (●) bzw. zu den Neben- und Gastdarstellern (•) je Staffel, die Gesamtanzahl der Episoden mit Auftritten sowie die deutschen Synchronsprecher.
Den zweistündigen Pilotfilm strahlte CBS am Freitag, den 18. Dezember 1992, erstmals aus. Die folgenden Episoden der ersten Staffel wurden wöchentlich im Abendprogramm desselben Wochentags erstausgestrahlt, einem traditionell wenig zuschauerträchtigen Sendeplatz. Mit der Hoffnung auf eine Verbesserung der Einschaltquoten wechselte CBS den Sendeplatz der Serie für die letzten fünf Episoden der Staffel auf den Donnerstagabend, an dem Picket Fences parallel zu L.A. Law gesendet wurde. Die zweite Staffel begann erneut am Freitagabend, lediglich die zweite Episode wurde erneut Donnerstags gezeigt. Die Einschaltquoten der zweiten und dritten Staffel waren im Vergleich zu ihren Vorgängerstaffeln besser. Den Freitagabend-Sendeplatz hatte die Serie bis Februar 1996 inne. Bis dahin waren 15 Episoden der vierten Staffel erstausgestrahlt. CBS räumte wegen schlechter Einschaltquoten in der vierten Staffel den Sendeplatz für die neue Serie Nash Bridges und stellte Picket Fences ein. Drei Episoden, darunter die den Serienabschluss bildende, strahlte CBS im April 1996 erstmals aus. Die übrigen vier Episoden reichte der Sender erst nach Saisonende, im Juni, nach.
Die deutsche Synchronfassung der Serie strahlte Sat.1 ab 1995 aus. Den Pilotfilm zeigte der Privatsender im Hauptabendprogramm des 5. Januar 1995 erstmals. Die folgenden Episoden wurden ab 9. Januar 1995 im wöchentlichen Rhythmus abends erstausgestrahlt – bis zum 20. März 1995 Montags, ab dem 29. März 1995 Mittwochs. Bis zum 3. Januar 1996 hatte Sat.1 so alle Episoden bis zur sechsten Episode der dritten Staffel ausgestrahlt. Weitere 13 Episoden der dritten Staffel zeigte Sat.1 wöchentlich am Dienstagabend von November 1996 bis Februar 1997 erstmals. Alle restlichen Episoden der Serie liefen bei Sat.1 im werktäglichen Nachmittagsprogramm im Juli und August 1997 in Erstausstrahlung. Die Serie war für den Sender zumindest so erfolgreich, dass er sie – auch auf Zuschauerzuschriften hin – im Anschluss daran auf dem gleichen Sendeplatz noch einmal komplett wiederholte.
Im Juni 2007 veröffentlichte die Produktionsfirma 20th Century Fox im Regionalcode 1 für USA und Kanada die erste Staffel der Serie auf DVD. Weitere Staffeln wurden dort noch nicht veröffentlicht. Zwischen 2014 und 2016 erschienen alle vier Staffeln allerdings in Australien auf DVD.
Das deutsche Unternehmen Fernsehjuwelen veröffentlichte die Serie 2016 erstmals auf DVD. Die erste Staffel erschien am 15. April, die zweite Staffel am 8. Juli, die dritte und die vierte Staffel erschienen am 4. November.
Die fiktive Stadt Rome diente Kelley als Spiegelbild der US-Gesellschaft. Das Konzept der Serie zusammenfassend, sagte er, „sie handelt mehr als alles andere vom Leben in einer Gemeinschaft, vom Leben in der Familie, am Arbeitsplatz und in der Stadt, die eine Gemeinschaft ist“. Es ging ihm mit der Serie darum, sympathische Figuren mit ihren Scheinheiligkeiten und Vorurteilen zu konfrontieren. Die Figuren sollten ihrer eigenen Angst gegenüberstehen, sodass in den Geschichten moralisch-ethische Dilemmas ohne einfache Antworten aufgeworfen würden. Kelley betonte, dass die Serie keine besondere politische Ausrichtung verfolgt und sowohl konservative als auch liberale Standpunkte aufgezeigt habe.Mehrere Journalisten, darunter auch Harald Keller, schätzten die von der Serie angesprochenen Themen wie AIDS und Euthanasie als provokativ ein. Der Essay-Autor Douglas E. Abrams interpretierte die in der Serie erzählten Gerichtsprozesse als „national civics lesson“, auf Deutsch etwa als „nationalen Unterricht in Civic Education“.
Ein wesentliches Merkmal der Serie ist, dass sie Probleme aus unterschiedlichen, konträren Blickwinkeln betrachtet. Zum Beispiel wird in der Episode Der Besucher (Staffel 1) einerseits die US-Bundesregierung für das Verbieten potenziell lebensrettender Experimente mit fötalem Gewebe negativ kritisiert. Demgegenüber warnt darin aber auch eine Figur vor der Gefahr, dass Fötalgewebe Frauen aus Profitgier zu Abtreibungen ermutigen könnte. Tom Shales, Journalist der Washington Post, schrieb diesbezüglich, dass Kelley seiner Serie keine Moralpredigten gebe. Ähnlicher Meinung war auch der US-Medienhistoriker Robert Thompson. Die Serie würde Probleme in doppelbödiger Weise und nicht moralisierend aufzeigen. Die Betrachtung von Problemen aus unterschiedlichen Blickwinkeln hätte Picket Fences zudem zur ersten „post-politically correct television series“ der Hauptsendezeit gemacht, auf Deutsch etwa zur ersten Primetime-Fernsehserie, die über politische Korrektheit hinaus gehe. Beispielhaft dafür sei die Episode Anstandsregeln (Staffel 2) mit dem Thema sexuelle Belästigung. Darin ist Kimberly Brock wütend auf ihren Jugendfreund, der sie nach erfolgreichem Belegen eines Seminars über sexuelle Korrektheit jedes Mal fragt, ob er sie küssen oder berühren darf.
Entsprechend dem US-Wissenschaftler Robert Thompson wird an zahlreichen Episoden zumindest der ersten beiden Staffeln der Einfluss von Twin Peaks deutlich. Zum Beispiel wird in einer Episode von Picket Fences eine Frau durch Einsperren in ihre Geschirrspülmaschine ermordet und zusammen mit ihrem Lieblingsgeschirr in den Spülgang geschickt; in einer anderen Episode summen Nonnen beim Durchführen von Sterbehilfe die Melodie von Killing Me Softly. Die Figur Carter Pike sei wie „Quincy with a genital fixation“ (Deutsch etwa: „Quincy mit genitaler Fixierung“), weil Pike stets eine Begründung dafür finde, die intimen Teile von Leichnamen zu untersuchen.Thompson befand allerdings weiterhin, dass die Serie Picket Fences ihre verrückten Elemente „in den Dienst von soliden, linearen Geschichten über ernste Probleme“ gestellt habe, wohingegen Twin Peaks gegen Ende zu wenig mehr als einer Serie über ihre eigene Verrücktheit geworden sei.
Anlässlich des Beginns der Erstausstrahlung waren die Kritiken in den Vereinigten Staaten gespalten. Tom Shales von der Washington Post etwa befand die Serie einerseits für „häufig einnehmend, originell, gut gespielt und beißend komisch“, hingegen wirkten „manche Ungeheuerlichkeiten“ wie der Fund einer Leiche in einem Geschirrspüler „selbstgefällig, überflüssig und schlicht durchschnittlich“. Ken Tucker, Autor des US-Magazins Entertainment Weekly, gab sich zufrieden mit den Szenen, die im Haus der Brocks spielen; hier habe die Serie ihren eigenen Rhythmus und einen frischen Blickwinkel auf das Familienleben. Hingegen werde sie zur „Show für Twin-Peaks-Freaks“, sobald das Polizeirevier zum Schauplatz werde, etwa weil die „orakelhafte Klugheit“ der Figur Ginny Weedon unverständlich sei, ohne Weedons Vergangenheit und Hintergrund zu kennen. Picket Fences versuche freilich, eine angenehmere, leisere Art von Twin Peaks zu sein, jedoch bewege die von der Serie angestrebte lockere, paradoxe Laune eher zum Ab- als zum Anschalten.Wenige Wochen, bevor die erste Staffel 1993 im Fernsehen zu Ende ging, meinte der Journalist John J. O’Connor in der New York Times anerkennend, dass die Serie nun – im Gegensatz zu ihrem Beginn, als sie zu sehr versucht habe, anders zu sein – bedeutendere Probleme behandele und es verstehe, mutig, berührend und reizvoll zu sein. An der Serie zeige sich, dass Kelley ein talentierter Autor sei. Ken Tucker von Entertainment Weekly war hingegen auch zur Mitte der Erstausstrahlung der zweiten Staffel nicht besonders angetan von der Serie: Etwa, dass „ernsthafte Kontroversen unter langweiligen und ärgerlichen Reden erdrückt“ würden, suggeriere in Verbindung mit den niedrigen Einschaltquoten und der Überhäufung mit Preisen, dass die Serie „den Triumph des Normalverbraucher-Intellektualismus“ im Fernsehen repräsentiere.Variety-Autor Todd Everett schrieb im März 1995, dass es sich bei Picket Fences um eine der lustigsten Serien im Fernsehen handele und dass Kelley es verstehe, beide Seiten eines kontroversen Themas zu beleuchten. Ähnlicher Meinung war auch der Journalist Volker Zastrow 1997 in der Frankfurter Allgemeinen Zeitung: Wie die Serie verwandte Geschichten erzähle, in denen derselbe Sachverhalt aus unterschiedlichen Perspektiven beleuchtet wird, geschehe mit „großer Kunstfertigkeit“. Er hielt die Serie für „gut gemacht“, auch weil sie unter den Zuschauern Anteilnahme an anfangs fremden Geschichten und Figuren bewirke und ein „Schredder für Vorurteile, letztlich für den selbstgerechten Denkstil“ sei.
Die Religionsdarstellung in der Serie fiel auf ein geteiltes Echo. Der Medienhistoriker Robert J. Thompson etwa fand in seinem Buch Television’s Second Golden Age (1996) lobende Worte. Er bescheinigte der Serie, religiöse Probleme geschickt und, ohne Partei zu ergreifen, zu behandeln, aber gleichzeitig auch nicht alle existierenden, organisierten Glauben in „Chris-in-the-morning’s theistic melting pot“ (Deutsch etwa: „irgendeinen theistischen Schmelztiegel“) zu werfen. Zudem habe es die Serie verstanden, göttliche Handlungen anzuerkennen, ohne dabei in die rührselige Melodramatik der Serie Ein Engel auf Erden (1984–1989) abzugleiten.Der PBS-Moderator Michael Medved lobte die Serie grundsätzlich dafür, religiöse Themen zu fokussieren. Er beanstandete aber eine mangelnde Ausgeglichenheit, denn die Geschichten zeigten üblicherweise „weltliche Menschen, die die religiösen Menschen etwas lehren“, beispielsweise, wenn ein fanatischer, religiöser Arzt dafür bestraft werde, dass er anderen Menschen die Möglichkeit einer Jungfrauengeburt aufgezeigt habe. Auch darüber hinaus war die Religionsdarstellung in der Serie Anlass für Kritik. Zum Beispiel empörten sich Christliche Wissenschaftler über einen in der Serie gezeigten Kaiserschnitt, der gegen den Glauben der Eltern der Mutter verstoße. Zudem strahlte eine von Mormonen geführte US-Fernsehstation die Serie zeitweise nicht aus, um damit gegen eine Episode über einen bigamistischen Mormonen zu protestieren. Wegen dieses Aspekts, aber auch anderen Episoden, wurde die Serie zudem in einer großangelegten Studie der konservativen US-Organisation Media Research Center negativ kritisiert. Im übrigen kritisierten jüdische Zuschauer die Darstellung der Figur Douglas Wambaugh als antisemitisch. David E. Kelley reagierte auf die Kritik mit der Episode Ein schwerer Fall (Staffel 2), in der sich Wambaugh gegen die Kritik seines Rabbis an seinen geschmacklosen Äußerungen verteidigt.
Picket Fences wurde bei zahlreichen Fernsehpreisen nominiert und prämiert. Je einen Preisgewinn gab es beim Golden Globe Award und beim Humanitas-Preis; beim Primetime Emmy Award waren es sogar 14 Prämierungen.
Für den bedeutsamsten US-Fernsehpreis, den Primetime Emmy Award, wurde Picket Fences zwischen 1993 und 1996 insgesamt 27-mal nominiert. In der für Dramaserien wichtigsten Kategorie Beste Dramaserie gab es je eine Prämierung für die erste und die zweite Staffel. Die meisten anderen Nominierungen gab es für die Leistungen einzelner Schauspieler. Kathy Baker, als einziges Cast-Mitglied in jeder Staffel vorgeschlagen, gewann den Preis als beste Hauptdarstellerin dreimal (1993, 1995, 1996). Tom Skerritt, nominiert als bester Hauptdarsteller 1993 und 1994, gewann 1993. Auch Ray Walston und Fyvush Finkel waren für ihre Leistung in der Serie mehrfach nominiert: In der Kategorie Bester Nebendarsteller in einer Dramaserie erhielt Walston zwei Preise (bei drei Nominierungen) und Finkel einen Emmy (bei zwei Nominierungen). Weitere zwei Emmys (bei sieben Nominierungen) gab es für männliche und weibliche Gastdarsteller. Darüber hinaus war die Serie in jedem Jahr einmal in der Kategorie Beste Kostüme für eine Serie vorgeschlagen, zwei Nominierungen davon waren erfolgreich.
Picket Fences wurde mit der ersten Staffel zur erst dritten Fernsehserie überhaupt, die in derselben Saison sowohl als beste Dramaserie als auch für den besten Hauptdarsteller und die beste Hauptdarstellerin prämiert wurde.
Auch beim Golden Globe Award, für den es insgesamt neun Nominierungen gab, war Kathy Baker unter den Schauspielern am erfolgreichsten: Dreimal als beste Hauptdarstellerin in einer Dramaserie nominiert (1994, 1995, 1996), gewann sie den Preis 1994. In den übrigen Kategorien blieb es bei Nominierungen: Picket Fences als beste Dramaserie und Tom Skerritt als bester Hauptdarsteller in einer Dramaserie wurden 1994 und 1995 vorgeschlagen. Des Weiteren waren Leigh Taylor-Young, Darstellerin der Rachel Harris, und Fyvush Finkel als Nebendarsteller nominiert.
Bei dem für Jungschauspieler bestimmten Preis Young Artist Award gab es acht Nominierungen, von denen sieben an die Darsteller der drei Brock-Kinder gingen. Holly Marie Combs gewann 1993, Adam Wylie, dreimal nominiert, gewann 1994. Die drei Darsteller waren zusammen 1994 in der Kategorie Bestes junges Ensemble in einer Fernsehserie vorgeschlagen.
Insgesamt 22 Nominierungen und 7 Prämierungen gab es zwischen 1993 und 1996 für den Fernsehpreis Q Award, der von der Organisation Viewers for Quality Television (Deutsch etwa: Zuschauer für Qualitätsfernsehen) bis 2000 organisiert wurde. Dreimal war die Serie hier als Beste Qualitätsdramaserie vorgeschlagen (mit einer Prämierung 1995); alle übrigen Nominierungen gab es für Schauspieler.
Zu den wichtigsten übrigen Preisen, bei denen es Nominierungen und teilweise Prämierungen gab, gehören der populäre Krimipreis Edgar Allan Poe Award (eine Nominierung 1994 für die Episode Selbstjustiz); der unter anderem die Menschenwürde und freie Meinungsäußerung würdigende Humanitas-Preis (drei Nominierungen 1994–1996, eine Prämierung 1996) sowie die Preise der Gewerkschaften von Schauspielern (ein Gewinn für Kathy Baker, drei weitere Nominierungen), Drehbuchautoren (zwei Nominierungen) und Regisseuren (eine Prämierung und eine weitere Nominierung).
Darüber hinaus wurde die Serie noch mit mindestens je einem Preis der US-Organisationen National Easter Seals Society, die für behinderte Menschen eintritt, und Alzheimer’s Association geehrt.
Douglas E. Abrams: Picket Fences, in: Robert M. Jarvis, Paul R. Joseph (Hrsg.): Prime Time Law. Fictional Television as Legal Narrative. Carolina Academic Press, Durham 1998, ISBN 0-89089-805-7 (englisch), S. 129–144
Jill Gerston: This Season They’ve Rebuilt ‘Picket Fences’ …, in: New York Times vom 21. November 1993 (englisch)
Robert J. Thompson: Television’s Second Golden Age. From Hill Street Blues to ER. Continuum, New York 1996, ISBN 0-8264-0901-6 (englisch), S. 167 ff.
