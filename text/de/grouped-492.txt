
Die Schizophrenie ist eine psychische Störung, die weltweit mit einem Lebenszeitrisiko von ca. 1 % auftritt. Die Krankheit hat einen variablen Verlauf und beginnt bei der Mehrzahl der Patienten vor dem 35. Lebensjahr. Die Ursache der Erkrankung ist unbekannt. Das Erscheinungsbild der Schizophrenie ist durch Positiv- und Negativsymptome gekennzeichnet, die sich in den verschiedenen Krankheitsstadien unterschiedlich manifestieren. Dieser Artikel gibt eine Übersicht über die Formen des krankheitsbedingten Erlebens und Verhaltens von Patienten mit einer Schizophrenie (Symptomatik) sowie über das Verfahren des richtigen Erkennens der Erkrankung (Diagnose).
Aufgrund der Vielgestaltigkeit der Schizophrenie als einer Gruppe von Erkrankungen (Bleuler) ist eine einheitliche Beschreibung von Symptomen nicht möglich. Es gibt auch keine Kardinalsymptome der Schizophrenie im engeren Sinne, da die Ursache der Erkrankung unbekannt ist. Im Laufe der Zeit wurden unterschiedliche Krankheitskonzepte der Schizophrenie entwickelt, die jeweils einen eigenen Wert auf bestimmte Symptome gelegt haben.
Die Grundlagen eines diagnostischen psychiatrischen Prozesses können unter den allgemeinen Stichworten der psychiatrischen Untersuchung und Befunderhebung und der psychiatrischen Diagnose und Klassifikation zusammengefasst werden. Die psychiatrische Untersuchung umfasst Gespräch, psychopathologische Befunderhebung und verschiedene Untersuchungsebenen. Um diese zu strukturieren, wurden die unterschiedlichsten Erhebungsinstrumente entwickelt. Für den deutschsprachigen Bereich sei hier vor allem das AMDP-System-System (AMDP: Association of Methodology and Documentation in Psychiatry) erwähnt. Die psychiatrische Klassifikation kennt heute zwei Klassifikationssysteme, die ICD der Weltgesundheitsorganisation (WHO) und das DSM-5 der American Psychiatric Association (APA). Zur klassifikatorischen Diagnostik wurden spezielle Erhebungsinstrumente entwickelt. Das Strukturierte klinische Interview für DSM-IV (SKID) dient dabei zur Klassifikation nach dem DSM und die International Diagnostic Checklist (IDCL) dient als Checkliste für eine Klassifikation nach dem ICD-System. Es gibt auch eine Reihe von Erhebungsinstrumenten, die für beide Klassifikationssysteme geeignet sind (DIA-X).
Die krankhafte Erlebensweise von Patienten mit einer Schizophrenie ist sehr vielgestaltig. Man unterscheidet unspezifische Symptome und charakteristische Symptome. Unspezifische Symptome treten nicht nur bei der Schizophrenie auf, sie helfen deshalb nicht bei der Erkennung der Krankheit. Sie können aber ein Maß für die Schwere der Erkrankung sein. Charakteristische Symptome sind solche, die sich bei der Schizophrenie häufig finden. Man unterscheidet dabei charakteristische Symptome für die verschiedenen Krankheitsphasen und charakteristische Symptome für verschiedene Krankheitstypen der Schizophrenie.
Bei den charakteristischen Symptomen im Verlauf der Krankheit unterscheidet man vor allem die Positiv- oder Plussymptomatik, die die akute Phase der Schizophrenie kennzeichnet, von der Negativ- oder Minussymptomatik, die im ganzen Krankheitsverlauf vorherrschend sein kann.Die vorherrschenden Symptome der Subtypen der Schizophrenie lassen sich unter den Stichworten Wahn für die paranoide Schizophrenie, affektive Veränderungen und Desorganisation des Denkens für die hebephrene Schizophrenie und psychomotorische Störungen für die katatone Schizophrenie zusammenfassen.
Schließlich kann man noch Krankheitsmerkmale unterscheiden, die sich nur oder vorwiegend durch einen Bericht des Patienten erschließen lassen (Stimmenhören), und solche, die sich nur oder vorwiegend durch Beobachtung erschließen lassen (Bewegungsstarre). Dem Vorschlag Kurt Schneiders folgend unterscheidet Gerd Huber in seinem Lehrbuch abnorme Erlebnisweise und abnormen Ausdruck. Diese Unterscheidung spiegelt die begriffliche Differenz von klinischen Symptomen (Beschwerden des Patienten) und klinischen Zeichen (Befund einer körperlichen Untersuchung) wider.
Es gibt eine Reihe von unspezifischen Symptomen bei der Schizophrenie. Solche Symptome erlauben nicht die Diagnose der Erkrankung. Sie treten auch bei anderen Erkrankungen auf und die Tatsache, dass ein Mensch solche Beschwerden hat, sagt nicht, dass er an einer Schizophrenie erkrankt ist. Aber viele Patienten mit einer Schizophrenie zeigen zusätzlich zu den charakteristischen Symptomen der Krankheit unspezifische Symptome. Eine Systematik der unspezifischen Symptome der Erkrankung kann auf verschiedene Weise erfolgen.
Eine Möglichkeit, die unspezifischen Symptome der Schizophrenie zu klassifizieren, besteht darin, die Vorpostensymptome der Erkrankung zu identifizieren. Diese Vorpostensymptome oder häufigen Frühzeichen der Erkrankung sind in Untersuchungen zum Beginn und Frühverlauf der Schizophrenie identifiziert worden. Die häufigsten Symptome im Frühverlauf der Schizophrenie sind: Unruhe, Depression, Angst, Denk- und Konzentrationsstörungen und Sorgen. Andere Untersucher haben als häufige Frühwarnzeichen bei 72 % der Betroffenen Ruhelosigkeit, bei 64 % Schlafstörungen, bei 62 % Nervosität, bei 60 % Schwierigkeiten bei der Arbeit sowie bei 56 % das Gefühl, nicht verstanden zu werden, gefunden.
Eine andere Möglichkeit, die unspezifischen Symptome der Schizophrenie zu klassifizieren, wird in Skalen zur Erfassung des psychopathologischen Befundes realisiert. Eine häufig benutzte Skala ist die Positiv- und Negativ-Syndrom-Skala (PANSS). Sie enthält neben sieben Positiv- und sieben Negativ-Symptomen auch eine Liste von sechzehn unspezifischen Symptomen wie Angst, Schuldgefühle, Sorge um körperliche Integrität oder Willensstörung.
Es gibt verschiedene Möglichkeiten, die charakteristischen psychischen Krankheitsmerkmale der Schizophrenie zu klassifizieren: nach dem Positiv-Negativ-Konzept, nach den Symptomen der akuten und chronischen Schizophrenie, nach häufig auftretenden Symptomen oder im Sinne der Erstrangsymptome nach Kurt Schneider.
Die Symptome der Schizophrenie können in die zwei Gruppen der Positiv- und Negativ-Symptome eingeteilt werden. Dabei sind die Positivsymptome solche, die bei einem akuten Schub der Erkrankung besonders deutlich zutage treten, und die Negativsymptome solche, die häufig als ein zeitlich überdauerndes Merkmal der Krankheit imponieren. Als Negativsymptome gelten die so genannten „sechs A“ nach Andreasen: Affektverflachung, Alogie (Sprachverarmung), Abulie/Apathie (Willenlosigkeit), Anhedonie (Unfähigkeit, positive Gefühle zu empfinden), Aufmerksamkeitsstörungen und Asozialität (Störung der Kontaktfähigkeit). Die häufigsten Positivsymptome sind: Wahn, Halluzinationen, Denkstörungen und Ich-Erlebnisstörungen. Obwohl das dichotome Modell der Schizophrenie, das Nancy Andreasen in dieser Arbeit vorgestellt hat, einer kritischen Überprüfung nicht standhielt, war die Einführung des Positiv-Negativ-Konzeptes in der Schizophrenieforschung überaus erfolgreich.
Wenn man nach Tim Crow die Schizophrenie in Typ-I- und Typ-II-Schizophrenie unterteilt, dann ergibt sich eine Ordnung der Symptome danach, ob sie vorwiegend in der akuten oder in der chronischen Phase auftreten. Die häufigsten Symptome der akuten Phase sind u.  a.: Mangel an Krankheitseinsicht, akustische Halluzinationen und Wahn. Die häufigsten Symptome der chronischen Phase sind u.  a.: sozialer Rückzug, Antriebsarmut und Sprachverarmung. Diese Klassifikation der Schizophrenie konnte aber in nachfolgenden empirischen Untersuchungen nicht repliziert werden.
andere Beeinflussungserlebnisse mit dem Charakter des von außen Gemachten (z. B. leibliche Beeinflussungserlebnisse).Die empirisch häufigsten Symptome der Schizophrenie sind: Störungen von Denken und Sprache (hier vor allem die Denkzerfahrenheit), Störungen der Affektivität (Affektverflachung und Depressivität), Halluzinationen (dialogische und kommentierende Stimmen), Wahn (z.  B. der Verfolgungswahn) und Ich-Störungen (die sogenannten Störungen der Meinhaftigkeit des Erlebens).
Durch die Untersuchung von Symptomgruppen haben verschiedene Untersucher Hypothesen für eine Subklassifikation der Schizophrenie aufgestellt, die das alte Klassifikationssystem nach Kraepelin (paranoid, hebephren, kataton) ablösen sollte. Überraschenderweise haben sich fast alle diese Versuche als untauglich erwiesen, die Schizophrenie klinisch in Subtypen zu unterteilen. Das Konzept der Syndromcluster nach Liddle (Realitätsverzerrung, psychomotorische Verarmung und Desorganisation) erscheint verschiedenen Autoren als erfolgversprechender, da es den empirischen Nachweis und die klinische Beobachtung stützt, dass schizophrene Patienten im Verlauf ihrer Erkrankung Symptome der verschiedenen Subtypen im Wechsel zeigen können.
In Anlehnung an Schneider unterscheidet G. Huber die abnorme Erlebnisweise vom abnormen Ausdruck. Als abnorme Erlebnisweise der Schizophrenen gelten demnach vor allem die Symptome ersten Ranges nach Schneider, die sich auch als Symptomgruppe 1–4 im ICD 10 finden. Die Tabelle gibt einen nach Huber modifizierten Überblick:
Patienten mit einer Schizophrenie haben gelegentlich bestimmte körperliche Symptome, sogenannte „neurological soft signs“ (nichtlokalisatorische neurologische Zeichen). Zu ihnen zählen abnorme unwillkürliche Bewegungen, intermittierende Sakkaden und eine reduzierte p300-Amplitude. Außerdem findet sich bei Schizophrenen eine Vielfalt von vegetativen Störungen.Die Bewertung solcher Phänomene wie der gestörten Augenfolgebewegung bei schizophrenen Patienten und ihren nächsten Angehörigen ist umstritten. Manche Autoren haben vermutet, es handele sich um einen so genannten intermediären Endophänotyp, eine Störung, die genetisch bedingt ist und eng mit der physiologischen Ursache der Schizophrenie verknüpft ist. Diese Hypothese ist allerdings umstritten, wiewohl das Konzept der Endophänotypen im Rahmen einer neurobiologischen Ursachenforschung zur Schizophrenie sehr populär ist.
Generell gilt, dass Patienten mit einer Schizophrenie bei technischen Untersuchungen keine Auffälligkeiten zeigen. Die körperliche Gesundheit gilt ja gemäß den Diagnosekriterien des ICD als Voraussetzung dafür, dass die Diagnose einer Schizophrenie gestellt werden darf. Die Ausnahmen von dieser Regel werden in dem oben genannten Hauptartikel ausführlich diskutiert. Unabhängig davon findet man bei Patienten, die schon länger erkrankt sind und eine chronische Verlaufsform der Erkrankung zeigen, aufgrund von Begleiterkrankungen nicht selten Blutbildveränderungen. So können Neuroleptika geringfügige Erhöhungen der Leberwerte verursachen. Manche Patienten zeigen Verhaltensanomalien (z.  B. eine wahnhaft induzierte Polydipsie), die sich dann in veränderten Laborwerten darstellen (im Falle der Polydipsie eine Erniedrigung der Serum-Natriumwerte).
Um den Diagnoseprozess der Schizophrenie (wie für alle seelischen Erkrankungen) nach ICD- oder DSM-5 zu verstehen, muss man einige Grundprinzipien aktueller Klassifikationssysteme in der Psychiatrie kennen.Diese sind:
Um eine operationalisierte Diagnostik für eine Erkrankung vornehmen zu können braucht man zwei Dinge: erstens diagnostische Kriterien, also Symptome, Zeichen, Befunde, Zeit- und Verlaufskriterien im Sinne von Einschluss- und Ausschlusskriterien; zweitens Entscheidungs- und Verknüpfungsregeln für diese Kriterien.
Die Symptomkriterien werden in Lehrbüchern der Psychopathologie oder in den Handbüchern und Manualen zu psychiatrischen Skalen genau beschrieben und sind oftmals vom alltäglichen Sprachgebrauch verschieden. Die benutzen Begriffe, wie „Episode“ oder „Störung“ unterliegen ebenfalls genauen Definitionen und dürfen nicht mit Alltagsbegriffen verwechselt werden. Die Operationalisierung erfolgt unterschiedlich streng, für Forschungszwecke etwa werden strengere Kriterien angelegt.
Für die Schizophrenie unterscheidet der ICD-Katalog allgemeine diagnostische Kriterien für die Schizophrenie und einen Ausschlussvorbehalt. Dann werden diagnostische Kriterien für die Subtypen der Erkrankung (paranoid, hebephren, kataton und undifferenziert) vorgeschrieben, sowie für die postschizophrene Depression, das schizophrene Residuum und die Schizophrenia simplex. Außerdem werden Regeln für die Verlaufsbilder angegeben.
Der diagnostische Algorithmus zur Schizophrenie sieht gemäß ICD 10 folgendes vor. Es wird zuerst ein Zeitkriterium definiert: Die Symptome müssen mindestens einen Monat kontinuierlich vorliegen. Sodann werden zwei Reihen von Symptomgruppen definiert. Die erste Reihe umfasst die Symptomgruppen 1 – 4 Die zweite Reihe umfasst die Symptomgruppen 5 – 9. Dabei stimmt die Symptomgruppe 1 – 4 nach dem ICD 10 inhaltlich weitgehend mit den Erstrangsymptomen nach Kurt Schneider überein.
Zum Abschluss wird Ausschlussvorbehalt definiert. Eine Schizophrenie soll nicht diagnostiziert werden, wenn die Symptomkonstellation eher auf ausgeprägte manische oder depressive Zustände schließen lässt. (Differenzialdiagnose resp. Differenzialtypologie nach K. Schneider gegen andere „endogene Psychosen“) oder wenn eine somatische Gehirnerkrankung vorliegt (Tumor) oder wenn Hinweise für Intoxikationen oder Substanzentzug als Ursache für die Symptome vorliegen (Differenzialdiagnose gegen körperlich bedingte Störungen = „organische Psychosen“)
Der Algorithmus lautet dann: Wenn ein eindeutiges Symptom der Symptomgruppe 1 – 4 oder zwei eindeutige Symptome der Symptomgruppen 5 – 9 mindestens einen Monat kontinuierlich vorliegen und sich keine Ausschlusskriterien finden, darf die Diagnose einer Schizophrenie gestellt werden.
Für die Schizophrenie wird dann noch die Krankheit den Subtypen nach dem ICD zugeordnet und das Verlaufsbild mit Hilfe von acht verschiedenen Regeln klassifiziert. Eine operationalisierte ICD-Diagnose der Schizophrenie kann dann etwa so aussehen:
Wenn ein Patient über mindestens einen Monat einen kulturell unangemessenen Wahn zeigt (Symptom der Symptomgruppe 1 – 4),
Wenn der Patient zwischen den akuten Krankheitsphasen symptomfrei oder symptomarm war, lautet die Diagnose:
Episodisch remittierend (Verlaufskriterium Nr. 3). x3.Die vollständige Notation heißt dann: Paranoide Schizophrenie, episodisch remittierend (ICD 10 F 20. 03)
Mit dem Begriff der Komorbidität meint man das gemeinsame Auftreten verschiedener Erkrankungen. Die Diagnoseregeln des ICD 10 fordern, dass man kein Symptom unterschlägt, weil es nicht zu einer Diagnose passt, sondern so viele Diagnosen stellt, wie zur Abbildung aller gefundenen Symptome notwendig sind. Dieses Vorgehen ist keineswegs selbstverständlich, was erst im Vergleich mit historischen Konzepten, etwa Karl Jaspers Schichtenregeln klar wird.
In den modernen Diagnosesystemen geht man von solchen, zwar naheliegenden, aber dennoch empirisch nicht belegbaren Vorannahmen ab. Die Gründe dafür sind vielfältig:
Wenn man die Schichtenregel verlässt, ändern sich die Prävalenzzahlen: Bestimmte Diagnosen treten dann häufiger auf.Die Einführung des Konzeptes der Komorbidität hat ergeben, dass bestimmte Erkrankungen (beispielsweise Sucht oder Persönlichkeitsstörungen) häufig kombiniert auftreten. Dieses Phänomen wird unterschiedlich erklärt, etwa so, dass komorbide Erkrankungen Folge einer bestimmten anderen Erkrankung seien (Beispiel: Sucht als Folge der Angst), dass die Komorbidität auf gemeinsame Ursachen verschiedener Erkrankungen hinweist (Beispiel: Angst und Depression) oder dass die Komorbidität ein Artefakt aufgrund unscharfer diagnostischer Kriterien oder fehlerhafter Diagnosealgorithmen sei (Beispiel: abhängige Persönlichkeit und soziale Phobie).
Der Grundgedanke der multiaxialen Diagnostik in der Psychiatrie ist die Überlegung, alle Lebensumstände, die zum Krankheitsverlauf beitragen, formalisiert darzustellen. Der Tatsache, dass solche Lebensumstände eine große Bedeutung haben, hat schon Kraepelin mit seinem Begriff der „pathoplastischen“ Bedingungen Rechnung getragen. In den modernen multiaxialen Ansätzen ist dies systematisch ausgeführt.
Das Mehrachsensystem von Rutter aus dem Jahr 1969.Es gibt viele Ansätze zur multiaxialen Diagnostik und keine Übereinstimmung, welche Achsen notwendig sind. Aus diesem Grund soll hier lediglich der multiaxiale Ansatz nach ICD 10 dargestellt werden. Im ICD 10 gibt es für seelische Erkrankungen drei Achsen. Achse I beschreibt die klinischen Diagnosen, Achse II die so genannten psychosozialen Funktionseinschränkungen und Achse III Probleme der Lebensführung und Lebensbewältigung. Das DSM kennt fünf Achsen. Achse I-III entspricht den klinischen Diagnosen des ICD-10, Achse V erfasst das soziale Funktionsniveau und Achse IV psychosoziale und umgebungsbedingte Probleme. In der folgenden Tabelle werden die Achsen von ICD und DSM gegenübergestellt.
Die Ergebnisse der Achsenbeurteilung können nun einerseits als ICD-Diagnosen dargestellt werden und andererseits als numerische Werte anhand von Skalen angegeben werden.
Achse  II: Global Assessment of Functioning Scale von 50, analoge Werte für den WHO-Disability Diagnostic Scale.
Achse  III: ICD 10 Z56. 0 (Arbeitslosigkeit); ICD 10 Z60. 2 (alleinlebende Person); ICD 10 Z 59. 6 (niedriges Einkommen)Auf diese Weise gelingt es, systematisch wichtige Umstände zu erfassen, die den Schweregrad einer Erkrankung aufzeigen. Darüber hinaus ist es durch die Formalisierung möglich, die erfassten Daten rechnergestützt auszuwerten und für Studien zu vergleichen. Für die psychiatrische Forschung sind multiaxiale Ansätze heute unverzichtbar.
Das Hauptproblem der multiaxialen Diagnostik ist die Vielfalt der Systeme und der mangelnde Konsens über die Verwendung der verschiedenen Typen. Dies schränkt den Wert der Verfahren, nämlich die Vergleichbarkeit für wissenschaftliche Studien, ein. Zudem zeigen manche Achsen inhaltliche Überschneidungen, sind also nicht unabhängig voneinander.
Die Differenzialdiagnose der Schizophrenie ist vielgestaltig. Generell unterstellt man dabei folgende Vorannahme: Die Schizophrenie ist immer eine Psychose, aber nicht alle Psychosen sind eine Schizophrenie. Als Kernfrage kann man dann formulieren, bei welchen Erkrankungen die häufigsten Positivsymptome der Schizophrenie (Wahn und Halluzinationen) auch auftreten können und wie man solche Erkrankungen von der Schizophrenie abgrenzt. Dabei soll die Schizophrenie gegen substanzinduzierte Psychosen, somatische Erkrankungen und andere psychische Störungen abgegrenzt werden.
Der ICD-Katalog definiert in diesem Sinne, dass eine Schizophrenie nicht diagnostiziert werden soll, wenn die psychotische Symptomatik als Folge einer Intoxikation oder eines Entzuges auftritt (Alkohol, Drogen, Medikamente) oder in Begleitung einer körperlichen Erkrankung des Gehirns erscheint (Epilepsie, Gehirntumor, Schädel-Hirn-Trauma, Infektion des Zentralnervensystems etc.). Hier erfolgt die Differentialdiagnose durch einen Ausschluss einer körperlichen Erkrankung. Die Leitlinie der Differentialdiagnose lautet demnach, dass die Diagnose einer Schizophrenie nur gestellt werden soll, wenn der betreffende Patient körperlich gesund ist und keine psychotropen Substanzen einnimmt.
Sodann erfolgt die Abgrenzung der Schizophrenie gegen andere psychische Störungen. Die Abgrenzung gegen andere Psychosen, insbesondere gegenüber den affektiven Störungen, bezeichnet man nach K. Schneider nicht als Differenzialdiagnose, sondern als Differenzialtypologie, da die Ursache der Schizophrenie unbekannt ist. Hier kommen an erster Stelle in Frage die:
Manie oder bipolare Störung mit psychotischen Symptomen (F30/31)Üblicherweise wird die Abgrenzung vorgenommen, indem man zwei Kriterien zum Anschlag bringt, nämlich den Verlauf und das Fehlen oder Überwiegen der Symptomgruppe 1 – 4 nach dem ICD bzw. der Erstrangsymptome nach Schneider. Wenn im Verlauf der Erkrankung die Psychose schnell auftritt, schnell und vollständig remittiert und dann keine weitere psychotische Symptomatik mehr auftritt, soll die Diagnose einer akuten Psychose gestellt werden (F23). Wenn bei den Patienten schizophrene Symptome und depressive oder manische Symptome in der gleichen Intensität vorliegen, soll die Diagnose einer schizoaffektiven Störung gestellt werden (F25). Für den Fall, dass bei den Patienten nur Wahnsymptome auftreten und diese über längere Zeit anhalten soll die Diagnose einer anhaltend wahnhaften Störung gestellt werden. Ist der Wahn kurzzeitig und vorübergehend, wird die Diagnose einer akuten wahnhaften psychotischen Störung gestellt (F22 oder F23. 3). Treten bei einem Patienten psychotische und affektive Symptome auf, wobei aber die Symptome aus dem Kreis der affektiven Störungen überwiegen, wird die Diagnose einer affektiven Störung gestellt (F3x). Das Auftreten isolierter Symptome, wie Halluzinationen oder eines kulturell angepassten Wahns ist nicht wegweisend für eine Schizophrenie und gilt nach Überzeugung verschiedener Autoren auch nicht immer als Krankheitszeichen.
Janzarik hat mit der Bezeichnung „Psychose des schizoaffektiven Zwischenbereiches“ eine Erkrankung beschrieben, bei der es zu einem gleichzeitigen Auftreten schizophrener und manischer bzw. depressiver Symptome kommt. Damit wird eine Erkrankung bezeichnet, die der ICD mit dem Begriff „Schizoaffektive Störung“ unter F25 behandelt.
Diese Erkrankung ist von anderen Autoren mit unterschiedlichen Begriffen bezeichnet worden. Schneider hat von „Zwischen-Fällen“ zwischen den affektiven und schizophrenen Psychosen gesprochen, Kasanin sprach von „schizoaffektiven Psychosen“, Leonhard von „unsystematischen“ oder „zykloiden Psychosen“ und die skandinavische Schule (Langfeldt) von „schizophreniformen Psychosen“Karl Leonhard hat sechs Hauptgruppen der endogenen Psychosen unterschieden:
Bipolare KrankheitDie zykloiden Psychosen: Angst-Glücks-Psychose, Erregt-gehemmte Verwirrtheitspsychose, Hyperkinetisch-akinetische Motilitätspsychose
Die systematischen Schizophrenien: Katatonien, Hebephrenien und Paraphrenien.Dabei sollten die zykloiden Psychosen eine gute Prognose haben und „defektfrei“ ausheilen.
Zur Frage der Diagnostik und Prognose der schizoaffektiven Psychose haben sich Huber und Mitarbeiter in der „Bonn Studie“ geäußert. Hier wurden vier Psychosetypen des schizoaffektiven Zwischenbereiches gefunden und ihre Prognose war insgesamt signifikant günstiger als die des Gesamtkollektivs der Bonner Schizophrenie-Studie. Huber bezeichnet diesen Erkrankungstyp als „schizoaffektive Psychosen“ nach Kasanin, Spitzer und Angst oder „zykloide Psychosen“ nach Leonhard und Perris.Die Übereinstimmung von „zykloiden Psychosen“ und der „schizioaffektiven Störung“ ist von anderen Autoren in Frage gestellt worden. Michael Zaudig unterscheidet zwei Konzepte von Psychosen mit guter Prognose, die traditionellen Konzepte der „Bouffee delirante“, der „zykloiden Psychose“ und der „Schizoaffectiven“ nach Kasanin auf der einen Seite und die „Schizoaffektiven Psychosen“ nach den Kriterien von Kendell, Welner, DSM und ICD. Dabei soll Zaudig zufolge keine Übereinstimmung der beiden Gruppen bestehen. Neuere Arbeiten der Gruppe um Beckmann unterstreichen die Tatsache, dass die sog. „zykloiden Psychosen“ nicht zu den affektiven Störungen (bipolare Störung) zu rechnen sind.In dem Lehrbuch von Mathias Berger wird die „Schizoaffektive Störung“ als eine Krankheit beschrieben, bei der eine Unsicherheit besteht, ob sie den affektiven oder schizophrenen Erkrankungen zuzuordnen sei. Das Konzept der schizoaffektiven Psychose bleibe kontrovers. Die Leohard-Klassifikation mit ihren Konzepten der zykloiden Psychose und unsystematischen Schizophrenie versuche dieser Unsicherheit abzuhelfen. Es werden verschiedene Möglichkeiten diskutiert, wie die schizoaffektive Störung einzuordnen sei.Im ICD wird die “zykloide Psychose” nicht als mit der „Schizoaffektiven Störung“ identisch angenommen. Sie wird unter den „Sonstigen nichtorganischen psychotischen Störungen“ eingeordnet (ICD 10 F 28).Damit bleibt festzuhalten, das Leonhard vier Gruppen von Psychosen unterscheidet: die affektiven, die zykloiden, die unsystematischen und die systematischen Psychosen. In der deutschen Psychiatrie haben Huber und Zaudig die Übereinstimmung der zykloiden Psychosen mit der schizoaffektiven Störung des ICD gesehen und Beckmann und Mitarbeiter die zykloiden Psychosen als eigenständige Gruppe unabhängig von der schizoaffektiven Störung und den bipolaren Störungen angenommen.
Wenn Patienten von Halluzinationen und Wahn berichten und dabei ängstlich und beunruhigt sind, kann die akute psychotische Episode einer Schizophrenie auch von Laien erkannt werden. Aber diese Krisen kennzeichnen das Leben eines Menschen mit einer Schizophrenie meist nur für kurze Zeiträume. Unabhängig von den akuten psychotischen Episoden ist das Erleben der Patienten meist von Defiziterfahrungen geprägt: Depressivität, soziale Behinderung und gesellschaftliche Stigmatisierung gehören dabei genauso zum Alltag der Kranken wie Stimmenhören und wahnhafte Befürchtungen.
Die Beurteilung von Ausmaß und die Unterscheidung aller damit einhergehenden Beschwerden erfordert nicht nur Erfahrung und Übung, sondern auch eine Verständigung der Untersucher über gemeinsame Standards zur Beurteilung der verschiedenen Items. Aus diesem Grund wurden Erhebungsinstrumente entwickelt, deren Anwendung eine besondere Einarbeitung und Schulung erfordert. Dasselbe gilt für die operationalisierte Diagnose der Erkrankungen nach den internationalen Klassifikationssystemen. Hier ist vor allem die Abstimmung von Erhebungsinstrument und Klassifikationssystem (z.  B. SCID und DSM) von Vorteil.
Durch die Verwendung solcher standardisierter Verfahren wird in der Psychiatrie eine Vergleichbarkeit von Daten in wissenschaftlichen Studien erreicht, die die Untersuchung großer Fallzahlen überhaupt erst möglich macht. Das Ziel dieser standardisierten Verfahren ist die Etablierung der evidenzbasierten Medizin im Falle der Behandlung der Schizophrenie.
Mathias Berger (Hrsg.): Psychische Erkrankungen. Klinik und Therapie. 4. Auflage. Urban & Fischer, München 2012, ISBN 978-3-437-22483-6.
Heinz Häfner u. a.: Beginn und Frühverlauf schizophrener Erkrankungen. In: Joachim Klosterkötter (Hrsg.): Frühdiagnostik und Frühbehandlung psychischer Störungen. Springer, Berlin 1998, ISBN 3-540-64440-7.
Heinz Häfner: Das Rätsel Schizophrenie. Eine Krankheit wird entschlüsselt. 3. Auflage. Beck, München 2005, ISBN 3-406-52458-3, S. 76ff.
Heinz Häfner: Schizophrenie: erkennen, verstehen, behandeln. Beck, München 2010, ISBN 978-3-406-58797-9.
Gerd Huber, Gisela Gross: Psychiatrie Lehrbuch für Studium und Weiterbildung. 7. Auflage. Schattauer, Stuttgart/ New York 2005, ISBN 3-7945-2214-1.

Eine Synchronmaschine ist eine rotierende elektrische Maschine, in der der Rotor (auch: Läufer) synchron mit dem Drehfeld des Stators läuft. Synchronmaschinen werden häufig als Drehstrommaschinen, also als Drehstrom-Synchronmaschinen ausgeführt. Vom Prinzip her kann jede Synchronmaschine als elektrischer Motor und elektrischer Generator betrieben werden. Synchrongeneratoren dienen in der Energiewirtschaft in einem weiten Leistungsbereich der Bereitstellung von elektrischer Energie. Synchronmotoren finden vielseitigen Einsatz als Antriebsmaschinen in der Industrie, zum Beispiel als Antriebe für Schiffe und Züge oder für Pumpen und Verdichter.
Die Synchronmaschine trägt ihren Namen wegen der Betriebseigenschaft, dass ihr Rotor exakt mit dem durch die Netzfrequenz vorgegebenen Drehfeld synchron umläuft. Das unterscheidet Synchronmaschinen von Asynchronmaschinen, deren Rotor dem Drehfeld im Motorbetrieb nach- und im Generatorbetrieb voreilt. Ein weiteres Unterscheidungsmerkmal ist, dass im Gegensatz zu Asynchronmaschinen für den Betrieb von Synchronmaschinen ein Erregerfeld benötigt wird. Bevor eine Synchronmaschine als Generator ans Netz geschaltet wird, muss sie mit dem Netz synchronisiert werden. Im Generatorbetrieb läuft die Maschine allgemein mit relativ konstanter Drehzahl. Synchronmotoren müssen dagegen oft in ihrer Drehzahl variabel sein. Um einen Synchronmotor stufenlos in der Drehzahl regeln zu können, wird Leistungselektronik wie z. B. Frequenzumrichter verwendet. Ein Drehgeber (Strichgeber, Resolver) erfasst im Betrieb ständig die Läuferstellungsänderung. Daraus ermittelt die Steuerungselektronik die tatsächliche Drehzahl. Bei Belastung läuft der Läufer des Synchronmotors dem Drehfeld im lastabhängigen Polradwinkel hinterher. Im Generatorbetrieb ist der Polradwinkel positiv in Drehrichtung, eilt also vor. Synchronmaschinen können Blindleistung aufnehmen oder abgeben. Dadurch kann die Maschine zudem zur Blindleistungskompensation verwendet werden. Das Blindleistungsverhalten lässt sich über die Erregung beeinflussen.
Als Vorläufer der dreiphasigen Synchronmaschine kam ab Mitte des 19. Jahrhunderts der einphasige Wechselstromgenerator zur Versorgung von Beleuchtungsanlagen zum Einsatz. 1887 entwickelten Friedrich August Haselwander und der US-Amerikaner Charles Schenk Bradley unabhängig voneinander den dreiphasigen Synchrongenerator. Bei den Entwicklungen bildeten sich die Bauformen der Schenkelpol- und Vollpolmaschine aus. Ein Mitgründer der Brown, Boveri AG, Charles E. L. Brown, gilt als Erfinder des Walzenläufers, mit in Nuten am Umfang verteilter Erregerwicklung.
Die Weiterentwicklung der Synchronmaschine hing stark mit dem Ausbau der elektrischen Energieversorgung im Rahmen der Elektrifizierung und dem Bedarf von immer leistungsstärkeren Generatoren zusammen. Zuerst entstanden Einzelpol- beziehungsweise Schenkelpolmaschinen, da diese geeignet waren, mit den langsamlaufenden Kolbendampfmaschinen als Antriebsmaschine Elektrizität zu erzeugen. Als die Dampfturbinen die Kolbendampfmaschinen ersetzten, kamen die schnelllaufenden walzenförmigen Vollpolläufer zum Einsatz. Der Synchronmaschine kommt eine große Bedeutung bei der Bereitstellung von Elektroenergie zu. In Großkraftwerken, wie Kohle- oder Kernkraftwerken, kommen fast ausschließlich Synchrongeneratoren zum Einsatz. Die Bedeutung der Synchronmaschine in diesem Bereich wird zukünftig jedoch abnehmen, da mit Weiterentwicklung im Bereich der regenerativen Energien Anlagen mit kleineren Einzelleistungen wie zum Beispiel Windkraftanlagen und damit auch alternative Maschinentypen zum Einsatz kommen. Außerdem werden Synchronmaschinen oder andere Maschinentypen für bestimmte Verfahren der Energiebereitstellung überhaupt nicht benötigt, wie zum Beispiel bei Photovoltaikanlagen.
Unabhängig davon wurden in der Industrie schon immer Synchronmaschinen eingesetzt, wenn eine konstante Antriebsdrehzahl oder Phasenschieberbetrieb benötigt wurde.
Synchronmaschinen werden in verschiedenen Bauformen ausgeführt. Sie werden als Außen- oder Innenpolmaschinen gefertigt. Beide Maschinentypen haben gemeinsam, dass sie wie alle Drehstrommaschinen über einen Läufer und einen Ständer verfügen. In jedem Fall wird eine Erregereinrichtung für den Betrieb der Maschinen benötigt. Außerdem erfolgt nochmals eine Unterteilung in Schenkelpol- und Vollpolmaschinen.
Die Ständerwicklung besteht aus drei um 120°/p (p = Polpaarzahl) versetzten Wicklungssträngen, die mit U, V und W bezeichnet werden. Sie sind in Stern- oder Dreieckschaltung verschaltet. Über die Ständerwicklung wird im Generatorbetrieb elektrische Energie ins Netz gespeist beziehungsweise im Motorbetrieb aus dem Netz bezogen. Der Aufbau des Ständers gleicht dem der Drehstrom-Asynchronmaschine. Der Ständer der Innenpolmaschine wird auch Anker genannt und die Ständerwicklung dementsprechend Ankerwicklung. Der Anker der Synchronmaschine ist nicht zu verwechseln mit dem Anker der Gleichstrommaschine, bei der der Läufer Anker genannt wird.
Der Läufer der Innenpolmaschine kann als Schenkelpolläufer oder Vollpolläufer ausgeführt sein. Rotor, Polrad und seltener Induktor sind ebenfalls Bezeichnungen für beide Läuferbauformen. Der Vollpolläufer wird zudem als Walzenläufer und Volltrommelläufer bezeichnet. Dieser ist rotationssymmetrisch aufgebaut und trägt die Erregerwicklung. Die Erregerwicklung ist in die Nuten des Vollpolläufers eingebracht und mit Nutkeilen befestigt. Schenkelpolläufer besitzen ausgeprägte Polschuhe und Schenkel, weswegen sie einen großen Durchmesser besitzen. Die Erregerwicklung ist auf die Schenkel des Läufers gewickelt.
Es gibt verschiedene Prinzipien der Erregung, beispielsweise die statische Erregung. Bei diesem Prinzip sind die Enden der Erregerwicklung über Schleifringe, die sich auf der Läuferwelle befinden, herausgeführt. Über Kohlebürsten wird die Erregerspannung an die Erregerwicklung gelegt. Ein anderes Prinzip ist die bürstenlose Erregung über Außenpol-Synchrongeneratoren und mitrotierende Diodengleichrichter (sog. RG-Sätze). Diese Technik wird aber infolge der steigenden dynamischen Anforderungen (Pendeldämpfungsgerät, engl. Power System Stabilizer, PSS) nur noch selten in Kraftwerksneubauten eingesetzt, weil RG-Erregungen wesentlich langsamer als Schleifringerregungen reagieren.
Handelt es sich um eine permanentmagneterregte Synchronmaschine (PSM), trägt der Läufer Permanentmagnete zur Erregung. Die Permanentmagnet-Erregung gewinnt immer mehr an Bedeutung.
Die Hybridsynchronmaschine (HSM) hingegen vereint die Wirkung der elektromagnetischen Reluktanz und der Wirkung von Permanentmagneten zur Drehmomentbildung.Dämpferwicklung (Dämpferkäfig)
Größere Synchronmaschinen verfügen über eine Dämpferwicklung (Dämpferkäfig). Sie wirkt sich auf das Betriebsverhalten von Synchronmaschinen aus. Bei Vollpolmaschinen sitzt die Dämpferwicklung in den Nuten der Erregerwicklung oder zwischen diesen Nuten in gesonderten Dämpfernuten. Bei Schenkelpolmaschinen sitzt die Dämpferwicklung in gesonderten Dämpfernuten der Polschuhe. Die Dämpferwicklung bei Vollpolmaschinen ähnelt vom Prinzip her dem Aufbau des Kurzschlussläufers einer Asynchronmaschine. Synchronmaschinen können aber in Abhängigkeit von der Bauform ohne eine Dämpferwicklung eine Eigendämpfung aufweisen, die sich ebenfalls auf den Betrieb auswirkt.
Die wichtigste Aufgabe der Dämpferwicklung von Synchronmaschinen besteht darin, mechanische Pendelmomente zu dämpfen. Pendelmomente treten auf durch Asynchronbetrieb, an die Synchronmaschine angekuppelte Maschinen mit periodischem Drehmoment (z. B. Verbrennungsmotoren als Antriebsmaschine oder Kolbenkompressoren als Arbeitsmaschine) und Laststöße. Im unsymmetrischen Betrieb (Schieflast) und im Extremfall bei Einphasenbetrieb tritt ein inverses Drehfeld auf, das ebenfalls gedämpft wird. Ungedämpft hätte das inverse Drehfeld hohe Verluste zur Folge.
Für den Generatorbetrieb ist vor allem die Dämpfung der inversen Felder von Bedeutung. Inverse Felder verursachen einen Strom in der Dämpferwicklung, dessen Frequenz doppelt so groß wie die Netzfrequenz ist. Die Dämpferwicklung wird hierbei mit geringem Widerstand ausgeführt, um die Verluste gering zu halten.
Im Motorbetrieb sind vor allem Pendelmomente zu dämpfen. Bei Belastung mit einem konstanten Lastmoment besteht unter einem konstanten Polradwinkel ein Gleichgewicht zwischen dem durch die Last abgeforderten und dem durch die Maschine zugeführten Drehmoment (siehe auch Federmodell des Polradwinkels einer Synchronmaschine). Durch plötzliche Erhöhung des Lastmomentes (Laststoß) verzögert sich wegen des Massenträgheitsmoments des Läufers seine Drehbewegung über den Polradwinkel hinaus. Das Lastmoment ist nun kleiner als das Motormoment und das verursacht wiederum durch das Massenträgheitsmoment eine Beschleunigung bis zu einem zu geringen Polradwinkel. Dieses Pendeln wiederholt sich mit immer kleiner werdender Amplitude, bis wieder ein Gleichgewicht erreicht ist. Durch die Relativbewegung zwischen Ständerdrehfeld und Läufer wird nach dem Prinzip der Asynchronmaschine ein Drehmoment erzeugt, welches den Pendelbewegungen entgegenwirkt. Ähnlich wirken ebenfalls Massivteile des Läufers wie der massive Läuferballen der Vollpolmaschine oder die massiven Polschuhe der Schenkelpolmaschine. Das heißt, eine gewisse Dämpfung kann auch ohne Dämpferwicklung stattfinden. Neben dem Dämpfen von Pendelmomenten kann die Dämpferwicklung auch zum Selbstanlauf nach dem Prinzip des Asynchronmotors mit Käfigläufer dienen.
Vollpolmaschinen werden mit hohen Drehzahlen betrieben und eignen sich deshalb gut zum Einsatz als Turbogeneratoren. Die Läufer dieser Generatoren werden Turboläufer genannt. Sie sind mit wenigen Polpaaren ausgeführt und laufen bei 50 Hz Netzfrequenz mit bis zu 3000 min−1. Aufgrund der hohen Drehzahlen und der auf den Läufer wirkenden Kräfte müssen diese Generatoren schlank gebaut werden und sind wegen der Gefahr einer Überdrehzahl nicht leerlauffähig. Die Baugröße von Vollpolmaschinen ist im Durchmesser durch die Fliehkraftgrenze und in der Länge durch die Durchbiegegrenze beschränkt.
Schenkelpolmaschinen werden häufig als niedertourige Generatoren mit großen Durchmessern und geringer Länge eingesetzt. Sie sind mit großer Polpaarzahl ausgeführt und laufen mit Drehzahlen von 60 bis 750 min−1.
Im Ständer der Außenpolmaschine befinden sich ausgeprägte Polschuhe und Schenkel, welche die Erregerwicklung tragen. Auf dem Läufer, im Fall der Außenpolmaschine ebenfalls Anker genannt, befindet sich die dreisträngige Läuferwicklung. Die Enden der Läuferwicklung sind über Schleifringe herausgeführt. Kohlebürsten nehmen im Generatorbetrieb die bereitgestellte Leistung ab, oder führen die benötigte Leistung im Motorbetrieb zu. Diese Bauform eignet sich nicht für Maschinen mit großer Bemessungsleistung, da die Ströme in Abhängigkeit von der Leistung steigen. Damit verbunden sind der Anstieg der Verluste am Schleifringapparat und die Notwendigkeit, den Schleifringapparat größer auszuführen, um die Ströme tragen zu können. Für große Leistungen kommen Innenpolmaschinen zum Einsatz.
Die Wicklungen von Generatoren sind für die Höhe der Ströme auszulegen, die bei einem Kurzschluss auftreten. Das betrifft ebenso die Erregerwicklung, da auch in ihr im Kurzschlussfall hohe Stromspitzen auftreten. Der höchste Kurzschlussstrom tritt bei einem dreipoligen Klemmenkurzschluss auf, wenn sich die Maschine bei Bemessungsdrehzahl im Leerlauf befindet und bei Bemessungsspannung erregt ist. Laut DIN VDE 0530 darf der Kurzschlussstrom maximal den 21-fachen Effektivwert und den 15-fachen Scheitelwert des Bemessungsstroms betragen.
Die Ständerwicklungen und die Erregerwicklung von Synchronmaschinen erwärmen sich im Betrieb durch die auftretenden Ströme. Die Wärme muss abgeführt werden. Im unteren Leistungsbereich geschieht das z. B. über Kühlrippen des Ständers und mittels Lüfter. Dabei zirkuliert die Luft im Gehäuse und um die Wicklungen. Für die Zirkulation ist ein Lüfter auf der Läuferwelle angekuppelt. Möglich ist auch eine Fremdlüftung über einen externen Lüfter. Großgeneratoren erwärmen sich sehr stark. Die Wärme wird hier über eine Wasser- und Wasserstoffkühlung abgeführt. Dabei zirkuliert Deionat durch die als Hohlleiter ausgeführte Ständerwicklung. Anstelle von Luft befindet sich unter Druck stehender Wasserstoff im Gehäuse, das in dem Fall völlig dicht sein und sogar einer Knallgasexplosion standhalten muss. Aufgrund der großen Wärmeleitfähigkeit von Wasserstoff wird so eine wesentlich bessere Kühlung erreicht als mit Luft; es wurden auch Prototypen mit supraleitender Erregerwicklung getestet. Ziel der Forschung ist u. a. die Erhöhung der Luftspaltdichte und des Strombelages. Mit der Technik soll ermöglicht werden, die aktive Masse der Maschine bei gleicher Leistung zu halbieren.
Hauptanwendungen der Synchronmaschinen sind die Drehstromgeneratoren in Kraftwerken. Fast die gesamte konventionelle Produktion elektrischer Energie erfolgt mit Synchrongeneratoren. In Wärmekraftwerken kommen Vollpolmaschinen mit Leistungen bis fast 2000 MVA und Ausgangsspannungen von 21 bis 27 kV zum Einsatz. Im Mülheimer Siemens-Werk wurde der weltweit größte Generator für das finnische Kernkraftwerk Olkiluoto gefertigt. Er hat eine Bemessungsscheinleistung von 1992 MVA. Diese Generatoren, mit ihren schnell umlaufenden Turboläufern, werden in Einheit mit den Turbinen Turbosätze genannt. Die langsamlaufenden Schenkelpolmaschinen in Wasserkraftwerken werden Wasserkraft- oder Hydrogeneratoren genannt und liefern bei maximal 25 kV Ständerspannung Leistungen bis zu 1000 MVA. Generatoren kleinerer Leistung von 10 kVA bis 10 MVA kommen in Kleinkraftwerken und Dieselgeneratoren zum Einsatz und sind meist ebenfalls als Schenkelpolmaschine ausgeführt. Synchrongeneratoren für Windkraftanlagen werden zurzeit mit bis zu 8 MW Leistung gefertigt. Hinzu kommt der Einsatz bei der Versorgung von lokalen Netzen. So findet der Synchrongenerator auch Verwendung bei der Bereitstellung von Elektroenergie zum Betrieb von Schienenfahrzeugen und Schiffsantrieben sowie wohl zukünftig auch von Straßenfahrzeugen. Eine Sonderbauform der Schenkelpolmaschine bildet die Klauenpolmaschine, sie kommt vor allem als Kfz-Lichtmaschine (Generator) zum Einsatz.
Drehstrom-Synchronmotoren großer Leistung dienen als Antrieb für Gebläse, Pumpen und Verdichter sowie teilweise als Bahnantriebe (SNCF BB 26000, TGV, AGV). Mit der Möglichkeit, die Drehzahlregelung über Frequenzumrichter vorzunehmen, verdrängte der Synchronmotor große Gleichstrommaschinen, aber auch Gasturbinen zum Antrieb von Turboverdichtern. Im Bereich kleiner und mittlerer Leistung kommen Motoren mit Permanentmagneten für Hilfs- und Fahrzeugantriebe zur Anwendung. Eine Anwendung im Bereich der Automatisierungstechnik stellt die Kombination von zwei Synchronmaschinen dar. Diese Kombination dient als Sensor und Aktuator zur Übermittlung von Winkelpositionen des Läufers und wird auch als Drehmelder oder als Drehmeldetransformator bezeichnet. Neben Synchronmaschinen werden als Drehmelder auch andere Maschinentypen eingesetzt.
Ein Beispiel für die Verwendung einer kleinen Synchronmaschine außerhalb der Energietechnik stellt der Synchronmotor in der Hammond-Orgel dar.
Die Wirtschaftlichkeit einer Maschine wird unter anderem durch die Anschaffungs- und Betriebskosten sowie den Wirkungsgrad bestimmt. Der Wirkungsgrad der Synchronmaschine (ca. 95…99 % in Abhängigkeit von der Baugröße und der nötigen Erregerleistung) liegt aufgrund der synchronen Strom- und Spannungsphasen generell über dem der Asynchronmaschine. Große Synchronmaschinen wie z. B. der Turbogenerator zählen damit zu den effizientesten Energiewandlern. Wegen der Erregereinrichtung der Synchronmaschine ist der Aufbau der Synchronmaschine komplexer als bei der Asynchronmaschine und damit auch teurer. Der Aufwand für die Steuerelektronik ist ähnlich hoch wie bei der Asynchronmaschine. Permanentmagneterregte Synchronmaschinen erreichen noch höhere Wirkungsgrade, da ihnen keine Erregerleistung zugeführt werden muss. Bei gleichbleibender Leistung und größerer Leistungsdichte verringert sich die Masse der Maschinen oder verringert sich die Baugröße. Generatoren dieser Bauart erreichen in Windkraftanlagen einen Wirkungsgrad von über 98 % und liegen damit über dem Wirkungsgrad von Maschinen gleicher Größe mit elektrischer Erregung. Permanentmagneterregung kommt nur bei Maschinen kleiner bis mittlerer Baugröße zum Einsatz. Die Kosten für die Magnete fallen bei größeren Maschinen immer mehr ins Gewicht, so dass die Wirtschaftlichkeit gegenüber Maschinen mit elektromagnetischer Erregung nicht mehr gegeben ist. Die komplizierte Montage der Magnete stellt außerdem einen großen Nachteil dar.Die folgenden Hersteller sind eine Auswahl mit einigen ihrer Produkte im Bereich der Synchronmaschinen:
Lloyd Dynamowerke – Synchrongeneratoren und -motoren, Hochspannungs-Synchrongeneratoren und -motoren, Schiffsantriebe
VEM Gruppe – Synchrongeneratoren, Hochspannungs-Synchronmotoren, SchiffsantriebeUnter Hochspannungsmotoren oder Hochspannungsgeneratoren versteht man Maschinen mit Bemessungsspannungen über 1 kV. Diese Bezeichnungen kommen daher, dass in den VDE-Vorschriften Spannungen über 1 kV als Hochspannung bezeichnet werden.
stets Erregerleistung notwendig, wenn nicht permanenterregt bzw. teures Material für Permanentmagnete
Damit die Synchronmaschine als elektrischer Generator, also als Drehstrom-Synchrongenerator, arbeiten kann, ist ein Erregerfeld im Läuferkreis notwendig (Innenpolmaschine). Das heißt, durch eine gleichstromerregte Läuferwicklung (Erregerwicklung) oder einen Permanentmagneten muss ein magnetisches Feld (Erregerfeld) erzeugt werden, das in den Strängen der Ständerwicklung eine Ständerspannung 
   induziert. Die Stränge der Ständerwicklung sind zum Stern verkettet. Man erhält an den Generatorklemmen (Enden der Stränge U, V, W) eine Dreiphasenwechselspannung, also drei um 120° phasenverschobene Wechselspannungen. Die Ständerstrangspannung 
    {\displaystyle {\underline {U}}_{\mathrm {S} }={j({\underline {I}}_{\mathrm {S} }\cdot X_{\mathrm {d} })+{\underline {U}}_{\mathrm {p} }}}
  Bei der Verwendung einer Erregerwicklung muss zur Erzeugung des Erregerfeldes Erregerleistung zugeführt werden. Dazu gibt es verschiedene Erregersysteme, beispielsweise die statische Erregereinrichtung oder die bürstenlose Erregereinrichtung. Um bei plötzlichem Lastabwurf Schäden am Generator zu vermeiden, ist bei größeren Maschinen eine eigene Entregungsschaltung vorgesehen.
  ist die Drehfelddrehzahl (bei Synchronmaschinen Drehfelddrehzahl = Rotordrehzahl) auf Minuten bezogen, gilt:
  So laufen bei einer Frequenz der Ständerspannung von 50 Hz = 50/s · 60 s/min = 3000 min−1 ein zweipoliger (
Außerdem ist eine an die Generatorwelle angekuppelte Arbeitsmaschine notwendig wie z. B. ein Verbrennungsmotor oder eine Turbine, die den Läufer mit dem Erregerfeld rotatorisch antreibt. Das bedeutet, die Arbeitsmaschine führt dem Generator mechanische Leistung zu, die der Generator in elektrische Leistung wandelt. Die zugeführte mechanische und die abgegebene elektrische Wirkleistung erhält man rechnerisch wie folgt:
    {\displaystyle P_{\mathrm {el} }=3\cdot U_{\mathrm {iN} }\cdot I_{\mathrm {iN} }\cdot \cos \varphi }
  Diese Gleichung ist gültig für stern- sowie dreieckgeschaltete Maschinen. Wenn bezogene, nicht absolute Werte für die Berechnung verwendet werden, muss die 3 entfernt werden.
  . Beim realen Generator treten jedoch Hysterese- und Stromwärmeverluste sowie Reibungsverluste auf. Dividiert man die abgeführte elektrische Leistung durch die zugeführte mechanische Leistung, erhält man den Wirkungsgrad der Maschine, der immer kleiner als 1 ist, also unter 100 % liegt.
  Die Flussverkettung kann im Leerlaufversuch ermittelt werden. Dazu treibt man die Maschine mit einer bekannten Winkelgeschwindigkeit 
   an und misst die Spannung über einer der Phasen zum Neutralleiter (im vereinfachten einphasigen Ersatzschaltbild entspricht dies der Spannung 
Die Netzschaltung des Generators findet statt, wenn alle Synchronisationsbedingungen hergestellt sind.
Der Generator würde dadurch beschleunigen, doch bildet sich durch die Belastung durch die elektrischen Verbraucher im Netz ein Gegenmoment aus, das dem Moment der Antriebsmaschine entgegenwirkt.
Bei konstanten Momenten bilden sich ein Gleichgewicht und ein konstanter Polradwinkel aus und die synchrone Drehzahl bleibt erhalten; schwankende Belastungen im Netz können dieses Gleichgewicht stören.Die Ständerspannung 
   und konstanter Drehzahl ergeben sich verschiedene Kennlinienverläufe für kapazitive, induktive und ohmsche Lasten. Mit kapazitiver Last ergibt sich eine Spannungsüberhöhung, für ohmsche Last ergibt sich ein schwacher Abfall und für induktive Last ein starker Abfall der Ständerspannung. Um die Ständerspannung konstant zu halten, muss also der Erregerstrom entsprechend der Last geregelt werden. Die Regulierkennlinie stellt dar, wie der Erregerstrom entsprechend den verschiedenen Lasten geregelt werden muss: induktive Last bedarf einer starken Erhöhung des Erregerstroms, ohmsche Last einer schwachen. Um der starken Erhöhung der Ständerspannung bei kapazitiver Last entgegenzuwirken, muss der Erregerstrom stark gesenkt werden. Bei Generatoren in Großkraftwerken wird der Erregerstrom konstant gehalten. Hier erfolgt die Spannungsregelung mittels Stufenschalter der nachgeschalteten Maschinentransformatoren.
Synchrongeneratoren können bei asynchroner Netzschaltung Schaden nehmen, wenn keine Sicherheitseinrichtungen wirken. Eine Fehlsynchronisation eines Generators hat Ausgleichsströme zur Folge, die wiederum Drehmomente nach sich ziehen. Kleine Fehlsynchronisationen und damit verbundene Pendelungen (verursacht durch die Drehmomente) werden durch die Dämpferwicklungen reduziert. Große Fehlsynchronisationen führen zu Schäden am Generator, da die damit verbundenen großen Drehmomente auf die Maschine und das Maschinenfundament wirken.
Soll ein Generator Energie in ein Verbundnetz speisen, so sind vor einer Synchronisation Synchronisations- oder auch Parallelschaltbedingungen zu erfüllen:
gleiche PhasenfolgeFür die Synchronisation stehen verschiedene Geräte und Schaltungen zur Verfügung (Hell- oder Dunkelschaltung, Synchronoskop), jedoch wird heute meist auf die automatische Synchronisation durch digitale Steuerungstechnik vertraut. Der Generator wird nach Herstellung der Synchronisationsbedingungen im Leerlauf ans Netz geschaltet und kann danach elektrisch belastet werden, also elektrische Leistung abgeben.
Für den Motorbetrieb ist wie beim Generatorbetrieb auch eine erregte Läuferwicklung (Erregerwicklung) oder ein Permanentmagnet notwendig, um ein Erregerfeld zu erzeugen. Außerdem muss über die Ständerwicklungen elektrische Energie zugeführt werden, damit der Drehstrom-Synchronmotor ein Drehmoment an der Welle abgeben kann. Die aufgenommene elektrische Leistung berechnet sich wie folgt:
    {\displaystyle P_{\mathrm {el} }={{\sqrt {3}}\cdot U_{\mathrm {S} }\cdot I_{S}\cdot \cos \varphi }}
  Die abgegebene mechanische Leistung entspricht der aufgenommenen elektrischen Leistung, abzüglich des Verlustleistungsanteils 
  Das Verhältnis von abgegebener mechanischer Leistung zu aufgenommener elektrischer Leistung drückt den Wirkungsgrad der Maschine aus.
Das vereinfachte Ersatzschaltbild der Synchronmaschine ist im Abschnitt Generatorbetrieb zu finden. Im Artikel Drehstrommaschine ist das Antriebsprinzip durch ein Drehfeld beschrieben, welches sowohl für Synchron-, als auch Asynchronmotoren gilt.
Der Motor würde seine Drehzahl verringern, doch nimmt der Motor nun elektrische Leistung auf und der Ständerstrom 
   (gegenüber dem Leerlauf → Leerlaufzeigerbild siehe Generatorbetrieb) mit dem Winkel des Polrades entgegen der Drehrichtung.
Der Motor läuft mit synchroner Drehzahl weiter; es entsteht kein Schlupf wie beim Asynchronmotor.Synchronmotoren mit geringer Dämpfung laufen nicht allein an. Der Läufer eines Synchronmotors besitzt in der Regel ein zu großes Massenträgheitsmoment, um dem Drehfeld aus dem Stillstand zu folgen. Deshalb muss die Motordrehzahl unbelastet in die Nähe der Drehfelddrehzahl gebracht werden. Dann wird die Erregung zugeschaltet und der Läufer des Motors wird in den synchronen Lauf gezogen. Danach kann der Motor belastet werden. Für den Anlauf stehen verschiedene Verfahren zur Verfügung:
Anwurfmotor: Ein angekuppelter Anwurfmotor (auch Anlaufmotor) bringt die Drehzahl des Synchronmotors in die Nähe der Drehfelddrehzahl. Nach erfolgter Synchronisation wird der Anwurfmotor abgekuppelt.
Asynchron-Anlauf durch zusätzlichen Dämpferkäfig im Läuferkreis: Durch den Dämpferkäfig kann der Synchronmotor nach dem Prinzip der Asynchronmaschine anlaufen. Erreicht die Motordrehzahl nach Zuschalten der Erregung die Drehfelddrehzahl, verliert der Dämpferkäfig seine Wirkung als Anlaufkäfig und der Motor läuft als Synchronmaschine weiter. Beim Hochlauf ist die Erregerwicklung zumeist über einen Widerstand kurzgeschlossen, um die Induktion hoher Spannungen zu vermeiden und um das Hochlaufmoment zu erhöhen.
Frequenzanlauf: Die Frequenz der Speisespannung wird von Null bis zur Bemessungsfrequenz oder der daraus resultierenden Bemessungsdrehfelddrehzahl kontinuierlich gesteigert. Ein veraltetes Verfahren dazu stellt die Frequenzwandlung mittels vorgeschalteten Asynchrongenerators dar. Die Frequenz der abgegebenen Spannung des Generators wird über die zugeführte Drehzahl oder seinen Schlupf gesteigert. Heute werden leistungselektronische Umrichter zum Frequenzanlauf genutzt. Mit diesem Verfahren ist auch ein Lastanlauf möglich.
Als Phasenschieberbetrieb wird eine Betriebsart der ans Netz synchronisierten Synchronmaschine bezeichnet, bei der fast ausschließlich Blindleistung aus dem Netz bezogen oder in das Netz abgegeben wird. Die Synchronmaschine wird dabei im mechanischen Leerlauf betrieben, die dabei trotzdem aufgenommene, vergleichsweise geringe Wirkleistung dient dazu, die Verluste wie thermische Verluste in den elektrischen Wicklungen oder Verluste zufolge der mechanischen Reibung in den Lagern abzudecken.
Durch Erhöhen oder Absenken des Erregerstroms wird die Höhe der ans Netz abgegebenen oder aus dem Netz aufgenommenen Blindleistung beeinflusst. Bei Übererregung wird induktive Blindleistung abgegeben (Verhalten wie Kondensator) und untererregt nimmt die Synchronmaschine induktive Blindleistung auf (Verhalten wie Spule). Die Abgabe induktiver Blindleistung entspricht einer Aufnahme von kapazitiver Blindleistung und umgekehrt, gemäß der Bezeichnung der Blindleistungs-Flussrichtung. Die Synchronmaschine als Phasenschieber dient primär der Lastflusssteuerung in vermaschten Stromnetzen und sekundär der Blindleistungskompensation.
In der Regel wird eine Synchronmaschine im Phasenschieberbetrieb übererregt betrieben, da Energienetze meist mehr durch induktive als durch kapazitive Verbraucher belastet werden. Energienetze nehmen kapazitiven Charakter durch Leitungskapazitäten an, wenn nur wenige Verbraucher am Netz sind. In diesem Fall wird die Synchronmaschine im Phasenschieberbetrieb untererregt betrieben.
Es wird zwischen reinen Phasenschiebern und Synchrongeneratoren im Phasenschieberbetrieb unterschieden.
Phasenschieber sind speziell auf diese Funktion ausgelegte Synchronmotoren und besitzen als wesentliches Merkmal keine nach außen geführte mechanische Welle. Sie dienen ausschließlich, in Abhängigkeit von der Erregung, der Bereitstellung von induktiver oder kapazitiver Blindleistung im Versorgungsnetz. Phasenschieber finden primär zur Steuerung der Blindleistung in größeren Umspannwerken (Netzknotenpunkten) Anwendung oder werden in der Nähe von größeren Anlagen installiert, deren Blindleistung zu kompensieren ist. Sie können grundsätzlich als Schenkelpolmaschine oder Vollpolmaschine ausgeführt sein.
Synchrongeneratoren im Phasenschieberbetrieb sind herkömmliche Synchronmaschinen und befinden sich beispielsweise in Kraftwerken, die zeitweise und nach Bedarf als Phasenschieber betrieben werden. Beispielsweise laufen Synchronmaschinen in Pumpspeicherkraftwerken, die sich nicht im Pump- oder Generatorbetrieb befinden, im Leerlauf und können so im Phasenschieberbetrieb verwendet werden. Bei Gasturbinenkraftwerken wird der Generator im Phasenschieberbetrieb mittels mechanischer Kupplung von der Gasturbine getrennt, um zusätzliche Wirkleistungsverluste, verursacht durch Kompression in der Gasturbine, zu verhindern.
Betreibt man eine Synchronmaschine mit konstanter Netzspannung im Phasenschieberbetrieb, so lassen sich die nach ihrer Kurvenform benannten V-Kurven aufnehmen. Ändert man bei verschiedenen konstanten Wirkleistungen 
   und über- oder untererregt man damit die Synchronmaschine und trägt man dann die sich ergebenen Ständerströme 
   auf, so erhält man die charakteristischen V-Kurven. Die mit Wirkstrom belastete Synchronmaschine kann zusätzlich so viel aus der Über- oder Untererregung folgenden Blindstrom übernehmen, bis der Bemessungsstrom erreicht ist.
Im Bild sind fünf Kurven mit den Minima P0 bis zu P4 zu sehen, die sich bei verschiedenen Wirk- zu Bemessungsleistungsverhältnissen PS/PN ergeben. In den Minima der Kurven wird nur Wirkleistung umgesetzt, links und rechts davon zusätzlich Blindleistung. Bei der Kurve mit dem Minimum P0 handelt es sich um reinen Phasenschieberbetrieb, dabei wird keine Wirkleistung umgesetzt.
Beim Erreichen der Stabilitätsgrenze fällt die Maschine im Motorbetrieb außer Tritt oder geht im Generatorbetrieb durch.
Mit der Stromortskurve lässt sich das Betriebsverhalten von Synchronmaschinen darstellen. Es lassen sich Aussagen zur Betriebsart, dem Erregergrad und der Betriebsstabilität einer Synchronmaschine treffen. Aus dem vereinfachten Ersatzschaltbild (RS=0; siehe Generatorbetrieb) folgt die Formel für die Ständerspannung:
    {\displaystyle {\underline {I}}_{S}={\mathrm {-j} {\frac {{\underline {U}}_{S}}{{X}_{d}}}+\mathrm {j} {\frac {{\underline {U}}_{P}}{{X}_{d}}}}}
  In der Ortskurve liegt der Zeiger der Ständerspannung in der reellen Achse (Re). Um die Spitze des Zeigers 
   variabel, so dass sich eine konzentrische Schar von Stromortskurven für die Synchronmaschine ergibt. Bei 
Um das Funktionsprinzip einer Synchronmaschine besser verstehen zu können, sollte man die Feldwelle im Luftspalt betrachten. Das nebenstehende Bild zeigt eine zweipolige Synchronmaschine (2 Magnete, ein Nordpol, ein Südpol) mit einer dreiphasigen Einlochwicklung (6 Stränge, 6 Nuten). Die Maschine befindet sich im Leerlauf.
Die x-Achse (0° bis 360°) verläuft im Luftspalt und steht für den Rotorumfang (der hier, um sich nicht auf einen bestimmten Radius festlegen zu müssen, in Graden angegeben wird). Die y-Achse zeigt nach oben und gibt den Wert für die magnetische Flussdichte 
   an. Die z-Achse beschreibt den Drehwinkel von 0° (entspricht im Bild R1) bis 180° (entspricht im Bild R31), also einer halben Umdrehung.
Deutlich zu sehen ist die Wirkung der beiden Magnete, die zunächst ein etwa trapezförmiges Feld von 10° bis 170° beziehungsweise von 190° bis 350° erzeugen. Die mittlere Breite dieses Trapezes (etwa 140°) entspricht in etwa der Breite des Magneten. Dieses Trapez ist unabhängig von dem Drehwinkel (z-Achse) immer vorhanden.
Die schrägen „Rillen“ werden von den Nuten erzeugt: Dort, wo die Nut gerade ist, ist der Luftspalt größer und stellt für den magnetischen Fluss einen größeren Widerstand dar, die Flussdichte ist an dieser Stelle geringer. Da sich die Nuten am Magneten vorbeidrehen, erscheint die Rille im Diagramm schräg. Verfolgt man eine Rille von 
Um nun ein Drehmoment zu erzeugen, muss in den Nuten, die genau unter den Magneten sind, ein Strom fließen. Nach dem Prinzip der Lorentz-Kraft
Um das maximale Moment zu erzeugen (das gleichzeitig das Kippmoment ist), muss der in der Regel sinusförmige Strombelag in Phase mit der Feldwelle sein.
DIN ISO 1940-1 – Anforderungen an die Auswuchtgüte starrer Rotoren; Bestimmung der zulässigen Restunwucht
DIN ISO 7919-… – Mechanische Schwingungen von Maschinen mit Ausnahme von Kolbenmaschinen – Messung und Bewertung von Wellenschwingungen
DIN ISO 8821-… – Mechanische Schwingungen Vereinbarung über die Passfeder – Art beim Auswuchten von Wellen und Verbundteilen
DIN ISO 10816-… – Mechanische Schwingungen – Bewertung von Schwingungen von Maschinen durch Messungen an nicht-rotierenden Teilenfür ex-geschützte Bereiche kommen gesonderte Normen hinzu:
DIN VDE 0166 – Errichten elektrischer Anlagen in durch explosionsgefährliche Stoffe gefährdeten Bereiche
DIN EN 50014 – Elektrische Betriebsmittel für explosionsgefährdete Bereiche; Allgemeine Bestimmungen
DIN EN 50016 – Elektrische Betriebsmittel für explosionsgefährdete Bereiche; Überdruck-Kapselung „p“
DIN EN 50019 – Elektrische Betriebsmittel für explosionsgefährdete Bereiche; Erhöhte Sicherheit „e“
Peter-Klaus Budig: Stromrichtergespeiste Synchronmaschine. Theorie und Anwendungen. VDE-Verlag, Berlin 2003, ISBN 3-8007-2518-5.

Ein Synthetic Aperture Radar (Abkürzung SAR, deutsch etwa „Radar mit synthetischer Apertur“) gehört zur Klasse der abbildenden Radare und wird als Sensor zur Fernerkundung genutzt. Es wird wie ein Side-Looking-Airborne-Radar aus Flugzeugen oder Satelliten eingesetzt und liefert wie diese eine zweidimensionale Darstellung eines Geländeausschnitts durch Abtastung der Erdoberfläche mit elektromagnetischen Wellen, allerdings mit einem sehr viel höheren Auflösungsvermögen. Alle Radargeräte, die nicht das Verfahren für SAR anwenden, werden als Real Aperture Radar (Abkürzung RAR, dt. „Radar mit echter Apertur“) bezeichnet.
Die von einem SAR erzeugten Abbildungen sind aufgrund ihrer Ähnlichkeit mit fotografischen Aufnahmen verhältnismäßig leicht interpretierbar und werden für Erderkundungs-, Kartierungs- und Aufklärungszwecke verwendet. Ein SAR ist im Gegensatz zu optischen Sensoren bei nahezu allen Witterungsbedingungen einsatzfähig, da Trübungen der Atmosphäre durch Nebel, Regen oder Schnee die Mikrowellenstrahlung im Vergleich zu Lichtstrahlen weitaus weniger schwächen. Darüber hinaus kann ein SAR, wie jeder aktive Radarsensor, auch bei Nacht eingesetzt werden. Man spricht in dieser Beziehung auch von einem aktiven Fernerkundungssystem, das die beobachteten Objekte selbst beleuchtet.
Während sich die geometrische Auflösung eines RAR wegen des divergierenden Antennenstrahls mit zunehmendem Objektabstand verschlechtert, kann mit einem SAR eine unter bestimmten Bedingungen von der Schrägentfernung und der Wellenlänge unabhängige Ortsauflösung bis herab in den Meter- und Dezimeterbereich erzielt werden.
Wenn von einem Radar mit synthetischer Apertur gesprochen wird, so wird meist das sogenannte focused SAR gemeint: eine zusätzliche Fokussierung der einzelnen Signale wird dadurch erreicht, dass Phasenunterschiede, die durch Laufzeitunterschiede zwischen den einzelnen Antennenpositionen entstehen, durch den Signalprozessor ausgeglichen werden. Werden keine Phasenkorrekturen an den Echosignalen vorgenommen, spricht man von unfocused SAR.
Das SAR-Prinzip erfordert eine senkrecht zur Strahlrichtung bewegte Antenne, deren Position jederzeit exakt bekannt ist. Die Bewegungsrichtung wird üblicherweise als Along Track oder Azimuth (dt.: ‚Flugrichtung oder Azimut‘) und die Querkoordinate dazu als Cross Track oder Range (dt.: ‚Querrichtung oder Entfernung‘) bezeichnet. In der Literatur wird Along Track auch als Cross Range bezeichnet. Footprint nennt man den Bereich, den die reale Antenne momentan erfasst, Swath (dt. Schwad) den Geländestreifen, den der Footprint durch die Fortbewegung der realen Antenne überstreicht. Die Geometrie entspricht der eines einfachen Side-Looking-Airborne-Radar.
Das Prinzip der synthetischen Apertur (hier noch unfokussiert) besteht darin, die Momentaufnahme einer großen Antenne durch viele Aufnahmen einer kleinen, bewegten Antenne zu ersetzen. Im Verlauf dieser Bewegung wird jedes Objekt im Zielgebiet unter veränderlichem Blickwinkel angestrahlt und entsprechend aufgenommen. Sofern der Weg der realen Antenne hinreichend genau bekannt und die Szenerie unbeweglich ist, kann aus Intensität und Phasenlage der empfangenen Radarechos die Apertur einer großen Antenne synthetisiert und so eine hohe Ortsauflösung in Bewegungsrichtung der Antenne erzielt werden. Praktisch kann man sich das als eine sehr große Phased-Array-Antenne vorstellen, deren Einzelstrahler nicht parallel verschaltet sind, sondern deren Positionen durch eine kleine Antenne zeitlich nacheinander aufgenommen werden. Durch den Radarsignalprozessor werden die einzelnen Amplituden und Phasenlagen so miteinander verbunden, als ob eine Phased-Array-Antenne mit einer sehr großen Apertur verwendet worden wäre. Das azimutale Auflösungsvermögen ist hier noch entfernungsabhängig und beträgt ½(λ∙R)½  mit R als die Entfernung und λ als die verwendete Wellenlänge.
Modernere Rechentechnik ermöglicht, dass für jedes einzelne abgebildete Pixel die Phase des von diesem Ort empfangenen Signals geändert werden kann. Das SAR kann so für jede einzelne Entfernung die Laufzeitunterschiede zwischen den einzelnen Antennenpositionen korrigieren. Orte, die sich näher am Radar befinden, haben aufgrund der trigonometrischen Verhältnisse größere Laufzeitunterschiede, als Orte, die sich weiter weg befinden. Dieser Laufzeitunterschied wird als Phasenunterschied gemessen. Aus den aufgezeichneten Echodaten wird für jeden angestrahlten Ort eine eigene synthetische Antenne berechnet, deren Winkelauflösung im Azimut so gewählt wird, dass für alle betrachteten Entfernungen die geometrische Along-Track-Auflösung gleich ist.
Für die gleiche Winkelauflösung benötigt eine synthetische Apertur nur die halbe Länge einer realen Apertur.
Bei einer realen Apertur beziehen sich Entfernungsänderungen und somit messbare Phasenverschiebungen der Radarechos eines aus Sicht der Antenne parallel vorbei wandernden Objekts immer auf den Ort der Antennenmitte. Bei einer synthetischen Apertur wirken sich zusätzlich die Entfernungs- und Phasenänderungen infolge der nacheinander unterschiedlichen Position der realen Antenne längs der synthetischen Apertur aus.
Damit eine synthetische Apertur realisiert werden kann, ist es zwingend notwendig, dass das Radarsystem voll kohärent arbeitet. Das heißt, die Phasenbeziehung zwischen Sende- und Empfangssignal und von Sendepuls zu Sendepuls muss exakt bekannt sein. Dazu bedient man sich üblicherweise einer hochstabilen Frequenzquelle, von der alle benötigten Misch- und Abtastfrequenzen sowie alle zeitlich periodischen Vorgänge abgeleitet werden.
Die mit einem SAR erzielbare bestmögliche Auflösung ist gleich der halben Länge der realen Antenne in Azimut- bzw. Flugrichtung, d. h. bei einer Verkleinerung der azimutalen Antennenlänge LAz (in der Abbildung oben mit L bezeichnet) der realen Antenne verbessert sich die Auflösefähigkeit δ Az gemäß :
  Zur Herleitung sind im Diagramm oben drei Flugpositionen 1, 2 und 3 der in Azimutrichtung bewegten Antenne eingezeichnet. Wie beim RAR beträgt die azimutale Winkelauflösung 
  'Position 2 markiere den Ort des minimalen Abstandes von einem Objekt im Punkt P zur Flugbahn. Ist S0 die zugehörige Schrägentfernung, dann hat die Achse dAz der bestrahlten Fläche die Länge:
  Der Punkt P wird nicht nur von der mittleren Flugposition 2, sondern auch von jeder Position zwischen 1 und 3 bestrahlt. Der Abstand M der Positionen 1–3 entspricht somit genau dem Durchmesser dAz des Antennenleuchtflecks in der fraglichen Entfernung S0.
Das SAR nutzt sämtliche empfangenen Informationen vom Objekt im Punkt P, die von allen Aufnahmen im Bereich M=dAz stammen. Rechentechnisch wird nach Aufnahme und Speicherung aller Werte eine Antenne mit der azimutalen Länge dAz simuliert, die gemäß der oben erwähnten Eigenschaft der synthetischen Apertur mit einer gemäß Gl. (3) halbierten Auflösung:
    {\displaystyle \delta _{Az}={\frac {\lambda S_{0}}{2}}{\frac {L_{Az}}{\lambda S_{0}}}={\frac {L_{Az}}{2}}}
  Damit ist die Auflösung der synthetischen Apertur unabhängig von Wellenlänge und Objektentfernung.
Eine andere Beschreibung des SAR-Prinzips liefert die Betrachtung der Doppler-Verschiebung der von einem Objekt reflektierten Echosignale: Beim Eintritt in den Strahlenkegel der Antenne werden die von einem Objekt zurückgeworfenen Echos aufgrund der abnehmenden Entfernung in Richtung höherer Frequenzen verschoben. Nach Passieren des Minimalabstandes (miss distance, genau in Querabposition) vergrößert sich der Abstand wieder und die empfangenen Signale werden zu niedrigeren Frequenzen hin verschoben.
Im Empfänger wird die Mittenfrequenz des Echosignals durch Mischung mit der Mittenfrequenz des Sendesignals auf Null gebracht (Superhet- oder Überlagerungsprinzip). Die verbleibenden Abweichungen von Null bezeichnet man als Dopplerfrequenz oder kurz Doppler. Den Dopplerverlauf der Echos eines Objektes von zunächst positiven Werten durch Null zu negativen Werten nennt man Dopplerhistorie.
Jedes Objekt mit derselben Entfernung zur Flugbahn hat auch dieselbe Dopplerhistorie, allerdings zeitlich verschoben, so wie es der Anordnung längs des Flugwegs und der Fluggeschwindigkeit entspricht.
Objekte in anderen Entfernungen haben dagegen entweder, wenn sie näher liegen, eine zeitlich kürzere oder, wenn sie entfernter liegen, eine längere Dopplerhistorie bei gleichem Frequenzumfang, der als Dopplerbandbreite bezeichnet wird.
Bei nicht zu großem Abstrahlwinkel der realen Antenne kann die Dopplerhistorie als linearer Verlauf der Frequenz über der Zeit angesehen werden, d. h., das auf Null abgemischte Echosignal eines Objektes mit Mittenfrequenz Null stellt ein linear frequenzmoduliertes Signal dar.
Diese als (Down-)Chirp bezeichnete Signalform liegt infolge des gepulsten und kohärenten Sendesignals als Folge von komplexwertigen Einzelwerten vor. Multipliziert man diese Einzelwerte mit korrespondierenden Werten eines gleichartigen Chirps, jedoch mit ansteigender Frequenz (Up-Chirp), so heben sich die den Frequenzänderungen zugrunde liegenden Phasendrehungen auf. Die Addition der resultierenden Einzelwerte liefert nun das Ergebnis der synthetischen Apertur für das speziell betrachtete Objekt.
Diesen Vorgang nennt man Korrelation. Die für jede Entfernung passend zu erzeugende Korrelationsfunktion wird Replika genannt. Sie entspricht im Idealfall den konjugiert komplexen Echowerten eines punktförmigen Zieles.
Während eine angepasste Korrelationsfunktion eine konstruktive Addition aller Einzelbeiträge bewirkt, hat eine nicht angepasste Funktion lediglich ein zufälliges Additionsergebnis zur Folge. Auf diese Weise wird das Echo des betrachteten Objekts, welches gleichzeitig mit den Echos anderer, ebenfalls angestrahlter Objekte am Radarempfänger eintrifft, aus dem Signalgemisch ausgefiltert.
   der sich ständig ändernde azimutale Winkel ist, den die Richtung zum Objekt bei P mit der Antennenachse bildet, ist die dem Winkel zugeordnete Dopplerverschiebung des Echosignals dieses Objekts gegeben durch:
    {\displaystyle f_{D}(\varphi )=2{\frac {v_{0}}{\lambda }}\sin \varphi \approx 2{\frac {v_{0}}{\lambda }}\varphi }
Die gesamte Dopplerbandbreite BD des Echosignals ergibt sich, wenn man die maximal genutzten Azimutwinkel einsetzt und die Werte voneinander subtrahiert:
    {\displaystyle B_{D}=f_{D}\left({\frac {\varphi _{Az}}{2}}\right)-f_{D}\left({\frac {-\varphi _{Az}}{2}}\right)\approx {\frac {v_{0}}{L_{Az}}}-{\frac {-v_{0}}{L_{Az}}}={\frac {2v_{0}}{L_{Az}}}}
  Die Frequenz eines Signals der Dauer T kann bestenfalls mit einer Frequenzauflösung δf = 1/T bestimmt werden. Auf das SAR-Signal angewendet heißt dies, dass die bestmögliche Frequenzauflösung durch die verfügbare Beobachtungszeit bestimmt wird. Diese ist aber gleich der Zeit, die das Radar zum Durchqueren der Strecke M = dAz benötigt:
  begrenzt. Gemäß Gl. (6) entspricht diese Dopplerfrequenzauflösung einer räumlichen Winkelauflösung von:
    {\displaystyle \delta \varphi \approx {\frac {\lambda }{2v_{0}}}\delta f_{D}={\frac {L_{Az}}{2S_{0}}}}
    {\displaystyle K={\frac {B_{D}}{\delta f_{D}}}=2{\frac {\lambda S_{0}}{L_{Az}^{2}}}=T_{SAR}B_{D}}
  Filter aneinandergereiht die gesamte Dopplerbandbreite abdecken. Die Echos eines Objekts erscheinen, entsprechend ihrer momentanen Dopplerverschiebung, nacheinander am Ausgang eines jeden Filters. Erfasst man diese Signale und addiert sie zeit- und phasenrichtig, so wird das Ergebnis eine K-fach höhere Amplitude aufweisen, verglichen mit einem Signal am Ausgang eines Filters. Die Energie dieses Nutzsignals steigt also auf den K²-fachen Wert, die Energie unerwünschter Signalbestandteile, wie Rauschen oder Echos von Nachbarobjekten dagegen, wegen der zufälligen Natur der Additionen, nur auf das K-fache. Damit verbessert sich der Störabstand (SNR = Signal-to-Noise-Ratio) – das ist das Verhältnis von Nutzenergie zu Störenergie – ebenfalls um das K-fache.
Der Wert K = TSAR BD wird als Zeit-Bandbreitenprodukt bezeichnet. Wie man leicht nachrechnen kann, ist die Auflösung gleich der synthetischen Aperturlänge, dividiert durch das Zeit-Bandbreitenprodukt sowie gleich der Fluggeschwindigkeit dividiert durch die Dopplerbandbreite:
    {\displaystyle \delta _{Az}={\frac {L_{SAR}}{T_{SAR}B_{D}}}={\frac {v_{0}T_{SAR}}{T_{SAR}B_{D}}}={\frac {v_{0}}{B_{D}}}}
Um in 10 km Entfernung eine Azimut-Auflösung von 1 m zu erzielen, ist bei einer Verwendung einer realen Antenne eine Aperturlänge von 10 km / 1 m = 10.000 Wellenlängen erforderlich. Bei 10 GHz Sendefrequenz, entsprechend 3 cm Wellenlänge, sind das rund 300 m, also eine praktisch nicht realisierbare Größe.
Wie oben erwähnt, braucht eine entsprechende synthetische Apertur nur halb so lang zu sein. Die gleiche Auflösung wird also mit Echodaten bewerkstelligt, die längs einer Strecke von 5.000 Wellenlängen bzw. 150 m aufgezeichnet wurden. Die reale Antenne muss aber sicherstellen, dass das betreffende Objekt während des ganzen Weges angestrahlt werden kann. Dazu ist eine reale Aperturlänge in Azimut von 10 km / 5.000 = 2 m erforderlich.
Aus der Länge der synthetischen Apertur (hier im Beispiel L = 150 m) kann ein virtuelles Nah- und Fernfeld der synthetischen Apertur der Antenne berechnet werden. Die Grenze zwischen beiden Regionen liegt bei rfern ≈ 2 · L2 / λ und hier bei etwa 1500 km. Erst danach würden die elektromagnetischen Wellen der einzelnen Quellorte eine ebene Wellenfront bilden. Die meisten Satelliten haben ihre Umlaufbahn innerhalb dieser Entfernung, sie befinden sich also im Nahfeld der synthetischen Apertur. Die Entfernung zum Ziel unterscheidet sich zwischen den Positionen der Plattform. Wenn sich das Ziel auf der Mittelachse der realen Apertur befindet ist die Entfernung geringer als wenn die reale Antenne von einer Randposition zum Ziel hin schielen muss. Das drückt sich in einem Phasenunterschied Δφ aus. Somit kann nicht eine einfache Summierung der Realanteile der Einzeldiagramme vorgenommen werden, sondern es muss wie im Nahfeld notwendig auch der Imaginäranteil berücksichtigt werden. Daraus ergibt sich, dass in der Bildbearbeitungssoftware für jede einzelne Impulsperiode eine Phasenkorrektur vorzunehmen ist um ein scharfes Abbild zu erzeugen, was zu dem Begriff „focused SAR“ führt.
Das Zeit-Bandbreitenprodukt beträgt nach Gl. (12) dann 2 × 3 cm × 10 km / (2 m × 2 m) = 150, so wie es gemäß Gl. (13) auch sein muss. Bei einer Fluggeschwindigkeit von 100 m/s ist die Dopplerbandbreite 100 Hz, die Aperturzeit 1,5 s und die bestmögliche Frequenzauflösung 0,67 Hz.
Die Bildkoordinate senkrecht zur Flugrichtung (Range) wird ebenso wie beim RAR (auch: Side-Looking-Airborne-Radar,SLAR) durch Entfernungsmessung erzeugt. Diese erfolgt durch Auswertung der unterschiedlichen Signallaufzeiten der Echos verschieden weit entfernter Objekte. Eine solche Messung kann nur in radialer Richtung (= Ausbreitungsrichtung des Sendesignals) erfolgen. Damit eine Bodenfläche in Querrichtung durch eine Entfernungsmessung abgebildet werden kann, muss die Antennenblickrichtung eine seitliche Komponente aufweisen. Somit ist der (auf den Boden projizierte) Flugweg eines SAR immer in einem gewissen Abstand parallel zur nahen Kante des Schwades.
Die Auflösung in radialer Richtung (Slant Range) wird grundsätzlich durch die Signalbandbreite des verwendeten Sendesignals bestimmt. Bei steilen Einfallswinkeln verschlechtert sich die erzielbare Range-Auflösung in der Ebene (Ground-Range Resolution) entsprechend der Projektion der radialen Auflösungsstrecke auf den ebenen Boden. Bei 45° Einfallswinkel ist sie daher um den Faktor 1,4 schlechter als in radialer Richtung. Bei senkrechtem Einfall ist eine Entfernungsauflösung in der Ebene nicht mehr definiert.
Damit sich eine bildhafte Darstellung des abgeflogenen Geländes ergibt, ist es sinnvoll, die Ground-Range-Auflösung vergleichbar zur Azimut-Auflösung zu wählen. Maßgebend für die Slant-Range-Auflösung ist zunächst die Bandbreite 
  c ist die Lichtgeschwindigkeit. Für 1 m Auflösung sind also 150 MHz Signalbandbreite erforderlich.
Gegenüber der Slant-Range-Auflösung ist die Ground-Range-Auflösung infolge der Projektion umso stärker herabgesetzt, je steiler der Streifwinkel ε des einfallenden Strahls gegenüber dem Boden ist:
  Daher wird die Entfernungsauflösung häufig entsprechend feiner als die Azimut-Auflösung gewählt (bei 45° also etwa 70 % vom Azimutwert).
In den ersten Dekaden der Radarentwicklung verwendete man unmodulierte Pulse, d. h. Signale, die zum Beispiel aus einem kontinuierlichen Signal (CW von engl. Continuous Wave) durch kurzes Hochtasten der Senderöhre 'ausgeschnitten' wurden. Ein solches Signal hat eine Bandbreite, die seiner Dauer umgekehrt proportional ist:
  Steigende Auflösungsanforderungen führten demnach zu immer kürzeren Pulsen; den dadurch reduzierten Energieinhalt versuchte man durch immer höhere Sendeleistungen zu kompensieren. Je nach Frequenzbereich konnten 10 MW oder höhere Pulsleistungen realisiert werden. Einer Erhöhung der Pulswiederholfrequenz (PRF, Pulse Repetition Frequency) zur Verbesserung der Energiebilanz stehen häufig andere Gesichtspunkte, wie u. a. die Entfernungseindeutigkeit, entgegen.
Weil sich die Pulsleistung aus technischen Gründen (Spannungsfestigkeit der Bauteile) nicht beliebig steigern lässt, ging man in den 60er Jahren zunehmend zu den Pulskompressionsverfahren über. Hierzu wird ein vergleichsweise langer Puls während der Aussendung in seiner Frequenz geändert. Am häufigsten wird eine lineare Frequenzmodulation (LFM) angewendet, bei der sich die Sendefrequenz linear von einer unteren Grenze bis zu einer oberen Grenze (Up-Chirp) oder umgekehrt (Down-Chirp) ändert. Der Begriff Chirp kommt daher, weil sich ein akustisches LFM-Signal wie Zwitschern anhört. Fledermäuse verwenden übrigens diese Signalform im Ultraschallbereich.
Empfängerseitig wird dieses Signal durch geeignete Verfahren in einen der Bandbreite entsprechenden kurzen Puls verwandelt.
Zu Beginn verwendete man analoge SAW-Komponenten (SAW = surface acoustic wave, dt. akustische Oberflächenwelle) zur Pulsexpansion und -kompression. Ein kurzer Puls regt eine akustische Oberflächenwelle an, die über ein Substrat mit dispersiven Eigenschaften läuft. Am anderen Ende des Substrates kommen die verschiedenen Frequenzanteile zu unterschiedlichen Zeiten an und bilden so den erwünschten LFM-Puls. Zur Kompression wird ein gleichartiges SAW-Bauteil mit komplementärer Charakteristik verwendet und der gestreckte Puls so wieder zeitlich unter Beibehaltung seiner Bandbreite auf seine ursprüngliche Länge komprimiert.
Seit etwa Mitte der 1980er Jahre die Digitaltechnik in Frequenzbereiche jenseits von 100 MHz vorgestoßen ist, werden praktisch nur noch digitale Signalprozessoren verwendet. Diese verwenden schnelle Digital-Analogwandler, die aus vorherberechneten Daten das Signal – ggf. in mehreren zusammenzusetzenden Frequenzabschnitten – synthetisch erzeugen. Beim Empfang wird das Echo unkomprimiert digitalisiert und die Pulskompression durch ein Korrelationsverfahren im Rechner vorgenommen. Der Vorteil der digitalen Technik liegt darin, dass die Replika für die Kompression unmittelbar aus dem Sendesignal durch Einschleifen in den Empfänger gewonnen werden kann. Die im Sendesignal enthaltenen Abweichungen von der idealen Form, zum Beispiel durch Verzerrungen im Hochfrequenz-Sendeverstärker (HPA von engl. High Power Amplifier), werden somit unmittelbar erfasst. Durch Bildung der konjugiert komplexen Funktion aus den abgetasteten Daten wird die Replika erzeugt. Eine Kompression mit dieser Referenzfunktion entspricht einer Filterung mit einem angepassten Filter (engl. Matched Filter), welches, bei weißem Hintergrundrauschen, das Ausgangssignal mit dem höchstmöglichen Signal/Rausch-Abstand (engl. Signal/Noise-, kurz S/N-Ratio) liefert.
Die Eigenschaften der Pulskompression entsprechen denjenigen des SAR-Signals im Dopplerbereich. So gibt auch hier das Zeit-Bandbreitenprodukt (häufig größer als 1000) den Verkürzungsfaktor für das Chirp-Signal ebenso wie den Gewinn an Störabstand.
Abschließend sei noch bemerkt, dass die für eine bestimmte Auflösung erforderliche Bandbreite auf mehrere Pulse verteilt werden kann (Frequency-Step-Verfahren). Dadurch sinken kostspielige Bandbreitenanforderungen an die Radarkomponenten. Gleichzeitig steigt jedoch die Komplexität der radarinternen Steuerung und des SAR-Prozessors.
Dieser Typ Antenne ähnelt den vielfach verwendeten Satelliten-TV-Empfangsantennen. Die Eigenschaften wie Größe, Bündelungsfähigkeit, Nebenzipfelverhalten u. a. werden unveränderlich beim Entwurf festgelegt. Für eine Schwenkung im Raum (zum Beispiel bei Elevation oder Azimut) muss eine mechanische Drehvorrichtung und/oder mehrere Feed-Elemente vorgesehen werden. Der Vorteil dieses Antennentyps liegt in seiner Eignung für große Bandbreiten bei kostengünstiger Realisierung. Die Reflektorantenne erfordert einen HF-Leistungsverstärker (HPA, High Power Amplifier) als Quelle für das Sendesignal. Die praktisch erforderlichen HF-Leistungen im Bereich von etwa 1 bis 10 kW können gegenwärtig nur durch Röhrenverstärker, meist Wanderfeldröhren (Traveling Wave Tube Amplifier, kurz TWTA) bereitgestellt werden.
Eine Phased-Array-Antenne setzt sich aus vielen Einzelstrahlern zusammen, die auf einer ebenen Fläche in einem regelmäßigen Raster angeordnet sind. Jeder dieser Strahler oder auch eine Strahlergruppe ist über einen Phasenschieber mit einem Speisenetzwerk verbunden. Die Blickrichtung der Antenne kann durch Änderung der Phasenschiebereinstellungen in einem weiten Bereich (bei Festinstallationen bis zu ±60°) elektronisch geschwenkt werden. Der Vorteil ist die praktisch verzögerungsfrei agierende Strahlsteuerung, wie sie bei Multimode-Radargeräten und speziellen SAR-Modi häufig erforderlich ist. Nachteilig sind die im Vergleich zur Reflektorantenne hohen Kosten. Große Schwenkwinkel und hohe Signalbandbreite erfordern spezielle Speisenetzwerke mit in Echtzeit steuerbarer Laufzeit (engl. True Time Delay, kurz TTD), um der Dispersion der Signale zu begegnen. Auch die passive Array-Antenne benötigt eine zentrale Leistungsquelle in Form eines HPA.
Diese erst in neuerer Zeit realisierbare Antenne ist eine Array-Antenne, bei der jeder Strahler oder kleine Gruppen von Strahlern jeweils einen eigenen Sendeverstärker und ein eigenes Empfangsteil besitzen (Active Electronically Scanned Array). Die Agilität dieses Antennentyps entspricht derjenigen der passiven Array-Antenne, wobei ein zusätzlicher Freiheitsgrad durch selektive Abschaltmöglichkeit einzelner Sendeverstärker hinzukommt. Der hohe Aufwand wird durch einige Vorteile gerechtfertigt. So gestattet die verteilte Erzeugung der Sendeenergie, Halbleiterverstärker mit niedriger Betriebsspannung zu benutzen. Außerdem führt der Ausfall einzelner Verstärker nicht zur Unbrauchbarkeit des Gesamt-Systems (Redundanz).
Zu Beginn der SAR-Technologie in den 1950 bis 1960er Jahren gab es nur die analoge Signalverarbeitung. Zur Pulskompression benutzte man SAW-Techniken und zur SAR-Fokussierung optische Prozessoren in Form konisch und zylindrisch geschliffener Linsen. Der Nachteil: die Linsen waren nur für eine genau definierte Geometrie bzgl. Höhe und Seitenabstand verwendbar. Mit diesen Verfahren gelang es zwar, Auflösungen im m-Bereich zu realisieren, jedoch führte die fehlende Bewegungskompensation nur in Ausnahmefällen zu optimalen Resultaten.
Erst mit der Einführung schnellerer Rechner und Analog-/Digitalwandler zu Anfang der 1980er Jahre erlebte das SAR-Prinzip den erhofften Durchbruch. Bedingt durch die anfangs kärgliche Rechenleistung suchte man nach rechenzeitsparenden Algorithmen zur SAR-Prozessierung. Das zunächst zur Anwendung gekommene Prinzip war der Range-Doppler-Prozessor, bei dem die Fokussierung in den beiden Koordinaten hauptsächlich durch die schnelle Fourier-Transformation (FFT von engl. Fast Fourier Transformation) erledigt wurden. Diese Prozessoren arbeiteten noch off-line mit Datenaufzeichnung und lieferten die Ergebnisse erst nach der jeweiligen Befliegung.
Inzwischen sind weitere Algorithmen (Chirp Scaling, Frequency Scaling u. v. a.) verfügbar. Diese nun erlauben eine echtzeitfähige SAR-Prozessierung auch für sehr spezielle SAR-Modi (s. u.).
Eine SAR-Fokussierung hat nur dann ein gutes Ergebnis zur Folge, wenn der Ort der Antenne weniger als etwa λ/16 von der idealen Flugbahn abweicht. Bei 10 GHz Sendefrequenz sind das weniger als 2 mm! Eine der wichtigsten Aufgaben eines SAR-Prozessors für Systeme im Lufteinsatz ist daher heute die Bewegungskompensation. Dazu werden einerseits die Lage- und Bewegungsdaten hochempfindlicher, GPS-gestützter Kreiselplattformen aufgezeichnet und ausgewertet und zusätzlich Autofokus-Rechenverfahren angewendet, um die unvermeidlichen Abweichungen von einer idealen Flugbahn zu erkennen und zu beseitigen. Autofokusverfahren erfordern ein mehrfaches Berechnen von SAR-Bildausschnitten, um daraus die Bewegungsfehler zu ermitteln. Daher ist die erforderliche Rechenkapazität bei Echtzeitanforderungen erheblich höher als bei Systemen ohne Autofokus-Fähigkeit.
Dieses Verfahren ist das Standardverfahren: Das Antennendiagramm wird im Cross Track oder Range Bereich nicht geschwenkt. Der Schwad liegt parallel zum ground track (Projektion des Flugweges auf die Erdoberfläche).
Ein SAR-Bild kann auch dann erzeugt werden, wenn die Blickrichtung der Antenne nicht querab, sondern schräg nach vorn oder hinten gerichtet ist. Die Prozessierung erfordert zusätzliche Algorithmen zur Korrektur der sich nicht rechtwinklig schneidenden Koordinaten Range und Doppler. In Vorausrichtung und unterhalb des Flugweges versagt das SAR-Prinzip aus prinzipiellen Gründen.
Bei diesem SAR-Verfahren wird die Azimut-Auflösung gegenüber der in (1) angegebenen Grenze dadurch verbessert, dass die Antenne für längere Zeit fest auf ein bestimmtes Zielgebiet (Spot) gerichtet bleibt; im Azimut also entsprechend gedreht wird. Dadurch erhöht sich das Zeit-Bandbreitenprodukt und mithin verbessert sich die erzielbare Auflösung. Dies geschieht allerdings auf Kosten der insgesamt abbildbaren Fläche, denn der nächste Spot kann erst in einem durch die Beobachtungszeit und die Fluggeschwindigkeit bestimmten Abstand ins Visier genommen werden.
Hierbei macht man von der Agilität einer passiven oder aktiven Array-Antenne Gebrauch, indem mehrere Streifen in verschiedenen Abständen und Squint-Winkeln quasi gleichzeitig nach einem ausgeklügelten Ablaufplan bedient werden.
Bedingt durch die kohärente SAR-Signalverarbeitung, eignet sich das SAR auch für dreidimensionale Abbildungen. Dazu wird in einer geringen Höhe oberhalb der SAR-Antenne eine zweite Antenne mit komplettem Empfangszug installiert. Die aus beiden Empfängern stammenden komplexen SAR-Bilder unterscheiden sich aufgrund der unterschiedlichen Echo-Laufwege in der Phase. Dieser Phasenunterschied kann zur Bestimmung der Objekthöhen und somit zur Erstellung eines dreidimensionalen Geländemodells genutzt werden. Bei Vorhandensein eines festen Bezugspunktes lassen sich durch differenzielle Interferometrie exakte Höhen mit Genauigkeiten bis in den mm-Bereich hinein bestimmen.Das Verfahren funktioniert auch bei Systemen mit nur einer Empfangsantenne. Dazu wertet man die Aufnahme-Daten zweier paralleler Flugwege interferometrisch aus (Two-Pass Interferometrie). Wegen des zeitlichen Abstandes beider Aufnahmen werden bewegte Elemente jedoch nicht erfasst.
Ein polarimetrisches Radar ist in der Lage Wellen unterschiedlicher Polarisierung zu senden und zu empfangen. Aus der Polarisierung der empfangenen Wellen bzw. der Polarisationsänderung lassen sich weitere Informationen über das abgebildete Gelände gewinnen, die zum Beispiel die Unterscheidung zwischen Wald und Häusern erleichtern.
Das ISAR stellt eine Umkehr des klassischen SAR-Prinzips dar: die Radarantenne steht fest und das beobachtete Objekt bewegt sich. Die erzielbare Auflösung wird durch das Zeit-Bandbreitenprodukt der Echosignale bestimmt. Das Verfahren wird zum Beispiel zur Abbildung von Satelliten verwendet. Ferner kann ein im Seegang oder durch eigene Fahrt bewegtes Schiff durch ISAR so abgebildet werden, dass der Schiffstyp erkennbar wird.
Bei bistatischem bzw. multistatischem SAR sind Sender und Empfänger auf zwei bzw. mehreren Trägerplattformen montiert. Somit können mehr Informationen über die Rückstreueigenschaften mit flexibleren Ein- und Ausfallswinkeln gewonnen werden. Eine technische Schwierigkeit ist dabei die Synchronisation der Oszillatoren. Auch müssen bei der Prozessierung neue Verfahren angewendet werden.
Die mittels SAR gewonnenen Abbildungen weisen einige Besonderheiten auf, die bei der Auswertung berücksichtigt werden müssen:
Als Foreshortening bezeichnet man eine verkürzte Darstellung tatsächlicher Entfernungen (Stauchung von Entfernungen). Man stelle sich einen Berg vor, der von den Radar-Strahlen eines SAR abgetastet wird. Die Basis des Berges (im Bild: a) reflektiert zuerst die Radar-Strahlen, danach den Gipfel (im Bild: b). Liegen die beiden Zeitpunkte der Reflexion sehr dicht beieinander, wird die tatsächliche Entfernung (a – b) zwischen Basis und Gipfel des Berges gestaucht (a' – b') wiedergegeben. Dieser Effekt erschwert die Interpretation einer Gebirgslandschaft.
Bei einem hohen Objekt, wie beispielsweise einem Turm, hat die Turmspitze einen geringeren Abstand zum Radar als der Fußpunkt. Die Spitze des Turmes wird früher, also näher, abgebildet. So entsteht der Eindruck eines Überhanges in einem Radar-Bild: der Punkt b' würde noch vor dem Punkt a' dargestellt. Dies kann wie beim Foreshortening bei Abbildungen von gebirgigen Geländen zu Interpretationsschwierigkeiten führen.
Bedingt durch die Ausleuchtung mittels mitgeführter „Lichtquelle“ weisen die Abbildungen Schatten, also Orte ohne reflektierte Echos, auf. Diese entstehen, wie bei der optischen Abbildung, dort, wo Gebiete durch höhere Objekte vom Radarstrahl abgeschattet werden. Der Effekt ist umso ausgeprägter, je flacher der Streifwinkel und je höher das schattenwerfende Objekt ist. Andererseits erlauben die Schatten auch ein gutes Interpretieren der plastisch wirkenden Abbildungen. Ein Streifwinkel von 5° gilt als untere Grenze für gut auswertbare SAR-Bilder.
Ein bewegtes Objekt wird am falschen Ort abgebildet. Dies erfolgt deshalb, weil sich zu der Dopplerhistorie eines festen Objekts der Dopplerversatz des bewegten Objekts addiert bzw. subtrahiert. Dies entspricht aber der Historie eines später oder früher angeordneten Objekts. Ein Objekt, das sich vom Satelliten aus gesehen fortbewegt, erscheint in Azimuthrichtung näher. :  Das SAR-Foto rechts wurde von einem Satelliten aufgenommen, der nach Norden, also vom unteren zum oberen Bildrand, geflogen ist und seinen SAR-Sensor nach Osten, also nach rechts, ausgerichtet hatte. Schiffe sind als helle Reflexionen zu erkennen. Ölabsonderungen auf ihrem Fahrtweg dämpfen Oberflächenwellen. Von dort wird Radarstrahlung nur geringfügig reflektiert, die Fahrspur erscheint schwarz. Ausgeprägte Bugwellen sind zu erkennen. Schiffe, die sich von rechts nach links auf den Satelliten zu bewegen, erscheinen in Flugrichtung des Satelliten nach oben versetzt. Die Schiffe befinden sich oberhalb ihrer Fahrspur. Entsprechend erscheinen die nach rechts fahrenden Schiffe im unteren Bildteil unterhalb der dunklen Fahrlinie.
Unter Speckle versteht man die Eigenart einer kohärenten Abbildung, dass flächige Objekte, wie zum Beispiel bestellte Äcker, von Bildpunkt zu Bildpunkt, aufgrund der zufälligen Zusammensetzung der Echos aus Einzelbeiträgen, völlig andere Werte annehmen können. Bilder mit Speckle wirken daher zerrissen und körnig. Speckle kann, auf Kosten der Auflösung, durch die Anwendung des Multilook-Verfahrens reduziert werden. Dazu werden mehrere schlechter aufgelöste SAR-Bilder aus unterschiedlichen Dopplerbereichen berechnet und anschließend inkohärent (energiemäßig) addiert. Die zufällige Verteilung der Werte eines Flächen-Bildpunkts sorgt für eine Reduzierung des Speckle.
Durch seine vielseitigen Anwendungsmöglichkeiten, insbesondere in der Fernerkundung, hat SAR eine weltweite Bedeutung erlangt, so dass die Gründung einer eigenen, speziell auf SAR fokussierten Tagung notwendig erschien. Die Eusar ist schwerpunktmäßig dem Radarsensor, seinen Technologien einschließlich bilderzeugender Signalverarbeitung und Bildverarbeitung gewidmet, bietet aber auch ein Forum für Anwender von SAR-Daten. EUSAR ist bis heute die einzige auf SAR spezialisierte Tagung weltweit.
Flugzeuggetragene SAR-Systeme werden, aufgrund ihrer Allwetterfähigkeit, vorwiegend für militärische Aufklärung eingesetzt. Die derzeit (2005) technisch erzielbare geometrische Auflösung liegt bei unter 15 cm, was eine HF-Bandbreite von mehr als 1 GHz erforderlich macht. Da Aufklärungsradar mehrere Betriebsmodi besitzt, arbeitet dies System stets mit elektronisch schwenkbaren passiven oder zunehmend auch aktiven Array-Antennen mit Längen von 1–4 m in Azimut. Auf Bewegungskompensation und Echtzeitfähigkeit wird großer Wert gelegt, d. h., die Systeme erzeugen hoch aufgelöste Abbildungen an Bord und übermitteln sie den auswertenden Stellen am Boden. Die dazu erforderliche Rechenkapazität erfordert, sowohl beim Einbauvolumen, als auch bei der Primärenergie, den größten Teil der an Bord verfügbaren Ressourcen. Siehe auch SOSTAR-X.
Eine andere Klasse stellen Mini-SARs für den Einsatz an Bord von Marschflugkörpern (Drohnen) dar. Hier ist kleinstmöglichstes Bauvolumen bei hoher Auflösung (< 1 m) und mäßiger Streifenbreite (1–3 km) gefragt. Inzwischen kann auch bei diesen Anwendungen die erforderliche Prozessorkapazität an Bord installiert werden, so dass nur noch schon aufgearbeitete End-Ergebnisse per Telemetrie zum Boden übertragen werden müssen. Bei hohen Trägergeschwindigkeiten sind die erforderlichen Maßnahmen zur Bewegungskompensation gering, so dass der Prozessor an Bord durch diese Unter-Aufgabe nur verhältnismäßig wenig belastet ist.
Zivil wird das SAR praktisch ausschließlich zu Kartierungszwecken, fast stets in der Form des interferometrischen SAR an Bord von Turboprop-Maschinen aus eingesetzt. Deren geometrische Auflösung liegt üblicherweise im Bereich 0,5–2 m. Das Jet Propulsion Laboratory verwendet zurzeit eine Gulfstream III u. a. zur Erforschung der Folgen der Ölpest im Golf von Mexiko.
Anfänglich wurde Satelliten-SAR als reine Forschungsprojekte realisiert, derzeitig tritt es in die Phase zunehmender militärischer und ziviler Nutzung ein.
Militärisch wird die Aufklärung eines jeden Punktes auf der Erde innerhalb gegebener Zeiten mit Auflösungen im Bereich unter 1 m verlangt. Dazu sind mehrere Satelliten mit gleicher Ausrüstung und abgestimmten Flugbahnen erforderlich. Um die Kosten im Rahmen zu halten, sind Abstriche bei der Ausstattung unumgänglich. So ist die anfangs vor Jahren noch geforderte aktive Array-Antenne bei praktischen Systemen (zum Beispiel SAR-Lupe) längst einer einfachen Reflektorantenne gewichen.
Auf ziviler Seite werden die forschungsorientierten SAR-Systeme der Vergangenheit allmählich durch kommerzielle Angebote zur Abbildung kundenspezifischer Areale abgelöst. Auch hier führt der Zwang zur Kostensenkung zur Bevorzugung möglichst einfacher Systeme.
Das Foto rechts zeigt ein SAR-Bildbeispiel. Die kleinen weißen Punkte sind Ölstationen, die schwarzen Flächen dünne Ölfilme. Die langperiodischen Wasserwellen oben sind sog. innere Wellen, die kleinen Wellen mit Wellenlängen um 100 m, siehe unterer Pfeil, sind durch Wind erzeugte Oberflächenwellen. Die Detailauflösung des 25 × 34 km² großen Areals ist besser als 100 m.
Von den Raumsonden Venera 15, 16 und Magellan wurde nach dem SAR-Verfahren der Planet Venus kartiert. Die Raumsonde Cassini-Huygens kartiert mit dem SAR-Verfahren den Saturnmond Titan.
Weitere Informationen über bereits realisierte oder in der Entstehung begriffene Satelliten-SAR-Systeme können den hier angeführten Seiten entnommen werden:
SAR in den Medien: Artikel „Stille Wächter über uns“ in der Neuen Zürcher Zeitung (NZZ) (PDF; 290 kB)
Shahan A. Hovanessian: Introduction to Synthetic Array and Imaging Radars. Artech House, Dedham MA 1980, ISBN 0-89006-082-7.
George W. Stimson: Introduction to Airborne Radar. Hughes Aircraft Co., El Segundo CA 1983.In Einzelkapiteln weitreichender Zusammenstellungen von Radaranwendungen und -technologien wird das SAR-Prinzip in den Büchern des Radar-"Papstes" Skolnik abgehandelt:
Merrill I. Skolnik: Introduction to Radar Systems. 2nd edition. McGraw-Hill Kogakusha Ltd., New York NY u. a. 1980, ISBN 0-07-057909-1.
Merrill I. Skolnik (Hrsg.): Radar Handbook. 3nd Edition. McGraw-Hill, New York NY 2008, ISBN 978-0-07-148547-0, (Chapter 17).Mehr auf der Theorie der Signalverarbeitung basierende Abhandlungen findet man bei:
David K. Barton: Radars. Band 3: Pulse Compression. Artech House, Dedham MA 1975, ISBN 0-89006-032-0.

T-Lymphozyten oder kurz T-Zellen bilden eine Gruppe von weißen Blutzellen, die der Immunabwehr dient. T-Lymphozyten stellen gemeinsam mit den B-Lymphozyten die erworbene (adaptive) Immunantwort dar. Das T im Namen steht für den Thymus, in dem die Zellen ausreifen.
Wie alle Blutzellen werden T-Zellen im Knochenmark erzeugt. Von dort wandern sie in den Thymus, wo MHC-Rezeptoren auf ihrer Oberfläche ausgebildet werden. Durch zunächst eine positive Selektion, mit einer anschließenden negativen Selektion werden all diejenigen ausgemustert, die auf körpereigene Proteine reagieren, oder körpereigene MHC-Rezeptoren nicht erkennen können. Die restlichen, übrig gebliebenen T-Zellen können dann nur körperfremde Antigene erkennen und bekämpfen den Körper dadurch nicht selbst. Die Proteine in den selektierten Zellmembranen, auch T-Zell-Rezeptoren (TCR) genannt, können dann – ähnlich wie die von B-Lymphozyten produzierten Antikörper – körperfremde Stoffe erkennen. Im Gegensatz zu Antikörpern erkennen T-Zellen körperfremde Stoffe jedoch nur dann, wenn deren Antigene auf der Oberfläche anderer Zellen an deren MHC gebunden sind. Freie Antigene werden von T-Lymphozyten nur erkannt, wenn sie von sogenannten antigenpräsentierenden Zellen aktiv vorgezeigt werden (sog. MHC-Restriktion).
T-Zellen wandern durch den Organismus und überwachen ständig die Membranzusammensetzung der Körperzellen auf krankhafte Veränderungen. Fremdartige oder veränderte Substanzen auf der Zelloberfläche können beispielsweise durch eine Virusinfektion oder durch eine Mutation der Erbsubstanz hervorgerufen werden. Wenn eines der präsentierten MHC-I- oder MHC-II-Moleküle auf der Oberfläche der kranken Zelle exakt zu dem individuellen Rezeptor einer vorbeikommenden T-Zelle passt wie ein Schlüssel in das zugehörige Schloss, und wenn gleichzeitig eine Costimulanz (etwa das Oberflächenprotein B7) präsentiert wird, geht die T-Zelle durch Aktivierung bestimmter Gene des Zellkerns in den aktivierten Zustand über. Antigenrezeptor und Corezeptor bilden zusammen das Aktivierungssignal. Die Zelle wächst und differenziert sich aus. Je nach Zellart werden dann unterschiedliche Mechanismen ausgelöst. T-Killerzellen (durch den CD8-Rezeptor gekennzeichnet) zerstören die kranke Zelle direkt; T-Helferzellen (mit CD4-Rezeptor) schlagen mit löslichen Botenstoffen (Zytokinen) Alarm und locken zusätzliche Immunzellen an. Regulatorische T-Zellen verhindern überschießende Angriffe auf intakte Körperzellen, helfen also bei der Selbsttoleranz. T-Zellen sind somit für die zellvermittelte Zytotoxizität, für die Steuerung der humoralen Immunantwort, und nicht zuletzt auch für viele allergische Reaktionen verantwortlich. Dabei hängt die Stärke der verschiedenen Reaktionen vom stimulierenden Antigen, von der Art der präsentierenden Zelle, und von weiteren zum Teil noch unbekannten Faktoren ab.
Im Thymus, einem lymphatischen Organ, werden die neuen T-Zellen für ihre unterschiedlichen Funktionen vorbereitet. Eine Einteilung kann anhand der Oberflächenantigene CD4 und CD8 erfolgen: CD4+-T-Lymphozyten werden als Helferzellen angesehen; ihr Rezeptor erkennt MHC-Klasse-II-Moleküle. CD8+-T-Lymphozyten gelten als zytotoxische T-Zellen; ihr Rezeptor erkennt Antigene, die von fast allen Körperzellen über MHC-Klasse-I-Moleküle präsentiert werden. Tatsächlich wird damit aber nur die häufigste Kombination von T-Zell-Phänotyp und -Funktion wiedergegeben; es gibt auch CD4+-zytotoxische T-Zellen und CD8+-T-Helferzellen. CD4+-T-Zellen sind vor allem im peripheren Blut und in stark durchbluteten lymphatischen Geweben wie den parafollikulären Regionen von Lymphknoten, Milz und Tonsillen zu finden. CD8+-T-Zellen kann man dagegen eher im Knochenmark und in den lymphatischen Geweben der Magen-Darm-Schleimhaut, der Atmungsorgane und der Harnwege nachweisen.
Naive (nicht aktivierte) T-Zellen bewegen sich ständig zwischen dem Blut und diesen lymphatischen Geweben. Sie besitzen zu diesem Zweck eine geringe amöboide Beweglichkeit und sind mit Zelladhäsionsmolekülen und Rezeptoren für Chemokine ausgestattet. Den Blutstrom verlassen sie mittels Diapedese durch die Wände der postkapillären Venolen. Von dort aus wandern sie durch das Gewebe und kehren mit der Lymphe über den Ductus thoracicus, der in den linken Venenwinkel mündet, wieder ins Blut zurück. Eine weitere Möglichkeit besteht darin, dass die Lymphozyten durch die Wände einer hochendothelialen Venolen (HEV) in ein sekundär lymphatisches Organ einwandern.
Immunzellen können Substanzen freisetzen, die den Stoffwechsel in den Knochen beeinflussen. Unter Östrogenmangel wurden im Mausmodell T-Lymphozyten zur Produktion von TNF-α und Osteoprotegerin angeregt; dies könnte zur Entwicklung des Knochenmineralverlustes der Versuchstiere beigetragen haben. Thymuslose Mäuse, denen die Ovarien entfernt worden waren, erlitten trotz Hormonmangel keinen Knochenverlust. Bei thymuslosen Nacktmäusen und -ratten ist die Umsatzrate des Knochens allgemein geringer. Osteoprotegerin von aktivierten T-Lymphozyten stimuliert den osteoklastischen Abbau der Knochensubstanz und könnte an der Entstehung von Knochen- und Gelenk-Erkrankungen beteiligt sein.
T- und B-Lymphozyten sind kugelige Zellen von ähnlicher Größe wie rote Blutkörperchen; ihr Durchmesser beträgt beim Menschen etwa 7,5 µm. Sie können voneinander mikroskopisch oder elektronenmikroskopisch nicht unterschieden werden. Nur mittels der Immunhistochemie können Markerproteine wie das für T-Lymphozyten charakteristische CD3 und das für B-Lymphozyten spezifische CD19 dargestellt werden. Das Chromatin im runden oder leicht eingedellten, nichtgelappten Zellkern ist dicht, schollig und kräftig anfärbbar. Der Plasmasaum um den Kern ist schmal und lichtmikroskopisch kaum zu sehen. Die zahlreichen Lysosomen können als azurophile Granula sichtbar werden. Die Zellsubstanz enthält reichlich freie Ribosomen. Der Golgi-Apparat ist kleiner als bei den Retikulumzellen.
Jeder TCR auf peripheren T-Zellen ist an ein CD3-Rezeptormolekül gebunden. Der CD3-Rezeptor leitet das Aktivierungssignal in das Zellinnere. Er bindet sowohl an TCRαβ als auch TCRγδ. Das Ausmaß der Reaktion der Rezeptor- mit den Antigen-MHC-Komplexen hängt von der Konzentration beider Partner ab, d. h. ihrer Dichte auf den beteiligten Zellmembranen, und von der spezifischen Affinität des TCR. Mit der Kristallographie wurde die dreidimensionale Struktur des TCR aufgeklärt. Die antigenbindende, hypervariable V-Region ähnelt der entsprechenden V-Domäne von Antikörpern. Diese Molekülabschnitte in Form von exponierten Schleifen bestimmen die Antigenspezifität des Rezeptors und werden auch complementarity determining regions CDR genannt.
Der TCR gehört wie der Antigenrezeptor der B-Lymphozyten zur Immunglobulin-Gen-Superfamilie. Zwei von vier möglichen Proteinketten (bezeichnet mit α, β, γ, δ) sind über Disulfidbrücken verbunden. Meist ist der TCR ein αβ-Heterodimer, seltener γδ-Heterodimer. Es können also zwei Subpopulationen von T-Zellen unterschieden werden. Die α-Ketten wiegen 43–49, die β-Ketten 38–44 Kilodalton, die γ-Kette 55–60 und die δ-Kette ca. 40 Kilodalton. Der Komplex aus Rezeptor und MHC ist mit 15 nm klein im Vergleich zu anderen Membranproteinen. Die Gene für die α- und δ-Kette liegen verschachtelt am gleichen Genort auf dem Chromosom 14q11-12, das γ-Ketten-Gen liegt auf Chromosom 7p15 und das β-Ketten-Gen auf Chromosom 7q32-35. Die Anordnung der Gene macht es nicht möglich, dass eine Zelle gleichzeitig Rezeptoren als γδ- und αβ- Heterodimere ausbildet.
Im Blutkreislauf und in den lymphatischen Organen gehören 95–98 % der T-Zellen der αβ-Subpopulation an. CD4+- und CD8+-T-Zellen gehören zu ihr. γδ-T-Zellen sind überwiegend (bis zu 50 %) in epithelialen Geweben wie der Haut, der Darmschleimhaut oder den Geschlechtsorganen zu finden, also an den Körperoberflächen.
Während in den 80er Jahren T-Zellen in die beiden Formen T-Helfer- (CD4+) und T-Suppressor-Zellen (CD8+) unterteilt wurden, kennt man inzwischen die hohe "Plastizität" der T-Zellen, die sich in andere Subtypen wandeln oder Charakteristika mehrerer Subtypen ausbilden können, je nach vorhandenen löslichen Mediatoren, und die dem Subtypen spezifischen Zytokine und Interleukine produzieren können. Subtypen sind z. B. T1, T2, T9 oder T17.
T-Zellen mit Helferfunktion sezernieren unterschiedliche Zytokine und können danach eingeteilt werden, ob diese Botenstoffe an der zellvermittelten Immunantwort beteiligt sind, oder ob die humorale Immunantwort der B-Lymphozyten stimuliert wird. So induziert die Anwesenheit von IL-12 und Interferon-γ (IFN-γ) die Differenzierung zur TH1-Zelle, während IL-4 und IL-6 eine Differenzierung zur TH2-Zelle fördern. Beispielsweise gehören unter den CD4+-Lymphozyten solche zur ersten Gruppe (Typ 1), die Interferon-γ (IFN-γ), IL-2, und TNF-α sezernieren. CD4+-Lymphozyten, die die Zytokine IL-4, IL-5, IL-6, IL-10 und IL-13 erzeugen, werden dem Typ 2 zugerechnet. Die gleiche Unterscheidung kann auch für sezernierende CD8+-T-Zellen und für solche mit einem γδ-T-Zell-Antigenrezeptor getroffen werden. Außerdem gibt es T-Helferzellen mit einem gemischten Zytokinmuster, die als Typ0-T-Zellen bezeichnet werden.
Die Unterschiede zwischen Typ1-T-Zellen und Typ2-T-Zellen wurden erstmals 1986 von Tim Mosmann beschrieben.
Die cytotoxischen T-Zellen (CTL, veraltet Killerzellen) sind in der Regel durch CD8+-αβ-Heterodimere auf der Oberfläche gekennzeichnet. Sie erkennen auf MHC-I-Molekülen präsentierte Antigene, vor allem viral infizierte Zellen und Tumorzellen. CTL lösen in den defekten Zellen über deren physiologische Signalwege (Fas/FasL; Perforin/Granzyme) – den programmierten Zelltod aus.
Die Intensität der Immunantwort muss ständig kontrolliert werden, um einerseits die Krebszellen und Krankheitserreger zu vernichten, dabei aber Autoimmunität gegen normale Gewebe zu unterdrücken. Außerdem muss die Nachproduktion und Reifung der Leukozyten konstant gehalten werden. Ein Teil der Kontrollmechanismen wird von regulatorischen T-Zellen (veraltet Suppressor-T-Zellen) ausgeübt: über Zytokine wie IL-10 und TGF-β, durch das Abfangen von Antigenen, Wachstums- und Differenzierungsfaktoren, durch CTLA4-vermittelte Begrenzung der klonalen Expansion von B-Zellen, und durch das Abtöten von überschüssigen T-Zellen über Fas/FasL-vermittelte Signale. Die regulatorischen T-Zellen werden anhand ihrer Zytokinprofile weiter unterteilt, etwa in (CD4+-CD25+-T-reg-Zellen, TR1-Zellen, TH3-Lymphozyten und NKT-Zellen, CD8+-regulatorische Zellen).
T-Gedächtniszellen bilden eine Art „immunologisches Gedächtnis“, indem sie nach ihrer Aktivierung im Blut verbleiben. Bei einer erneuten Infektion desselben Erregers wird die ursprüngliche Aktivierung wiederhergestellt. Die Anwesenheit von Gedächtniszellen steigert die Vermehrung von antigenspezifischen T-Zellen um das 10- bis 100fache. Die Gedächtnisrolle kann sowohl durch CD4+ als auch durch CD8+-T-Gedächtniszellen ausgeübt werden.
Die Natürlichen Killer T-Zellen sind eine kleine Anzahl von zytotoxischen αβ-T-Zellen, die keine antigenspezifischen Rezeptoren besitzen, aber dennoch die Präsentation von MHC-I-Antigenkomplexen erkennen können. Es sind T-Zellen, man darf sie an dieser Stelle also nicht mit den Natürlichen Killerzellen des unspezifischen Immunsystems verwechseln. NK-T-Zellen sind durch das Molekül NKR-P1A, ein dem Lektin ähnliches Protein, auf ihrer Oberfläche gekennzeichnet. Weitere von NK-Zellen exprimierte Marker sind CD56, Neural cell adhesion molecule-1 (NCAM-1) und CD57. Diese Zellen produzieren auch die zytotoxischen Effektormoleküle Perforin und Granzym. Die Aufgabe der NK-T-Zellen soll in der Kontrolle von Autoimmunerkrankungen liegen.
γδ T-Zellen machen nur einen kleinen Prozentsatz der T-Zellen in Blut und lymphoiden Organen aus, sind aber sehr prominent in der Haut und vielen Epithel-Geweben vertreten. Ihr wesentliches Merkmal ist ein T-Zellrezeptor, der aus den γ- und δ-Untereinheiten besteht. Der γδ TCR ist deutlich weniger variantenreich als der αβ TCR, von den vielen theoretisch möglichen Kombinationen der verschiedenen Gen-Segmente werden nur einige wenige verwendet. Die Bindungspartner des γδ TCR sind noch weitgehend unbekannt, wahrscheinlich handelt es sich aber vorwiegend um körpereigene Moleküle (der αβ TCR erkennt in der Regel Antigene von Krankheitserregern).In Entwicklung und Funktion unterscheiden sich γδ T-Zellen deutlich von αβ T-Zellen. So verlassen sie den Thymus bereits in einem voraktivierten Zustand, der eine rasche Reaktion und schnelle Ausschüttung von wirksamen Substanzen ermöglicht. Die Aktivierung kann wahrscheinlich auch unabhängig vom γδ TCR durch Zytokine erfolgen. γδ T-Zellen erkennen Gewebeschäden und -veränderungen (wie etwa Krebs) und aktivieren daraufhin sowohl angeborene als auch erworbene Komponenten des Immunsystems.
Ererbte Immundefekte, die sowohl die T-Zellen wie auch die B-Zellen betreffen, d. h. die zelluläre und die humorale Immunantwort schädigen, nennt man schwere kombinierte Immundefekte (SCID). Die betroffenen Kinder müssen in möglichst keimarmer Umgebung gepflegt werden und haben langfristig nur nach erfolgreicher Knochenmarktransplantation eine Überlebenschance.
Das Di-George-Syndrom verhindert die Entwicklung von Epithelgewebe im Thymus des Fetus. Daher können die T-Zellen nicht ausreifen, die zelluläre Immunreaktion ist stark vermindert.
Patienten mit Nacktes-Lymphozyten-Syndrom entwickeln Leukozyten und Thymuszellen ohne MHC-II-Moleküle und damit einen Mangel an CD4+ T-Lymphozyten.
Erworbene Immundefekte können durch verschiedenen Krankheiten, durch Mangelernährung, durch schädliche Effekte der Umwelt oder therapeutische Maßnahmen verursacht werden.
Das Humane Immundefizienz-Virus (HIV) infiziert CD4+ T-Lymphozyten, dendritische Zellen und Makrophagen, was zur Immunschwäche-Krankheit AIDS führt. Die Viren HTLV I und HTLV II können bei Menschen und Primaten T-Lymphozyten befallen und verschiedene Erkrankungen auslösen, unter anderem die Adulte T-Zell-Leukämie und die Tropische Spastische Paraparese.
Von einer Überempfindlichkeitsreaktion, oder spezifischer Allergie, spricht man, wenn eine unangemessene Immunreaktion gegen körpereigenes Gewebe oder auf ein eigentlich harmloses Antigen (Staub, Pollen, Nahrungs- oder Arzneimittel) ausgelöst wird. Unter den vier Typen nach Coombs und Gell sind T-Zellen vor allem beim Typ I (Soforttyp) und Typ IV (verzögerter Typ) beteiligt. Beim Soforttyp liegt eine übersteigerte T2-Antwort gekennzeichnet, bei der verzögerten Allergie eine anhaltend übersteigerte Tätigkeit der T1-Zellen vermittelt und damit eine persistierende Entzündung.
Autoimmunerkrankungen sind chronische Erkrankungen, die durch Immunreaktionen gegen körpereigene Antigene verursacht werden. So gibt es beim Diabetes mellitus vom Typ I die Beobachtung, dass Insulin-spezifische CD8+ T-Zellen β-Zellen des Pankreas angreifen. Auch bei der rheumatoiden Arthritis sind autoreaktive T-Zellen nachgewiesen worden. Der weitverbreiteten Theorie zur Multiplen Sklerose zufolge wird auch diese Erkrankung durch aktivierte T-Zellen eingeleitet, die die Myelinscheiden der Nervenzellen zerstören.
Bestimmte Arzneimittel können erwünschte und unerwünschte Immundefizienzen hervorrufen. Nach Organtransplantationen ist die Gefahr einer Transplantabstoßung gegeben, die sowohl zelluläre wie auch humorale Immunreaktionen einbezieht. Im Vordergrund steht die T-Zell-Reaktion gegen allogene und xenogene MHC-Moleküle im fremden Gewebe. Untersuchungen zeigen drei Mechanismen: Die akute Abstoßung durch CD8+ T-Zellen, die chronische Abstoßung durch CD4+ T-Zellen, und eine Schädigung der das Transplantat versorgenden Blutgefäße. Alle drei Mechanismen können durch immunsuppressive Medikamente dauerhaft unterdrückt werden. Auch wachstumshemmende, zellabtötende Medikamente wie Zytostatika und Bestrahlungen mit ionisierender Strahlung können weiße Blutkörperchen und insbesondere T-Lymphozyten schädigen.
Entartete T-Zellen sind der Ausgangspunkt einer Gruppe von Tumorerkrankungen (der malignen Lymphome), und der Akuten lymphatischen Leukämie, die oft Patienten im Kindesalter betrifft.
In Wirbellosen (wie Einzellern, Schwämmen, Ringelwürmern und Arthropoden) finden sich weder Lymphozyten noch Lymphknoten. In Wirbeltieren kommen Lymphknoten erst bei den Vögeln und Säugetieren vor, dagegen sind die Lymphozyten schon eher im Stammbaum bei Knorpel- und Knochenfische sowie Amphibien und Reptilien vorhanden.
Zu Beginn des 20. Jahrhunderts war Gegenstand der wissenschaftlichen Auseinandersetzung, ob die Immunität mancher Menschen gegen Ansteckung auf zellulären oder humoralen Vorgängen beruht. Der Zoologe Elias Metschnikow (1845–1916) beobachtete, dass sich um einen in einen Seestern gestochenen Dorn bewegliche Zellen ansammelten. Metschnikow nahm an, dass diese Zellen eingedrungene Bakterien auffressen (Phagozytosenlehre). Demgegenüber vertraten Gelehrte wie Emil Adolf von Behring (1854–1917) die Ansicht, Immunität werde durch im Blutserum gelöste Stoffe erzeugt. Bering hatte 1888 festgestellt, dass die Vermehrung von Milzbrand-Bakterien durch Serum von resistenten Ratten verhindert wird, nicht aber durch Serum von gegen Milzbrand empfindlichen Meerschweinchen. Gegen Vibrio metschnikovii wirkte nur das Serum von solchen Meerschweinchen, die zuvor mit diesem Keim infiziert gewesen waren, und deren Serum wirkte wiederum nicht gegen andere Keime. Damit konnte Behring auch Hans Buchner widerlegen, der geglaubt hatte, dass das Blutserum eine unspezifische bakterizide Aktivität habe. Gemeinsam mit Kitasato entwickelte Behring seine Lehre von der humoralen Immunität und die sogenannte „Blutserumtherapie“.
Belgische Forscher (Denys, Lecleff und Marchand), insbesondere aber Almroth Wright und S. R. Douglas konnten den scheinbaren Widerspruch beider Theorien um 1903 auflösen. Wright und Douglas fanden im Serum phagozytosefördernde Stoffe, die sie Opsonine nannten – die heutigen Antikörper – die zelluläre und humorale Vorgänge verbanden. Nach der von Linus Pauling 1940 veröffentlichten Instruktionstheorie bildeten Antigene eine Instruktion, nach der Blutzellen ein universelles Immunoprotein zu einem passenden spezifischen Antikörper umformen.
Abweichend davon vertraten Niels Jerne (Klon-Selektionstheorie) und Paul Ehrlich (Seitenkettentheorie) die Ansicht, sämtliche Immunoglobuline seien bereits vorgeformt und das richtige werde durch das eingeführte Antigen selektiert. Frank MacFarlane Burnet erkannte dann, dass nicht die zirkulierenden Antikörper selektiert werden, sondern einzelne immunkompetente Zellen, die dann durch Vermehrung einen spezifisch produzierenden Klon bilden (Nobelpreis 1960). Während des embryonalen Lebens entstehen durch somatische Mutationen zahllose Varianten von möglichen Antigenrezeptoren; gleichzeitig werden solche Zellen, die Rezeptoren für körpereigene Antigene tragen, wieder eliminiert.
Bis 1926 wurde die Rolle der Lymphozyten bei der Abstoßung von körperfremden Gewebe erkannt. Gowans beschrieb 1964, dass solche Lymphozyten überall verfügbar sind, indem sie aus dem Milchbrustgang ins Blut und, über die sekundären Lymphorgane, dann wieder ins Gewebe wechseln. Die besondere Bedeutung des Thymus wurde 1968 an leukämischen Mäusen entdeckt.
Mitte der 1960er unterschied man B- und T-Lymphozyten. Deren Zusammenspiel bei der Antikörperherstellung beschrieb Jerne 1974 (Nobelpreis 1984). 1975 unterschieden Kisielow und Mitarbeiter zytotoxische von nicht-zytotoxischen T-Zellen.  1976 zeigten Rolf Zinkernagel und Peter Doherty, dass die T-Zelle nur aktiviert wird, wenn das auslösende Antigen am MHC präsentiert ist. 1982 gelang es, einen mAb zu synthetisieren, der T-Zell-Lymphomzellen bei Mäusen erkannte. Die Oberflächenstrukturen und TCRs der T-Zellen wurden genauer an T-Zell-Hybridomen und leukämischen T-Zelllinien beschrieben. 1979 fand Kung die CD3-Proteine an der Seite des T-Zell-Antigenrezeptors; deren biochemische Charakterisierung folgte 1984 durch eine Forschungsgruppe von Cox Terhorst.
Der T-Zell-Rezeptor wurde 1983 in Mäusen als 45–50 kDa großes Heterodimer, mit einer α- und einer β-Kette beschrieben.
Im folgenden Jahr gelang die mRNA-Isolation auch des menschlichen TCRs, erstmals unter Zuhilfenahme der Klonierung von β-Ketten des humanen und Maus-TCRs. Wenige Jahre später wurde ein zweiter, dem αβ-TCR ähnlicher TCR aufgefunden – der γδ-T-Zell-Antigenrezeptor. Ebenfalls 1986 wurde die MHC-Restriktion des T-Zell-Antigenrezeptors erstmals beschrieben. TCR-Gene können in chromosomale Mutationen einbezogen sein, die krebsfördernde Onkogene aktivieren. Mit Hilfe molekularer Proben von TCR konnten Gene identifiziert werden, die bei der Entwicklung von Leukämien und Lymphomen eine Rolle spielen.
1988–89 wurde gezeigt, dass CD8 der rezeptierende Partner für solche Antigene ist, die am MHC-I präsentiert werden. Das Gedächtnis von CD4- und CD8-Zellen wurde beschrieben.
G. A. Holländer: Immunologie, Grundlagen für Klinik und Praxis. 1. Auflage. Elsevier, München 2006, ISBN 3-437-21301-6. 
I. Jahn: Geschichte der Biologie, Theorien, Methoden, Institutionen, Kurzbibliographien. 3. Auflage. Gustav Fischer, Jena 1998, ISBN 3-437-35010-2. 
A. Wollmar, T. Dingermann: Immunologie, Grundlagen und Wirkstoffe. Unter Mitarbeit von I. Zündorf. Wissenschaftliche Verlagsgesellschaft, Stuttgart 2005, ISBN 3-8047-2189-3. 
O. Bucher, H. Wartenberg: Cytologie Histologie und mikroskopische Anatomie des Menschen. 11. Auflage. Hans Huber, Bern/ Stuttgart/ Toronto 1992, ISBN 3-456-81803-3. 
K. Munk: Grundstudium Biologie Zoologie. Gustav Fischer, Heidelberg/ Berlin 2002, ISBN 3-8274-0908-X.
uni-tuebingen. de/List/List01. aspx?subject=Immunbiologie Vorlesung Immunbiologie der T-Lymphozyten Videoaufzeichnungen einer Vorlesung. Von TIMMS, Tübinger Internet Multimedia Server der Universität Tübingen.

Tabernae ist der Name der römischen Siedlung, aus der Rheinzabern (heute Rheinland-Pfalz) entstand. Der Ort war in der Antike ein bedeutendes Produktionszentrum für Keramikwaren, darunter besonders das Tafelgeschirr Terra Sigillata. Die Siedlung bestand vom 1. Jahrhundert n. Chr. bis in die Spätantike.
Die größte Siedlungsausdehnung und der Höhepunkt der Sigillata-Manufaktur mit einer marktbeherrschenden Stellung in den römischen Rhein- und Donauprovinzen fielen in das späte 2. und frühe 3. Jahrhundert als Folge günstiger Transportbedingungen an der Römischen Rheintalstraße und leicht erschließbarer Rohstoffvorkommen. Mit dem Limesfall war ein deutlicher Einschnitt feststellbar. Aus der spätrömischen Zeit gibt es zahlreiche Belege für eine Militär- und Raststation sowie eine Ziegelproduktion durch das Militär.
Der Name Tabernae (lateinisch für Laden oder Schankwirtschaft, in diesem Fall wohl eher Raststation) für das antike Rheinzabern ist durch mehrere Schriftquellen belegt. Die älteste Erwähnung stammt aus dem Itinerarium Antonini aus der Zeit des Kaisers Caracalla. Als Wegestation ist der Ort ferner in der Tabula Peutingeriana verzeichnet. Die spätantike Notitia dignitatum nennt eine Truppenabteilung der Menapii, die zum spätrömischen Heer gehörte, in Tabernae. Ebenfalls wird der Ort in einem Lobgedicht des Symmachus an Kaiser Valentinian I. erwähnt. Der Namenszusatz Rhenanae ist für die Antike nicht belegt. Es könnte sich um einen späteren Zusatz zur Unterscheidung von Bergzabern handeln, da beide Orte seit dem frühen Mittelalter im Besitz des Reichsklosters Klingenmünster nachweisbar sind.
Rheinzabern liegt an der Römischen Rheintalstraße westlich des Rheins, der hier in römischer Zeit stark mäandrierte. In etwa 1000 m Entfernung zur heutigen Ortschaft liegt das markante Hochufer. Nördlich und südlich der Siedlung befinden sich heute noch ausgedehnte Waldgebiete, die zum Bienwald gehören. Hier lagerten unter den lokalen alluvialen Sandböden leicht zugängliche Tonvorkommen. Antike Tongruben sind heute noch in der Nähe des Otterbachs als Geländemulden zu erkennen.
Durch ihre gute Erhaltung im Bienwald und Funde zahlreicher Leugensteine gilt die Römerstraße zwischen Straßburg (Argentoratum) und Speyer (Noviomagus) als sehr gut erforscht. Der erste Stein wurde 1824 im Nachbarort Jockgrim entdeckt. 1936 wurde westlich von Hagenbach eine Ansammlung von sechs Leugensteinen gefunden, auf denen noch fünf Inschriften erhalten waren. Die Ansammlung erklärt sich daraus, dass die Steine jeweils erneuert wurden, während die älteren an ihrem Platz blieben. Heute befindet sich dort eine Nachbildung.
Die verkehrsgünstige Lage und die leichte Verfügbarkeit der Rohstoffe Ton und Holz führten bereits im 1. Jahrhundert n. Chr. zur Entstehung einer Siedlung, die wie viele Vici im Römischen Reich stark gewerblich orientiert war. Die Hauptachse der Siedlung bildete dabei die Römerstraße, die meist als Kiesdamm von 6 bis 6,50 m Breite mit beiderseitigen Entwässerungsgräben ausgeführt war. Bäche nördlich und südlich des Ortes wurden durch Furten oder später Brücken überquert, worauf eine Bauinschrift am Rottenbach hinweist, die aber mehrere Brücken nennt. Das Original der Inschrift ging 1870 beim Beschuss der Stadt Straßburg verloren.
Die frühe Präsenz von Truppen hat in der Vergangenheit oft zur Vermutung eines Militärlagers in Rheinzabern geführt. In der Mühlgasse und Hoppelgasse wurden Grabenspuren entdeckt, die aber nicht sicher als Militärlager gedeutet werden können. Militärisches Ausrüstungsgut liegt im Fundmaterial vor, entstammt allerdings meist der zivilen Bebauung. Es liegt somit nahe, dass die militärische Nutzung vorwiegend mit der Ausbeutung der örtlichen Tonvorkommen in Verbindung stand.
Mit dem Ende der Produktion in militärischer Regie um 80 n. Chr. wurden die Anlagen bald von zivilen Unternehmern übernommen. Zweifellos bildete die Keramikherstellung den Grundstock für die folgende zivile Besiedlung, was durch viele Werkstattareale im Hofbereich der Häuser belegt wird. Bislang nicht lokalisiert werden konnte die für den Ort namensgebende Raststation.
Um 150 n. Chr. wurde begonnen, neben den anderen Keramikprodukten auch Terra Sigillata herzustellen. Die günstige Lage an den Rohstoffvorkommen und die guten Transportbedingungen über den Rhein und seine Nebenflüsse führten zu einem reißenden Absatz der Rheinzaberner Sigillata. Im Fundmaterial der meisten Siedlungs- und Militärplätze der Nordwestprovinzen verdrängte sie die zuvor im mittleren Gallien hergestellten Waren im Verlauf des späten 2. Jahrhunderts und nahm zusammen mit der Sigillata-Manufaktur am Pacelliufer in Trier (Augusta Treverorum) eine marktbeherrschende Stellung ein.Die Hauptproduktion dauerte etwa 110 Jahre und endete in der Zeit des Limesfalls, als die Absatzmärkte rechts des Rheins verloren gingen. Direkte Auswirkungen der Reichskrise des 3. Jahrhunderts auf die Siedlungen sind durch die Hortfunde von Hagenbach und Neupotz belegt. In Rheinzabern selbst wird das Vordringen der Germanen und die Notsituation der Bevölkerung durch einen Depotfund, bestehend aus Bronzegeschirr und Gläsern, dokumentiert, der 1882 in einem Haus nördlich der Römerstraße gefunden wurde. Im Terra-Sigillata-Museum ist ein weiterer Münzhort aus dieser Zeit ausgestellt, der in einem Brennofen verborgen worden war. Eine vollständige Zerstörung des Ortes ist bislang bis auf den Einzelfund einer Münze des Postumus in einer Brandschicht nicht zu belegen. Die Münzzufuhr scheint in den Jahren 270 bis 300 n. Chr. ausgesetzt zu haben.
In geringerem Umfang scheint es noch Keramik- sowie Sigillata-Produktion bis in das 4. Jahrhundert gegeben zu haben. Erst mit den Wirren der Zeit des Gegenkaisers Magnentius um 352 n. Chr. brach die Produktion von Gefäßkeramik endgültig ab. Ein kleiner Hortfund aus 37 Münzen endet mit einer Prägung des Constans. Ab der Mitte des 4. Jahrhunderts wurde der Ort vorwiegend militärisch genutzt. Die notitia dignitatum nennt die spätrömische Einheit der Menapii, die zugehörige Befestigung ist nicht lokalisiert. Diese dürfte sich im nördlichen Teil Rheinzaberns befunden haben, auf den sich die spätere Besiedlung beschränkte. In der Nähe befand sich auch eine mehrere hundert Körpergräber umfassende spätantike Nekropole. Die Tonvorkommen wurden wieder zur Herstellung von Ziegeln mit Militärstempeln genutzt, von denen zahlreiche Einheiten durch Stempel sowie zwei Ofenfunde belegt sind.
Das endgültige Ende der römischen Siedlung kam mit dem Rheinübergang von 406. In Rheinzabern zeugt davon ein weiterer Münzschatz, der in spätantiken Bauresten gefunden wurde. Er endet mit einer Prägung des Honorius. Aus dem Gräberfeld im Oberstboth liegen einige – in christlicher Tradition beigabenlose – Gräber vor, die bis weit in das fortgeschrittene 5. Jahrhundert datieren dürften.
Seit 45 n. Chr. sind in Tabernae Militärziegeleien der Obergermanischen Legionen gesichert. Den Funden gestempelter Ziegel zufolge waren dies die in Mainz (Mogontiacum) stationierten Legionen I adiutrix, IIII Macedonica, XIV Gemina, XXI Rapax und XXII Primigenia, kurzfristig auch die Legio VII Gemina.
Ab etwa 80 n. Chr. endete der Ziegeleibetrieb der Legionen vorläufig. Die 22. Legion ziegelte nun näher am Limes in Frankfurt-Nied. In der mittleren Kaiserzeit ließ nur noch die in Straßburg stationierte Legio VIII Augusta gelegentlich in Tabernae Ziegel herstellen, wobei die Produktion nicht mehr das Ausmaß des 1. Jahrhunderts erreichte. Die VIII. Legion betrieb darüber hinaus eigene Ziegeleien in Straßburg-Koenigshoffen. Die Lücke wurde geschlossen von zivilen Unternehmern, deren Produktion mit Ziegeln, Grob- und Feinkeramik (Terra Nigra) sehr umfassend war. Versuche mit Terra Nigra hat es auch schon vereinzelt im 1. Jahrhundert gegeben.
Während die Ziegelproduktion in der mittleren und hohen Kaiserzeit in der Hand privater Unternehmer lag, wurden in der Spätantike seit der Mitte des 4. Jahrhunderts wieder Ziegel in militärischer Regie produziert. Durch Stempelfunde sind die Einheiten der Menapii, Martenses, Acincenses, Cornacenses und Portisienses bekannt. Von den Cornacenses wurde in den 24 Morgen ein Ofen ergraben, ein Ofen mit Ziegeln der Portisienses befand sich im Bereich der Römerbadschule.
Die Produktion des im römischen Reich weit verbreiteten feinen Tischgeschirrs, sogenannter Terra Sigillata begann um 150 n. Chr. Vermutlich aufgrund der günstigen lokalen Gegebenheiten ließen sich Töpfer hier nieder, die zuvor in anderen Manufakturen durch Töpferstempel belegt sind. Sie brachten das nötige Wissen zur Herstellung des glänzenden Überzugs (Engobe) sowie zur Herstellung der Punzenstempel und Formschüsseln mit. Zu den frühesten Töpfern gehören Ianus, Reginus, wenig später Cerialis und Belsus, die zuvor in Heiligenberg im Unterelsass getöpfert hatten. Neben den sogenannten Bilderschüsseln (Form Dragendorff 37) wurden auch glattwandige Gefäße hergestellt, die üblicherweise einen Töpferstempel trugen. In der späteren Zeit sind Verzierungen mit Barbotine häufig.Aus Rheinzabern sind bislang etwa 300 Namen von Töpfern aus der Zeit zwischen 150 und 260 n. Chr. bekannt. Namentlich nicht bekannt sind etwa 90 Hersteller der Bilderschüsseln, die nur nach dem Stil zu identifizieren sind. Die Produktionszahlen werden anhand der Funde auf durchschnittlich 500.000 bis eine Million Gefäße pro Jahr geschätzt.Von den Produktionsstätten konnten vor allem die Abbaugruben für Ton im Bienwald am Otterbach aufgefunden werden. Die gewonnenen Tone mussten für die aufwändige Verzierungstechnik in verschiedenen Schlämmbecken aufbereitet werden, von denen im Ortsbereich einige nachgewiesen wurden. Die größten erreichten eine Seitenlänge von sechs Metern. Die eigentliche Gefäßherstellung benötigte größere, hallenartige Bauten, die meist einen Ziegelboden besaßen. Belegt sind außerdem größere Hallen als Pfostenbauten mit einer Länge bis zu 50 Meter, die zur Lagerung und Trocknung der Gefäße dienten.Die TS-Herstellung benötigte besondere Öfen, in denen Temperaturen bis zu 950 °C erreicht wurden. Bisher wurden in Rheinzabern sechs solcher Öfen gefunden, einer davon ist heute in einen gemeinsamen Schutzbau mit dem Kindergarten in der Faustinastraße integriert. Die runden Öfen besaßen in der Frühzeit zunächst Durchmesser von 100–150 cm, später waren größere Öfen mit drei Metern Durchmesser üblich. Die Öfen besaßen runde Brennkammern mit langen Schürkanälen. Einige Öfen mit rechteckigem Grundriss dienten der Herstellung von Baukeramik.
Im Terra-Sigillata-Museum werden heute neben der Ortsgeschichte besonders die Herstellung der Sigillata und die zahlreichen Produktionsfunde gezeigt. Durch Fehlbrände und weitere Töpfereiabfälle ist dabei die Zahl komplett erhaltener Gefäße besonders hoch. Bemerkenswert und für Terra-Sigillata-Produktionsorte charakteristisch sind neben den Ofenfunden zahlreiche Punzenstempel und Formschüsseln im Fundmaterial.
Die Bebauung und ihre zugehörigen rechteckigen Grundstücke zogen sich beiderseits der Römerstraße auf einer Länge von etwa 900 Metern hin. Nachweisbar ist um 70 n. Chr. eine Bebauung in Form von Streifenhäusern, die als unterste Schichten etwa 1,5 Meter unter der heutigen Oberfläche gut fassbar sind. Zu dieser Zeit sind bereits Keramiköfen im gesamten Vicus nachweisbar.
Im späten 1. Jahrhundert n. Chr. hatte sich die Siedlung bereits weit nach Süden ausgedehnt. Zuverlässige Aussagen über die Zivilsiedlung im 2. und 3. Jahrhundert lassen sich aufgrund der durch Überbauung in Rheinzabern meist sehr ausschnitthaften Befunde nicht gewinnen. Im Nordteil der Siedlung scheinen einige Gebäude massiver in Stein ausgebaut worden zu sein.
Der Vicus wurde im Nordosten und Südwesten von zwei größeren Gräberfeldern begrenzt. Das nordöstliche Gräberfeld „Rehgärten“ weist 137 Brandgräber und 5 Körperbestattungen aus der Frühzeit der Siedlung im 1. und 2. Jahrhundert auf. Es wurde in spätantiker Zeit erneut aufgesucht. Im südwestlichen Gräberfeld „Rappenfeld“ fanden sich bislang 442 Brandgräber und 4 Körperbestattungen des 1. bis 3. Jahrhunderts. 
Über öffentliche Gebäude des Vicus ist bislang nichts bekannt. Auch fehlen Hinweise auf Markt- und Badeanlagen. Ein größeres Badegebäude, das 1855/1905 am Otterbach ausgegraben wurde, ist Teil eines hangaufwärts gelegenen römischen Gutshofs (Villa rustica). Heiligtümer wurden ebenfalls nicht ergraben, es liegen aber zahlreiche Götterweihungen vor, die auf solche hindeuten. Darunter sind zwei sehr qualitätvolle Fünfgöttersteine mit Darstellungen von Apollo, Fortuna, Vulcanus, Minerva und Mercurius. In dem stark auf Handel orientierten Ort sind die Weihungen für Mercurius naturgemäß am häufigsten im Fundmaterial vertreten, gefolgt von Jupiter und Silvanus. Belegt sind weiterhin eine Matronendarstellung, Epona, Minerva, Juno, Hercules und Vulcanus.
Helmut Bernhard: Rheinzabern GER. Industrieort Tabernae. In: Heinz Cüppers (Hrsg.): Die Römer in Rheinland-Pfalz. Lizenzausgabe, Nikol, Hamburg 2002, ISBN 3-933203-60-0, S. 532–539.
Fridolin Reutti: Tonverarbeitende Industrie im römischen Rheinzabern. Vorbericht für die Grabungen der Jahre 1978-1981. In: Germania 61, 1983, S. 33–69.
Fridolin Reutti: Neue archäologische Forschungen  im römischen Rheinzabern. Hrsg.: Verein Terra Sigillata-Museum Rheinzabern e. V., Rheinzabern 1984.
Friedrich Sprater: Das römische Rheinzabern. Verlag Historisches Museum der Pfalz, Speyer 1948. (teilweise veraltet).
Rainer Wiegels: Tabernae [1]. In: Der Neue Pauly (DNP). Band 11, Metzler, Stuttgart 2001, ISBN 3-476-01481-9, Sp. 1194.
Rainer Wiegels: Inschriften des römischen Rheinzabern. In: Mitteilungen des Historischen Vereins der Pfalz 87, 1989, S. 11–89.
Pia Eschbaumer: Terra Sigillata. In: Thomas Fischer (Hrsg.): Die römischen Provinzen. Eine Einführung in ihre Archäologie. Theiss, Stuttgart 2001, ISBN 3-8062-1591-X, S. 267–290, hier: S. 287–289.
Wilhelm Ludowici: Katalog V. Stempel-Namen und Bilder römischer Töpfer, Legions-Ziegel-Stempel, Formen von Sigillata und anderen Gefäßen aus meinen Ausgrabungen in Rheinzabern 1901–1914. Jockgrim 1927.
Wilhelm Ludowici: Katalog VI meiner Ausgrabungen in Rheinzabern 1901–1914. Die Bilderschüsseln der römischen Töpfer von Rheinzabern. Tafelband. Bearbeitet von Heinrich Ricken, Darmstadt 1942.
Heinrich Ricken: Die Bilderschüsseln der römischen Töpfer von Rheinzabern. Textband mit Typenbildern zu Katalog VI der Ausgrabungen von W. Ludowici in Rheinzabern 1901–1904. Bearbeitet von Ch. Fischer. Frankfurt 1963.
Manuel Thomas (Bearb.): Die Dekorationsserien der Rheinzaberner Reliefsigillata/von Heinrich Ricken. Aus dem Nachlass bearb. von Manuel Thomas. (Text- und Tafelband) Habelt, Bonn 2005, ISBN 3-7749-3315-4 (Materialien zur römisch-germanischen Keramik 14).
„Tonspuren“ – Spuren des Lebens und Arbeitens in Tabernae, Seite des Terra-Sigillata-Museums Rheinzabern

Tabgha [tabɡɑ] ist eine Ortschaft am Nordufer des Sees Genezareth in Galiläa im nördlichen Teil Israels. Es ist der Austrittspunkt mehrerer Quellen, die in den See münden, und eine christliche Pilgerstätte, die mit dem Wirken Jesu, insbesondere der überlieferten Brotvermehrung, in Verbindung gebracht wird.
In den Evangelien nehmen der See und allgemein Galiläa als erster Wirkungsbereich Jesu eine wichtige Rolle ein. In Tabgha befinden sich die Brotvermehrungskirche, die Primatskapelle und antike Ruinenreste der Kapelle der Seligkeiten, die der Tradition nach an das Handeln Jesu erinnern. Die Kirchen werden von zwei Klostergemeinschaften – italienischen Franziskanern und deutschen Benediktinern – betreut. Als Einrichtung für Gäste ist ein Pilgerhaus vorhanden und südlich der Brotvermehrungskirche wurde zu Beginn der 1980er Jahre eine Behinderten- und Jugendbegegnungsstätte eingerichtet. In unmittelbarer Nähe liegen weitere christliche Stätten, vor allem der Berg der Seligpreisungen nördlich, Kafarnaum sowie Bethsaida östlich und Magdala südlich von Tabgha.
Seit dem 30. Juni 2000 stehen der See Genezareth und seine antiken Stätten Korazim, Kafarnaum und Tabgha auf der Tentativliste der UNESCO, der Vorschlagsliste für einen Eintrag auf der Welterbeliste.
Der Name Tabgha ist die verkürzte Form der arabischen Ortsbezeichnung عين الطابغة, DMG ʿAin aṭ-Ṭābiġa; diese Bezeichnung leitet sich vom griechischen Heptapegon (chorion) (Επτάπηγον, wörtlich: Siebenquelliges Landstück) ab.
Bereits Pilger in der byzantinischen Zeit benannten den Ort so, weil dort sieben Quellen entspringen. Auch die hebräische Bezeichnung des Ortes עין שבע (En Scheva) bedeutet Siebenquell.
Tabgha liegt in Galiläa im nördlichen Teil Israels unmittelbar am Nordwestufer des Sees Genezareth. Um den See führt eine Uferstraße. Zwei Kilometer südwestlich von Kafarnaum weicht die Straßenführung nach Tiberias einem Bergausläufer aus. Auf dem Berg liegt die Kirche der Seligpreisungen, fünf bis zehn Meter über der Straße am Steilhang befinden sich die antiken Ruinenreste der Kapelle der Seligkeiten. Auf der anderen Straßenseite etwa auf der Höhenlinie 200 m unter dem Meeresspiegel treten die ersten Quellen aus. Das Landstück Heptapegon reicht von diesen Quellen bis zum Berg Kinneret im Westen.
Am Ufer des Sees Genezareth treten mehrere Quellen aus. Dabei werden zwei Gruppen unterschieden, solche mit einem hohen Kalzium-Anteil, dazu gehören die Quellen in Tabgha sowie die von Fuliya und Tiberias, und solche mit einem hohen Magnesium-Anteil, dazu zählen die Quellen an der Süd-Ostseite des Sees, wie Gofra, Ha'On 1 und Hammat Gader.
Die sieben Quellen von Tabgha sind in ihrem Salzgehalt und in ihrer Temperatur sehr verschieden. Sie gehen auf tief ins Erdinnere reichende geologische Verwerfungen zurück. Etwa 500 Meter weiter nach Westen trifft in der Talsenke die von Rosh Pina kommende Straße auf die Uferstraße nach Tiberias; hier verläuft die zweite tief reichende geologische Verwerfung.
Im Einzugsgebiet von Tabgha streichen die Gesteine der Judea-, Mt.-Scopus- und der Avedat-Gruppe aus. Den östlichen Teil Tabghas bildet der basaltische Korazim-Block. Die Grundwasser stammen überwiegend aus dem Oberen Aquifer und unterscheiden sich bezüglich der Chloridität (0,2 bis 2,4 g/l) und Temperatur (19 bis 39 °C). Grund dafür ist die Abhängigkeit der aufsteigenden Sole vom Mischungsgrad mit nicht salinarem Grundwasser.
Das heutige Tabgha ist ein Pilgerort und umfasst das Priorat Tabgha der Dormitio-Abtei zu Jerusalem, zu dem die Brotvermehrungskirche, das Benediktinerkloster, ein Pilgerhaus, eine Stätte zur Behinderten- und Jugendbegegnung, ein Schwesternhaus und umfangreiche Plantagen gehören. Westlich davon, am Fuß des Tell el Oreme, hat der Deutsche Verein vom Heiligen Lande das alte Pilgerhospiz, das nach der Staatsgründung des Staates Israel lange Zeit als Jugendherberge diente, renoviert und erweitert. Der Tell el Oreme, die neue Jugendherberge Karei Deshe und eine in der Nähe befindliche Ausgrabung eines muslimischen Palastes gehören zu Tabgha und liegen auf dem Besitz des Deutschen Vereins vom Heiligen Land. Östlich des Priorates Tabgha, von der Kustodie des Heiligen Landes der Franziskaner (OFM) betreut, liegt die Primatskapelle. 50 Meter weiter östlich an der Straße Richtung Kafarnaum steht der aus der byzantinischen Zeit stammende Turm, der im Arabischen Hammam Ayub (Bad des Ijob) oder auch Tannur Ayub (Ofen des Ijob) genannt wird, und der eine der Quellen Tabghas fasst.
Am südöstlichen Rand von Tabgha im See Genezareth befinden sich Reste einer kleinen Hafenanlage, die aufgrund der dort entdeckten Keramik in das 3. und 4. Jahrhundert datiert wird. Auch unregelmäßige Anker aus Basalt konnten dort geborgen werden.
Das Klima in Tabgha ist eine Mischung aus Mittelmeer- und Steppenklima. Die Durchschnittstemperatur liegt bei 22,9 °C. Die wärmsten Monate sind Juli, August und September mit durchschnittlich 27, 28 beziehungsweise 26 °C und die kältesten Dezember, Januar und Februar mit 15, 14 beziehungsweise 15 °C im Mittel. Der meiste Niederschlag fällt im Dezember und im Januar mit durchschnittlich 130 Millimeter, der geringste von Mai bis September mit durchschnittlich weniger als fünf Millimeter. Der Jahresdurchschnitt an Niederschlägen liegt bei 463 Millimeter. Die Lufttemperaturen steigen im Sommer auf über 40 °C und die Wassertemperaturen auf bis zu 30 °C. Der Wind bläst häufig stark ablandig vom Westen und breitet sich über den See abschwächend nach Osten aus. Der frühsommerliche Wüstenwind (arab. Chamsin, hebr. Scharav) kann starke Hitzewellen mit bis zu 50 °C bringen. Die Wassermasse des See Genezareth bildet einen Wärmespeicher, der durch seine Abstrahlung im Winter zu Durchschnittstemperaturen von 14 °C beiträgt.
In Tabgha wurden immer wieder Reihen von Palmen angepflanzt. Von den früher für die Bodenentwässerung gesetzten Eukalyptusbäumen musste nach mehreren Sturmschäden Ende der 1990er Jahre ein Großteil aus Sicherheitsgründen gefällt werden.
Auf dem Gelände blühen an vielen Stellen große Bougainvillea-Büsche. An Nutzpflanzen wurden auf den landwirtschaftlichen Flächen zuletzt überwiegend Mangos und Grapefruits angebaut.
An Landtieren sind aufgrund der relativ hohen Temperaturen im Sommer vor allem Klippschliefer (Procavia capensis syriaca), Gewöhnliche Chamäleons (Chamaeleo chamaeleon) und Geckos (Gekkonidae) anzutreffen.
Im Seebereich vor den Quellen von Tabgha schwimmen der so genannte Petrusfisch (Sarotherodon galilaeus, arabisch Musht) sowie die Kinneret-Sardine (Acanthobrama terrae-sanctae), aber auch die Süßwassermuschel (Unio tigridis) in der essbaren Unterart Unio tigridis terminalis und die Süßwasserschnecke der Art Melanopsis praemorsa.
Für frühere Epochen, als das Ufer des Sees noch deutlich sumpfiger und mit Papyrus bestanden war, sind Wildschweine und Flusspferde (Hippopotamus amphibius) durch Knochenfunde nachweisbar. Während Erstere bis heute an der Jordanmündung vorhanden sind, kamen Letztere wohl nur bis in die späte Eisenzeit am See Genezareth vor.
In der Sammlung der Königlichen Museen für Kunst und Geschichte in Brüssel befinden sich mehrere mittelsteinzeitliche Fundstücke wie Steinmesser mit der Fundortangabe Tabgha.Im südwestlichen Teil von Tabgha in den Schichten des Tell el Oreme befinden sich die Überreste der biblischen Stadt Kinneret. Anhand der gefundenen Keramik wurde sie in die Mittlere und Jüngere Bronzezeit datiert. Die Stadt war von einer über zehn Meter breiten Stadtmauer umgeben. Zwischen dem Tell el Oreme und Tabgha verlief während der Zeit der römischen Besetzung die Via Maris, eine Römerstraße, die Ägypten mit den nördlicheren römischen Provinzen verband. Auch die Reste eines römischen Aquäduktes, der parallel zu dieser Straße verlief, sind erhalten.
Drei Geschichten aus dem Neuen Testament werden nach der traditionellen Überlieferung mit Tabgha in Verbindung gebracht. Zwar reichen die Traditionen bis ins 3. Jahrhundert zurück, belastbare Anhaltspunkte dafür, dass die Ereignisse tatsächlich in Tabgha stattgefunden haben, gibt es jedoch nicht.
Die Speisung der Fünftausend – nach biblischer Überlieferung soll Jesus mit fünf Broten und zwei Fischen 5000 Männer sowie Frauen und Kinder gespeist haben (Mt 14,13–21  und Parallelstellen).
Die Einsetzung des Papsttums – die Erscheinung des auferstandenen Jesus, über die das Johannesevangelium (Joh 21 ) berichtet, wird ebenfalls in Tabgha lokalisiert: Jesus erscheint seinen Jüngern während des Fischens am Seeufer und beauftragt Simon Petrus nach einem gemeinsamen Mahl dreimal, „seine Lämmer zu weiden“. Nach katholischer Lesart erfolgt in diesem Auftrag die Einsetzung des Petrus zum Oberhaupt aller Gläubigen und damit zum ersten Papst.
Auch die Heilung des Aussätzigen durch Jesus soll sich in dem 200 Meter entfernten Turm Tannur Ayub zugetragen haben (Mt 8,1–5 ). Dafür, dass schon die frühen Christen diesen Platz als den Ort verehrten, an dem Jesus den Aussätzigen heilte, sprechen Erwähnungen des Ortes in frühen Pilgerberichten. Die arabischen Beduinen der Gegend haben diese Geschichte in ihre Tradition aufgenommen. Da der Koran jedoch an Aussätzigen nur Ijob kennt, wurde der Ort mit diesem identifiziert.
Die Quellen des Ortes werden bereits in einer Beschreibung von Josephus Flavius genannt. Bei der Eroberung Taricheas im Jahre 67 durch Kaiser Vespasian beschreibt Flavius den Jordanlauf sowie Landschaft und See Gennesar. Dabei schreibt er: „Zu dem milden Klima gesellt sich dann eine sehr kräftige Quelle, […] Einige haben diese Quelle schon für eine Ader des Nil gehalten, da in ihr Rabenfische wie im See bei Alexandria sich finden.“
Die erste Kirche am Ort war ein einschiffiger Bau, von 15,5 × 9,5 Meter Größe, der an der Straße ausgerichtet und noch nicht geostet war. Diese Kirche ist im 4. Jahrhundert errichtet worden. Ein 1911 entdeckter Basaltstein trug die Grabinschrift eines gewissen Josephus, in dem einige Forscher den Erbauer des ersten Kirchenbaus sehen.
Dieser Bau ist die erste Kirche in ganz Galiläa, die von einer Pilgerin gesehen und schriftlich bezeugt wurde, denn von 381 bis 384 bereiste die Pilgerin Egeria (auch Aetheria oder Etheria) das Heilige Land und verfasste darüber einen Reisebericht. Über Tabgha schrieb sie: „Dort am Meere [von Galiläa] ist eine Ebene mit viel Gras und Palmen und daneben sieben Quellen, die reichlich Wasser liefern. In dieser Ebene hat der Herr mit fünf Broten und zwei Fischen das Volk gespeist. Der Stein, auf den der Herr das Brot legte, ist zu einem Altar gemacht.“Im 5. Jahrhundert wurde der erste Bau durch eine größere dreischiffige kreuzförmige Säulenbasilika ersetzt. Dieser Kirchenbau wird 530 in der Beschreibung heiliger Stätten von Theodosius genannt. Die nächste und letzte antike Nennung des Ortes findet sich bei dem anonymen Pilger von Piacenza, der um 570 berichtet, dass er den Ort der Speisung der Fünftausend besucht hat und dort ausgedehnte Felder und Pflanzungen von Ölbäumen und Palmen gesehen habe. Die Basilika wurde während der ersten Hälfte des 7. Jahrhunderts zerstört. Ob im Verlauf der persischen (614) oder arabischen (635) Invasion ist ungeklärt. Der gallische Bischof Arculf, der um 670 die Quellen besuchte, fand kein stehendes Gebäude mehr, sondern nur noch umgestürzte Säulen.
Nahe dem Ort entstand im frühen 8. Jahrhundert der umayyadische Kalifenpalast Khirbat al-Minya. Das bescheidene Hangkloster mit der Kapelle der Seligpreisungen und das schlichte Heiligtum der Mensa Domini am Ufer des Sees scheinen weiterbestanden zu haben. Während der Kreuzzüge wurde die Mensa Domini mit einer norwegischen Stabkirche überbaut. Nördlich davon errichteten die Kreuzfahrer einen Turm, der jedoch bald nach den Kreuzzügen wieder verfiel. Insgesamt ist Tabgha im Mittelalter vollständig verödet. Einzig über Karten wurde der biblische Bezug weiter überliefert.
Im Jahr 1596 wurde das Dorf „at-Tabigha“ als Teil des Osmanischen Reiches gegründet. Es war ein Dorf mit ungefähr 44 Einwohnern im Bezirk von Jira innerhalb des Distrikts von Safed. Während des Census 1931 wurde dokumentiert, dass at-Tabigha aus 53 Häusern bestand und eine Bevölkerung von 223 Moslems, 21 Christen und einem Juden aufwies.
Im 19. Jahrhundert ragten nur noch wenige Mauerzüge aus dem Boden und die Bedeutung des Ortes war zunächst weitgehend unbekannt. Erst 1887 wurde eine landwirtschaftliche Siedlung angelegt; dabei entdeckte man die ersten Mosaiken. Der deutsche Vermessungsingenieur Gottlieb Schumacher, der am Bau der Hedschasbahn beteiligt war, empfahl auf einer Tabgha-Karte von 1889 Ausgrabungen vorzunehmen.Bei der vom 11. Oktober bis 26. November 1898 dauernden Palästinareise Kaiser Wilhelms II. wurde dieser von Pastor Herman Baumeister (1867–1898), dem Vertreter der in Tabgha ansässigen Christen, am 25. Oktober in Haifa begrüßt.
Die ersten, im März 1911 begonnenen archäologischen Grabungen im Auftrag der Görres-Gesellschaft unter Leitung von Paul Karge mussten aufgrund ungeklärter Besitzverhältnisse am südlichen Grundstücksrand schon bald wieder eingestellt werden.
Während des Ersten Weltkrieges kam es auch in Tabgha, das im Gebiet des Osmanischen Reiches lag und von Deutschen bewohnt war, zu Kampfhandlungen.
Davon zeugen mehrere Grabinschriften auf dem Deutschen Soldatenfriedhof in Nazareth. Über das genaue Ausmaß ist jedoch nichts bekannt.
Im Februar 1932 wurden die archäologischen Grabungen, diesmal unter Leitung von Andreas Evaristus Mader, wieder aufgenommen. Auch der deutsche Archäologe Oswin Puttrich-Reignard nahm für mehrere Wochen an der Grabung der Görres-Gesellschaft teil. Die dabei aufgedeckten Mosaikflächen wurden 1936 von Bernhard Gauer aus Düsseldorf restauriert und durch den Bau einer einfachen Hallenkirche vor der Zerstörung geschützt. Diesen Behelfsbau ließ der Deutsche Verein vom Heiligen Lande 1979 abreißen und durch den gegenwärtigen Bau ersetzen.Während des Zweiten Weltkrieges erlitten die Benediktinermönche sehr unterschiedliche Schicksale. Während die deutschen Mönche von den britischen Streitkräften interniert wurden, kämpften die Mönche anderer Nationen (Kroatien, Frankreich etc.) auf Seiten der alliierten Streitkräfte im Nahen Osten und Nordafrika. Nach dem Krieg kehrten sie nach Tabgha zurück, waren aber in den folgenden israelisch-arabischen Konflikten immer wieder bedroht. Insbesondere Aktionen der syrischen Streitkräfte, die bis zur Jordanmündung Zugang hatten, erzwangen immer wieder ein Verlassen des Klosters. Dies änderte sich 1967 mit der Besetzung der Golanhöhen durch die israelische Armee.
Am 4. Mai 1948, kurz vor dem Ausbruch des Israelisch-Arabischen Krieges, wurde das Dorf Tabgha von Einheiten der Palmach, unterstützt von der Alexandroni Brigade und regionalen Hagana Einheiten, erobert. Die arabischen Einwohner wurden, auf Befehl von Yigal Allon, vertrieben und ihre Häuser und Zelte zerstört.Im Jahr 1968 fanden Ausgrabungen durch Bellarmino Bagatti und Stanislao Loffreda im Auftrag des Studium Biblicum Franciscanum auf dem Gelände statt. Die Grabungskampagne von 1979 bis 1980 wurde von Renate Rosenthal und Malka Hershkovitz im Auftrag des Israel Department of Antiquities and Museums, der Hebräischen Universität Jerusalem und der Abtei Dormitio geleitet.Gisela Helmecke publizierte einen Überblick über die Grabungen des Berliner Museums für Islamische Kunst in Tabgha.
Am 27. Juli 2014 drangen 70 bis 80 jüdische Jugendliche auf das Gelände und demolierten die beiden am See gelegenen Gottesdienstplätze „Dalmanutha“.In der Nacht vom 17. auf den 18. Juni 2015 gegen 3:30 Uhr am Morgen wurde das Atrium der Brotvermehrungskirche durch Brandstifter schwer beschädigt. Bei diesem Brandanschlag wurde ein Mönch und eine Volontärin verletzt. Am 21. Juni 2015 protestierten etwa 4000 christliche Demonstranten in der Nähe der Kirche, nachdem es vorher zu einem neuerlichen Schwelbrand gekommen war. Am 12. Juli 2015 wurden zunächst drei, später noch zwei weitere jüdische Personen verhaftet, die aus einer extremistischen Ideologier heraus handelten. Die Reparaturkosten der Brandschäden in Höhe von 1,6 Millionen Euro trägt der israelische Entschädigungsfond. Im Februar 2017 wurde das Atrium der Brotvermehrungskirche wieder eingeweiht.Es wurden zu Beginn der 2010er Jahre die griechischen Inschriften an einem Taufstein in Tabgha und weitere Graffiti untersucht.
Im westlichen Teil des Geländes befindet sich die aus hellem Stein erbaute Brotvermehrungskirche. Die beiden Vorgängerbauten entstanden im 4. und 5. Jahrhundert. Das heutige, dem byzantinischen Stil nachempfundene Kirchengebäude mit vorgelagertem Atrium und Narthex wurde 1980 bis 1982 im Auftrag des Deutschen Vereins vom Heiligen Lande nach den Plänen der Kölner Architekten Anton Goergen und Fritz Baumann auf den Grundmauern aus dem 5. Jahrhundert errichtet; stellenweise sind noch die alten schwarzen Basaltmauern zu erkennen. Die hellen Steine für den Kirchenbau stammen aus Taiyiba, der offene Dachstuhl aus Deutschland und die roten Ziegel aus Italien. Das Portal der Kirche wurde von Elmar Hillebrand gestaltet.
Die gesamte Anlage der Brotvermehrungskirche war ursprünglich mit Mosaiken ausgelegt. Die Mosaikwürfel sind aus Missikalksteinen im Farbspektrum von blauschwarz bis weiß. Nur blau und grün fehlen. Die Mosaiken entstammen unterschiedlichen Zeitperioden. Von besonderer künstlerischer Qualität sind die Darstellungen von Wasservögeln und Sumpfpflanzen in den Seitenschiffen und im Querschiff. Sehr bekannt ist das Mosaik am Altar, das einen Korb mit vier Broten (das fünfte Brot ist das bei der Eucharistie verwendete Brot auf dem Altar) sowie zwei Fische links und rechts davon zeigt. Der Stein unter dem Altar wird besonders verehrt als die Stelle, auf der Jesus vor der Brotvermehrung die Brote und Fische abgelegt haben soll. Die Mosaiken der Kirche werden auf die Mitte des 4. Jahrhunderts datiert, das berühmte Brot-und-Fisch-Mosaik ist als spätestes Mosaik wohl auf das beginnende 5. Jahrhundert zu datieren.
Im östlichen Teil Tabghas unmittelbar am Seeufer befindet sich die Primatskapelle oder auch mensa domini, die an die Erscheinung Jesu am See nach seiner Auferstehung, das anschließende gemeinsame Mahl mit seinen Jüngern und den Auftrag an Petrus erinnert. Vermutlich ist sie bereits der sechste Kirchenbau an diesem Ort.
Schon Egeria erwähnte im 4. Jahrhundert dort eine Kirche, der mehrere Bauten bis hin zu einer norwegischen (Stab-)Kirche zur Zeit der Kreuzfahrer folgten. Der Stabkirchenbau verfiel jedoch schon kurz nach dem Ende der Kreuzzüge. Das heutige Gebäude wurde 1933 erbaut. Im Gegensatz zur Brotvermehrungskirche besteht die Kapelle aus schwarzem Basalt. Das Kircheninnere dominiert ein großer Steinblock, an dem das Mahl stattgefunden haben soll.
An den folgenden weiteren Orten der unmittelbaren Umgebung sollen sich der traditionellen Überlieferung zufolge Ereignisse des Neuen Testamentes abgespielt haben:
Dalmanutha (griechisch δαλμανουθα) hat sich einzelnen Forschern zufolge in der Nähe von Tabgha befunden. Ein Gebetsplatz unmittelbar am See wurde deshalb so benannt.  In Mk 8,10  schreibt Markus nach der Speisung der Viertausend: „Und sogleich stieg er mit seinen Jüngern in das Schiff und kam in die Gegend von Dalmanutha“. Andere Forscher vermuten Dalmanutha in der Nähe des antiken Migdal.
Eremos, eine kleine Höhle unmittelbar oberhalb von Tabgha, in die Jesus sich auf der Suche nach Ruhe zurückgezogen haben soll.
Das 1939 gegründete Priorat gehört zur Dormitio-Abtei Jerusalem. Die Benediktinermönche leben auf dem Gelände des Deutschen Vereins vom Heiligen Lande in der Nähe der Brotvermehrungskirche. Die beiden ehemaligen Gebäude des Konvents entstanden 1956. Am 27. Februar 2007 wurde der Grundstein für den Neubau des Benediktinerklosters gelegt. Am 17. Mai 2012 wurde das neue Kloster von Kardinal Meissner eingeweiht.Seit Dezember 1994 stehen dem Prior für die Betreuung des Ortes Benediktinerinnen von den Philippinen zur Seite. Ihr Konvent befindet sich derzeit in dem am nächsten zum See gelegenen Gebäude auf halbem Wege zwischen Brotvermehrungskirche und Pilgerhaus. Die Arbeiten in Laden, Küche und Landwirtschaft werden mit Hilfe griechisch-katholischer, drusischer und moslemischer Mitarbeiter aus Dörfern in Nordgaliläa, insbesondere aus dem Dorf Rameh durchgeführt.
Seit 1889 betreuen Franziskanermönche der Kustodie des Heiligen Landes (Custodia di terra santa) die östliche Hälfte von Tabgha. Die Baulichkeiten beschränken sich auf die Primatskapelle und wenige Häuser für die betreuenden Mönche. Der überwiegende Teil ist unbebaut.
Landrat Leopold Janssen, Präsident des Palästina-Vereins der Katholiken Deutschlands, brachte 1887 9000 Franken für den Ankauf eines etwa 40 Hektar großen Grundstückes am See Genezareth auf. Die lokalen Behörden machten zunächst Schwierigkeiten, aber 1889 gelang es dem schwäbischen Maurermeister Franz Keller, das Gelände für den Verein zu erwerben. Am 6. Februar 1889 errichtete er ein in Safed vorgefertigtes Häuschen, dessen Einzelteile in der Nacht mit Kamelen nach Tabgha transportiert worden waren.Mit dem Bau eines kleinen Hospizes, des Kernbaus des Zentralgebäudes, wurde bereits 1890 begonnen. Drei Jahre später, 1893, kamen die ersten Pilger in das in der Folgezeit immer weiter ausgebaute Hospiz. Das Tabgha-Hospiz, das heutige Pilgerhaus des Deutschen Vereins vom Heiligen Lande, bot zu dieser Zeit 50 Gästen Platz.
1891 übernahm Pfarrer Dom Zephirin Biever aus Luxemburg die Leitung und beteiligte sich 16 Jahre lang unter dem arabischen Namen Abuna Daut am Aufbau Tabghas. Er starb 1915 als Generalvikar von Zypern.1913 übernahm der Lazaristenpater Johannes Taepper die Leitung. Zunächst sah er seine Hauptaufgabe darin, die 200 Hektar landwirtschaftliche Nutzfläche zu verwalten. Nach mehreren Missernten betrieb er jedoch verstärkt den Ausbau des Pilger-Hospizes. Die Zahl der Besucher, besonders aus England und Amerika, stieg nach dem Ersten Weltkrieg immer stärker an. Kurz vor dem Ausbruch des Zweiten Weltkrieges musste Johannes Taepper nach 25-jähriger Tätigkeit wegen einer Herzerkrankung nach Deutschland zurückkehren. Dort starb er 1946.
1948 wurden die Gebäude von den Israelis konfisziert und zunächst als Verwaltungsgebäude genutzt. Später wurde das Gelände in eine israelische Jugendherberge, die sogenannte (alte) Karei Deshe (Grüne Wiese), umgewandelt. Leiter der Karei Deshe war der israelische Botaniker Shlomo Ilan. Unter ihm wurde der einzigartige Bambuswald angepflanzt, der bis heute im Gelände des Pilgerhauses zu sehen ist, aber auch die haushohen Gummibäume und andere Pflanzen. Nach langen Verhandlungen gelang es zu Beginn der 1990er-Jahre dem Deutschen Verein vom Heiligen Lande, die Baulichkeiten zurückzutauschen. Im Gegenzug wurde die neue israelische Jugendherberge Karei Deshe mit deutscher Unterstützung auf verpachtetem Land des Vereins gebaut.Am 24. März 2000 segnete Papst Johannes Paul II. den Grundstein des Pilgerhauses und nach zwei Jahren Bauzeit wurde die neue Anlage von Joachim Kardinal Meisner eingeweiht.Die architektonische Umsetzung des Projektes lag in den Händen der Architekten Guggenheim-Bloch in Zusammenarbeit mit der Firma Rosiny aus Köln.Die geistliche Leitung des Pilgerhauses liegt seit 2002 in den Händen von Ludger Bornemann, der dafür 2012 zum päpstlichen Ehrenkaplan (Monsignore) ernannt wurde. Patron des Pilgerhospizes ist der Kölner Kardinal Meisner.
Seit Januar 2015 wird das Pilgerhaus von Jubrail Gabby Mashael geführt. Er kommt aus Nazareth und hat 23 Jahre in München gelebt.
Unweit des Ortes liegt 200 Meter vom Nordufer des Sees Genezareth die archäologische Grabungsstelle Khirbat al-Minya. Die Ruine des umayyadischen Kalifenpalastes (Wüstenschloss) stammt aus dem frühen 8. Jahrhundert und erinnert äußerlich an ein römisches Militärlager. Zur luxuriösen Innenausstattung gehört eine palasteigene Moschee und eine frühislamische Badeanlage.
Nachdem der Bau der Brotvermehrungskirche 1982 beendet war, fragte sich die benediktinische Gemeinschaft unter dem damaligen Prior Immanuel Jacobs, was sie dem Land und seinen ärmeren Bevölkerungsschichten anbieten könnten. Die Antwort traf in Form einer Bitte des SOS-Kinderdorfes in Bethlehem ein: „Palästinensische Kinder würden gerne ein paar Tage Ferien in Tabgha machen.“Auf dem Gelände zwischen der Brotvermehrungskirche und Dalmanutha wurde daraufhin eine Begegnungsstätte eingerichtet. Eines der Ziele dieser Einrichtung ist, behinderten und nichtbehinderten Kindern und Jugendlichen aus Israel und dem Westjordanland die Möglichkeit zu geben, sich auf neutralem Boden friedlich zu begegnen.
Bereits im zweiten Jahr seines Bestehens, während der Ersten Intifada, bewährte sich die Stätte, als Gruppen aus dem Westjordanland mehrere Monate in Tabgha bleiben mussten, da ihnen die Rückreise verweigert wurde. Sumaya Farhat-Naser schrieb über diese Zeit: „Ein kleiner Beitrag zur Verständigung war 1988 in Tabgha möglich geworden. Dort gab es ein Erholungszentrum für behinderte Kinder. Es gelang mir, mit dem Prior des Klosters und mit dem deutschen Leiterpaar ein Projekt für invalide und verwundete palästinensische Jugendliche zu verwirklichen, die an den Folgen von Schussverletzungen litten. Oft habe ich selber Gruppen von fünfzehn bis dreißig Verletzten aus Gaza, Jerusalem und Nablus nach Tabgha geschmuggelt. An diesem humanitären Einsatz beteiligten sich erstmals gemeinsam palästinensische und israelische Ärzte.“Aufgrund der Vermittlerfunktion des Platzes konnte später sogar ein Treffen zwischen israelischen Veteranen des Jom-Kippur-Krieges und Intifadaopfern in Tabgha stattfinden. Gefördert wurde die Einrichtung vom Bundesministerium für Jugend, Familie und Gesundheit unter Leitung von Rita Süssmuth.An Einrichtungen stehen ein behindertengerechtes Gebäude für die Übernachtung, das so genannte Beit Noah mit derzeit 33 Betten und als Versorgungseinrichtung das Beit Benedikt mit Küche und Store zur Verfügung. Der Umfang der Übernachtungsmöglichkeiten in großen Zelten schwankt, derzeit gibt es 24 Schlafmöglichkeiten; maximal gab es 120 Zeltplätze gleichzeitig. Die Wege und Einrichtungen des Zeltplatzes wurden rollstuhlgerecht angelegt. Ebenso wurde eine der salzhaltigen Quellen (Q 2) so kanalisiert und ausgebaut, dass ein Pool entstand, der mit dem Rollstuhl befahren werden kann.
Die Leitung der Begegnungsstätte lag 14 Jahre lang in den Händen von Leitungspaaren aus Deutschland. Von 1984 bis 1988 waren es Ulla und Johannes Roelofsen, die vor allem mit der Errichtung der Infrastruktur beschäftigt waren. Von 1988 bis 1991 führten Renate Wolff-Zenner und Günter Zenner die Begegnungsstätte, von 1992 bis 1995 Barbara Viehoff und Helmut Röhrbein-Viehoff und von 2000 bis 2003 hatten Karin und Meinrad Bauer die Leitung inne. Seither organisieren die Benediktinermönche in Zusammenarbeit mit den philippinischen Schwestern die Begegnungsarbeit. Im September 2009 übernahm Nicole Bader von Pater Basilius die Leitung und seit September 2010 führt Paul Nordhausen-Besalel die Begegnungsstätte. Die Arbeit in der Begegnungsstätte wurde von Beginn an durch Zivildienstleistende (Sozialdienst nach § 14b ZDG) aus Deutschland und internationale Volontärinnen und Volontäre unterstützt.
Derzeit helfen in der Begegnungsstätte vier deutschsprachige Freiwillige, zwei US-Amerikaner und zwei Senior-Volontäre.
Tabgha war immer wieder Zwischenstation auf Reisen politischer, religiöser und anderer Persönlichkeiten des öffentlichen Lebens. So besuchte 1899/1900 während seiner Reise in den Orient auch der Schriftsteller Karl May den Ort. Er schenkte dem Verein für seine Aufnahme im Pilgerhospiz mehrere Bücher mit handgeschriebener Widmung, die aber verschollen sind. Zwischen 1934 und 1939 machte der schwedische Fotograf Gästgifvar Eric Matson (* 1888; † 1977), der im Auftrag der American Colony Jerusalem unter anderem für das National Geographic Magazine tätig war, von Tabgha Fotoaufnahmen.Mit Paul VI. (1897–1978) besuchte 1964 erstmals ein Papst den Ort. Ihm folgte im März 2000 Papst Johannes Paul II. (1920–2005).1982 zur Grundsteinlegung der Brotvermehrungskirche weilte der Kölner Joseph Kardinal Höffner (1906–1987) in Tabgha. 1987 besuchte Kardinal O’Connor (1920–2000) aus New York den Ort und im Jahr 2002 eröffnete Joachim Kardinal Meisner das neue Pilgerhaus. Im November 2010 war der Patriarchatsvikar für Israel, Msgr. Giacinto-Boulos Marcuzzo in Tabgha.Auch bei weltlichen Besuchern Israels steht Tabgha häufig auf dem Besuchsprogramm. So kam 1964 Togos Staatsoberhaupt Nicolas Grunitzky, 1992 Michail Gorbatschow und zwei Jahre später (1994) König Juan Carlos von Spanien.
An deutschen Politikern waren zuletzt 2005 Bundespräsident Horst Köhler, 2007 Bundesaußenminister Frank-Walter Steinmeier und 2010 Bundespräsident Christian Wulff in Tabgha.Seit 2007 ist Tabgha eine Station auf dem so genannten Jesus Trail, einer etwa 120 Kilometer langen Wander- und Pilgerroute, die sich an Lebensstationen des historischen Jesus orientiert.
Tabgha liegt etwa 200 Meter von der Busstation Capernaum (Kfar Nahum Junction) der Buslinie Egged entfernt. Diese Station liegt auf der Nord-Süd-Verbindungsstraße Nr. 90 zwischen Tiberias und Safed und wird von den Buslinien 840, 841 und 963 bedient. Auf der abzweigenden Straße Nr. 87, einem Teilstück der Ringstraße um den See Genezareth, fahren zwischen der Kreuzung an der Busstation und Kafarnaum nur sporadisch Busse. Die nächste zentrale Busstation mit Verbindungen in alle Richtungen befindet sich in Tiberias.Boote auf dem See Genezareth verkehren nach Bedarf von Kafarnaum, Ginnossar und Tiberias aus. In Tabgha fehlen zwar Anlegestege, trotzdem sind bei günstigen Wasserverhältnissen Anlandungen möglich.
Der nächste internationale Flughafen ist der Flughafen Ben Gurion etwa 150 Kilometer südöstlich von Tabgha. Der nächste nationale Flughafen für Inlandsflüge ist der Flughafen Haifa.
Internationale Schiffsverbindungen über das Mittelmeer nach Zypern und Griechenland gibt es ab Haifa, etwa 50 Kilometer westlich von Tabgha. Ebenfalls in Haifa befindet sich die nächstgelegene Eisenbahnstation der Eisenbahngesellschaft Israel Railways.
Die Bezeichnung „Tabgha“ wird aufgrund ihrer Kürze und des biblischen Bezuges von mehreren religiösen Bewegungen für ihre Einrichtungen in Anspruch genommen, wie der Jugendkirche Tabgha in Oberhausen oder der Tabgha Foundation in Minneapolis (USA).
Weiterhin wird der Name von einem Hotel in Tiflis (Georgien) und einem weiteren in Harrisburg (Illinois/USA) benutzt.
Anneliese und Anton Goergen: Tabgha am See Genesareth: Biblische Stätte der Brotvermehrung. München [und andere] 1989. 
Markus Krastl: Tabgha als Memorialstätte der Speisung der Fünftausend; Eine topographisch-archäologische Studie (Diplomarbeit an der Theologischen Fak. Trier). Trier 2002. 
Erich Läufer: Tabgha – Wo die Brotvermehrung stattfand; Biblisches Heiligtum am See Gennesaret. Köln 2000, ISBN 3-7616-1452-7. 
Andreas Evaristus Mader: Die Ausgrabungen der Kirche der Brotvermehrung durch die Görresgesellschaft. In: Theologie und Glaube 25. 1933, S. 669–677. 
Stephan Mock und Michael Schäbitz: Das Heilige Land als Auftrag: 1855–2005. 150 Jahre Deutscher Verein vom Heiligen Lande. Köln 2005, ISBN 3-00-015693-3. 
Bargil Pixner: Wege des Messias und Stätten der Urkirche. Gießen 1994, ISBN 3-7655-9802-X, S. 102 f. 
Rainer Riesner: Heptapegon und Kapernaum – Zwei byzantinische Pilgerstätten am See Gennesaret. In: G. Fassbeck, S. Fortner, A. Rottloff, J. Zangenberg (Hrsg.): Leben am See Gennesaret; Kulturgeschichtliche Entdeckungen in einer biblischen Region. Mainz 2003, ISBN 3-8053-2914-8, S. 173–180. 
Barbara und Helmut Röhrbein-Viehoff: Tabgha – Ort der Brotvermehrung; Jesus zieht sich in die Einsamkeit zurück. In: Welt und Umwelt der bibel. Band 4, Nr. 4, 2006, S. 23–26. 
Schiel, Basilius: Tabgha 2012: Festschrift zur Einweihung des neuen Klostergebäudes am 17. Mai 2012. Emerezian Est., Jerusalem 2012, ISBN 978-965-7409-05-3. 
Alfons Maria Schneider: Die Brotvermehrungskirche von et-Tabgha am See Gennesaret und ihre Mosaiken. [Collectana Hierosolymitana. Veröffentlichungen des orientalischen Instituts der Görresgesellschaft 4]. Paderborn 1934. 
Alfons Maria Schneider: Die Kapelle der sogenannten Mensa Domini bei et-Tabgha. In: Zeitschrift des deutschen Palästina-Vereins. Band 60, 1937, S. 133–135. 
Alois Peitz, Hubertus Hillinger, Susanne Hoffmann-Hillinger: Neubau Kloster Tabgha. Trier 2014, ISBN 978-3-00-045054-9. Karten und Abbildungen
Der Westen Tabghas, in: Volkmar Fritz: Tell El-Oreme/Kinneret. In: G. Fassbeck, S. Fortner, A. Rottloff, J. Zangenberg (Hrsg.): Leben am See Gennesaret. Mainz 2003, S. 33–42, hier S. 33.
Bargil Pixner: Der Osten Tabghas. In: Mit Jesus durch Galiläa nach dem fünften Evangelium. Rosh Pina 1992, S. 133. 
Die Library of Congress hält etwa 40 schwarz-weiß Abbildungen überwiegend aus den 1930er Jahren bereit.

Taekwondo (koreanisch 태권도, auch Tae-Kwon-Do oder Taekwon-Do) ist eine koreanische Kampfkunst, die oft als Kampfsport ausgeübt wird. Die drei Silben des Namens stehen für Fußtechnik (tae), Handtechnik (kwon) und Weg (do). Obwohl Taekwondo große Ähnlichkeiten mit anderen asiatischen Kampfsportarten aufweist, unterscheidet es sich in einigen wesentlichen Punkten von diesen. So ist die Taekwondo-Technik sehr auf Schnelligkeit und Dynamik ausgelegt, was nicht zuletzt durch den Wettkampf bedingt ist. Im Taekwondo dominieren Fußtechniken deutlicher als in vergleichbaren Kampfsportarten.
do = „Weg“, „Lehre“ (wie im Deutschen ist „Weg“ auch als Methode oder Zielstreben zu verstehen; Do leitet sich vom chinesischen Begriff Dào ab).Dies kann als „Der Weg des Fuß- und Faustkampfes“ oder auch als „Der Weg mit Fuß und Faust“ interpretiert werden.
Taekwondo entwickelte sich nach der japanischen Herrschaft in Korea, die bis 1945 dauerte, aus dem japanischen Karate. Die Ähnlichkeiten beispielsweise in Bezug auf Techniken und Formenlauf sind so groß, dass man Taekwondo als Karate-Stil ansehen kann. Der Begriff Taekwondo tauchte erstmals 1955 auf und wurde von General Choi Hong-hi (ITF) unter Einfluss des Shotokan-Karate entwickelt. Später kristallisierten sich Taekwondo-Unterstile heraus. Weltweit gibt es hauptsächlich drei Taekwondo-Stile (ITF traditionell, ITF reformiert und WT), die sich in der Formausübung (Hyeong, Tul und Pumsae) und im sportlichen Kampf unterscheiden. Im olympischen Wettkampfsystem wurde das Verbot ergänzt, mit der Faust den Kopf zu treffen.
Taekwondo als moderner Sport unterteilt sich in einzelne Disziplinen. Je nach Verein oder Schule werden die Schwerpunkte im Training unterschiedlich gesetzt.
Grundschule (Gibon Yeonseup): Üben einzelner Bewegungen und Techniken durch mehrfaches Wiederholen, ohne Gegner.
Formenlauf (Teul, Hyeong, Pumsae (Taegeuk/Palgue)): festgelegte Techniken werden in vorgegebener Reihenfolge durchgeführt.
Einschrittkampf (Hanbon Gyeorugi, Ilbo Matsogi, Ilbo Daeryeon): Ein Übungskampf mit festgelegter Technikenreihenfolge gegen einen Gegner. Neben dem Einschrittkampf gibt es auch noch den Zwei- und Dreischrittkampf (Ibo- bzw. Sambo-Matsogi, Ibo- bzw. Sambo-Daeryeon); sie haben eher untergeordnete Bedeutung.
Bruchtest (Gyeokpa): Zerstören von Holzbrettern, Ziegeln oder sonstigen Materialien mittels Taekwondo-Techniken.
Freikampf (Daeryeon, Matsogi oder Gyeorugi): Freier Übungskampf gegen einen Gegner, häufig ohne Berührung.
Selbstverteidigung (Hosinsul): Selbstverteidigung gegen einen oder mehrere unbewaffnete oder bewaffnete Gegner.
Durch kontinuierliches Training und bewusste Ausübung dieser Disziplinen soll der Taekwondoin, so wird ein Taekwondo-Betreibender genannt, seinen Geist schulen. General Choi Hong-hi, der Begründer des ursprünglichen Taekwondos, hat dies in fünf zu erreichenden Zielen zusammengefasst, die als „Grundsätze des Taekwondo“ gelten:
Beakjul-bool-gul, die UnbezwingbarkeitUm diese Ziele zu erreichen, stellte Choi Hong-hi einen Eid auf, dem sich alle Taekwondo-Schüler verpflichtet fühlen sollen:
Um mit einer Taekwondo-Technik die nötige Kraft und die damit verbundene durchschlagende Wirkung zu erzielen, bedient sich der Taekwondoin bestimmter physikalischer Gesetzmäßigkeiten. Das Wissen um diese physikalischen Gesetze nannte Choi Hong-hi „Theorie der Kraft“, wobei im Taekwondo der Begriff „Kraft“ synonym mit der physikalischen Kraft und den physikalisch verwandten Begriffen Druck (Physik) und Impuls verwendet wird. Die „Theorie der Kraft“ besteht aus:
Konzentration: Die gesamte Kraft genau im Moment des Schlages auf eine möglichst kleine Fläche wirken zu lassen. Große Fläche = kleine Kraftwirkung, kleine Fläche = große Kraftwirkung.
Gleichgewicht: Angriff wird wirksamer und Abwehr wird stabiler, wenn der Körper sich im Gleichgewicht befindet.
Atmungskontrolle: Eigene Schlagwirkung und Schutz des eigenen Körpers erhöhen sich durch Anspannen der Bauchmuskeln (Ausatmen und Pressen) im Moment des Schlages.
Masse: Je größer die am Schlag beteiligte Masse (Hüfte und gesamter Körper, nicht nur der schlagende oder tretende Körperteil), desto größer die wirksame Kraft.
Wie in vielen Ländern, aus denen Kampfsportarten hervorgegangen sind, gibt es auch in Korea eine alte Tradition an Kampfkünsten. Korea kann auf eine etwa anderthalb Jahrtausende alte eigenständige Kampfkunst-Tradition zurückblicken, jedoch gibt es keinen direkten Einfluss von ihnen auf das Taekwondo, das erst nach 1945 aus dem japanischen Karate entstand. Die gelegentlich anzutreffende Behauptung, Taekwondo stamme bereits vom legendären Staatengründer Dangun ab und sei somit letztlich über 4000 Jahre alt, entbehrt jeder historischen Grundlage.
Nach 1910 wurde Groß-Korea von Japan annektiert. Alles, was Kultur und Geschichte Koreas ausgemacht hatte, wurde systematisch unterdrückt und verboten. Das galt auch für traditionelle koreanische Kampfarten wie Taekgyeon und Ssireum. Die japanischen Kolonialherren brachten Kampfarten wie Jiu Jitsu, Kendo, Judo und Karate von zu Hause mit. Während der Besatzungszeit Koreas zerstreuten die Japaner Versammlungen von mehr als zehn Koreanern mit ihren Gerten. Kampfkunst bzw. Kampfsport war in Korea traditionell jedoch eine gesellige Aktivität. Anders als in Japan gab es auch keine Formen, so dass ein Training alleine nicht üblich war. Wie u. a. Song Dok-ki für das Taekgyeon überlieferte, spielten Wettkämpfe immer eine große Rolle. Es gab also zwar kein direktes Verbot von Kampfsport oder -kunst, aber das Versammlungsverbot traf natürlich Taekgyeon, Ssireum und Gungsul genau wie alle anderen koreanischen Traditionen, so dass sie um Haaresbreite ausgelöscht wurden.
Nach der Unabhängigkeit Koreas im Jahr 1945 kehrten Koreaner zurück in ihr Heimatland, die in Japan und der Mandschurei japanisches Karate gelernt hatten. Sie eröffneten die fünf ursprünglichen Kampfkunst-Schulen, aus denen später das Taekwondo entstehen sollte. Die Namen dieser Schulen endeten alle auf Kwan, was im wörtlichen Sinne „Halle“ bedeutet.
Lee Won-Kuk hatte Shotokan-Karate bei Gichin Funakoshi gelernt und begann bereits 1944, Dangsudo in seiner Schule, dem Cheongdo-Kwan („Halle des wahren Weges“) in Seoul, zu unterrichten. Lee flüchtete 1953 aus politischen Gründen nach Japan und emigrierte 1976 in die USA.
Hwang Ki lernte ab 1936 in der ebenfalls japanisch besetzten Mandschurei vermutlich Karate, auch wenn er den Stil später als einen chinesischen ausgab. 1945 gründete er in Seoul den Moo Duk Kwan (etwa „Halle der Kampftugenden“). Seinen Stil nannte er zunächst ebenfalls Dangsudo, später dann, in Korea, Subakdo. Auf internationaler Ebene behielt er den Namen Dangsudo (geschrieben „Tang Soo Do“, abgekürzt TSD) bei, unter dem sein Stil vor allem in den USA heute noch betrieben wird.
Chun Sang-Sup hatte Judo und Karate während seines Studiums in Japan gelernt und schloss sich 1946 dem Yeonmu-Kwan an, der größten Seouler Judo-Schule, wo er neben Judo auch Gongsudo unterrichtete. Chun gilt als im Korea-Krieg verschollen. Seine Schüler änderten den Schulnamen daraufhin in Jido-Kwan („Weg der Weisheit“).
Yoon Byung-In kehrte als ranghöchster koreanischer Karateka aus Japan zurück, wo er bei Kanken Toyama (Shudokan-Stilgründer) den 5. Dan im Shudokan-Karate erreicht hatte. Er soll in der Mandschurei auch Kwon Bop (chinesisches Quanfa/Kung fu) gelernt haben.
Ebenfalls 1946 gründete er den Changmu-Kwan im Seouler YMCA und nannte seinen Stil (vermutlich aus politischen, das heißt anti-japanischen Gründen) Kwon-Bop („Faustmethode“). Yoon wurde vermutlich während des Korea-Krieges nach Nordkorea verschleppt.
Ro Byung-Jik hatte zusammen mit Lee Won-Kuk Shotokan-Karate bei Gichin Funakoshi gelernt und trug bei seiner Rückkehr den 1. Dan. Seine erste Schule gründete er bereits vor der Unabhängigkeit in Kaesŏng im heutigen Nordkorea, zog aber mangels Erfolg 1946 nach Seoul und eröffnete dort den Seongmu-Kwan (abgeleitet von „Seong Do Kwan“, der koreanischen Aussprache des japanischen Shotokan).Alle nannten ihren Stil zunächst Dangsudo (Tangsoodo), „Weg der (Dang-)China-Hand“, oder Gongsudo (Kongsoodo), „Weg der leeren Hand“. In beiden Fällen handelt es sich um die koreanische Aussprache dessen, was auf japanisch Karate gelesen wird. Das Wort „Karate“ erfuhr in den 1930ern eine Deutungs- und Bedeutungsänderung von „(Dang-)China-Hand“ in „leere Hand“. In diesen fünf ersten Seouler Taekwondo-Schulen wurde ursprünglich also die eine oder andere Art Karate trainiert, und Ausländern gegenüber wurde es bis in die 1960er Jahre hinein als „Koreanisches Karate“ vorgestellt. Allerdings bestanden zwischen den Schulen unterschiedliche Standards für Dan-Prüfungen.
Bereits vor dem Koreakrieg (1950–1953) war es zu ersten Gesprächen über einen eventuellen Dachverband gekommen, doch erst während des Kriegs einigten sich die Kwan-Vertreter in Busan auf die Koreanische Gongsudo-Vereinigung. Diese erste Vereinigung zerfiel bereits nach wenigen Monaten, weil Hwang Ki gleich darauf in Seoul im Alleingang die Koreanische Dangsudo-Vereinigung gründete, woraufhin auch Son Duk-sung aus der Gongsudo-Vereinigung austrat. Son Duk-sung hatte inzwischen die Leitung des Cheongdo-Kwan übernommen, damals die größte zivile Kampfkunst-Schule.
Kurz nach dem Krieg gelang es Generalmajor Choi Hong-hi, durch seine Schüler Einfluss auf die Leitung des Cheongdo-Kwan zu nehmen; er selber wurde Kwan-Chef ehrenhalber. Choi hatte Anfang der 1940er Jahre in Japan je nach Quelle den 1. oder 2. Dan im Karate erlangt, bevor er erst der japanischen, nach Koreas Unabhängigkeit der koreanischen Armee beitrat. Bei jeder Gelegenheit trainierte er seine Untergebenen und Kollegen im Karate und traf dabei auf den hochtalentierten Nam Tae-hi, der Dangsudo im Cheongdo-Kwan gelernt hatte und gleich Chois rechte Hand wurde. Nam Tae-hi beeindruckte Koreas Präsident Syngman Rhee während einer Demonstration im Jahre 1952 mit einem Dachziegel-Bruchtest so sehr, dass dieser Gongsudo-Training für alle Soldaten anordnete. Dazu gründeten Choi und Nam 1953 den militärinternen Odo-Kwan („Mein Weg“), der im Laufe der Zeit zur einflussreichsten Kampfkunst-Schule wurde, denn früher oder später musste jeder junge Koreaner das Militär passieren. Somit verschärfte sich die Situation für die anderen Kwan, denn im Militär wurden zunächst nur die Dan-Graduierungen des Choi-hörigen Cheongdo-Kwan anerkannt.
In den späteren 1950er Jahren spitzte sich die Lage auf einen Machtkampf zwischen Hwang Ki und Choi Hong-hi zu. Hwang organisierte mehrere Dangsudo-Vorführungen und bemühte sich, seinen Stil über seine Schüler im Militär bekannt zu machen. 1955 organisierte Choi mit Unterstützung der Regierung eine Kommission, die erneut über eine Vereinigung der verschiedenen Gongsudo-Stile verhandelte. Diese Kommission umfasste allerdings nicht alle betroffenen Kwan, sondern bestand aus Vertretern des Cheongdo-Kwan, des Odo-Kwan, des Militärs und der Regierung. Bei dieser Gelegenheit kreierte Choi Hong-hi am 11. April 1955 den Namen „Taekwondo“, ein Name, der, schmissig ausgesprochen, ganz bewusst an das traditionelle Taekgyeon erinnern sollte, auch wenn es keine inhaltliche Verwandtschaft dazu gab. Dieser Name wurde bis in die 1960er Jahre außerhalb von Chois Einflussbereich, also dem Cheongdo-Kwan und dem Odo-Kwan, nicht verwendet.
Hwang Ki kreierte ebenfalls einen neuen Namen für seinen Stil, nachdem er 1957 das alte Buch „Muye Dobo Tongji“ (etwa „Illustriertes Handbuch der Kampfkünste“) von etwa 1790 wiederentdeckt und ins moderne Koreanisch übersetzt hatte: Subakdo, etwa „Weg der schlagenden Hand“. Daneben behielt er die Bezeichnung Dangsudo für seine internationalen Bestrebungen bei, unter der er zunächst lokale Vorführungen und ab den 1960er Jahren internationale Turniere organisierte.
Mit Unterstützung der Rhee-Regierung organisierte Choi 1959 die Gründung der ersten Koreanischen Taekwondo-Vereinigung und wurde deren erster Präsident. Hwang Ki und andere plädierten dabei für den Namen Dangsudo, aber mittels seiner militärischen Autorität konnte Choi sich durchsetzen.
Chois Machtbasis brach im Zuge der Studentenrevolution am 19. April 1960 zusammen, ebenso die frisch gegründete, aber offiziell noch nicht registrierte Taekwondo-Vereinigung. Hwang Ki nutzte die Gunst der Stunde: Mithilfe eines guten politischen Kontaktes im Ministerium gelang ihm kurz darauf handstreichartig die Registrierung seines eigenen Verbandes, den er in Koreanische Subakdo-Vereinigung umbenannte. Damit war der Weg für Taekwondo zunächst verbaut, denn eine zweite Vereinigung für den gleichen Sport registrieren zu lassen war nicht möglich.
Am 16. Mai 1961 putschte General Park Chung-hee, und kurz danach wurde per Dekret Nr. 6 die Neuordnung der Dangsudo/Gongsudo/Subakdo-Registrierung verordnet. Dies hätte die große Stunde des Generals Choi Hong-hi werden können, doch es gab Differenzen zwischen den beiden Militärführern, und Choi wurde als Botschafter nach Malaysia abgeschoben. Die koreanische Taekwondo-Entwicklung fand für die nächsten vier Jahre ohne Choi statt. Er entwickelte im Exil sein Hyeong-System (siehe unten, „Formenlauf“) und setzte seine Bemühungen eigenmächtig fort, Taekwondo international, etwa bei den US-Truppen in Vietnam, bekannt zu machen.
Im September 1961 kam es zur Gründung der Koreanischen Taesudo-Vereinigung (Korean Taesoodo Association, kurz KTA), wobei man sich auf den neuen Namen „Taesudo“ (etwa „Tritt-Hand-Weg“) als Kompromiss zwischen Dangsudo, Subakdo und Taekwondo einigte. Man entwickelte einheitliche Prüfungs- und Wettkampfregeln und schickte Show-Teams ins Ausland.
Korean Taekwondo Association: 1965 kehrte Choi Hong-hi nach Korea zurück, und er wurde gleich zum neuen KTA-Präsidenten gewählt. Sofort änderte er den Namen der Kunst in Taekwondo – angeblich wurde die Namensänderung mit einer Stimme Mehrheit beschlossen – und forcierte die Bestrebungen nach Internationalisierung. So kam Taekwondo nach Deutschland und führte 1967 zur Gründung des Deutschen Taekwondo-Verbandes mit Ausrichtung der 1. Deutschen Taekwondo-Meisterschaft. Hwang Kis Moo Duk Kwan spaltete sich über die Streitfrage, ob man Chois KTA folgen solle oder nicht, und viele seiner Schüler schlossen sich der KTA an. Hwang Ki selbst blieb von der KTA unabhängig und gründete später im Ausland, insbesondere in den USA, verschiedene Dangsudo-Verbände.
Gründung der ITF: Der permanente Streit zwischen KTA-Präsident Choi und den anderen Kwan-Leitern führte dazu, dass man Choi bereits ein Jahr später nötigte, vom Posten zurückzutreten und ihm im Gegenzug die Gründung eines eigenen Verbandes, der International Taekwon-Do Federation, kurz ITF, zusicherte. Sie wurde am 22. März 1966 in Seoul mit den Gründungsländern Arabien, Deutschland (West), Italien, Korea, Malaysia, Singapur, Türkei, USA und Vietnam vollzogen. Erster und bis zu seinem Tod einziger Präsident war selbstverständlich Choi Hong-hi.
In den folgenden Jahren wuchs der Konflikt zwischen der KTA und der ITF, sodass man in der KTA eigene Formen entwickelte, die Pumsae (erst acht Palgwe, dann acht Taegeuk) und die neun Yudanja (koreanische Aussprache des japanischen „Yudansha“, siehe unten, „Formenlauf“).
1971 wurde Kim Un-Yong zum 6. KTA-Präsidenten gewählt. Im selben Jahr stellte sich der südkoreanische Präsident Park Chung-hee zur Wiederwahl, und weil er eine Krise kommen sah, rief er Ende des Jahres den nationalen Notstand aus. Noch vorher entdeckte er Taekwondo als nationales Erziehungsmittel und fertigte am 20. März 1971 höchstpersönlich eine Kalligrafie an, mit der er Taekwondo zum koreanischen Nationalsport (Gukki Taekwondo, etwa „nationaler Schatz Taekwondo“) erklärte. Im selben Jahr erfolgte die Grundsteinlegung des Kukkiwon (etwa „Ausübungsstätte des nationalen Schatzes“), des „Welt-Taekwondo-Hauptquartiers“ (so der offizielle Titel), das 1972 fertiggestellt wurde. Präsident war ebenfalls Kim Un-yong.
Trennung der Verbände in WT und ITF: Im selben Jahr verließ Choi Hong-hi vermutlich wegen Verbandsstreitigkeiten Südkorea. Er verlegte den Sitz der ITF nach Toronto in Kanada und begann die Reform seines Taekwon-Do. Als Folge davon wurde am 28. Mai 1973 im Zuge der im Kukkiwon stattfindenden ersten Taekwondo-Weltmeisterschaft die World Taekwondo, kurz WT, mit Sitz in Seoul gegründet. Auch hier wurde Kim Un-Yong Präsident. KTA, WT und Kukkiwon arbeiteten nun mit Unterstützung der Park-Regierung Hand in Hand daran, die verschiedenen Taekwondo-Schulen (Kwan) Südkoreas aufzulösen, um ein einheitliches Taekwondo-System durchzusetzen. Hwang Ki gewann zwar diverse Prozesse dagegen, doch der Druck auf ihn und seine Schule wurde immer größer, bis er schließlich nachgab und 1974 in die USA zog. 1976 wurden die noch bestehenden Kwan durch Nummern ersetzt und zwei Jahre später ganz aufgelöst.
Die späteren 1970er und 1980er Jahre waren geprägt durch den Konflikt beider Taekwondo-Weltverbände, respektive ihrer Präsidenten Choi Hong-hi und Kim Un-Yong. Kim konnte dabei auf die massive Unterstützung seiner Regierung bauen, und so gelang ihm schließlich 1980 die Anerkennung der WT als Weltfachverband Taekwondo vom IOC. Bei den Olympischen Spielen 1988 in Seoul und 1992 in Barcelona war das WT-Taekwondo als Demonstrationswettbewerb zugelassen, seit den Olympischen Spielen 2000 in Sydney ist es eine vollwertige olympische Disziplin.
Choi ging einen anderen Weg und besuchte mit einem Team 1981 Nordkorea, wo seitdem ITF-Taekwondo betrieben wird. Das wurde ihm in Südkorea sogleich als Landesverrat angelastet. Bis heute wird sein Name dort weitgehend verschwiegen, und seine Leistungen als „Vater des Taekwondo“ werden nicht anerkannt. Er starb am 20. Januar 2002 in Nordkorea, Hwang Ki ebenfalls 2002 in Südkorea, und Kim Un-yong wurde im Juni 2004 wegen Korruption und Veruntreuung zu einer zweieinhalbjährigen Freiheitsstrafe verurteilt, aus der er Ende Juni 2005 im Zuge einer Generalamnestie entlassen wurde.
Taekwondo ist sowohl national als auch international in sehr viele Verbände zersplittert; es lassen sich allerdings zwei dominante Organisationen identifizieren: die beiden Weltverbände ITF (International Taekwon-Do Federation, gegründet im Jahr 1966) und WT (World Taekwondo, gegründet 1973). In Deutschland ist die Deutsche Taekwondo Union (DTU) dem Weltverband WT angegliedert. Die DTU ist dem Deutschen Olympischen Sportbund angegliedert und somit offizieller Taekwondo-Verband in Deutschland.
Darüber hinaus gibt es viele unabhängige Schulen, die sich mehr oder weniger an die Verbandsstile anlehnen oder sich am „traditionellen“ Taekwondo-Stil orientieren, wie er ursprünglich von General Choi Hong-hi in den 1950er und 1960er Jahren entwickelt wurde. Ein Beispiel hierfür ist das „Traditionelle Taekwondo“ nach Kwon Jae-hwa, welches sich deutlich von dem „modernen“ Taekwondo der DTU, ITF und WT unterscheidet, vor allem durch den Verzicht auf Schutzausrüstung beim Wettkampf. Es wird kontaktloser Kampf praktiziert, Schläge und Tritte werden kurz vor dem Gegner abgestoppt.
Die ITF (International Taekwondo Federation) wurde am 22. März 1966 in Seoul gegründet. Gründungsmitglieder waren die Landesverbände Arabien, Deutschland, Italien, Korea, Malaysia, Singapur, Türkei, USA und Vietnam. Choi Hong-hi wurde der erste Präsident der ITF und hatte dieses Amt bis zu seinem Tode 2002 inne. In den nachfolgenden Jahren kamen zahlreiche neue Landesverbände hinzu. Zurzeit gehören der ITF über 100 Landesverbände an, und die Zahl der Schüler geht in die Millionen. Zwei Jahre nachdem die ITF ihren Hauptsitz nach Toronto verlegt hatte (1972), wurde die erste ITF-TKD-WM durchgeführt. Die ITF hat ihren Sitz in Wien, nachdem ihr Gründer General Choi Hong-hi nach Kanada emigrierte und den Sitz der ITF zunächst nach Toronto und dann 1985 nach Wien verlegt hatte.
Die WT hat ihren Sitz in Seoul (Südkorea), der Gründer ist Kim Un-Yong. Sie wurde 1973 als Reaktion auf die Emigration von General Choi und die parallel stattfindende Verlegung der ITF-Zentrale gegründet. Begründung dafür war, dass Taekwondo als koreanischer Nationalsport seinen Zentralsitz unbedingt in Korea haben sollte. Unter dem Dach der WT findet das Olympische Taekwondo statt, daher ist eine Teilnahme an den Olympischen Spielen nur als Angehöriger der WT möglich. Der WT gehören 191 (Stand: April 2010) nationale Verbände mit über 30 Millionen Mitgliedern an.
Aus verbandspolitischen Gründen haben sich im Taekwondo verschiedene Stile entwickelt, auch deshalb, weil sich gerade die großen Weltverbände gezielt weiterentwickeln: vor allem die WT versucht, den Sport publikumswirksamer und damit die Wettkämpfe attraktiver zu gestalten. Demgegenüber setzen die traditionellen Schulen auf das Althergebrachte, das sie bewahren wollen. Die Stile unterscheiden sich daher vor allem in den Formenläufen, in der Namensgebung der Techniken sowie in der Art des Wettkampfes. Die Techniken selbst sind im Grunde identisch. In der Körperbewegung gibt es augenfällige Unterschiede: In den traditionelleren Taekwondo-Schulen werden Bewegungen zumeist, dem Karate ähnlich, zwischen Positionen mit tieferem und breiterem Stand durchgeführt. Der Körperschwerpunkt wird kontinuierlich niedrig gehalten und wenn möglich auf einer Linie bewegt. Die moderneren, wettkampforientierten Richtungen gingen zu höheren Ständen über. Zwischen einzelnen Positionen im Formenlauf wird der Körper deutlich mehr auf und ab bewegt. Hinzu kommt, dass diverse Großmeister den jeweiligen Stil ebenfalls leicht beeinflussen, was dazu führt, dass alle untergeordneten Schulen diesen Stil übernehmen. Dies betrifft vor allem bestimmte Techniken und hier insbesondere den jeweiligen Bewegungsablauf. Einige Großmeister verlangen weiche, fließende Bewegungen, andere kantig-dynamische. Auch die Ausführungsgeschwindigkeit der jeweiligen Technik unterscheidet sich oftmals.
Im Wesentlichen lassen sich drei Haupt-Stilrichtungen identifizieren: das traditionelle ITF-Taekwondo, wie es ursprünglich in den Anfangsjahren praktiziert wurde; das reformierte ITF-Taekwondo, wie es von Choi Hong-hi nach 1972 aus dem traditionellen Taekwondo entwickelt wurde; das WT-Taekwondo, das sich nach 1973 aus dem traditionellen Taekwondo hervortat. Die meisten Verbände, Schulen und Vereine zumindest in Deutschland lassen sich bezüglich ihrer Art, den Sport auszuüben, einer dieser drei Stilrichtungen zuordnen.
Zur Abgrenzung musste sogar die Schreibweise des Begriffes Taekwondo herhalten. Traditionell heißt es „Taekwon-Do“; diese Schreibweise hat auch die ITF behalten. Die WT schreibt den Namen „Taekwondo“. Manche Schulen trennen die Silben komplett und schreiben „Tae-Kwon-Do“. Die offizielle Umschrift des Begriffs 태권도 ist „Taegwondo“ in Südkorea (Revidierte Romanisierung) und „T'aekwŏndo“ (McCune-Reischauer-Romanisierung) in Nordkorea; diese Schreibweisen werden aber praktisch nie verwendet.
Auch Techniken werden manchmal unterschiedlich benannt, obwohl sie in gleicher Weise ausgeführt werden. Das resultiert vor allem darin, dass die Übersetzung der koreanischen Schreibweisen in westliche Schriften nicht ganz eindeutig ist. Daher können solche Bezeichnungen voneinander abweichen (vergleiche Taekwondo-Begriffe).
Formen (englisch: Pattern) sind festgelegte Schritt- und Technikfolgen. Sie gleichen einem Kampf gegen imaginäre Gegner und dienen vor allem der Automatisierung von Bewegungsfolgen und dem Training von passenden Atemtechniken.
Der geschichtliche Hintergrund ist angeblich, dass es früher viel zu gefährlich gewesen wäre, einen Trainingskampf gegen einen echten Gegner zu führen – bei Verletzung oder Tod hätte dies zu erheblichen wirtschaftlichen Problemen (Arbeitskraft in der Landwirtschaft) und entsprechenden Racheakten der Familie des Opfers geführt. Es gibt noch weitere Theorien über die Entstehung von Formen, die sich in allen asiatischen Kampfarten und in den unterschiedlichsten kulturellen Kontexten entwickelt haben.
Teul (von Choi Hong-hi später aus den Hyeong weiterentwickelt, siehe dort)1) Die ersten acht Formen haben keine eigenen Namen, sondern als Gesamtheit den Namen Taeguk. Die Namen der einzelnen Formen Il Jang bis Pal Jang stellen lediglich eine Nummerierung in sinokoreanischer Zählweise dar. Parallel zu der Taeguk-Schule existiert auch eine Palgue-Schule, ebenfalls mit den Formen Il Jang bis Pal Jang. Ab dem 1. Dan heißen die Formen weder Palgue noch Taeguk, sondern jede Form hat einen eigenen Namen. Der Oberbegriff für die Formen der Palgue, Taeguk, und der in ihrer Gesamtheit als 'Yudanja' bezeichneten einzeln benannten Formen ab dem 1. Dan lautet Pumsae.
2) Es gibt traditionell 20 Hyeongs. Dann wurden die 20 Hyeongs um weitere 4 Hyeongs ergänzt, um symbolisch für die 24 Stunden am Tag auch 24 Hyeongs zu haben. Die Hyeong Tong-Il war die 20. Hyeong und wurde dann zur 24. Hyong, da sie für die Wiedervereinigung Koreas steht. Als General Choi anfing, die Hyeongs zu verändern, und sogar eine weitere Form entwickelte, um diese gegen eine andere auszutauschen, benannte er die Hyeongs in Teul um. Zum Vergleich der traditionellen Reihenfolge der Hyeongs mit der Reihenfolge der Teul vergleiche diese Liste.
4) Vollständiger Name dieser Formen ist je nach Formenschule '<Formenschule> <Nummer> Jang', z. B. 'Taeguk Pal Jang' oder 'Palgue Sa Jang'.
Zu diesen Formen gibt es noch die „Vierseitengrundschule“ (Sajojirugi), die zwei Techniken enthält, die in vier Richtungen ausgeführt werden. Diese Techniken sind meist die ersten, die man lernt (Apkubi-araemakki und Momtong-chongwon-chirugi).
Das Taekwondo hat sich von einem koreanischen Volkssport mit der Verbreitung in der Welt, der Austragung von internationalen Wettkämpfen und der Aufnahme in das Programm der Olympischen Spiele zu einem modernen Wettkampfsport entwickelt. Nach Angaben der WT trainieren weltweit über 40 Millionen Athleten den dynamischen Vollkontakt-Wettkampfsport, seit der offiziellen olympischen Anerkennung in Sydney 2000 mit steigender Tendenz.
Der Wettkampf (Freikampf) findet auf einem abgegrenzten Feld statt und wird von mehreren Punktrichtern bewertet, von einem Kampfrichter geleitet. Der Wettkampf geht über wenige Minuten (olympisch drei Runden über jeweils zwei Minuten mit jeweils einer Minute Pause), in denen die Teilnehmer versuchen müssen, mit Taekwondo-Techniken den Gegner zu treffen (Vollkontakt). Je nach getroffener Körperstelle (Torso zwei Punkte und Kopf 3 Punkte) werden Punkte vergeben, für Drehtechniken wird jeweils ein Zusatzpunkt gegeben, bei unsportlichem Verhalten können auch Strafen (Punktabzüge) vergeben werden. Der Wettkampf kann jedoch auch durch ein K.O. entschieden werden. Die genauen Kampfordnungen unterscheiden sich von Verband zu Verband, können aber in der Regel auf den Webseiten der Verbände eingesehen werden (siehe Weblinks, unten). Die olympischen Wettkämpfe finden in vier der sonst üblichen acht Gewichtsklassen für Männer und Frauen nach den international gültigen Wettkampfregeln der WT statt. Im Vollkontakt tragen die Wettkämpfer exakt vorgeschriebene Schutzausrüstung (Kopfschutz, Schienbein- und Ellbogenschoner, Tiefschutz, Zahnschutz, Brustpanzer).
Als Konsequenz der starken Wettkampforientierung in der olympischen Sportart werden schwerpunktmäßig Techniken und Kombinationen geübt, die im Wettkampf gemäß der Wettkampfordnung Trefferpunkte bringen. Im Gegensatz dazu besinnen sich die traditionellen Schulen auf ein Taekwondo ohne Wettkampfdruck und üben demzufolge das gesamte Technikspektrum. Dennoch finden auch hier Freikämpfe (meist Leicht- beziehungsweise Semikontakt) statt. Hier stehen allerdings statt der Trefferwirkung eher die korrekte und ästhetische Ausführung der Technik(en) im Vordergrund.
Neben dem Freikampf werden auch Formenturniere ausgetragen, diese Wettkampfdisziplin ist allerdings nicht olympisch.
Taekwondo wurde ab 1965 durch die Großmeister Choi Hong-hi und Kwon Jae-hwa auch im deutschsprachigen Raum verbreitet (diese Arbeit wurde später von vielen anderen koreanischen Großmeistern unterstützt und fortgesetzt, die zum Teil heute noch in Deutschland ansässig sind). Hervorzuheben sind der langjährige DTU-Bundestrainer Park Soo-nam aus Stuttgart, unter dessen Regie Deutschland ununterbrochen in Folge (1976, 1978, 1980, 1982, 1984) Europameister wurde und zahlreiche Medaillen auf Weltebene hervorgebracht hat, sowie sein Vorgänger Shin Boo-Young, der deutscher Nationaltrainer von 1972 bis 1975 war. Unter anderem errang das deutsche Team zweimal Gold, 1979 durch Rainer Müller und 1982 durch Dirk Jung, sowie zweimal Bronze in Korea bei den ersten olympischen TKD-Wettkämpfen 1988 in Seoul durch Markus Woznicki (Europameister 1988) und Michael Arndt (Weltmeister 1987).
Die ersten deutschen Meisterschaften fanden bereits 1967 in München statt. Die ersten WM-Teilnehmer Deutschlands gewannen in Korea 1973 Silber durch Armando Chavero und Bronze durch Georg Karrenberg (beide Leichtgewicht). Ebenfalls in Korea errangen 1975 jeweils eine Silbermedaille Wolfgang Dahmen (Federgewicht) und Meinolf Lüttecken (Schwergewicht), sowie Hubert Leuchter (Bantamgewicht) Bronze.
Erster Bundestrainer der Sektion Taekwondo im Deutschen Judo-Bund (DJB) wurde 1972 Kwon Jae-hwa, der den zunächst provisorisch eingesetzten Kim Kwang-Il ablöste.
Die Deutsche Taekwondo Union (DTU) wurde 1981 gegründet und ging aus der Sektion Taekwondo des Deutschen Judo-Bundes hervor. Die DTU ist Mitglied in der European Taekwondo Union (ETU) sowie des Weltdachverbandes WT. Damit ist die DTU vom Deutschen Olympischen Sportbund als einziger Verband anerkannt und berechtigt, Sportler zu den Olympischen Spielen zu entsenden. Heute trainieren über 58.000 Aktive in der DTU, welche in etwa 850 Vereinen den Sport ausüben. Zur DTU gehören 17 Landesverbände.
Die ITF-D mit Sitz in Köln ist ein deutscher Nationalverband. Sie ist deren europäischem und internationalem Verband angeschlossen. Präsident ist seit 2007 Walter Komorowski (7. Dan). Über 17 Jahre (1989–2007) war Paul Weiler (8. Dan) als Präsident maßgebend am Aufbau des Verbandes und der Verbandsstrukturen beteiligt, nach dem er die ITF-D von seinem Vorgänger Lee, Ky-Yung übernommen hatte. Der Ursprung dieses Verbands reicht in Deutschland bis ins Jahr 1966 zurück. Die Strukturen wurden in zahlreichen europäischen Ländern übernommen. Heute ist Paul Weiler Vizepräsident in einem der Weltverbände.
Ein weiterer deutscher Verband ist die International Taekwon-Do Federation-Germany (ITF-G) mit Hauptsitz in Marburg unter der Präsidentschaft von Andreas Granzow (7. Dan) und dem Vizepräsidenten Bruno Newel (5. Dan). Die ITF-Germany ist offizieller deutscher Vertreter der International Taekwon-Do Federation in Wien und stellt in Kooperation mit dem NWTV eine Mitgliedervertretung der ITF in Deutschland dar. Die ITF-Germany e. V. entstand 2011 und ist Mitglied der europäischen EITF.
Die NAG mit Sitz in Gladbeck ist ein weiterer deutscher Verband, der durch Abspaltung von der ITF-D entstand. Er wird von Dario Fimiani (4. Dan) geleitet. Abspaltungsgrund war hier die gewünschte Zusammenarbeit mit Choi Jeong-hwa (dem Sohn von Choi Hong-hi) und dessen Verband.
Seit 2003 findet in Deutschland innerhalb der DTU die Taekwondo-Bundesliga statt, die im Freikampf (olympische Disziplin) den deutschen Taekwondo-Mannschaftsmeister ermittelt und den Sport publikumswirksam einem breiteren Zuschauerkreis auf regionaler Ebene näher bringt. Bei den Olympischen Spielen 2000 in Sydney gewann Deutschland erstmals eine Silbermedaille durch Faissal Ebnoutalib (Herren –80 kg). Der ehemalige Sportsoldat und dreifache Weltmeister (2 × CISM und WM 1995) Aziz Acharki belegte den 5. Platz (Herren –68 kg), und Fadime Helvacioglu (Damen –49 kg) schied bei den Frauen in den Vorkämpfen vorzeitig aus.
Bei den erstmals ausgetragenen Olympischen Jugend-Sommerspielen 2010 in Singapur gewann für Deutschland
2003 fand die WT-Weltmeisterschaft in Garmisch-Partenkirchen statt. Etwa 1000 Teilnehmer aus über 100 Ländern nahmen daran teil. Deutschland errang insgesamt drei Medaillen: Silber für Mohamed Ebnoutalib, Bronze jeweils für Thucuc Pham und CISM-Goldmedaillengewinner Erdal Aylanc. Nach der WM 1979 in Sindelfingen konnte nach 24 Jahren erneut eine Taekwondo-WM in Deutschland ausgetragen werden.
Europameisterschaften werden seit 1976 (Barcelona) ausgetragen und finden in der Regel alle zwei Jahre, abwechselnd zu den WT-Weltmeisterschaften, statt. Nach 1978 (München) und 1984 (Stuttgart) wurde 2006 in Bonn erneut eine Europameisterschaft in Deutschland ausgetragen.
Der Kampfanzug (Dobok) ist ein Anzug aus leichtem, weißgebleichtem Stoff, der aus einer Art Jacke (Sang-I), Hose (Hang-I) und Gürtel (Ty) besteht. Er ist strapazierfähig, lässt alle Bewegungen zu und widersteht leichtem bis mittlerem Reißen. Zur Grundbekleidung kommen gegebenenfalls noch Schutzausrüstungen für den Wettkampf hinzu (siehe oben). Jegliche Form von Schmuck (Ringe, Hals-/Fußkettchen, Armbänder, Uhren und große Ohrringe) muss wegen der Verletzungsgefahr vor dem Training abgelegt werden.
Die Füße bleiben unbekleidet. Ausnahmen gibt es für Sportler mit Fußverletzungen oder ähnlichem, bei Bedarf sollte man den Lehrer fragen. Spezielle Taekwondo-Schuhe gibt es zwar, doch sollten diese nur zu speziellen Anlässen (Vorführungen oder Training im Freien) getragen werden.
Das Oberteil soll das Gesäß bedecken, seine Ärmel reichen mindestens über den halben Unterarm, höchstens bis zu den Handgelenken. Schwarzer Rand und schwarzes Revers sind nur für Danträger zulässig. Im traditionellen Taekwon-Do ist das Oberteil ähnlich wie im Judo und Karate eine Jacke, in den wettkampforientierten Varianten ist es dagegen auf der Vorderseite geschlossen, so dass man es über den Kopf zieht.
Die Hose ist so gearbeitet, dass ein seitlicher Spagat möglich ist. Sie reicht mindestens bis zur halben Wade.
An Jacke und/oder Hose können auch Verbandsabzeichen und Aufdrucke angebracht werden, was durch die Bekleidungsordnungen der jeweiligen Verbände und Schulen geregelt wird.
Für Probetrainings ist auch ein (strapazierfähiger) Trainingsanzug zulässig. Bei Eintritt in einen Verband muss der Schüler allerdings einen Dobok erwerben. Das Tragen des Doboks soll die Schüler zu einer Einheit werden lassen, deshalb sind Abweichungen von der Kleidungsordnung unerwünscht.
Im Taekwondo hat der weiße Dobok sowie der weiße Gürtel auch symbolischen Charakter. Die Farbe Weiß ist rein und kann noch leicht alle anderen Farben annehmen. Sie ist wie ein noch unbeschriebenes Blatt, völlig leer. Ein Schüler im weißen Dobok ist vergleichbar mit einem noch leeren Glas, in das langsam neues Wissen der Meister eingegossen wird. Der Schüler sollte dieses Wissen und Können „aufsaugen“, verarbeiten, um es dann erfolgreich in die Tat umzusetzen. Unabhängig von dieser Bedeutung entstand der weiße Trainingsanzug wohl ganz pragmatisch aus der Tatsache, dass Farbstoffe früher sehr teuer waren.
Erwähnt werden soll hier als Erstes, dass die Erkennung des Ranges nicht der Hauptgrund ist, dass beim Taekwondo Gürtel getragen werden. Viel wichtiger ist, dass 3 Fingerbreiten unter dem Bauchnabel das oft in der asiatischen Philosophie genannte Zentrum liegt, das für die Entstehung der Lebenskraft (Chi) verantwortlich ist.
An der richtigen Stelle und mit richtigem Druck gebunden ermöglicht es der Gürtel, nahezu den gesamten Körper blitzartig anzuspannen, um zum Beispiel einen Tritt gezielt auszuführen oder um einen Treffer „einzustecken“. Dieses Phänomen kann man auch bei Gewichthebern beobachten, die den Kraftgürtel nicht am Bauch tragen, sondern drei Fingerbreiten unter dem Bauchnabel.
Die Graduierungs- beziehungsweise Gürtelsysteme der Kampfsportarten sind erst im 19. Jahrhundert entstanden und wurden erstmals vom Kanō Jigorō, dem Begründer des Judo eingeführt. Aber auch schon in historischen Zeiten zeigten unterschiedliche Kleider- und Gürtelfarben verschiedene Ränge in der höfischen Hierarchie an (sowohl in Asien als auch in Europa).
Zu Beginn des modernen Taekwondo gab es nur vier Gürtelfarben: weiß, blau, rot und schwarz, die Farben der Koreanischen Flagge. Diese wurden mittlerweile ergänzt durch gelb, grün und braun. Das moderne Graduierungssystem dient vor allem dazu, den Trainings- und Wissensstand zu repräsentieren. Die Aufstellung beim Taekwondo-Training wird aus praktischen Gründen im Block nach Gürtelfarben geordnet vorgenommen: rechts vorne steht der höchstgraduierte, links hinten der niedrigste Grad.
Die Gürtelgrade sind unterteilt in Schülerklasse (Kup, Zählung abwärts) und Meisterklasse (Dan oder Poom (WT; nur 1.–3.) bei unter 15-jährigen, Zählung aufwärts). Die Einteilung der Klassen ist je nach Verband unterschiedlich.
Der weiße Gürtel wird von Anfängern getragen, die noch unwissend sind und dem Taekwondo offen und wissbegierig gegenüberstehen.
Der grüne Gürtel symbolisiert die ersten Sprösslinge und Früchte, Zeichen dafür, dass sich die Trainingsanstrengungen gelohnt haben und etwas im Schüler heranreift.
Der blaue Gürtel steht für den Himmel und somit sinnbildlich für eine Grenze. Der Schüler muss nun zeigen, dass er in der Lage ist, Höheres anzustreben und auch zu erreichen.
Der rote Gürtel repräsentiert die Sonne, von der schon eine große Kraft ausgeht, dient dem Schüler aber auch als Signal. Er steht nun kurz davor, Meister zu werden, und wird angehalten, sich noch intensiver und ausdauernder mit dem Taekwondo zu beschäftigen. Einige Schulen verwenden den braunen Gürtel an Stelle des roten Gürtels. Braun symbolisiert die Borke des Baumstammes, was bedeutet, dass die Techniken sich bereits gefestigt haben und der Schüler kurz davor steht, Meister zu werden.
Schwarz und auch der „Schwarze Gürtel“ ist die Farbe der Meister und nur diesen vorbehalten. Schwarz, Symbol für das Weltall, vereinigt alle anderen Farben in sich und ist somit die stärkste aller Farben. Schwarz soll auch die Autorität, das Wissen und die Erfahrung der Meister symbolisieren. Daher dürfen auch nur Dan-Träger Doboks mit einem schwarzen Revers tragen, so wie generell alle Verzierungen am Trainingsanzug in Schwarz nur den Meistern zustehen.
Gürtelprüfungen finden meist nach festgelegten Schemata (Prüfungsordnung) statt und werden von Meistergraden abgenommen. Sie beinhalten Theoriewissen, Formenlauf und Demonstration von Techniken (abgesprochener Kampf, Freikampf, Bruchtests und manchmal auch Straßenkampf).
Taekwondo hat gewaltiges Potenzial, mit einer kleinen Unaufmerksamkeit kann man sich und andere verletzen. Der Lehrer ist für den geordneten Ablauf der Übungsstunde verantwortlich. Er kann aber nicht für lauter Einzelpersonen sorgen, die sich nicht an die Regeln halten. Deshalb müssen den Anweisungen des Lehrers unbedingt Folge geleistet werden, dazu gehört auch, dass man dem Lehrer seine volle Aufmerksamkeit schenkt.
Je nach Stilrichtung, Schule oder Großmeister gibt es unterschiedlich strikte, strenge oder verbindliche Ansprüche und Anforderungen an das Benehmen oder das Verhalten der Taekwondoins während einer Trainingseinheit. Je traditioneller Taekwondo ausgeübt wird, desto strenger sind diese Regeln gefasst und desto genauer wird auch auf ihre Einhaltung geachtet. Einige Regeln gelten jedoch grundsätzlich für das Taekwondo und werden nachfolgend aufgelistet:
Zum Training erscheint man pünktlich und in sauberer Sportkleidung (Dobok). Hände und Füße sind gewaschen, Finger- und Fußnägel sind kurz gehalten, um Verletzungen vorzubeugen.
Während einer Trainingseinheit darf nicht getrunken oder gegessen werden. Kaugummi kauen oder eine Rauchpause sind ebenfalls nicht gestattet. Die gesamte Aufmerksamkeit soll dem Lehrer beziehungsweise dem Übungspartner gewidmet sein.
Während einer Trainingseinheit sollte der Trainingsbereich möglichst nicht verlassen werden. Auf die Toilette sollte man vor Beginn des Trainings gehen. In dringenden Fällen meldet man sich beim Lehrer ab, doch sollte bedacht werden, dass jede Unterbrechung den Unterricht insgesamt stört, den eigenen Körper wieder auskühlen lässt und somit Verletzungsgefahr birgt. Außerdem können so Dreck, Steinchen oder Splitter aus dem Gangbereich auf die Trainingsfläche gebracht werden, was ebenfalls zu Problemen führen kann, da viele barfuß trainieren.
Bevor das Training beginnt, stellen sich die Schüler vor dem Meister in einer fest vorgegebenen Reihenfolge gemäß ihrer Graduierung auf. Der höchste Grad steht dabei immer vorne rechts.
Das Training beginnt, wenn der Lehrer den Befehl zur Aufstellung gibt. Üblicherweise wird der Trainer vom ersten Schüler (vorne rechts) auf koreanisch gegrüßt, dann verbeugt sich die Gruppe zum Lehrer und der Lehrer zur Gruppe hin. Einige Schulen legen Wert darauf, dass beim Begrüßungszeremoniell zusätzlich die Fahne Koreas gegrüßt wird.
Beim Training darf nicht geschwatzt oder laut gelacht werden. Die Kommandos des Lehrers müssen jederzeit verstanden werden können und müssen auch befolgt werden.
Nur der Lehrer oder hohe Graduierungen dürfen anderen Schülern Techniken beibringen oder die Schüler korrigieren. Damit wird sichergestellt, dass die Techniken richtig gelernt werden und sich keine Unsauberkeiten einschleichen. Dies gilt besonders für den Formenlauf, da sich sonst schnell falsche Bewegungsabläufe verbreiten können.
Angriffe gegeneinander, Bruchtests, Übungen mit Waffen (zum Beispiel bei der Selbstverteidigung) oder andere schwierige Übungen dürfen nur nach ausdrücklicher Genehmigung des Lehrers unter dessen Beobachtung durchgeführt werden. Ansonsten ist die Verletzungsgefahr zu groß.
Befiehlt der Lehrer Übungsabbruch (Kommando Geuman oder Baro oder Gallyeo), müssen alle Übungen sofort beendet werden.
Respekt und Formwahrung ist gerade in Asien selbstverständlicher Inhalt des täglichen Lebens. So auch beim Taekwondo.
Mit der Verneigung wird nicht nur Respekt vor dem Lehrer und dem Übungspartner ausgedrückt, sie dient vor allem der Sammlung und Konzentration. Sie sollte bewusst geschehen, denn sie zeigt an, dass man sich auf die bevorstehende Aufgabe konzentriert. Konzentration ist ein wesentliches Element im Taekwondo, sie ermöglicht komplexe Bewegungsabläufe und stellt sicher, dass der Partner nicht versehentlich verletzt wird.
Mit dem Gruß bestätigt man, dass man die Alltagssorgen abstreift, sich auf die bevorstehende Übung konzentriert. Es signalisiert dem Partner, dass man ihn als Person respektiert und darauf achten wird, fair und ohne Gefahr mit ihm zu üben.
beim Betreten und Verlassen des Übungsraums: Damit übertritt man ganz bewusst auch geistig die Schwelle vom Alltag zum Training und umgekehrt. Wenn Landesfahnen aufgehängt sind (zum Beispiel bei Prüfungen die koreanische neben der nationalen) begrüßt man auch die Fahnen, um dem Ursprungs- und Gastgeberland Respekt zu zeigen.
zu Beginn und Ende der Übungsstunde: Schüler und Lehrer bekunden gegenseitigen Respekt und versichern sich ihrer Konzentration auf die Übungen.
vor und nach Partnerübungen: Damit signalisieren sich die Partner, dass sie alle Aufmerksamkeit in die Ausübung der Technik legen, so dass der Partner nicht gefährdet wird.
vor und nach einem Bruchtest: Taekwondo ist zur Verteidigung gedacht und nicht zum Zerstören. Da beim Bruchtest etwas zerstört werden soll (zum Beispiel ein Holzbrett), fragt der Übende mit der Verneigung gegenüber dem Lehrer oder Prüfer um Erlaubnis nach, ausnahmsweise etwas zerstören zu dürfen.Die Verneigung wird meist mit dem Kommando Cha-ryeot (Achtung!) vorbereitet. Die Füße sind nebeneinander im Moa Seogi, Fäuste am gestreckten Arm leicht neben dem Körper, Gegenüber ansehen. In einer erneuerten Fassung der Geste, die vom WT abgesegnet wurde, werden die Händen auf die Hüfte gelegt und hängen nicht mehr seitlich am Körper. Es steht den Schulen aber frei zu wählen, welche Verbeugungstechnik sie von ihren Schülern erwarten. Mit dem Kommando Gyeong-nye (grüßen, verneigen) wird die Geste eingeleitet. Der Oberkörper beugt sich 45° vor, Arme mit den Fäusten werden leicht angewinkelt. Auch hier greift die neue Fassung, die Hände bleiben auf der Hüfte, während sich der Körper beugt. Eine Faust ist in diesem Fall nicht mehr angebracht.
Großmeister Song Chae-Yong berichtete in einem Interview 1987 über seine Anfänge als Taekwondo-Lehrer in München und die Unterschiede der Kulturen (aus Taekwon-Do im Westen, Mönchseulen-Verlag, 1989):
So habe ich Taekwon-Do an der Volkshochschule gemacht, im Herbst 1972. Damals habe ich viele Fehler gemacht. Ich wollte original Taekwon-Do zeigen und habe ein hartes Training gemacht. Die Leute konnten das aber nicht durchstehen. Ich wollte Taekwon-Do so weitergeben, wie ich es von meinem Lehrer gelernt hatte, auf die gleiche Art, aber die Leute konnten das nicht vertragen und sind immer wieder weggegangen. Daraufhin habe ich das Training milder gemacht.
Bei uns ist das etwas anderes gewesen. Disziplin ist sehr hart in Korea und besonders ein Judo- oder Taekwon-Do-Trainer gilt als Respektsperson. Man sagt Sahbum-Nim zu einem Meister in den Budo-Sportarten. Wenn also ein Sahbum-Nim das Training leitet, das ist dann vollkommen akzeptiert, was der macht, niemand kann etwas dagegen sagen. Ich habe mich das hier nicht getraut. In Korea ist Sahbum-Nim ein Begriff, aber nicht in Europa, hier denken die Leute: Ach, das ist ja nur ein Trainer! Damals haben wir in Korea streng mit Meditation das Training angefangen, aber ich habe befürchtet, dass die Leute hier das nicht wissen, dass sie es komisch finden, einfach so zu sitzen, mit geschlossenen Augen. In Korea durfte man im Übungsraum, im Dojang, nicht sprechen, man durfte nicht einmal die Zähne zeigen. Man achtete sogar darauf, nicht auf den Schatten des Lehrers zu treten. Ein Lehrer ist für uns eine absolute Respektsperson. Als ich hier in München an einem Gymnasium ein Praktikum machte für mein Diplom als Deutschlehrer, da war ich überrascht von der Atmosphäre des Unterrichts. Das kannte ich nicht. Das waren Schüler der 9. Klasse und die waren natürlich sehr frech. Am Schluss der Stunde packten sie einfach ihre Sachen und rannten weg, ohne zu grüßen. So etwas gibt es in Korea nicht.
Ein Lehrer ist grundsätzlich eine Respektsperson, also auch ein Sahbum-Nim. Vielleicht hat man aber auch Angst vor ihm, denn er ist ein Do-in, also nicht nur ein charakterlich, sondern auch ein körperlich geschulter Mann. Man fürchtet ihn also auch ein wenig. Für Japaner, Koreaner, Chinesen ist ein Sahbum-Nim ein Begriff, den die sofort verstehen. […] Was er sagt, das haben wir ohne Kritik angenommen. Wir hätten nie gewagt, „Warum?“ zu sagen.
Gerade asiatische Kampfsportarten gelten meist als Inbegriff des Zeremoniellen. Viele Europäer oder „normale“ Sportler machen sich darüber lustig oder finden es unangenehm, sehen vielleicht sogar religiöse oder sektiererische Hintergründe.
Neben den praktischen Aspekten (beispielsweise Verneigung als Signal, sich auf den Partner zu konzentrieren und ihm keine Verletzungen zuzufügen) gibt es aber auch eine andere interessante Sichtweise: So unbekannt, wie man in Europa immer annimmt, sind Höflichkeitsregeln nämlich gar nicht, wie Beispiele aus typisch europäischen Sportarten zeigen:
Beim Reitsport ist das formale Grüßen des Schiedsgerichts durch den Reiter streng vorgeschrieben und führt bei Nichtbeachtung zur Disqualifikation.
Bei typisch europäischen Schwertsportarten (zum Beispiel Fechten) wird ebenfalls formal gegrüßt, mit genau festgelegten Abläufen (zum Beispiel das Führen des Floretts zum Gesichtsschutz).
Die hohen Beintechniken des Taekwondo können langfristig bei falscher oder zu kurzer Aufwärmphase und bei falscher Ausführung zu Hüft- oder Muskelschäden (Zerrungen, Muskelfaserrisse und Vernarbung des Muskelgewebes) führen, da schnelle Dehnungen unter Anwendung von Schnellkraft ausgeführt werden. Sehr wichtig ist hier ein Training, das körperbewusst geführt wird. Hohe Tritte seitwärts müssen etwa mit ausgedrehtem Standbein durchgeführt werden, um Hüftschäden zu vermeiden. Bei korrekter Anleitung ist Taekwondo eine sehr gesunde Sportart, gerade für die Hüfte, da sie Dehnbarkeit und Beweglichkeit erhält. Eventuelle körperliche Beschwerden sollten vor Trainingsbeginn unbedingt mit dem Trainer geklärt werden.
Abhärten von Haut und Knochen durch entsprechende Maßnahmen (Schlagtraining und so weiter) können auf Dauer schaden, sind jedoch beim Taekwondo weniger üblich.
Bei Schnapptritten nach vorne und Handschlägen muss der Trainer sicherstellen, dass sie nicht bis zum Anschlagpunkt im Knie- oder Ellenbogengelenk durchgeführt werden. Wenn sich die gesamte Kraft des Schlages bei Übungen regelmäßig im Gelenk entlädt, führt dies zu Verschleißerscheinungen.
Manche Wettkampftechniken, die mit bloßem Fuß entschärft ausgeführt werden, etwa mit dem Außenrist anstatt mit dem Ballen, können bei Ausführungen in der Realität und gegen Gegenstände zu Verletzungen führen. Ein gutes Training vermittelt ein klares Bewusstsein für die Unterschiede zwischen Techniken im sportlichen Wettkampf und Techniken, wie sie im Bruchtest oder in einer realen Kampfsituation genutzt würden.
Gerd Gatzweiler: Handbuch Taekwondo: Technik – Training – Prüfungsordnung. ISBN 3-89899-398-1, ISBN 978-3-89899-398-2.
Choi Hong-hi: Taekwon-Do. Koreanische Kunst der Selbstverteidigung. 767 Seiten, Deutsche Erstausgabe 2003. Unter Mitarbeit des Autors überarbeitete Zusammenfassung der 15-bändigen TKD-Enzyklopädie.
Alex Gillis: Tödliche Kunst. Übersetzung von Thomas Kuklinski-Rhee. Zweite Auflage. Wilfried H. Peters, 2013, ISBN 978-3-923868-16-2.
