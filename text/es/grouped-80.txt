
Emma Charlotte Duerre Watson (París; 15 de abril de 1990) es una actriz, modelo y filántropa británica. Es principalmente conocida por interpretar a Hermione Granger en la saga de películas de Harry Potter. Watson fue elegida para interpretar a Hermione a la edad de nueve años, después de haber participado anteriormente solo en obras de teatro escolares.[3]​ Protagonizó, junto con Daniel Radcliffe y Rupert Grint, las ocho películas de la serie cinematográfica.[4]​ Debido a su trabajo en Harry Potter, ha sido galardonada con varios premios y se estima que ha ganado £ 26 millones.[5]​[6]​
Watson hizo su primera aparición fuera de Harry Potter en el telefilme Ballet Shoes transmitido por la BBC One el 26 de diciembre de 2007 y obtuvo una audiencia de 5,2 millones. En 2008, prestó su voz para la Princesa Pea en una película animada llamada The Tale of Despereaux, película basada en el libro homónimo de Kate DiCamillo. En 2011, participó en My Week with Marilyn, su primer trabajo después de finalizar la saga de Harry Potter. En 2012, protagonizó junto a Logan Lerman The Perks of Being a Wallflower, película basada en la novela homónima de Stephen Chbosky y fue elegida para interpretar a Illa en Noé, la epopeya bíblica de Darren Aronofsky. En 2013, lanzó The Bling Ring, película de Sofia Coppola, en la que interpreta a Nicki.
Aunque el interés principal de Watson es la actuación, también hace trabajos relacionados con la moda. Su debut en el modelaje se produjo en 2009, después de protagonizar la campaña británica otoño/invierno de la marca Burberry. También apareció en la campaña primavera/verano 2010 de Burberry. A partir de 2011, se convirtió en el rostro de Lancôme, después de haber realizado cuatro campañas para la marca. Watson también colaboró como estilista conjuntamente con la People Tree y con la italiana Alberta Ferretti, con el fin de producir colecciones de ropa ecológica. En octubre de 2013, fue elegida mediante una encuesta a nivel mundial realizada por la revista británica Empire como la Mujer más sexy de las estrellas cine.[7]​
Hija de los abogados británicos Jacqueline Luesby y Chris Watson,[8]​ ambos graduados de la Universidad de Oxford,[9]​ Emma Charlotte Duerre Watson nació en París (Francia), donde vivió hasta la edad de cinco años, cuando sus padres se divorciaron y ella se mudó con su madre y su hermano menor, Alex, a Oxford (Inglaterra).[8]​[10]​ Watson y su hermano pasaban los fines de semana en casa de su padre en Londres.[11]​ También tiene dos hermanos llamado Toby y Gastón; y dos hermanas llamadas Nina y Lucy, ambas gemelas, frutos del segundo matrimonio de su padre.[9]​ Después de haber vivido una época de su vida en Francia, Watson habla un poco de francés, aunque no tan bien como antes.[12]​ Antes de comenzar la escuela, Watson fue diagnosticada hiperactiva (TDAH). Toma Ritalin desde entonces.[13]​[14]​
Después de mudarse, Watson comenzó sus estudios en la escuela privada Dragon School de Oxford, en la que permaneció hasta 2003. A los seis años de edad, empezó a sentir interés en convertirse en actriz y comenzó estudios paralelos de canto, danza y teatro en Stagecoach Theatre Arts,[15]​ donde participó en varias obras de teatro como Arturo: Los años jóvenes y El príncipe feliz y otros cuentos,[8]​ pero sin nunca actuar profesionalmente.[16]​ Después de salir de la Dragon School, asistió hasta 2007 a Headington School, una escuela privada para niñas, también en Oxford, donde participó en los equipos de hockey y baile.[17]​ Durante el rodaje de Harry Potter, Watson y sus compañeros de reparto tenían cinco horas de clases diarias con profesores particulares, pues no era posible asistir a la escuela.
En el año 2000 comenzaron los castings para Harry Potter y la piedra filosofal,[18]​[19]​ la adaptación cinematográfica del superventas homónimo de la novelista británica J. K. Rowling.[20]​ La principal preocupación de los directores de casting era encontrar a los actores adecuados para interpretar los papeles del trío protagonista: Harry Potter y sus dos compañeros Hermione Granger y Ron Weasley, sus dos mejores amigos. Los encargados del casting encontraron a Watson mediante su profesora de teatro en Oxford y los productores quedaron gratamente impresionados por la confianza que tenía la joven en sí misma.[20]​ Tras ocho audiciones, el productor David Heyman les comunicó a Watson, Daniel Radcliffe y Rupert Grint, que habían sido seleccionados para interpretar a los personajes protagónicos Hermione Granger, Harry Potter y Ron Weasley, respectivamente. La autora de la novela, Rowling, ya había mostrado su apoyo hacia Watson desde que vio su primera prueba.[20]​
El debut de Watson como Hermione Granger llegó en 2001, con el estreno de Harry Potter y la piedra filosofal. La película batió récords de taquilla durante su primer fin de semana, siendo la producción más taquillera de ese año[21]​[22]​ y batió récords de mayor recaudación en un día de estreno ($ 31,6 millones) y de mayor recaudación en un fin de semana (93,5 millones de dólares) en los Estados Unidos, y fue la película más taquillera del año con un ingreso global de $ 974,8 millones.[23]​[24]​ La crítica elogió, mayoritariamente, el trabajo del joven trío protagonista, haciendo hincapié en la interpretación de Watson. El periódico inglés The Daily Telegraph describió su trabajo como «admirable»,[25]​ e IGN afirmó que «se adueñó de la función».[26]​ Watson fue nominada a cinco premios por su trabajo, y logró el Young Artist a la Mejor interpretación juvenil-Protagonista (Young Artist Award for Leading Young Actress).[27]​
Al año siguiente, Watson retomó el papel de Hermione en Harry Potter y la cámara secreta, la segunda entrega de la serie. Aunque la película recibió críticas mixtas por su ritmo y su dirección, los críticos en general, valoraron positivamente el trabajo del reparto. Los Angeles Times dijo que Watson y sus dos compañeros habían madurado desde la primera película,[28]​ mientras que The Times criticó al director Chris Columbus por «rebajar» la presencia del personaje de Hermione en comparación con los otros dos protagonistas.[29]​ Watson recibió un premio Otto por su trabajo, otorgado por la revista alemana Die Welt.[30]​
En mayo de 2004, fue lanzada Harry Potter y el prisionero de Azkaban, la tercera película de la serie. Watson se sintió realizada por su personaje, que desempeñó un papel más decisivo en esta película, y la definió como "carismática y fantástica para interpretar".[31]​ Si bien la crítica no había apreciado mucho la actuación de Daniel Radcliffe como el personaje del título, etiquetándolo de "torpe", la actuación de Watson fue bien recibida. El New York Times la elogió comentando que "afortunadamente, la suavidad del sr. Radcliffe se compensa con la inmensa impaciencia de la señorita Watson. Harry puede mostrar sus nuevas habilidades en la hechicería, pero es Hermione quien recibe los aplausos más fuertes por pinchar, merecidamente, la nariz de Draco Malfoy".[32]​ Aunque El prisionero de Azkaban fuera la película con la más baja recaudación de la serie ($ 796,7 millones),[33]​ Watson ganó el premio a la mejor actuación infantil de total Film y un premio Otto de la revista alemana Bravo.[34]​[35]​
Con el estreno en 2005 de Harry Potter y el cáliz de fuego, tanto Watson como la serie superaron todos los registros anteriores. La película batió récords de taquilla en su primer fin de semana, tanto en Estados Unidos como en el Reino Unido, así como también respecto a las anteriores entregas de la serie. La crítica elogió la creciente madurez de Watson y sus dos compañeros de reparto; The New York Times definió su interpretación como «de una seriedad conmovedora».[36]​ Para Watson, gran parte del humor de la película surgió a raíz de la tensión del trío protagonista mientras maduran. Afirmó: «Me emocionaban todas las discusiones (…) Creo que es mucho más realista que los protagonistas discutan y surjan problemas entre ellos».[37]​ Nominada para tres premios por El cáliz de fuego, Watson fue galardonada con un Otto de bronce.[38]​[39]​[40]​ Ese mismo año se convirtió en la persona más joven en aparecer en la portada de la revista Teen Vogue.[41]​ En 2006 interpretó a Hermione en The Queen´s Handbag (Children's Party at the Palace), un mini episodio especial de Harry Potter para celebrar el 80 cumpleaños de la reina Isabel II.[42]​
La quinta entrega de la franquicia de Harry Potter, Harry Potter y la Orden del Fénix, estrenada en 2007, fue todo un éxito financiero: estableció la cifra récord, a nivel mundial, de $ 333,7 millones en su primer fin de semana.[43]​ Watson ganó el primer National Movie Award a la mejor interpretación femenina y el premio a la mejor actriz en los Nickelodeon Kids' Choice Awards. El 9 de julio de 2007, Watson y sus compañeros Daniel Radcliffe y Rupert Grint, dejaron las huellas de sus manos, pies y varitas frente al Grauman's Chinese Theatre en Hollywood.[44]​
A pesar del éxito de La Orden del Fénix, el futuro de la franquicia se rodeó de dudas, ya que los tres actores principales no se decidían a firmar para continuar con sus papeles durante las dos últimas películas.[10]​ Radcliffe firmó eventualmente para las susodichas, pero Watson fue mucho más indecisa. Explicó que tomar la decisión no fue fácil, ya que la serie seguirá dominando su vida tres o cuatro años más, pero que a la larga le reportará «más ventajas que inconvenientes»[45]​ y admitió que ella «nunca podría dejar el papel de Hermione»,[46]​ Watson firmó para el papel en marzo de 2007.[47]​ A cambio de comprometerse con las películas finales, el pago de Watson se duplicó a £2 millones por película.[48]​ El rodaje de la sexta película comenzó a finales de 2007, las escenas de Watson fueron filmadas desde diciembre hasta mayo de 2008.[49]​
La sexta película de la serie, Harry Potter y el misterio del príncipe, originalmente prevista para noviembre de 2008, se estrenó el 15 de julio de 2009.[50]​[51]​ La película batió récords de mayor taquilla originada de las sesiones de la medianoche ($ 22 millones) y de mayor taquilla mundial durante el día de apertura ($ 104 millones).[52]​ Debido a que los protagonistas ya eran mayores, los críticos estaban dispuestos a juzgar sus rendimientos de la misma forma que hacían con el resto de las estrellas de cine. El diario Los Angeles Times describió las actuaciones como «una guía completa de actuación contemporánea»,[53]​ The Washington Post comentó que Watson había dado «su rendimiento más encantador hasta la fecha»,[54]​ mientras que The Daily Telegraph describió a los actores principales como «recién liberados y llenos de energía, dispuestos a dar todo lo que tienen en lo que queda de la serie».[55]​ Para Watson fue un reto interpretar a Granger en esta película, porque tenía que interpretarla mucho más emocional y vulnerable.[56]​
A comienzos de 2009 Watson empezó a filmar la última entrega de la serie, Harry Potter y las Reliquias de la Muerte. El rodaje concluyó a mediados de 2010.[57]​[58]​[59]​
Por motivos financieros y por el guion, el libro original se dividió en dos películas[60]​ que se rodaron una tras otra. Harry Potter y las Reliquias de la Muerte: parte 1 se estrenó en noviembre de 2010 y la Parte 2 el 15 de julio de 2011. El rodaje de Harry Potter y las Reliquias de la Muerte se realizó simultáneamente entre el 18 de febrero de 2009 y 12 de junio de 2010. Harry Potter y las Reliquias de la Muerte: parte 1 fue lanzada en noviembre de 2010 y rompió el récord del Misterio del príncipe de mayor taquilla originada de las sesiones de medianoche ($ 24 millones).[61]​ El Daily Mail elogió el trabajo de Watson y se percató de que ella "maduró y se convirtió en una actriz de cine prometedora".[62]​
Con el mismo sentimiento, el Metro Times escribió que Watson "ha demostrado que ha crecido para ser una buena actriz, capaz de manejar emociones fuertes".[63]​ Harry Potter y las Reliquias de la Muerte: parte 2 fue lanzada en julio de 2011 y fue la primera y única película de la serie en ser lanzada en 3D, consiguiendo una taquilla mundial de más de $ 1.000 millones.[64]​ También rompió varios récords como el de mayor recaudación mundial de apertura ($ 475,6 millones), de mayor recaudación en un solo día ($ 92,1 millones), de mayor taquilla originaria de las sesiones de medianoche ($ 43,5 millones) y de mayor debut en el mercado internacional ($ 307 millones).[64]​
Para 2006, Radcliffe y Grint ya habían expresado su deseo de continuar con sus futuras carreras como actores, en cambio, Watson manifestó su incertidumbre acerca de sus planes de futuro. En una entrevista para la revista Newsweek ese año, dijo: «Daniel y Rupert parecen tenerlo claro (…) Me encanta actuar, pero hay otras muchas cosas que me gustaría hacer».[65]​ Watson además expresó su interés en estar en un filme musical al finalizar la saga Harry Potter.[66]​
El primer papel de Watson fuera de la serie Harry Potter fue en la película para televisión Ballet Shoes, estrenada en 2007.[67]​ adaptación de la novela del mismo nombre de la escritora británica Noel Streatfeild.[68]​ Watson declaró: «Estaba todo preparado para volver a la escuela tras finalizar el rodaje de Harry Potter y la Orden del Fénix, pero no pude resistirme a Ballet Shoes. Adoro esa historia».[68]​ En esta adaptación televisiva a cargo de la BBC, Watson interpreta a la aspirante a actriz Pauline Fossil, la mayor de tres hermanas a través de las cuales gira la historia.[69]​ La directora Sandra Goldbacher comentó que «Emma era perfecta para interpretar a Pauline (…) desprende un aura de delicadeza que hace que quieras mirarla y mirarte en ella, una y otra vez».[68]​ Por su parte, Watson declaró: «Pauline está obsesionada con actuar y yo era igual cuando era más pequeña. Soñaba con eso. Practicaba frente a los espejos y me sentía la reina del drama. Solía llorar, gemir y gritar, y las pequeñas cosas se fueron transformando en grandes. No sé si mis padres lo llegaban a soportar».[70]​ El papel requirió que Watson se tiñera el pelo de rubio.[71]​ Ballet Shoes se estrenó el 26 de diciembre de 2007 (Boxing Day) en el Reino Unido,[72]​ con una audiencia estimada de 5,2 millones de telespectadores (22 % de la audiencia compartida).[73]​ En general, la película recibió críticas negativas. The Times la describió como una producción que «va progresando con pequeños momentos emocionantes, mágicos o dramáticos».[74]​[75]​
Watson también ha participado en la producción de animación The Tale of Despereaux, hecho que Watson ya había anunciado en julio de 2007 en su sitio oficial. The Tale of Despereaux se estrenó el 19 de diciembre de 2008 en el Reino Unido, Estados Unidos y España.[76]​ En esta película, Watson presta su voz al personaje de la princesa Pea. Se trata de una comedia destinada al público infantil, en la que también actúan Matthew Broderick y Tracey Ullman, así como también su compañero de la saga Harry Potter, Robbie Coltrane, entre otros.
En 2010 participa en el vídeo musical de la canción «Say You Don't Want It», perteneciente a la banda One Night Only, después de conocer al cantante principal, George Craig, en una campaña de Burberry ese mismo año.[77]​
En su primer trabajo después de finalizada la serie de Harry Potter, Watson hizo una pequeña, pero importante, participación en la película My Week with Marilyn, lanzado en noviembre de 2011. Watson interpretó a Lucy, una asistente de vestuario que se involucra con el protagonista Colin Clark en el momento en que este trabaja como asistente del director Laurence Olivier en The Prince and the Showgirl, y se involucra con la estrella de cine, Marilyn Monroe, formando un triángulo amoroso.[78]​ La escalada de Watson fue anunciada en septiembre de 2010.[78]​ También se anunció que su participación sería filmada en pocos días para que no hubiese un largo período de interrupción en sus clases de la universidad.[78]​ Simon Curtis, el director de la película, adjetivó el casting de Watson como "adecuado".[79]​ Uno de los productores de la película, Harvey Weinstein, elogió a Watson, diciendo que "ella tiene un don para la comedia y el drama […] siento que trabajaremos juntos muchas veces en el futuro".[79]​
En mayo de 2010, se informó de que Watson estaba en negociaciones para protagonizar The Perks of Being a Wallflower, película basada en la novela homónima de Stephen Chbosky.[80]​ Su participación fue confirmada en febrero de 2011.[81]​ Preguntado por la escalada de Watson, el autor del libro y también director y guionista de la película, Stephen Chbosky, expuso que "si fuera a retratar verdaderamente a Sam […] necesita a alguien que la incoporase – alguien amable y generosa como Emma ".[82]​ Además, añadió que "sólo sabía que ella era la elección correcta", porque para él, Watson "es más parecida a Sam que cualquier personaje que ha interpretado".[83]​ El rodaje tuvo lugar en Pittsburgh, de mayo a junio de 2011.[84]​ La película fue lanzada en septiembre de 2012 y logró una taquilla mundial de 33,3 millones de dólares.[85]​
En marzo de 2012, Watson confirmó que tendría un papel protagónico en el filme The Bling Ring, dirigido por Sofía Coppola.[86]​[87]​
[88]​ Su personaje, Nicki, se basa en Alexis Neiers, uno de los miembros de la pandilla verdadera.[89]​ Para Watson, el personaje es todo lo que ella rechaza: "es superficial, materialista, vanidosa, amoral […] sin embargo, es interesante para interpretar".[89]​ Cuando se le preguntó sobre el papel de Watson, la directora Sofia Coppola señaló que "es muy divertido verla tan diferente […] siempre quedaba sorprendida en el set al verla convertirse en ese personaje".[90]​ La película fue elegida para abrir la categoría Un certain regard en Festival de Cine de Cannes 2013.[91]​
También en 2012, Watson fue seleccionada para interpretar el papel de Ila en la película bíblica-épica Noé, dirigida por Darren Aronofsky,[92]​ siendo confirmada en junio de 2012, la película fue prevista para su lanzamiento en marzo de 2014.[93]​[94]​ En abril de 2012, Watson comenzó las negociaciones para hacer una aparición en la que se interpretaría a sí misma en This Is the End, película que muestra las celebridades en una fiesta en este momento en que ocurre el Apocalipsis.[95]​ Su participación fue confirmada en el mes siguiente.[95]​ La película se estrenó en junio de 2013.[96]​
El 5 de febrero de 2014 se confirmó que Watson se uniría al elenco de Regression (película) junto a Ethan Hawke, David Dencik, Devon Bostick y su compañero de Harry Potter, David Thewlis. El rodaje se realizó íntegramente en Toronto (Canadá) y comenzó el 15 de abril de 2014. La película tuvo su estreno mundial en el Festival de Cine Internacional de San Sebastian el 18 de septiembre de 2015, fue estrenada el 2 de octubre de 2015 en España y el 9 de octubre en el Reino Unido. También en 2014, se confirmó que Watson y Daniel Brühl interpretarían a una pareja en la próxima película de Florian Gallenberger, Colonia (película), basada en los hechos reales ocurridos en el contexto del golpe y del régimen militar chileno. La película comenzó a grabarse el 2 de octubre de 2014 en Luxemburgo y en Buenos Aires (Argentina) a principios de 2015. Se estrenó en el Festival Internacional de Cine de Toronto el 13 de septiembre de 2015. También fue proyectada en el Festival de Berlín el 12 de febrero de 2016. Fue lanzada el 15 de abril de 2016 en Estados Unidos y Canadá, y el 18 de febrero de 2016 en Alemania. Ambas películas recibieron críticas mayormente negativas.
En 2007, se anunció que Watson había firmado con Storm, una agencia de modelos británica.[97]​ Poco después, se difundieron rumores de que iba a firmar un contrato por tres millones de libras para sustituir a Keira Knightley como el rostro de la campaña de fragancia Coco Mademoiselle, de la marca Chanel.[98]​
En junio de 2009, después de semanas de especulaciones, se confirmó que Watson haría su debut como modelo como el rostro de la campaña de otoño/invierno 2009 de la diseñadora Burberry.[99]​Christopher Bailey, director creativo de la marca, informó conocer y admirar a Watson, en este sentido, "ella era una elección obvia para esta campaña […] también tiene una belleza clásica, una gran personalidad y un toque de modernidad".[99]​ Watson también apareció en la campaña primavera/verano de 2010 de la misma marca, junto con su hermano Alex, el músico George Craig,y los modelos Max Hurd y Matt Gilmour.[100]​ El famoso fotógrafo peruano, Mario Testino, fue el responsable de las imágenes en las dos colecciones.[99]​[100]​ Cuando Watson representó a Burberry, las ventas de la marca aumentaron más de un 24 %.[101]​ Después de la segunda colección, Watson fue reemplazada por la modelo británica Rosie Huntington-Whiteley.[101]​
También en 2009, se anunció que Watson colaboraría libremente con People Tree, una marca de moda de comercio justo, y para ser la cara de una colección de ropa de diseño ecológico enfocada a un público de entre 16 y 24 años, con el propósito de recaudar fondos para la People Tree Foundation.[102]​ Watson trabajó en la colección durante la noche, después de un día de rodaje, o cualquier fin de semana que tenía libre, y realmente se involucró en el proceso de producción.[103]​ La colección fue lanzada en febrero de 2010.[103]​ Watson continuó colaborando con People Tree y lanzó dos colecciones más, una en agosto de 2010 y otra en febrero de 2011.[104]​[105]​
En febrero de 2011, Watson recibió de las manos de la diseñadora Vivienne Westwood, el premio Ícono de la moda de la revista Elle británica.[97]​ En marzo de 2011, junto con la diseñadora italiana Alberta Ferretti lanzó otra colección de ropa ecológica, llamada Temas Pure de Emma Watson Alberta Ferrettia,[106]​ y anunció, por medio de su Twitter, que sería la nueva cara de la marca de cosméticos francesa, Lancôme.[107]​ También es la persona más joven en ser la imagen de la marca.[107]​ Desde 2011, Watson es el rostro de Lancôme e hizo cuatro campañas para la marca.[108]​
Según Watson, la moda le dio la oportunidad de tener una identidad fuera de la serie de Harry Potter, así que tuvo la oportunidad de crear su propio estilo y reinventarse a sí misma por su forma de vestir y sus cortes de cabello.[109]​
En septiembre de 2009, Watson anunció su asociación con la marca de moda People Tree,[110]​ una marca de moda de comercio justo, trabajando como "asesora creativa" para crear una línea de ropa de primavera, que fue lanzada en el 2010;[110]​[111]​ ésta contenía estilos inspirados por el sur de Francia y la ciudad de Londres.[111]​[112]​ La colección fue descrita por The Times como «muy inteligente»;[113]​ Watson comentó que «La moda es una gran manera de capacitar a las personas y darles destrezas, en vez de dar dinero a la caridad puedes ayudar a la gente comprando los diseños que hacen y así apoyar lo que los enorgullece».[114]​ Continuó su participación con People Tree, con la colección otoño/invierno 2010.[113]​[115]​
En 2009, Watson colaboró gratuitamente con dicha marca, para ser la imagen y la estilista de una colección de ropa ecológica, con el fin de recaudar fondos para la People Tree Fundation.[102]​ La colección se inició en 2010, durante un evento organizado por el príncipe Carlos, para promover la conciencia ambiental.[116]​
Por tratarse una empresa de comercio justo que ayuda a las familias de los países emergentes a salir de la línea de pobreza y que contribuye a una mejor oportunidad en la vida, Watson viajó a Bangladés como representante de People Tree para entender el proceso de producción y conocer a las personas que fabrican la ropa, que describió como "una experiencia increíble y única".[117]​ Watson informó creer que People Tree es un ejemplo a seguir en cuestión de la sostenibilidad y humanitarismo.[118]​
En junio de 2011, Watson aceptó posar para el artista británico Mark Demsteader, en el sentido de producir una colección de 30 cuadros de pintura realizados con diferentes técnicas como el aguada, carboncillo, tinta y óleo.[119]​ Al aceptar la invitación, Watson pidió que el 10% de las ganancias por la venta de las pinturas fueron donadas a la CAMFED International, una organización no gubernamental (ONG) británica que trabaja en la zonas rurales africanas que busca introducir a niñas en el ámbito escolar facilitándoles libros, uniformes y otros suministros necesarios.[119]​ En septiembre de 2012, Watson terminó representando a CAMFED Internacional como su embajadora oficial, por apoyar la causa de la importancia del estudio de la vida de un individuo y en la construcción de la sociedad, y declaró haber quedado "feliz de apoyar a Camfed y el trabajo increíble que ellos hacen".[120]​
En 2013, Watson posó para las fotos a favor de la campaña Natural Beauty, del fotógrafo estadounidense James Houston, con el propósito de recaudar fondos para la Global Green USA, una organización no gubernamental centrada en la sustentabilidad y la preservación del medio ambiente.[121]​ La exposición fue lanzada en 22 de abril, en el Día de la Tierra, en Nueva York y Los Ángeles.[121]​
El 20 de septiembre de 2014 en la ciudad de New York, ante la asamblea de las Naciones Unidas, y como Embajadora de la Buena Voluntad de la ONU Mujeres, Emma Watson dio un emotivo discurso[122]​ en el que defendió la igualdad política, económica y social[123]​ de los sexos, y en donde exhortó a mujeres y hombres a luchar por lo que ella llamó un movimiento por la libertad.[123]​ Este hecho ha marcado un momento en la carrera de Emma Watson en donde se le puede ver como a una artista, filántropa y mujer comprometida con el feminismo.
En junio de 2008, la prensa británica informó que Watson firmó un contrato de £ 3 millones para promocionar la marca francesa de alta costura Chanel.[124]​ Y que sería la imagen pública de Coco Mademoiselle, uno de los perfumes de la empresa, reemplazando a Keira Knightley.[124]​ Esto fue después negado de parte de los dos lados.
En junio de 2009, tras varios meses de rumores, Watson confirmó que ella se asociaría con Burberry como el rostro de su nueva campaña; recibió un pago estimado de seis cifras por modelar en la colección Otoño/Invierno de Burberry.[125]​[126]​[127]​ Más tarde apareció en la campaña primavera/Verano [2010] de Burberry junto con su hermano Alex y los músicos George Craig y Matt Gilmour.[128]​ Watson continuó su participación en la moda publicitaria al modelar para Lancôme en marzo de 2011.[129]​
Incluso teniendo que conciliar los estudios y el rodaje, en junio de 2006, Watson obtuvo el Certificado General de Educación Secundaria (General Certificate of Secondary Education o GCSE) con ocho A* (la más alta) y dos notas A (la segunda calificación más alta),[130]​ lo que hizo que se convirtiera en blanco de burlas, pero ella lo vio como un elogio.[131]​ En 2008, recibió tres A en su examen Niveles Avanzados (A-Level o Advanced Levels) en Literatura Inglesa, Geografía y Arte.[17]​ Después de terminar la escuela secundaria, Watson tomó un tiempo para terminar el rodaje de Harry Potter and the Deathly Hallows,[17]​ iniciado en febrero de 2009, antes de ir a la universidad.
En medio de varios rumores acerca de que universidad elegiría, Watson se mostró reacia a comprometerse públicamente a cualquier institución y dijo que anunciaría su decisión por primera vez en su sitio web oficial. En julio de 2009, Watson declaró que había elegido la Universidad de Brown, ubicada en Providence, Rhode Island.[132]​ En septiembre de 2009, comenzó a estudiar literatura Inglesa en la Universidad Brown.[133]​ Para Watson, estar en Brown la hizo salir de su zona de confort, que la dejó muy orgullosa, porque se traslada a un país diferente y fue capaz de probar nuevas cosas.[134]​ En marzo de 2011, anunció que iba a cerrar su curso para promover la última película de Harry Potter y centrarse en sus proyectos como actriz.[133]​ Sin embargo, se matriculó en la Universidad de Oxford para estudiar inglés como un complemento del curso de Brown y dejó claro que regresaría a esta para formarse.[135]​
Siempre en busca de una vida normal, Watson quiere seguir estudiando y decidido seguir adelante con su vida académica,[9]​ porque «ama estudiar más que cualquier otra cosa» y no quiere perder «la oportunidad de asistir a la universidad debido a que es el momento de averiguar y saber si lo desea».[136]​ Watson informó que quiere ir a la universidad y terminar sus estudios, siempre tratando de conciliarlos con su carrera de actriz.[56]​ Sin embargo, mientras asiste a la universidad, Watson ha tenido que rechazar varias «ofertas increíbles» para actuar, porque no quería interrumpir sus clases visto que «la experiencia de la universidad es muy importante» y no desistirá.[134]​ El 25 de mayo de 2014, Watson se graduó en la Universidad de Brown (EE. UU.), con una licenciatura en Literatura Inglesa.[137]​
Watson tuvo una relación durante dos años con el financiero Jay Barrymore,[138]​ y rompió con él en marzo de 2010, debido a la distancia, ya que ella estaba involucrada con sus estudios en la Universidad Brown en Estados Unidos, mientras que continuó residiendo en Reino Unido.[139]​[140]​ También en 2010, tuvo una breve relación con George Craig, líder de la banda One Night Only, y participó en uno de los vídeos musicales de banda.[141]​ Los dos se conocieron en la sesión de fotos para la campaña de otoño-invierno 2010 de Burberry, en la que eran modelos.[141]​
En mayo de 2011, Watson fue fotografiada mientras caminaba con el actor Johnny Simmons, su compañero de reparto en The Perks of Being a Wallflower y surgieron sospechas de que los dos estaban en una relación, negada en la época.[138]​ Sin embargo, en agosto de 2011, los dos fueron fotografiados besándose.[138]​ En noviembre de 2011, se informó de que habían puesto fin a la relación, y ciertos rumores mencionaron que el motivo de dicho fin de la relación era el regreso de Watson a Reino Unido para estudiar en la Universidad de Oxford.[142]​[143]​ Durante el festival de Coachella 2012 se produjo en abril, Watson fue fotografiada besándose con Will Adamowicz, su colega de la Universidad de Oxford.[142]​[144]​
En los últimos años, la familia de Watson se ha ampliado a raíz de los hijos de sus padres divorciados, fruto de sus nuevos matrimonios. Su padre tiene dos niñas gemelas, Nina y Lucy y un niño de cuatro años, Toby.[145]​ Del nuevo matrimonio de su madre, Watson tiene dos hermanos a los que «ve muy a menudo».[146]​ El hermano de Watson, Alexander, ha aparecido como extra en las dos primeras películas de Harry Potter, y Nina y Lucy participaron en la adaptación de la BBC Ballet Shoes, interpretando a la joven Pauline Fossil.[145]​
Tras su llegada a Oxford con su hermano y su madre, Watson se matriculó en la escuela The Dragon, un colegio privado donde permaneció hasta junio de 2003, año en el que se matriculó en la escuela Headington, un colegio privado femenino, también en Oxford.[8]​ Durante los rodajes, Watson y sus dos compañeros recibían clases con un tutor privado unas cinco horas al día.[147]​
El trabajo de Watson en la franquicia de Harry Potter le ha proporcionado unas ganancias de más de diez millones de libras esterlinas y ha reconocido que no volverá a necesitar trabajar nunca más para ganar dinero.[148]​ Sin embargo, se ha negado a abandonar los estudios para dedicarse como actriz a tiempo completo. Según Watson: «La gente no puede entender por qué no lo hago, pero la escuela me mantiene en contacto con mis amigos. En contacto con la realidad».[45]​ Considera que su experiencia como actriz infantil ha sido positiva y que sus padres y sus amigos le han ayudado a hacer de esa experiencia algo único.[41]​[146]​[149]​ Watson mantiene una estrecha relación con sus compañeros de reparto Daniel Radcliffe y Rupert Grint, que considera como su «inigualable apoyo» en las tensiones de los rodajes.[45]​
Watson afirma que sus intereses son bailar, cantar, el hockey sobre césped, el tenis, el arte y la música;[8]​ se describe a sí misma como «feminista». Admira a los actores Johnny Depp y Julia Roberts.[150]​

Emperador romano es el término utilizado por los historiadores para referirse a los gobernantes del Imperio romano tras el final de la República romana.
En la Antigua Roma no existía el título de «emperador romano», sino que este título era más bien una abreviatura práctica para una complicada reunión de cargos y poderes. A pesar de la popularidad actual del título, el primero en ostentarlo realmente fue Miguel I Rangabé a principios del siglo IX, cuando se hizo llamar Basileus Rhomaion (‘emperador de los romanos’). Hay que tener en cuenta que en aquella época el significado de Basileus había cambiado de ‘soberano’ a ‘emperador’. Tampoco existía ningún título o rango análogo al título de emperador, sino que todos los títulos asociados tradicionalmente al emperador tenían su origen en la época republicana.
La discusión sobre los emperadores romanos está influenciada en gran medida por el punto de vista editorial de los historiadores. Los mismos romanos no compartían los modernos conceptos monárquicos de «imperio» y «emperador». Durante su existencia, el Imperio romano conservó todas las instituciones políticas y las tradiciones de la República romana, incluyendo el Senado y las asambleas.
En general, no se puede describir a los emperadores como gobernantes de iure. Oficialmente, el cargo de emperador era considerado como el «primero entre iguales» (primus inter pares), y muchos de ellos no llegaron a ser gobernantes de facto, sino que frecuentemente fueron simples testaferros de poderosos burócratas, funcionarios, mujeres y generales.
La autoridad legal del Emperador derivaba de una extraordinaria concentración de poderes individuales y cargos preexistentes en la República, más que de un nuevo cargo político. Los emperadores continuaban siendo elegidos regularmente como cónsules y como censores, manteniendo así la tradición republicana. El emperador ostentaba en realidad los cargos no imperiales de Princeps Senatus (líder del Senado) y Pontifex Maximus (máxima autoridad religiosa del Imperio). El último emperador en ostentar dicho cargo fue Graciano, que en 382 lo cedió a Siricio, convirtiéndose desde entonces el título en un honor añadido al cargo de obispo de Roma.
Sin embargo, estos cargos solo proporcionaban prestigio (dignitas) a la persona del Emperador. Los poderes de este derivaban de la auctoritas. En la figura imperial se reunían las figuras autoritarias del imperium maius (comandante en jefe militar) y de la tribunicia potestas (máxima autoridad jurídica). Como resultado, el Emperador se encontraba por encima de los gobernadores provinciales y de los magistrados ordinarios. Tenía derecho a dictar penas de muerte, exigía obediencia de los ciudadanos comunes, disfrutaba de inviolabilidad personal (sacrosanctitas) y podía rescatar a cualquier plebeyo de las manos de los funcionarios, incluyendo de los tribunos de la plebe (ius intercessio).
El puesto de emperador no era una magistratura ni ningún otro cargo del Estado (de hecho, carecía de un uniforme como se prescribía para los magistrados, senadores y caballeros, si bien los últimos emperadores sí fueron distinguidos con la toga púrpura, lo que dio origen a la frase «vestir la púrpura» como sinónimo de la asunción de la dignidad imperial). Tampoco existió un título regular para el cargo hasta el siglo III d. C. Los títulos normalmente asociados a la dignidad imperial eran Emperador (Imperator, con el significado de supremo comandante militar), César (que originalmente tuvo el significado de cabeza designada, Nobilissimus Caesar) y Augusto (Augustus, con el significado de 'majestuoso' o 'venerable'). Tras el establecimiento de la tetrarquía por Diocleciano, la palabra «César» pasó a designar a los dos sub-emperadores menores, y «Augusto» a los dos emperadores mayores.
Los emperadores de las primeras dinastías eran considerados casi como la cabeza del Estado. Como princeps senatus, el emperador podía recibir a las embajadas extranjeras en Roma; sin embargo, Tiberio consideraba que esto era una labor para los senadores sin necesidad de su presencia. Por analogía, y en términos modernos, estos primeros emperadores podrían ser considerados como jefes de Estado.
La palabra princeps, cuyo significado era 'primer ciudadano', fue un término republicano usado para denominar a los ciudadanos que lideraban el Estado. Era un título meramente honorífico que no implicaba deberes ni poderes. Fue el preferido de César Augusto, puesto que su uso implicaba únicamente primacía, en oposición a imperator, que implicaba dominación. La posición real del emperador era en esencia la del Pontífice Máximo con poderes de Tribuno y sobre todos los demás ciudadanos. Se mantuvo la denominación de princeps para conservar la apariencia institucional republicana.
La palabra griega basileus (comúnmente traducida como 'rey') modificó su significado, convirtiéndose en sinónimo de emperador (y comenzó a ser más usada tras el reinado del Emperador bizantino Heraclio). Los griegos carecían de la sensibilidad republicana de los romanos y consideraban al emperador como un monarca. En la época de Diocleciano y posteriormente, el título princeps cayó en desuso, y fue reemplazado por el de dominus ('señor'). Los últimos emperadores usaron la fórmula Imperator Caesar NN Pius Felix (Invictus) Augustus, donde NN era el nombre individual del emperador de turno, Pius Felix significaba 'piadoso y bendito', e Invictus tenía el sentido de 'nunca derrotado'. El uso de princeps y dominus simboliza en un sentido amplio la diferencia entre las dos etapas del gobierno imperial conocidas como Principado y Dominado.
En la discusión sobre quién fue el primer Emperador romano debe tenerse en cuenta que, a fines del periodo republicano, no existía un nuevo título que implicara un poder individual semejante al de un monarca. Tomando como referencia la traducción al español de la palabra latina Imperator, Julio César habría sido emperador, como muchos otros generales romanos antes que él. En lugar de ello, y tras el final de las guerras civiles durante las que Julio César lideró su ejército para conseguir el poder, quedó claro por una parte que no existía consenso sobre el retorno de la monarquía, y por otro lado, que la presencia a un tiempo de tantos altos gobernantes con iguales poderes otorgados por el Senado luchando entre ellos debía llegar a su fin.
Con objeto de alcanzar esa monarquía no declarada, Julio César, y unos años más tarde Octavio, de una forma más sutil y gradual, trabajaron para acumular los cargos y títulos de mayor importancia en la República, haciendo que los poderes asociados a dichos cargos fueran permanentes y evitando que nadie con idénticas aspiraciones pudiera acumular o conservar poderes por sí mismos.
Julio César recorrió una parte considerable del camino en esta dirección, ostentando los cargos republicanos de cónsul (4 veces) y dictador (5 veces); consiguiendo ser nombrado «dictador vitalicio» (dictator perpetuus) en el 45 a. C. También había sido Pontífice Máximo durante varias décadas, y preparó su futura deificación (iniciando el llamado Culto Imperial). Aunque fue el último dictador de la República, Julio César murió muchos años antes del colapso final de las instituciones tradicionales republicanas que dieron paso al sistema que los historiadores modernos llamaron Principado.
En la época de su asesinato (44 a. C.) César ya era el hombre más poderoso de Roma, pero sin ser princeps, condición que los historiadores modernos consideran determinante para llamarle emperador. Por esta razón en la actualidad no es considerado como tal. A pesar de ello, consiguió algo que solo un monarca hubiera podido conseguir, si bien esto solo se haría evidente muchas décadas después de su muerte: había convertido sus grandes poderes republicanos en hereditarios a través de su testamento, en el que adoptaba a Octavio y le designaba como su único heredero político. Sin embargo, no sería hasta casi una década después de la muerte de César cuando Octavio alcanzaría el poder supremo, tras la guerra civil posterior a la muerte de César y el proceso gradual para neutralizar a sus compañeros en el triunvirato que culminó con la victoria sobre Marco Antonio y Cleopatra VII. De alguna forma, César construyó el armazón sobre el que se asentaría la condición futura del Emperador.
Sin embargo, no se puede marcar una línea a partir de la cual Octavio se convirtiese en emperador. A lo largo de su vida política, Octavio, también conocido como César Augusto, recibió y adoptó varios títulos que diferenciaban su condición de la del resto de los políticos, pero ninguna que claramente lo denominase como tal. Fue proclamado Augusto, pero este es considerado un sobrenombre o un adjetivo ("aumentador") más que un título. Con el tiempo, este adjetivo se tornaría sustantivo. Recibió también el título de pontifex maximus. Recibió del Senado la encomienda de la tribunicia potestas (el poder del tribunado), sin necesidad de ser uno de los tribunos; y también comenzó a usar Imperator, como parte de su nombre. Sin embargo, a pesar de que Augusto recibió diferentes títulos, no hubo cambios en la organización del Estado, la cual permaneció idéntica a la del período de la res publica.
Algunos historiadores como Tácito sugirieron que tras la muerte de Augusto habría sido posible el retorno al sistema republicano sin necesidad de ningún cambio, en el caso de que hubiera existido un deseo real de hacerlo (no permitiendo a Tiberio la acumulación de los mismos poderes, cosa que este hizo con rapidez). Incluso Tiberio siguió a grandes rasgos manteniendo inalterado el sistema de gobierno republicano.
Los historiadores de los primeros siglos tuvieron más en cuenta la continuidad: si existió una «monarquía sin reyes» hereditaria tras la República, esta habría comenzado con Julio César. En este sentido, Suetonio escribió las Vidas de los Doce Césares, compilando los emperadores desde Julio César e incluyendo a la dinastía Flavia (tras la muerte de Nerón, el nombre heredado ‘César’ se convirtió en un título). En libros de historia más recientes, sin embargo, se apunta que inmediatamente después del asesinato de Julio César, el Estado romano había vuelto en todos los aspectos a la República, y que el Segundo Triunvirato difícilmente podría ser considerado una monarquía. Estas tesis, ampliamente seguidas, ven a Augusto como el primer emperador en un sentido estricto, y se dice que se convirtió en tal cuando «restauró» el poder al Senado y al pueblo, acto que en sí mismo fue una demostración de su auctoritas, recibiendo el nombre de «Augusto» en el 27 a. C.
Aunque estos son los cargos, títulos y atribuciones más comunes, se debe tener en cuenta que no todos los emperadores romanos hicieron uso de ellos, y que en caso de hacerlo, posiblemente no los usaban al mismo tiempo. Los cargos de cónsul y censor, por ejemplo, no formaban parte integral de la dignidad imperial, siendo ostentados por diferentes personas además del emperador reinante.
Augustus (‘augusto’, ‘sagrado’ o ‘venerable’), un cognomen o apellido honorífico exclusivo del Emperador que portaron todos ellos a partir de Augusto, al que fue decretado por el Senado el 16 de enero de 27 a. C.
Autokratōr, título griego equivalente a ‘soberano’ con un significado semejante a ‘con plenos poderes’. Aparece solo en inscripciones y prosa en griego.
Basileus, título griego que significa ‘rey’; usado de forma popular en Oriente para referirse al emperador y que se convirtió en un título formal a partir del reinado de Heraclio. También usado exclusivamente en inscripciones y prosa griegas.
Caesar (‘césar’) o Nobilissimus Caesar (‘césar nobilísimo’), cognomen procedente de la familia de Julio César, usado posteriormente como nomen, bien para referirse al emperador (usado en segundo lugar, tras imperator), bien a los herederos (usado en último lugar tras su nombre ordinario).
Censor (‘censor’), cargo de la República ejercido por cinco años que ostentan dos individuos con las mismas atribuciones: velar por la moralidad pública y controlar los empadronamientos, incluidos los de los órdenes senatorial y ecuestre. Lo ejercieron muy pocos emperadores, como Claudio (47-48 d. C.), Vespasiano y Tito (73-74 d. C.).
Consul (‘cónsul’), la más alta de las magistraturas senatoriales de la República romana, de un año de vigencia (enero-diciembre), que ostentan al tiempo dos individuos con las mismas atribuciones. Son el poder ejecutivo del Senado. Los emperadores lo ejercían a voluntad, pero no siempre (Augusto lo fue 13 veces, Tiberio 2, Trajano 6, Adriano 3, etc.).
Dominus noster (‘nuestro señor’, ‘nuestro amo’), título honorífico que comienza a usarse a la vez o en vez de imperator caesar bajo el usurpador Magnencio (350-353 d. C.).
Imperator, magistrado portador de imperium, título obtenido tras la ascensión a la púrpura imperial o tras un importante triunfo militar. Este título, de origen republicano, se convirtió desde Augusto en el prenombre (praenomen) de la mayoría de los emperadores hasta mediados del siglo IV.
Imperator destinatus o imperator designatus (‘destinado para ser emperador’, ‘designado para ser emperador’), título para el heredero imperial usado por Septimio Severo para su hijo Caracalla.
Imperium maius, que indica que su poseedor ostenta el poder absoluto sobre todos los demás poderes, incluyendo la capacidad de sentenciar a muerte.
Pater patriae (‘padre de la patria’), título honorífico, decretado por primera vez para Augusto en 2 a. C.
Pontifex maximus (‘sumo pontífice’), título de origen republicano que implicaba la mayor de las autoridades religiosas. Estaban a la cabeza de los sacra (ritos oficiales de Roma). Los emperadores cristianos a partir de Graciano dejaron de usar este título al ser cedido este a los papas de Roma.
Princeps (‘primer ciudadano’, ‘príncipe’), título honorífico que denota el estatus del emperador como primus inter pares.
Princeps iuventutis (‘príncipe de la juventud’), título honorífico destinado al heredero del Imperio.
Tribunicia potestas (‘tribuno [potestad tribunicia]’), cargo senatorial de origen republicano (494 a. C.), que desde Augusto, en 23 a. C., es privativo del emperador. Mediante él obtenía poderes de tribuno, incluyendo la inviolabilidad (sacrosanctitas) y la capacidad de vetar las decisiones del Senado. Se renovaba anualmente (hasta Trajano en el dies imperii o de ascenso al trono, después cada 10 de diciembre) por lo que en las inscripciones imperiales es el marcador cronológico más fiable de la titulatura.Además, en epigrafía son frecuentes las siguientes abreviaturas como propias de la dignidad imperial:
DIV. - Divus, Diva: desde Augusto, designa al emperador, emperatriz o miembro de la familia imperial que ha recibido la apotheosis o declaración de divinización. Normalmente le sigue el nombre más popular del personaje en cuestión (Divus Augustus, Divus Hadrianus), excepto César, que fue designado simplemente Divus.
GERM. - Germanicus(otros epítetos de victoria sobre pueblos determinados: Britannicus, Dacicus, Parthicus, Sarmaticus, Alamannicus, etc., a veces seguidos de Maximus).
IMP. - Imperator (como prenombre y como indicador de victorias militares, suyas o de sus generales, en este caso le siguen numerales, excepto el I)
TRIB.POT. o TR.P. - Tribunicia potestas (habitualmente en ablativo o genitivo, le sigue el numeral, excepto el I)
Cuando Augusto estableció el Principado, cambió la autoridad suprema por una serie de poderes y cargos, lo que en sí mismo fue una demostración de autoridad. Como Princeps Senatus, el Emperador declaraba el inicio y el fin de cada sesión del Senado, imponía la agenda de este, la reglamentación a seguir por los senadores y se reunía con los embajadores extranjeros en nombre del Senado.
Como Pontifex Maximus, el Emperador era la cabeza religiosa del Imperio, correspondiéndole la presidencia de las ceremonias religiosas, la consagración de los templos, el control del calendario romano (suprimiendo y añadiendo días cuando era necesario), el nombramiento de las vírgenes vestales y de los flamen (sacerdotes), el liderazgo del Collegium Pontificum (dirección colegiada de los asuntos religiosos) y la interpretación de los dogmas de la religión romana.
Aunque estos poderes otorgaban al emperador una gran dignidad e influencia, en realidad no incluían por sí mismos ninguna autoridad legal. En el año 23 a. C., Augusto daría poder legal a la figura del Emperador. En primer lugar, con la inclusión entre sus cargos de la tribunicia potestas, o poderes de tribuno, sin necesidad de ostentar dicho cargo. Esto dio al Emperador inviolabilidad y la capacidad de perdonar a cualquier civil por cualquier tipo de acto criminal o de cualquier otro tipo. Con los poderes del tribuno, el Emperador podía condenar también a muerte sin juicio previo a cualquiera que interfiriera en el desempeño de sus deberes. Este «tribunado imperial» le permitía también manejar al Senado según sus deseos, proponer leyes, así como vetar sus decisiones y las propuestas de cualquier magistrado, incluyendo al tribuno de la plebe. También mediante este poder el Emperador podía convocar a las asambleas romanas, ejerciendo como presidente de las mismas y pudiendo proponer leyes en estos foros. Sin embargo, todos estos poderes solo eran aplicables dentro de la misma Roma, por lo que aún necesitaba otros poderes para poder vetar a los gobernadores y a los cónsules en las provincias del Imperio.
Para resolver este problema, Augusto trató de que se otorgara al Emperador el derecho a ostentar dos tipos diferentes de imperium: el primero como cónsul, lo que le daba el poder de la máxima magistratura dentro de Roma, y el segundo con el título de Imperium Maius, que le daba poderes fuera de Roma, o sea, como procónsul. Los cónsules y el Emperador tenían por lo tanto una autoridad semejante, pudiendo cada uno de ellos vetar las propuestas y actos de los otros. Sin embargo, fuera de Roma, el Emperador superaba en poderes a los cónsules, pudiendo vetarles sin que estos pudieran hacer otro tanto con él. El imperium maius le daba al Emperador autoridad sobre todos los gobernadores de las provincias romanas, convirtiéndole en la máxima autoridad en los asuntos provinciales y dándole el mando supremo de todas las legiones romanas. El Emperador, merced a este imperium, podía nombrar a los gobernadores de las provincias imperiales sin interferencia del Senado. La división de las provincias entre imperiales y consulares data, según Dión Casio, del 27 a. C.
Bajo la denominación de culto imperial se incluye el conjunto de rituales realizados en honor del emperador romano y su familia (una vez al año los habitantes debían quemar incienso ante su estatua, diciendo: «César es señor»). Anteriormente Alejandro Magno había afirmado ser descendiente de los dioses de Egipto, y decretó que debería de ser adorado en las ciudades de Grecia.[1]​
Todavía en vida de Julio César, este consintió en la erección de una estatua a cuyo pie rezaba la inscripción Deo invicto (en español, «Al dios invencible») en el 44 a. C. El mismo año se hizo nombrar dictador vitalicio. El Senado votó para que se le construyera un templo y se instituyeran juegos en su honor. Después de su muerte lo colocaron entre los demás dioses y le dedicaron un santuario en el foro. El heredero de César, Augusto, hizo construir un templo en Roma dedicado al «Divino Julio» (Divus Iulius). Como hijo adoptivo del deificado Julio, Augusto también recibió el título de Divi filius («Hijo de dios»). Se hizo llamar Augusto, fue honrado como divino y se le puso su nombre a un mes del año (agosto) tal como había sucedido con su padre (Julio). Aunque Augusto en vida no pidió ser adorado, después de su muerte el Senado le elevó al rango de dios y lo declaró inmortal.
El objetivo principal de este culto era demostrar la superioridad del gobernante mediante su adscripción a una esfera divina, y la sumisión de los habitantes a los dictados de aquel.
La adoración del emperador, ,que en realidad era política más que personal, fue un elemento poderoso de unidad en el imperio, puesto que era una especie de deber patriótico.[2]​
Tácito describe en sus Anales[3]​ que Augusto y Tiberio permitieron que se erigiera un único templo en su honor durante sus vidas. Estos templos contenían, no obstante, no solo las estatuas del emperador gobernante, que podía ser venerado a la manera de un dios, sino que también se dedicaban al pueblo de Roma, a la ciudad de Roma, en el caso de Augusto, y al Senado en el de Tiberio. Ambos templos estaban situados en la parte asiática del Imperio Romano. El templo de Augusto estaba situado en Pérgamo, mientras Tiberio no consintió ningún otro templo o estatua en su honor aparte de los existentes en Esmirna, ciudad elegida en el año 26 entre 11 candidatas para erigir estos templos. Tiberio aseguró ante el Senado que prefería ser más recordado más por sus actos que por las piedras. Sí permitió, en cambio, la construcción de un templo en honor de su antecesor y padre adoptivo, el ya Divus Augustus, en Tarragona, en el año 15 d. C.
Los numerosos templos y estatuas dedicados a Calígula, por orden propia, fueron todos ellos destruidos de inmediato tras la violenta muerte de este emperador. Al parecer, Claudio permitió la erección de un solo templo en su honor, continuando el ejemplo de Augusto y Tiberio. En esta ocasión el templo se erigió en Britania, tras la conquista de este territorio por Claudio.
Generalmente, los emperadores romanos evitaron reclamar para sí mismos el estatus de deidad en vida, a pesar de que algunos críticos insistieron en que hubieran debido hacerlo, y que lo contrario podría ser considerado un signo de debilidad. Otros romanos ridiculizaban la idea de que los emperadores fueran considerados dioses vivientes, e incluso veían con diversión la deificación de un emperador tras su muerte. Sobre este particular, el único escrito satírico de Séneca, la Apocolocyntosis divi Claudii (Conversión del divino Claudio en calabaza), muestra un amargo sarcasmo sobre la previsible deificación de Claudio, la cual se efectuó, de acuerdo con la versión de Tácito, en los funerales del emperador en el año 54.[4]​
Frecuentemente, los emperadores fallecidos durante este período fueron objeto de adoración, al menos, aquellos que no fueron tan impopulares para sus súbditos. La mayor parte de los emperadores se beneficiaron de la rápida deificación de sus predecesores: si dicho predecesor era un familiar relativamente cercano, aunque solo fuera por adopción, esto significaba que el nuevo Emperador contaba con un estatus cercano a la deidad, siendo divi filius, sin necesidad de parecer demasiado presuntuoso al reclamar para sí mismo la condición divina. Una famosa cita atribuida a Vespasiano en su lecho de muerte dice que sus últimas palabras, proferidas en tono irónico, fueron: Vae... puto deus fio! («¡Ay de mí, creo que me estoy convirtiendo en dios!»), al sentir que la muerte le llegaba.
Para las mujeres de las dinastías imperiales la adquisición del título de Augusta, otorgado solo de forma excepcional, significaba un paso esencial para alcanzar el estatus de divinidad. Lo alcanzaron, entre otras, Livia (bajo Tiberio), Popea Sabina (bajo Nerón), Marciana, Matidia la Mayor (ambas con Trajano), Plotina, Sabina (bajo Adriano), etc.
Para el culto específico de la domus augusta o familia imperial se creó el sacerdocio específico del flaminatus. Los flamines ejercían el de los varones y las flaminicae, frecuentemente sus esposas, el de las mujeres. El culto se extendía también a todos los ya fallecidos, caso en el que se mencionan como domus divina, divorum et divarum, etc. flamines y flaminicae existían en el nivel municipal y en el provincial, siendo el flaminado provincial masculino, que conllevaba también importantes gastos, una palanca muy importante para el ascenso a otros órdenes sociales.
La naturaleza del cargo imperial y el Principado fueron establecidos por el heredero de Julio César, Octavio, declarado en el testamento de César como hijo adoptivo de este. Octavio Augusto nombró más tarde como heredero al hijo del primer matrimonio de su esposa Livia con un joven de la distinguida familia Claudia, dando inicio a la dinastía Julia-Claudia, que terminaría tras la muerte de Nerón, tataranieto de Augusto por parte de su hija Julia y de Livia por parte del hijo de esta: Tiberio.
De este linaje fue también el emperador Calígula, sucesor de Tiberio, Claudio y Nerón, con cuya muerte finalizó la dinastía Julio-Claudia.
A lo largo del año 69, Nerón fue sucedido por una serie de usurpadores, dándose en llamar a este el año de los cuatro emperadores. El último de ellos, Vespasiano, estableció la dinastía Flavia, cuyo último Emperador, Domiciano, fue a su vez sucedido por Nerva. Nerva, anciano y sin hijos, adoptó a Trajano, ajeno a su familia, y le nombró su heredero.
Cuando Trajano accedió al trono imperial, siguió el ejemplo de su predecesor, adoptando a Adriano como heredero, lo que se convirtió en una práctica habitual en la sucesión del Imperio durante el siguiente siglo, dando origen a la época de «los cinco emperadores buenos», el periodo de mayor estabilidad y prosperidad de la historia del Imperio romano. Para algunos historiadores esta fue la era dorada de Roma. Los emperadores de esta dinastía fueron: Nerva, Trajano, Adriano, Antonino Pío y Marco Aurelio, quien le cedió el trono a su hijo Cómodo, un disoluto que rápidamente estropeó la obra de todo un siglo de buen gobierno del imperio.
El último de los «cinco emperadores buenos», Marco Aurelio, eligió por su parte a su hijo Cómodo como sucesor en lugar de adoptar a su heredero. El consiguiente desgobierno provocado por Cómodo condujo a su posterior asesinato, el 31 de diciembre de 192. Esto dio origen a un breve período de inestabilidad que terminó con el ascenso al poder imperial de Septimio Severo, quien estableció la dinastía de los Severos. Esta dinastía, a excepción del periodo 217-218, ostentó la púrpura hasta el año 235.
El ascenso al poder de Maximino el Tracio marcó el final de una era y el principio de otra. Fue uno de los últimos intentos del cada vez más impotente Senado para influir en la sucesión. Además, fue la primera vez que un hombre alcanzaba la púrpura basándose únicamente en su trayectoria militar. Tanto Vespasiano como Septimio Severo provenían de familias nobles o de clase media, mientras Maximino el Tracio procedía de una familia plebeya y bárbara. Nunca durante su reinado visitó Roma, y dio origen a una serie de «emperadores cuarteleros», provenientes todos ellos del Ejército. Entre 232 y 285, más de 12 emperadores accedieron a la púrpura, pero solo Valeriano y Caro llegaron a asegurarse la sucesión de sus hijos al trono, y ambas dinastías terminaron en solo dos generaciones.
El ascenso al trono imperial de Diocleciano el 20 de noviembre de 284, un comandante dálmata de la caballería de la guardia de Caro y Numeriano, de habla griega y clase baja, significó el abandono del concepto tradicional romano de «emperador». Este, que oficialmente se consideraba como el «primero entre iguales», dejó de serlo con Diocleciano, que incorporó el despotismo oriental en la dignidad imperial. Donde los anteriores emperadores habían vestido la toga púrpura y habían sido tratados con deferencia, Diocleciano vistió ropas y calzados enjoyados, y exigió de aquellos que le servían arrodillarse y besar el borde de sus ropas (adoratio).
En muchos sentidos, Diocleciano fue el primero de los emperadores monárquicos, hecho que se simboliza en que la palabra dominus ('señor') reemplazó a princeps como término preferente para referirse al emperador. De una forma significativa, ni Diocleciano ni su coemperador Maximiano habitaron mucho tiempo en Roma después de 286, estableciendo sus capitales imperiales en Nicomedia y Mediolanum (la actual Milán), respectivamente.
Además, Diocleciano estableció la tetrarquía, un sistema que dividió al Imperio Romano en Occidente y Oriente, cada una de las cuales tenía un Augusto como gobernante supremo y un César como ayudante del primero. El sistema de la tetrarquía degeneró en una guerra civil. El vencedor de estas guerras fue Constantino I el Grande, quien restauró el sistema de Diocleciano de división del Imperio en Este y Oeste. Constantino mantuvo Oriente para sí mismo y refundó la ciudad de Constantinopla como su nueva capital.
La dinastía que estableció Constantino también se vio pronto acosada por guerras civiles e intrigas cortesanas hasta que fue reemplazada de forma breve por Joviano, general de Juliano el Apóstata y, de forma más permanente, por Valentiniano I y la dinastía que este fundó en 364. A pesar de ser un soldado procedente de la clase media-baja, Valentiniano no fue un «emperador cuartelero», sino que fue elevado a la púrpura por un cónclave de generales veteranos y funcionarios civiles.
Teodosio I accedió al trono imperial en Oriente en el año 379, y se hizo con el control de Occidente en 394. Declaró ilegales la brujería, magia y adivinación, y convirtió al cristianismo en la religión oficial del Imperio. Teodosio fue el último emperador que gobernó la totalidad del Imperio Romano, ya que el reparto del mismo entre sus hijos Arcadio (Imperio Oriental) y Honorio (Imperio Occidental) tras su muerte en el año 395 representó la división definitiva del Imperio.
Sobre el final del siglo III, en un proceso que duró varios años, el Imperio romano se dividió en Oriente y Occidente, cada una de las cuales tuvo sus propios emperadores. En el Oeste, parte del Imperio donde estaba incluida la vieja capital de Roma, la línea sucesoria imperial se interrumpió a finales del siglo V, comenzando el periodo conocido como la Edad Media.
La sucesión de emperadores romanos en el Este continuó hasta la caída de Constantinopla en 1453, siendo el último emperador Constantino XI Paleólogo. Fueron estos emperadores los que normalizaron la dignidad imperial hasta el concepto moderno del término «Emperador», incorporando el título dentro de la organización del Estado, y adoptando el antes mencionado título Basileus Rhomaion ('Emperador de los Romanos', en griego). Los emperadores de Oriente dejaron de usar el latín como idioma oficial tras el reinado de Heraclio. Los historiadores suelen referirse al Imperio romano de Oriente como Imperio bizantino, aunque «bizantino» es un término que los propios bizantinos nunca usaron para referirse a sí mismos.
Tras la caída del Imperio bizantino en 1453, los zares rusos reclamaron los títulos de emperador y autócrata, que usarían hasta el fin del Imperio ruso en 1917; por su parte, los sultanes otomanos se consideraron herederos de este título hasta su caída en el 1922, porque a Mehmed II al conquistar Constantinopla le proclamaron César de los Romanos, comprando además el título a Demetrio Paleólogo, que además era su pariente por vía materna.
El último titular de la Corona del Imperio bizantino, Andrés Paleólogo, vendió su título imperial a Fernando II de Aragón e Isabel I de Castilla antes de su muerte en 1502.[5]​ Sin embargo, no se tiene constancia de que ningún monarca español haya usado los títulos imperiales bizantinos, que convierten al Rey de España en legítimo Emperador de Roma.
El concepto de «Imperio romano» sería recuperado en Occidente tras la coronación del rey franco Carlomagno como «Emperador romano» por el Papa el día de Navidad del año 800. Carlomagno y sus descendientes francos son llamados frecuentemente Emperadores de Occidente, e incluso cuando la desintegración del Imperio carolingio era ya patente, el título se conservó para la línea primogénita de la familia. Tras la formación de los nuevos reinos de Francia y Germania, pasaría más de medio siglo para que Otón I se convirtiera en líder del nuevo Sacro Imperio Romano Germánico en 962, si bien su potestad se reducía, prácticamente, a la región oriental del Imperio carolingio.
Esta nueva línea sucesoria estuvo compuesta por regla general de emperadores de origen alemán más que romano, aunque mantuvieron el nombre de «romanos» como símbolo de legitimidad. Esto duró hasta 1806, cuando Francisco II disolvió el Imperio durante las Guerras Napoleónicas con la clara intención de impedir que Napoleón Bonaparte se apropiara del título y la legitimidad histórica que este conllevaba. Estos emperadores usaron una variedad de títulos, entre los cuales el más frecuente sería Imperator Augustus, antes de terminar imponiéndose la denominación de Imperator Romanus Electus. Los historiadores les asignan comúnmente el nombre de «Sacro Emperador Romano» basándose en los usos históricos reales, y consideran al «Sacro Imperio Romano» como una institución separada y sin relación política con el antiguo Imperio romano.
Arce, Javier. Funus Imperatorum: Los funerales de los emperadores romanos. Alianza Editorial. ISBN 84-206-7068-5
Hidalgo de la Vega, María José. El intelectural, la realeza y el poder político en el imperio romano. Ediciones Universidad Salamanca. ISBN 84-7481-803-6

Una enana blanca es un remanente estelar que se genera cuando una estrella de masa menor que 1/9 - 1/10 masas solares ha agotado su combustible nuclear. De hecho, se trata de una etapa de la evolución estelar que atravesará el 97% de las estrellas que conocemos, incluido el Sol. Las enanas blancas son, junto a las enanas rojas, las estrellas más abundantes del universo.[1]​ El físico Stephen Hawking, en el glosario de su conocida obra Historia del tiempo, define la enana blanca de la siguiente manera: Estrella fría estable, mantenida por la repulsión debida al principio de exclusión entre electrones.[2]​
Las enanas blancas están compuestas por átomos en estado de plasma; como en su núcleo ya no se producen reacciones termonucleares, la estrella no tiene ninguna fuente de energía que equilibre el colapso gravitatorio, por lo que la enana blanca se va comprimiendo sobre sí misma debido a su propio peso. La distancia entre los átomos en el seno de la misma disminuye radicalmente, por lo que los electrones tienen menos espacio para moverse (en otras palabras, la densidad aumenta mucho, hasta órdenes de 106 g/cm3, una tonelada por centímetro cúbico y aún más). A estas densidades entran en juego el principio de indeterminación de Heisenberg y el principio de exclusión de Pauli para los electrones, los cuales se ven obligados a moverse a muy altas velocidades, generando la llamada presión de degeneración electrónica, que es la que efectivamente se opone al colapso de la estrella. Esta presión de degeneración electrónica es un fenómeno radicalmente diferente de la presión térmica, que es la que generalmente mantiene a las «estrellas normales». Las densidades mencionadas son tan enormes que una masa similar a la del Sol cabría en un volumen como el de la Tierra (lo que daría una densidad aproximada de 2 t/cm3), y solamente son superadas por las densidades de las estrellas de neutrones y de los agujeros negros. Las enanas blancas emiten solamente energía térmica almacenada, y por ello tienen luminosidades muy débiles.[3]​
Las estrellas de masa baja con intensidad intermedia (masas menores que 1/8 - 1/10 masas solares), al acabar la fusión del hidrógeno durante su vida en la secuencia principal, se expanden como gigantes rojas, y proceden a fusionar helio en carbono y oxígeno en su núcleo. Si la gigante roja no posee suficiente temperatura como para luego fusionar a su vez el carbono y el oxígeno, su núcleo se comprime por la gravedad y su envoltura es expulsada en una serie de pulsos térmicos durante la fase de gigante en la rama asintótica, produciendo así una nebulosa planetaria que envuelve un remanente estelar: la enana blanca.[4]​
El 99% de las enanas blancas está constituido básicamente por carbono y oxígeno, que son los residuos de la fusión del helio. Sin embargo, sobre la superficie hay una capa de hidrógeno y helio prensados y parcialmente degenerados, que forman la atmósfera de la enana blanca. Sólo unas pocas están formadas íntegramente por helio[5]​[6]​ al no haber llegado a quemarlo, o por oxígeno, neón y magnesio,[7]​ productos del quemado nuclear (fusión) del carbono.
Recién formadas, las enanas blancas poseen temperaturas muy altas, pero al no producir energía, se van enfriando gradualmente. En teoría, las enanas blancas se enfriarán con el tiempo hasta que ya no emitan radiación detectable, para entonces convertirse en  enanas negras.[4]​ Sin embargo, el proceso de enfriamiento es tan lento que la edad del universo desde el Big Bang es demasiado corta para albergar, en este momento, a una de estas enanas negras. De hecho, las enanas blancas más frías que se conocen poseen temperaturas de varios miles de K.[8]​[3]​ El término enana blanca fue acuñado por Willem Luyten en 1922,[9]​ aunque el nombre más apropiado para objetos de esta naturaleza es el de estrellas degeneradas.
La primera enana blanca se descubrió en el sistema estelar triple 40 Eridani, que está comprendido por la estrella de secuencia principal 40 Eridani A orbitando alrededor del sistema binario formado por la enana blanca 40 Eridani B, y 40 Eridani C, una enana roja de secuencia principal. Dicho sistema binario fue descubierto por William Herschel el 31 de enero de 1783.[10]​, p. 73 La misma estrella binaria fue observada posteriormente por Friedrich Georg Wilhelm von Struve y Otto Wilhelm von Struve en 1825 y 1851 respectivamente.[11]​[12]​ En 1910, Henry Norris Russell, Edward Charles Pickering, y Williamina Fleming, descubrieron que, a pesar de ser una estrella tenue, 40 Eridani B era de tipo espectral A, o blanca.[9]​ El tipo espectral de 40 Eridani B se confirmó oficialmente en 1914 por Walter Adams.[13]​
Durante el siglo XIX, las técnicas de medir la posición de las estrellas se volvieron lo suficientemente precisas como para poder detectar cambios muy pequeños en la posición de algunas de ellas. Friedrich Bessel, en 1844, utilizando estas técnicas percibió que las estrellas Sirio (α Canis Majoris) y Procyon (α Canis Minoris) estaban variando sus posiciones, por lo que dedujo que estos cambios de posición eran debidos a una estrella invisible hasta entonces.[14]​ Bessel estimó que el período de dicha estrella sería de, aproximadamente, medio siglo.[14]​ C.H.F.Peters calculó una órbita para dicha estrella en 1851.[15]​
La estrella mencionada no es otra que Sirio B, también conocida como el Cachorro, la segunda enana blanca descubierta. Tiene una temperatura superficial de unos 25.000 K, lo que la incluye dentro de las estrellas calientes. El 31 de enero de 1862, Alvan Graham Clark observó una especie de estrella oscura cerca de Sirio que no había sido avistada anteriormente,[15]​ y que más tarde se identificó como la estrella predicha por Bessel. A pesar de todo, Sirio B resultó ser 10.000 veces menos luminosa que la estrella principal Sirio A. Dado que tenía que tener un alto brillo por unidad de superficie, Sirio B tenía que ser, por fuerza, mucho más pequeña que Sirio A. Los cálculos determinaron un radio aproximadamente igual al de la Tierra. El análisis de la órbita del sistema estelar Sirio mostró que la masa de aquella extraña estrella era aproximadamente la misma que la del Sol. Esto implicaba que Sirio B debía de ser cientos de veces más densa que el plomo, algo que no se podía explicar hidrostáticamente. El misterio quedó sin resolver durante bastante tiempo, considerándose a Sirio B como una rareza imposible de explicar. Walter Adams anunció en 1915 que había descubierto que el espectro de Sirio B era similar al de su compañera.[16]​
En 1917 Adriaan Van Maanen descubrió la estrella de Van Maanen, una enana blanca aislada, que se convirtió en la tercera en ser descubierta.[17]​ Estas primeras tres enanas blancas descubiertas son las llamadas enanas blancas clásicas.[18]​, p. 2 A partir de entonces, se encontraron muchas estrellas blancas que poseían un alto movimiento propio, baja luminosidad y un radio similar al terrestre, por lo que también fueron clasificadas como enanas blancas.
El peculiar nombre de enana blanca se debe a que sus descubridores observaron que tenían un espectro blanco, esto es, sus temperaturas superficiales eran cercanas a los 10.000 K. Cuando realmente se conocieron las características de esos objetos, se comprobó que las hay de varias temperaturas (es decir, no son todas blancas) pero que las más comunes eran, en efecto, blancas. En realidad, pueden ir desde colores muy azules (temperaturas superiores a los 20.000 K con máximo de intensidad situado en longitudes de onda mucho más cortas que el visible) hasta muy rojos (temperaturas inferiores a 3.000 K y máximo de intensidad a longitudes de onda largas). Sin embargo, el primero en utilizar dicho término fue Willem Luyten, cuando examinaba en 1922 esta clase de estrellas.[9]​[19]​[20]​[21]​[22]​ El término fue popularizado más tarde por Arthur Eddington.[23]​[9]​
Las primeras enanas blancas descubiertas después de las tres clásicas lo fueron en la década de 1930. En 1939 se descubrieron 18 enanas blancas.[18]​, p. 3 Varios científicos, entre ellos Luyten, siguieron buscando enanas blancas en los años 1940. En 1950, ya se conocían alrededor de cien enanas blancas,[24]​ y en 1999, la cifra ya rondaba las 2.000.[25]​ Desde entonces, el Sloan Digital Sky Survey ha encontrado 9.000 nuevas enanas blancas.[26]​
El origen de estos cuerpos es progresivo y suave. En las estrellas maduras las capas más exteriores están muy expandidas en sus transformaciones a estrellas de la rama asintótica gigante y poco a poco se desprenden de su agotado núcleo. Cuando finalizan las reacciones de fusión, el núcleo se contrae y se calienta aunque sin llegar a la temperatura de ignición de la siguiente fase. Antes de llegar a dicha temperatura los electrones degeneran y detienen el proceso. Se forma así una enana blanca con una temperatura de partida en su núcleo de entre 100 y 200 millones de grados que se irá enfriando paulatinamente. El material desprendido formará, a su vez, una nebulosa planetaria en cuyo centro estará la enana blanca.
La enana blanca, una vez formada, va enfriándose y apagándose paulatinamente, de un color azul intenso pasará a un color rojizo, y después pasará al infrarrojo, con el tiempo la temperatura se igualará con la radiación de fondo del universo hasta, hipotéticamente, terminar siendo una enana negra, y vagar por el espacio indefinidamente. Para tomar conciencia de la lentitud del enfriamiento de las enanas blancas, cabe tener presente que el universo continúa expandiéndose, y se estima que en cuestión de 1019 a 1020 años, las galaxias se desvanecerán, ya que las estrellas de las que están formadas se dispersarán por el espacio intergaláctico.[27]​ Pues bien, se piensa que las enanas blancas sobrevivirán a este hecho, aunque bien es cierto que una colisión fortuita entre enanas blancas podría dar lugar a una estrella capaz de producir reacciones de fusión nuclear (fusionando helio o carbono en vez de hidrógeno), o a una enana blanca muy masiva que diera lugar a una supernova de tipo Ia.[27]​ Se cree que el tiempo de vida de una enana blanca es similar al tiempo de vida media del protón, que se estima desde los 1032 a los 1049 años según algunas teorías de la gran unificación. Si estas teorías fueran erróneas, el protón debería decaer mediante complejos procesos nucleares, o formando agujeros negros virtuales mediante procesos de gravedad cuántica, y en este caso la vida media del protón se situaría sobre los 10200 años. Si tomamos como cierto que los protones se desintegran, la masa de la enana blanca disminuiría muy lentamente a causa de la desintegración de sus núcleos atómicos, hasta llegar a tal punto en el que se convertiría en un pedazo de materia no degenerada, y finalmente desaparecería por completo.[27]​
Para que los electrones degenerados puedan sostener a la estrella, ésta no debe superar el límite de Chandrasekhar, que es de 1,44 masas solares.[28]​ Se conocen enanas blancas desde 0,17[29]​ hasta 1,33[30]​ masas solares, aunque la gran mayoría de ellas se encuentra entre 0,5 y 0,7 masas solares.[30]​ El radio estimado de las enanas blancas observadas se sitúa entre 0,008 y 0,02 veces el radio del Sol,[31]​ una cifra muy cercana al radio terrestre (aproximadamente 0,009 radios solares). Así pues, en las enanas blancas se comprime una masa similar a la del Sol en un volumen un millón de veces más reducido, por lo que la densidad es aproximadamente un millón de veces mayor que la del Sol (entre 106 y 107 g/cm³). Forman parte de las estrellas compactas, pues son una de las formas de materia más densas conocidas, solamente por detrás de las estrellas de neutrones, los agujeros negros, e, hipotéticamente, las estrellas de quarks.[32]​
Desde su descubrimiento, ya se conocía la enorme densidad de estas estrellas. Las enanas blancas que se encuentran en un sistema binario, como es el caso de Sirio B o 40 Eridani B, es posible calcular la masa partiendo de las observaciones de sus órbitas. Así se hizo en 1910 con Sirio B,[33]​ estimándose una masa aproximada de 0,94 masas solares (cálculos más recientes indican que su masa es de 1,00 masas solares).[34]​
La enorme densidad de estas estrellas confundió a los astrónomos que comenzaron a estudiarlas. Cuando Ernst Öpik calculó en 1916 la densidad de varias estrellas binarias, estimó que la densidad de 40 Eridani B era de 25.000 veces la densidad del Sol, lo cual calificó literalmente de "imposible". Como Arthur Eddington escribió en 1927:
Aprendemos de las estrellas lo que interpretamos de la luz que nos envían. El mensaje que nos envió la compañera de Sirio decía: "Estoy compuesta de un material 3.000 veces más denso que cualquier cosa que hayáis visto; una tonelada de mi material tendría el tamaño de un pequeño lingote que podríais colocar en una caja de cerillas" ¿Qué se podría responder a este mensaje? La respuesta que la mayoría de nosotros dimos en 1914 fue: "Cállate. No digas tonterías".[35]​, p. 50
Como Eddington señaló en 1924, densidades de tal magnitud implicarían que, según la teoría de la relatividad general, la luz proveniente de Sirio B debería poseer desplazamiento gravitacional hacia el rojo.[23]​ Adams lo confirmó en 1925 cuando logró medir dicho desplazamiento.[36]​
Estas densidades son posibles debido a que la materia no está compuesta por átomos normales que pueden formar enlaces químicos como estamos acostumbrados, sino que está en estado de plasma, y los núcleos y electrones no están cohesionados. Por tanto, en este estado no hay ningún obstáculo que impida que los átomos se acerquen entre sí, de otro modo sería imposible irrumpir el espacio que normalmente ocupan los orbitales atómicos de los electrones.[23]​ Eddington se preguntó qué pasaría cuando dicho plasma se enfriara y desapareciera la energía que mantiene ionizados a los átomos.[37]​ En 1926, R. H. Fowler resolvió esta paradoja mediante la aplicación de la recién instaurada mecánica cuántica. Los electrones se acercan tanto unos a otros que su posición se vuelve muy limitada, queriendo ocupar el mismo estado cuántico, pero para cumplir el principio de exclusión de Pauli y obedecer la estadística de Fermi-Dirac,[nota 1]​ introducida en 1926 para determinar la distribución estadística de partículas que cumplen el principio de exclusión de Pauli,[38]​ los electrones deberían moverse muy deprisa, presionándose unos a otros, lo que forma una presión de degeneración que compensa la gravitatoria, deteniendo así el colapso de la enana blanca. En el cero absoluto, todos los electrones no pueden conservar el estado fundamental, por lo que algunos de ellos se excitan hacia estados de energía más altos, dejando disponibles los estados más bajos de energía, esto recibe el nombre de líquido de Fermi. Los electrones en este estado reciben el nombre de electrones degenerados, y se traduce en que una enana blanca puede enfriarse hasta alcanzar el cero absoluto y todavía contener energía. Otra manera de llegar a esta conclusión es aplicando el principio de indeterminación: la alta densidad de electrones en una enana blanca significa que sus posiciones están muy restringidas, creando una incertidumbre en su dinámica. Esto deriva en que algunos electrones deben de poseer una gran cantidad de movimiento, y por tanto, tener una energía cinética muy elevada.[37]​[39]​
A esas densidades los iones tienen un recorrido libre medio extremadamente reducido; sin embargo, en el caso de los electrones es todo lo contrario: su recorrido es excepcionalmente grande debido a que, al estar degenerados, existen muy pocos huecos libres en el espacio de momentos y posiciones a los que un electrón pueda ir. La opacidad conductiva es, por ello, muy inferior a la radiativa.[nota 2]​ Esto hace que el transporte por conducción sea extremadamente eficiente en el interior de estos objetos lo que hace que sean casi isotérmicas. Pero esto ocurre solamente en su interior ya que en la atmósfera los electrones ya no están degenerados, por lo que el gradiente se acentúa considerablemente.
A medida que aumenta la compresión de una enana blanca, también lo hace el número de electrones en un determinado volumen de la misma. Aplicando tanto el principio de exclusión de Pauli como el principio de indeterminación, deducimos que aumenta la energía cinética de los electrones, lo que causa presión.[37]​[40]​ Dicha presión de degeneración de los electrones, que permite a la enana blanca resistir el colapso gravitatorio, depende solamente de la densidad, sin importar la temperatura. La densidad es tanto mayor cuanto más pesada sea la enana blanca, por lo tanto, la masa es inversamente proporcional al radio: a mayor masa, menor radio.[3]​
El hecho de que la masa de una enana blanca no pueda superar cierto límite es otra consecuencia de la presión de degeneración de los electrones. Estos límites fueron publicados primero en 1929 por Wilhelm Anderson[41]​ y después en 1930 por Edmund C. Stoner.[42]​ El valor actual del límite se publicó por primera vez en 1931 por Subrahmanyan Chandrasekhar.[nota 3]​[43]​[44]​ Como las enanas blancas de oxígeno-carbono están compuestas principalmente por carbono-12 y oxígeno-16, los cuales tienen un número atómico igual a la mitad de su masa molecular, la μe debe de ser igual a 2,[39]​ lo que conduce a la cifra de 1,44 masas solares. Junto con William Alfred Fowler, Chandrasekhar recibió el Premio Nobel de Física en 1983 por este trabajo, entre otros.[45]​ El límite recibe en la actualidad el nombre de límite de Chandrasekhar.
Esto no impide que estrellas de masas iniciales mayores puedan finalizar su ciclo como enanas blancas, ya que los intensos vientos estelares de las estrellas más masivas y el desprendimiento final de la cubierta de gas rebajan en mucho la masa inicial de la estrella hasta dejarla dentro de los límites de Chandrasekhar.
Si una enana blanca excede el límite de Chandrasekhar, y no hay reacciones nucleares, la presión ejercida por los electrones no puede contrarrestar por sí sola a la fuerza de la gravedad, por lo que colapsará en un objeto todavía más denso como una estrella de neutrones o un agujero negro.[46]​ Sin embargo, las enanas blancas pueden llegar a acretar masa adicional de estrellas próximas, siendo común en los sistemas binarios. Estos contactos violentos entre una estrella y una enana blanca pueden finalizar en novas y supernovas termonucleares de tipo «Ia», en la que la enana blanca se destruiría, justo antes de alcanzar el límite de Chandrasekhar.[47]​
Las enanas blancas poseen una luminosidad muy baja, por lo que ocupan la última franja del diagrama de Hertzsprung-Russell.[nota 4]​
Obtener la relación entre el radio y la masa de las enanas blancas es un proceso muy simple. La energía total de una enana blanca se obtiene sumando la energía potencial gravitatoria y la energía cinética. La energía potencial gravitatoria por unidad de masa de una enana blanca, Eg, viene dada por:
  donde G es la constante de gravitación universal, M es la masa de la enana blanca, y R es su radio. La energía cinética, Ec, se incrementa al aumentar el movimiento de los electrones, y su ecuación es:
  donde p es la cantidad de movimiento media de los electrones, m es la masa del electrón, y N es el número de electrones por unidad de masa. Debido a que los electrones están degenerados, podemos estimar p por estar en función de la cantidad de movimiento, Δp, dada por el principio de incertidumbre, que afirma que Δp Δx está en función de la constante reducida de Planck.[nota 5]​ Δx está en función de la distancia media entre electrones, cuyo valor es aproximadamente 
  , es decir, la inversa de la raíz cúbica de la densidad numérica de los electrones, n, por unidad de volumen. Dado que en una enana blanca hay N M electrones y su volumen está en función de R3,[39]​ n vendrá dada por:
    {\displaystyle E_{c}\approx {\frac {N(\Delta p)^{2}}{2m}}\approx {\frac {N\hbar ^{2}n^{2/3}}{2m}}\approx {\frac {M^{2/3}N^{5/3}\hbar ^{2}}{2mR^{2}}}}
  La enana blanca estará en equilibrio cuando su energía total (Eg + Ec), sea mínima. En ese momento, las energías potencial y cinética se pueden comparar, y derivan en una relación entre la masa y el radio al equiparar sus magnitudes:
    {\displaystyle |E_{g}|\approx {\frac {GM}{R}}=E_{c}\approx {\frac {M^{2/3}N^{5/3}\hbar ^{2}}{2mR^{2}}}}
  Si eliminamos N de la ecuación, la cual depende solamente de la composición de la estrella, y de la constante de gravitación universal, G, obtenemos una ecuación que relaciona la masa y el radio:
Este razonamiento incluye la fórmula p2/2m para la energía cinética, que se trata de una fórmula no relativista. Si quisiéramos introducir cálculos relativistas para cuando las velocidades de los electrones se acerquen a la velocidad de la luz, c, deberíamos sustituir p2/2m por la aproximación relativista p c para la energía cinética. Aplicando esta sustitución:
  Igualando esta ecuación a la ecuación de la energía potencial gravitatoria, Eg, podemos eliminar R, y la masa, M, debe ser:[39]​
  Para interpretar este resultado, vemos que si añadimos masa a una enana blanca, su radio disminuye, y según el principio de incertidumbre, la cantidad de movimiento, y por tanto la velocidad de los electrones, aumenta. A medida que aumenta esta velocidad y se va aproximando a la velocidad de la luz (c), los cálculos se vuelven más exactos, lo que significa que la masa de la enana blanca M se va aproximando a Mlímite. Por lo tanto, se demuestra así que ninguna enana blanca puede ser más pesada que el límite de masa.
Para un cálculo más exacto de la relación radio-masa y la masa límite de una determinada enana blanca, se debe calcular la ecuación de estado que describe la relación entre la densidad y la presión del material de la enana. Si tomamos como ejemplo los cálculos no relativistas, el radio es inversamente proporcional a la raíz cúbica de la masa.[44]​, eq. (80) Pero las correcciones en los cálculos relativistas indican que el radio toma el valor de cero en un valor finito de la masa. Dicho límite es el llamado límite de Chandrasekhar, rebasado el cual la enana blanca no puede soportar la fuerza de la gravedad con la presión de degeneración de los electrones. El gráfico del lateral muestra la comparación entre los cálculos relativistas, representados por la curva verde, y los no relativistas, representados por la curva azul, en una enana blanca compuesta por gas de Fermi en equilibrio hidrostático. A la masa molecular media por electrón, μe, se le ha asignado un valor de 2, el radio se mide en radios solares, y la masa en masas solares.[50]​[44]​
Los cálculos suponen que la enana blanca no posee rotación. Si tuviera rotación, la ecuación del equilibrio hidrostático tendría que modificarse para incluir la fuerza centrífuga tomando un sistema de referencia rotatorio,[51]​ pues para una enana blanca con rotación uniforme, el límite de masa aumenta muy ligeramente. Sin embargo, si la rotación de la estrella no es uniforme, y no se toma en cuenta la viscosidad, no habría límite de masa para un modelo de enana blanca en equilibrio estático, como señaló Fred Hoyle en 1947.[52]​ Aunque no todos estos modelos de estrellas en rotación son dinámicamente estables.[53]​
Las enanas blancas emiten un amplio espectro de radiación visible, que abarca desde un azul intenso correspondiente a estrellas de tipo O de secuencia principal, hasta las enanas rojas de tipo M.[54]​
La temperatura superficial de las enanas blancas, es decir, su temperatura efectiva[nota 6]​, comprende desde los 150.000 K[25]​ hasta temperaturas inferiores a los 4.000 K.[55]​[56]​
De acuerdo con la ley de Stefan-Boltzmann, mayor luminosidad implica mayor temperatura superficial, por lo que dicho rango de temperaturas en la superficie corresponde con una luminosidad desde 100 veces la del Sol, hasta una diezmilésima parte ella (1/10.000).[56]​ Las enanas blancas más calientes, cuya temperatura superficial sobrepasa los 30.000 K, son fuentes de rayos X blandos (de mayor longitud de onda, más cercanos a la banda ultravioleta), es decir, de menor energía. Esto permite, mediante la observación de rayos ultravioleta y de rayos X, obtener información acerca de la composición y de la estructura de las atmósferas de las enanas blancas, y así poder ser estudiadas en profundidad.[57]​ La radiación de una enana blanca proviene de la energía térmica almacenada, a no ser que acrete masa de una compañera o de cualquier otra fuente. Al tener una superficie tan reducida, el calor irradia muy lentamente, por lo que se mantienen calientes durante un largo período.[4]​ A medida que una enana blanca se enfría, la temperatura superficial desciende, el espectro de la radiación se va desplazando hacia un color rojizo, y la luminosidad disminuye, y al no tener otro tipo de sumidero de energía que la radiación, se deduce que con el tiempo se va enfriando más lentamente. Por ejemplo, Bergeron, Ruiz, y Leggett, estimaron que una enana blanca de carbono de 0,59 masas solares con una atmósfera de hidrógeno se había enfriado hasta una temperatura superficial de 7.140 K en, aproximadamente, 1,5 mil millones de años. Sin embargo, calcularon que para que se enfriara aproximadamente 500 kelvin más (hasta 6.590 K), necesitaría 0,3 mil millones de años, pero si repetimos dos veces más el proceso (hasta 6.030 K y 5.550 K), tardaría 0,4 y 1,1 miles de millones de años respectivamente.[58]​ La mayoría de las enanas blancas observadas poseen una temperatura superficial relativamente elevada, entre 8.000 K y 40.000 K.[59]​[26]​ Como cada vez se enfrían más lentamente, pasan la mayor parte de su vida en temperaturas frías, por lo que, al observar el universo, lo lógico sería que encontráramos más enanas blancas frías que calientes. Esto parece que se cumple,[60]​ pero esta tendencia se frena al llegar a temperaturas extremadamente frías. Sólo han sido observadas unas pocas enanas blancas por debajo de los 4.000 K,[61]​ y una de las más frías observadas es WD 0346+246, con una temperatura superficial aproximada de 3.900 K.[55]​ Esto tiene su explicación en que la edad del universo es finita,[62]​ y no les ha dado tiempo a enfriarse por debajo de dichas temperaturas. Una consecuencia práctica de esto es que la función de luminosidad de las enanas blancas puede ser utilizada para calcular la edad de las estrellas en una determinada región del espacio.[60]​
Con el tiempo, las enanas blancas se enfriarán hasta tal punto que dejarán de irradiar y se convertirán en enanas negras, aproximándose a la temperatura del entorno e igualándose con la radiación de fondo de microondas. Sin embargo, en la actualidad, y debido a la corta edad del universo, no hay indicios de la existencia de enanas negras.[3]​
G. P. Kuiper fue, en 1941, el primero en intentar clasificar el espectro de las enanas blancas,[54]​[63]​ y desde entonces se han utilizado varios sistemas de clasificación.[64]​[65]​
Edward M. Sion y varios coautores establecieron en 1983 el sistema utilizado en la actualidad, y desde entonces se ha revisado en diversas ocasiones. Dicho sistema clasifica el espectro con un símbolo, que suele consistir en una D inicial, seguido de una secuencia de letras mostradas en la tabla adyacente, y un índice de temperaturas, que se calcula dividiendo 50.400 K por la temperatura efectiva, ya que la temperatura superficial está íntimamente relacionada con el espectro. Por ejemplo:
Una enana blanca que solo posea líneas de absorción del He I y una temperatura efectiva de 15.000 K, corresponderá, según la notación, con DB3.
Una enana blanca que posea un campo magnético polarizado, una temperatura efectiva de 17.000 K, y una línea de absorción en la que domina el He I pero que también tiene H, se tratará de una DBAP3.Si la clasificación no está del todo clara, se pueden utilizar ciertos símbolos, como "?" o ":".[54]​[25]​
Aunque la mayoría de las enanas blancas están compuestas por oxígeno y carbono, la espectroscopia de la luz emitida revela que su atmósfera está compuesta casi en su totalidad o bien de hidrógeno, o bien de helio, y este elemento dominante es unas 1.000 veces más abundante en la atmósfera que los demás. La explicación de este hecho la proporcionó Évry Schatzman en la década de 1940, quien expuso que la alta gravedad superficial separaba los elementos, atrayendo más fuertemente los elementos pesados hacia su centro, quedando los más ligeros en la superficie.[66]​[67]​
La atmósfera, la única parte de las enanas blancas que podemos observar, es la parte superior de un residuo de la fase de la rama asintótica gigante, y puede contener material obtenido del medio interestelar. Se ha calculado que una atmósfera rica en helio posee una masa aproximada del 1% de la masa total de la estrella, y una atmósfera compuesta de hidrógeno, el 0,01% del total.[56]​[68]​
A pesar de la fracción que representa, esta capa externa determina la evolución térmica de la enana blanca; los electrones degenerados conducen bien el calor, por lo que la masa de la enana blanca es casi isotérmica: una temperatura superficial entre 8.000 K y 16.000 K corresponde con una temperatura del núcleo entre 5.000.000 K y 20.000.000 K. La opacidad a la radiación de las capas externas es una medida de las enanas blancas que permite que se enfríen con mayor lentitud.[56]​
Las enanas blancas del tipo DA, que se caracterizan por tener atmósferas ricas en hidrógeno, conforman el 80% de las enanas blancas analizadas espectroscópicamente.[56]​ La gran mayoría de los restantes tipos (DB, DC, DO, DZ) poseen atmósferas ricas en helio. Solo una pequeña fracción de las enanas blancas, aproximadamente el 0,1%, tienen atmósferas en las que el elemento principal es el carbono (tipo DQ).[69]​ Suponiendo que no hubiera carbono ni metales, el tipo espectral depende exclusivamente de la temperatura efectiva. Aproximadamente entre 45.000 K y 100.000 K el espectro más abundante sería el DO, caracterizado por helio ionizado. Entre 12.000 K y 30.000 K, destacarían las líneas de helio, y se clasificaría como DB. Por debajo de los 12.000 K, el espectro es continuo y se clasifica como DC.[68]​[56]​ No está claro el motivo por el cual escasean las enanas blancas DB, con temperaturas efectivas entre 30.000 K y 45.000 K. Una hipótesis sugiere que se debe a procesos de evolución atmosféricos, como la separación gravitacional y la mezcla convectiva.[56]​
En 1947, P. M. S. Blackett predijo que las enanas blancas deberían poseer campos magnéticos de una fuerza en su superficie de aproximadamente 1 millón de gauss (100 teslas), como consecuencia de una ley física que él mismo propuso, que afirmaba que un cuerpo en rotación y sin carga debería generar un campo magnético proporcional a su momento angular.[70]​ Esta teoría recibe el nombre de magnetismo gravitacional, conocida también como el efecto Blackett,[71]​ el cual nunca ha sido observado ni aceptado generalmente por la comunidad científica. Pocos años más tarde, en la década de 1950, el efecto Blackett fue refutado.[72]​, pp. 39–43En la década de 1960, se propuso otra teoría que afirmaba que las enanas blancas poseen tales campos magnéticos porque el flujo magnético de la superficie debía conservarse durante la evolución de una estrella no degenerativa a una enana blanca. Un campo magnético en la superficie de la estrella progenitora de 100 gauss (0,01 tesla) se convertiría así en un campo de 100·1002 = 1 millón de gauss (100 T) si el radio reduce en 100 veces su tamaño.[67]​, §8;[73]​, p. 484La primera enana blanca de cuyo campo magnético se tiene constancia es GJ 742, en 1970 se detectó que la estrella poseía un campo magnético procedente de la emisión de luz polarizada circularmente.[74]​ Se calcula que la fuerza del campo magnético en su superficie es de 300 millones de gauss (30 kT).[67]​ Desde entonces, se han descubierto campos magnéticos en más de 100 enanas blancas, el valor más bajo es de 2×103 gauss (0,2 T), y el más alto 109 (100 kT). Solamente se ha calculado el campo magnético de un reducido número de enanas blancas, y se estima que, al menos, un 10% de las enanas blancas tienen campos mayores de 1 millón de gauss (100T).[75]​[76]​
La presión de degeneración es un fenómeno cuántico independiente de la temperatura, por lo que las enanas blancas seguirán enfriándose toda su vida hasta igualar su temperatura con el entorno, es decir, hasta llegar casi al cero absoluto.
El material que compone las enanas blancas es inicialmente plasma, pero en la década de 1960 se predijo teóricamente que en una fase avanzada del enfriamiento, la enana blanca debería cristalizar, comenzando por el centro de la estrella.[77]​
Si se enfrían lo suficiente las interacciones entre iones se tornan relevantes y estos dejan de comportarse como un gas ideal pasando a ser un líquido de Coulomb. Pero por debajo de una cierta temperatura umbral (~ 1,7x107 K) los iones se disponen en forma de red cristalina de tipo bcc, por lo que se dice que la enana blanca ha cristalizado. Al cristalizar se libera calor latente ya que es un proceso de cambio de fase y eso afecta a la función de luminosidad. Esta transición de fase libera esa energía latente ralentizando un poco el enfriamiento.
La temperatura umbral se calcula mediante el parámetro que se indica a continuación el cual no es más que una relación entre las interacciones coulombianas y la agitación térmica. Mientras la energía coulombiana sea inferior a la térmica el comportamiento de los iones será de gas. Cuando sus valores sean comparables se comportará como un líquido y cuando la energía coulombiana sea claramente dominante la estrella tendrá un comportamiento sólido, un sólido de una dureza inimaginable a escala humana. El umbral de cristalización se considera normalmente que es: Γ0 ~170
En esa ecuación Z es el número atómico que para una enana blanca de carbono (Z=6) y oxígeno (Z=8) será 7 suponiendo que haya un 50% de cada elemento; K es la constante de Boltzmann; T la temperatura; y di es la distancia entre iones que está relacionada con la densidad de la estrella por la ecuación (4/3)πdi³~1/ni=(μimH)/ρ, donde ρ es la densidad, mH la masa del hidrógeno y μi el número másico medio que viene a ser 14 para las enanas de carbono y oxígeno (12+16)/2.
Ocurre que el oxígeno cristaliza antes que el carbono por lo que en la enana blanca empezará a diferenciarse un núcleo de oxígeno cristalizado rodeado por un fluido de carbono cada vez más empobrecido en oxígeno. La emisión de radiación latente contribuirá a frenar el enfriamiento y alargar la vida de las enanas blancas unas decenas de millones de años.
Otra consecuencia de este curioso fenómeno es que en las enanas blancas cristalizadas el potencial a romper para que se dé la fusión completa del carbono es mayor por lo que son potencialmente más explosivas en caso de tener una compañera cercana.
En el año 2004, Travis Matcalfe y un equipo de investigadores del Harvard-Smithsonian Center for Astrophysics estimaron, sobre la base de sus observaciones, que aproximadamente un 90% de la masa de la enana blanca BPM 37093 había cristalizado.[77]​[78]​[79]​[80]​
Trabajos independientes estiman que la masa cristalizada se sitúa entre el 32% y el 82% del total.[81]​
Las enanas blancas pulsantes tienen la peculiaridad de que su luminosidad es variable debido a las pulsaciones no radiales de las ondas de gravedad de la propia estrella. La observación de estas pequeñas variaciones en la emisión de luz, aproximadamente del 1% al 30%, permite analizar datos del interior de las enanas blancas mediante la astrosismología.[84]​
Existen tres grandes grupos en los que se dividen las enanas blancas pulsantes: el primer grupo posee atmósferas ricas en hidrógeno y son del tipo espectral DA, son las llamadas estrellas DAV o ZZ Ceti.[67]​ El segundo grupo posee atmósferas con helio abundante, tienen el tipo espectral DB, y son conocidas como DBV o V777 Her.[56]​ En el último grupo la atmósfera está compuesta en su mayoría por helio, carbono y oxígeno, son del tipo espectral PG 1159, y se denominan estrellas GW Virginis. A veces, este último grupo se puede subdividir en los grupos de estrellas DOV y PNNV.[83]​[85]​ Aunque a este grupo no se les puede considerar enanas blancas propiamente dichas, ya que no han alcanzado la zona de las enanas blancas en el diagrama de Hertzsprung-Russell, y por ello se las considera pre-enanas blancas.[83]​[86]​
Los primeros cálculos apuntaban que las enanas blancas variarían en periodos de 10 segundos, sin embargo, en la década de 1960 estas suposiciones se rechazaron al no coincidir con las observaciones.[67]​[87]​
La primera ZZ Ceti encontrada fue HL Tau 76 en el año 1968, descubierta por el astrónomo norteamericano Arlo U. Landolt. Landolt observó que las pulsaciones de la estrella variaban en un período de aproximadamente 12,5 minutos.[88]​ En 1970 se descubrió Ross 548, otra ZZ Ceti con el mismo tipo de variabilidad que HL Tau 76.[89]​ En 1972, la estrella obtuvo oficialmente la designación de ZZ Ceti.[90]​
Las enanas blancas pulsan de forma inestable al atravesar el rango de temperaturas efectivas entre 10.700 y 12.500 K,[91]​ y es por ello que todas las ZZ Ceti se encuentran entre este rango. Este tipo de estrellas presentan cambios de brillo con un período entre 30 segundos y 25 minutos, y una amplitud de 0,001 a 0,2 magnitudes. A veces se observan fluctuaciones de hasta casi 1 mag, pero ello se debe a la acción de compañeras UV Ceti cercanas. La medición de la variación del período de las pulsaciones en estrellas ZZ Ceti permite calcular el progreso del enfriamiento en enanas blancas de tipo DA, e incluso se pueden conseguir aproximaciones de la edad del disco galáctico en el que se encuentran.[92]​
En 1982, D. E. Winget y sus compañeros de trabajo sugirieron que las estrellas DB (enanas blancas con atmósferas compuestas fundamentalmente de helio) con temperaturas superficiales próximas a los 19.000 K, deberían emitir pulsos.[93]​ Winget buscó estrellas con estas características, y encontró la estrella variable GD 358, una DBV, como él mismo predijo que sería.[94]​ Esta fue la primera predicción de una clase de estrella variable antes de su observación.[68]​ En 1985, este tipo de estrellas fueron denominadas V777 Her.[95]​[56]​ Estas estrellas poseen temperaturas efectivas próximas a los 25.000 K.[67]​
Las estrellas GW Virginis son el tercer grupo de enanas blancas variables pulsantes, a veces se subdividen en los grupos DOV y PNNV. PG 1159-035 es la estrella prototipo.[83]​ Las variaciones de esta estrella, que también es la estrella prototipo de la clase PG 1159, fueron observadas por primera vez en 1979,[96]​ y se le designó con el nombre de GW Vir en 1985,[95]​ dando su nombre a esta clase de estrellas. Estas estrellas no llegan a ser enanas blancas literalmente, porque en el diagrama de Hertzsprung-Russell ocupan una posición intermedia entre la región de las enanas blancas y la zona de la rama asintótica gigante, y es por ello que se les denomina pre-enanas blancas.[83]​[86]​
Estas estrellas están muy calientes, su temperatura efectiva se sitúa entre 75.000 K y 200.000 K, poseen atmósferas ricas en helio, carbono, y oxígeno, y la gravedad en su superficie es relativamente baja (log g ≤ 6.5).[83]​ Es posible que estas estrellas se enfríen para dar lugar a enanas blancas de tipo espectral DO.[83]​
Los períodos del modo normal de las estrellas de clase GW Vir comprenden desde los 300 hasta los 5.000 segundos.[83]​
La excitación de las pulsaciones de las estrellas GW Vir fue estudiada, por primera vez, en la década de 1980,[97]​ pero continúa siendo todo un enigma veinte años después.[98]​ Desde el principio, se pensó que el mecanismo de excitación era causado por el llamado mecanismo κ, asociado con el carbono y el oxígeno ionizados por debajo de la superficie de la fotosfera, pero se pensó que este mecanismo no funcionaría si hubiera helio en la superficie. Sin embargo, parece que puede existir inestabilidad incluso en presencia de helio.[99]​
Las enanas blancas constituyen el final de la evolución estelar en estrellas de la secuencia principal comprendidas entre 0,07 y 10 masas solares.[100]​[1]​ La composición de la enana blanca difiere según la masa inicial de la estrella.
Las estrellas de baja masa (<0,5 MSol) no pasan por ninguna fase posterior a la de combustión del hidrógeno. Agotado éste, los electrones  de su núcleo degeneran mucho antes de alcanzar las temperaturas de ignición del helio por lo que, al final de sus días, estas estrellas se acaban convirtiendo en enanas blancas de helio. Solamente las estrellas de menos de media masa solar pueden dar lugar a este tipo de estrellas, y una estrella de esta masa viviría unos 80.000 millones de años. Si tenemos en cuenta que la edad del universo es de 13.000 millones de años,[8]​ parece lógico pensar que estas estrellas no se hayan podido formar aún.
Sin embargo, se han encontrado algunos objetos que se corresponden con las características de las enanas blancas de helio. La formación de estas estrellas se puede explicar por la interacción de dos estrellas en sistemas binarios, una estrella arrebata la capa externa de hidrógeno a una estrella roja en crecimiento hasta dejar solamente la capa de helio, dejando el objeto compacto desnudo.[5]​[6]​[4]​[101]​[102]​[103]​ El fenómeno también puede ser explicado por la pérdida de masa debido a un gran planeta cercano.[104]​
Si la masa de la estrella se sitúa entre 0,5 y 8MSol, al agotar todo el hidrógeno, su núcleo posee una temperatura tal que permite la fusión de helio en carbono y oxígeno mediante el proceso triple-alfa. Primero es consumido el helio del núcleo, y, una vez agotado, comienza a consumirse el helio disponible en una capa situada a su alrededor. Esto provoca que la estrella se expanda por última vez: comienza la fase de la rama asintótica gigante. A medida que aumenta la cantidad de carbono resultante de las reacciones triple alfa aumentan también las posibilidades de formar oxígeno, pero se desconoce la proporción de carbono y oxígeno ya que sus secciones eficaces no están bien definidas. Llegados a los momentos finales de la estrella, ésta intensificará cada vez más sus vientos estelares, expulsando progresivamente su cubierta de hidrógeno hasta dejar un núcleo desnudo y degenerado de carbono y oxígeno. Una estrella como el Sol expulsará en sus espasmos finales el 40% de su masa antes de finalizar sus días como una enana blanca. La nebulosa resultante de la expulsión de las capas exteriores recibe el nombre de nebulosa planetaria.
Los remanentes de las estrellas de masa comprendida entre 1,5 y 9 masas solares podrían llegar a superar con mucho la masa de Chandrasekhar. Si todas ellas evolucionaran para explotar como supernovas, como sería de suponer, se deberían observar muchas más en el cielo. Además, la composición en metales del gas interestelar debería ser más rica en hierro que en oxígeno, cosa que no ocurre. Esto se explica por la gran cantidad de masa que expulsan los fuertes vientos de estas estrellas, llegando hasta pérdidas de 8 masas solares a lo largo de su vida. Estas pérdidas de masa van a ser tanto más acentuadas cuanto mayor sea la estrella, así como mayor sea su metalicidad, la cual incrementa la opacidad. Por lo tanto, las estrellas en este rango de masas también acaban su vida como una enana blanca de carbono y oxígeno. Este tipo de enanas blancas son las más comunes que se observan en el universo.[101]​[105]​[106]​
El límite entre estrellas de masa media y masa alta (8 MSol < M < 10 MSol): ¿Enanas blancas de oxígeno y neón?
Las estrellas de masa elevada alcanzan en su núcleo la temperatura necesaria para fusionar el carbono en neón, y, seguidamente, el neón en hierro. Su destino final no es una enana blanca, ya que superan la masa máxima permitida y la presión de degeneración de los electrones no puede hacer frente a la gravedad, por lo que el núcleo colapsa y la estrella explota en una supernova de tipo II, dejando como remanente una estrella de neutrones, un agujero negro, o una forma exótica de estrella compacta.[100]​[107]​ Sin embargo, algunas estrellas comprendidas entre 8 y 10 MSol pueden ser capaces de fusionar carbono para producir neón, pero no ser lo suficientemente masivas para quemar neón. Si esto sucede, el núcleo no colapsa, y la fusión no llega a ser demasiado violenta, daría lugar a una enana blanca compuesta de oxígeno, neón, y magnesio.[108]​[109]​ Estas estrellas proceden de las llamadas ONeMg o novas de neón, cuyo espectro muestra elevadas abundancias de neón y magnesio.[7]​[110]​[111]​
El problema de determinar el rango de masas que da lugar a estos objetos procede de las elevadas tasas de pérdida de masa al final de la vida de las estrellas, lo que hace difícil de simular numéricamente con precisión qué estrellas se detienen en el carbono, cuáles en el oxígeno-neón y cuales llegan hasta el hierro. Así pues, es posible que el valor exacto dependa de la metalicidad de la estrella.
Las supernovas de tipo Ia han sido también propuestas como otra manera de formar (mejor dicho, transformar) enanas blancas. En este escenario, la explosión que se produce en este tipo de supernova no tiene la potencia suficiente como para destruir por completo la enana blanca y se limita a expulsar parte de su materia a grandes velocidades además de, al ser asimétrica, catapultar a la enana blanca a grandes velocidades convirtiéndola en una estrella hiperveloz. La materia que ha sido procesada en la supernova fallida es recapturada por la enana blanca, con los elementos más densos como el hierro cayendo al centro del astro y acumulándose allí.[112]​
Estas enanas blancas de núcleo de hierro serían más pequeñas que sus equivalentes formadas de carbono y oxígeno y cristalizarían y enfriarían más rápido también.[113]​
El sistema estelar o planetario de una enana blanca puede intervenir en su desarrollo de varias formas. El Telescopio espacial Spitzer de la NASA observó la zona central de la Nebulosa de la Hélice mediante espectroscopia infrarroja, y sugirió que allí se encontraba una nube de polvo, probablemente causada por colisiones entre cometas.[114]​[115]​ Del mismo modo, en 2004 se observa la presencia de una nube de polvo alrededor de la enana blanca G29-38, que posiblemente se formó a causa de la disgregación por fuerzas de marea de un cometa que transitó muy cerca de la enana blanca.[116]​
Ha habido también autores que han sugerido que las enanas blancas podrían estar acompañadas por los restos de planetas de tipo terrestre, los cuales habrían sobrevivido a la fase de gigante roja pero perdiendo sus capas exteriores y sólo quedando su núcleo;[117]​ posteriores estudios de la abundancia en metales de las atmósferas de las enanas blancas refuerzan esta idea y sugieren que al menos un 15% de estos objetos pueden tener planetas y/o asteroides orbitándolas,[118]​ ó al menos los mencionados restos de tales cuerpos, lo que también implica que al menos un 3,5% de las estrellas de espectro A y F pueden tener sistemas planetarios.[119]​
Si una enana blanca se encuentra en un sistema binario con una compañera, pueden ocurrir varios fenómenos:
La masa de una enana blanca aislada y sin rotación no puede sobrepasar el límite de Chandrasekhar de 1,4 masas solares, aunque este límite aumenta ligeramente si la enana blanca rota velozmente sobre su eje.[120]​ Sin embargo, las enanas blancas que forman parte de los sistemas binarios pueden acretar material de su compañera, normalmente una gigante roja, aumentando así tanto en masa como en densidad. Una vez que la masa ha alcanzado el límite de Chandrasekhar, los electrones ya no son capaces de sostener la estrella, lo cual aumenta la presión, lo que dispara la temperatura hasta iniciar una fusión en el núcleo de la enana que produzca una ignición explosiva, o colapsa formando una estrella de neutrones.[46]​ Según el modelo más común de formación de las supernovas de tipo Ia, una enana blanca de carbono y oxígeno acreta material de una compañera,[47]​ aumentando así su masa y compactando su núcleo. El calor del núcleo permite iniciar la reignición del carbono cuando la masa supera el límite de Chandrasekhar.[47]​ Las enanas blancas, como contrarrestan la gravedad mediante la presión de degeneración en vez de la presión térmica, al añadirles calor aumentan la temperatura pero no la presión, por lo que la enana blanca no se expande. En lugar de eso, la temperatura acelera la velocidad de fusión de la estrella. La llama termonuclear consume gran parte del carbono de la enana blanca en escasos segundos, causando una explosión de supernova de tipo Ia que acaba por destruir la estrella y expulsando su masa a velocidades cercanas a los 10.000 km/s, disipando grandes cantidades de polvo y gas.[3]​[47]​[121]​ Pero éste no es el único mecanismo válido para la formación de las supernovas de tipo Ia, si dos enanas blancas de carbono y oxígeno que conforman un sistema binario colisionan y se fusionan, formando un cuerpo de masa superior al límite de Chandrasekhar, el carbono puede iniciar su combustión, causando la explosión.[47]​, p. 14.
Cuando, a pesar de la acreción de material, la masa no alcanza el límite de Chandrasekhar, el hidrógeno acretado que se encuentra en la superficie puede inflamarse dando lugar a una explosión termonuclear. Como el núcleo de la enana blanca no sufre los efectos de dichas explosiones, la enana puede seguir acretando hidrógeno y continuar explosionando. Este fenómeno cataclísmico recibe el nombre de nova. También se han observado novas enanas, las cuales tienen picos de luminosidad más débiles que las novas propiamente dichas. Estos fenómenos no son producidos por fusión nuclear, sino que se deben a la energía potencial gravitatoria que se produce durante la acreción de material. En general, una estrella variable cataclísmica se refiere a cualquier sistema binario en el que una enana blanca acrete materia de una compañera. Aparte de las novas y de las novas enanas, se conoce multitud de clases diferentes de estrellas variables.[3]​[47]​[122]​[123]​ Se ha demostrado que las estrellas variables cataclísmicas, tanto por acreción como por fusión, son fuentes de rayos X.[123]​
En 2011 se sugirió que las enanas blancas de temperaturas superficiales inferiores a 10.000 Kelvin podrían tener una zona habitable que se extendería entre 0,005 y 0,02 unidades astronómicas y cuya duración sería de 3.000 millones de años, proponiéndose buscar alrededor de enanas blancas planetas de tipo terrestre que pudieran orbitar allí bien tras migrar desde órbitas exteriores, bien formándose allí; debido a que las enanas blancas tienen tamaños similares a los de dichos cuerpos, los tránsitos que pudieran producir tales hipotéticos planetas producirían eclipses importantes;[124]​ estudios posteriores, sin embargo, proponen que un planeta orbitando una enana blanca a una distancia tan escasa estaría sujeto, entre otros efectos, a fuerzas de marea causadas por su estrella, que podría producir en éste un efecto invernadero intenso volviéndole inhabitable y siendo más difícil que fueran habitables.[125]​ Otro problema con esta teoría es que, dejando aparte que un planeta pudiera formarse en un disco de acreción alrededor de una enana blanca, para llegar a una órbita tan cerrada solamente podría conseguirlo de dos maneras: ser absorbido por su estrella durante la fase de gigante roja y sobrevivir a su caída en espiral hacia el núcleo estelar (muy difícil para cuerpos de baja masa), o siendo enviado a ella tras interacciones gravitatorias con otros cuerpos (en cuyo caso se desprendería tal cantidad de energía orbital en calor que es muy posible que el planeta acabara convertido en un rescoldo inhabitable)[126]​
García Senz, Domingo (1991). Inestabilidad dinámica en enanas blancas bajo acreción. Universidad de Barcelona. Publicaciones y Ediciones. ISBN 84-7875-047-9. 
García-Berro Montilla, Enrique (1991). El diagrama de fase del plasma carbono-oxígeno y la función de luminosidad de las enanas blancas. Universidad de Barcelona. Publicaciones y Ediciones. ISBN 84-7875-065-7.
Stellar remnants, S. D. Kawaler, I. Novikov, G. Srinivasan, editado por Georges Meynet y Daniel Schaerer, Berlin: Springer, 1997. ISBN 3-540-61520-2.
Black holes, white dwarfs, and neutron stars: the physics of compact objects, Stuart L. Shapiro y Saul A. Teukolsky, New York: Wiley, 1983. ISBN 0-471-87317-9.
Alvan Clark & Sons, Artists in Optics, D. J. Warner y B. A. Ariail, Willmann-Bell; 2nd English edition, 1995. ISBN 0-943396-46-8.

La energía solar espacial (en inglés Space-based solar power, SSP), término estrechamente relacionado con satélite de energía solar (en inglés Solar Power Satellite), es la conversión de energía solar adquirida en el espacio en cualquier otro tipo de energía (principalmente electricidad), la cual se puede usar en el propio espacio o bien se puede transmitir a la Tierra. Desde mediados del siglo XX se vienen usando paneles fotovoltaicos en el espacio a bordo de satélites espaciales para producir la electricidad necesaria para su funcionamiento a partir de la luz solar. La novedad del concepto de SSP reside en la idea de adquirir energía a gran escala en el espacio y transmitirla a la Tierra de forma inalámbrica para su consumo sobre la superficie del planeta.[1]​
La energía solar es una fuente de energía renovable e inagotable y por ello tiene el potencial de resolver los problemas socioeconómicos y ambientales asociados con la dependencia de los recursos fósiles y de la energía nuclear. La energía solar espacial presenta pros y contras respecto a otras fuentes energéticas, en especial respecto a su variante terrestre. El aprovechamiento de los paneles en el espacio es mucho mayor que el de los paneles terrestres, al no verse afectados por la atenuación de la radiación solar en la atmósfera terrestre ni por las fases nocturnas, si bien la energía debe transmitirse a largas distancias con las correspondientes pérdidas energéticas. Por otro lado, la energía solar espacial tendría la ventaja de estar ubicada fuera del sistema ecológico terrestre, no generando prácticamente ningún desecho una vez en funcionamiento.
Los mayores frenos al desarrollo de los sistemas de SSP son el alto coste de la puesta en órbita de los paneles y ciertos obstáculos técnicos, especialmente la baja eficiencia de las células fotovoltaicas cuando trabajan a alta temperatura y la difícil transmisión de la energía a la superficie de la Tierra. Desde que a finales del siglo XIX se sentaron las bases teóricas de la tecnología fotovoltaica, el desarrollo de todas las tecnologías involucradas ha sido notorio. En la primera década del siglo XXI, equipos de investigadores europeos, estadounidenses y japoneses siguen trabajando para hacer esta tecnología posible algún día.
Para la SSP se han propuesto varias aplicaciones posibles así como diversas opciones tecnológicas, como por ejemplo el tipo de satélite o la frecuencia de emisión de la energía a la Tierra. Igualmente, incógnitas como los posibles efectos medioambientales de la transmisión de energía a la Tierra, la esperanza de vida de los paneles en el espacio, el tiempo de retorno energético o el papel que podría jugar la Luna siguen sin una respuesta clara.
Los estudios realizados en el siglo XIX por Michael Faraday, James Clerk Maxwell, Nikola Tesla y Heinrich Hertz sobre inducción electromagnética, fuerzas eléctricas y ondas electromagnéticas, y sobre todo los de Albert Einstein en 1905, proporcionaron la base teórica al efecto fotoeléctrico, que es el fundamento de la conversión de energía solar a electricidad.
Este efecto había sido reconocido empíricamente por primera vez en 1839 por el físico francés Alexandre-Edmond Becquerel, pero no sería hasta 1883  cuando Charles Fritts construyera la primera célula solar, recubriendo una muestra de selenio semiconductor con un pan de oro para formar el empalme. Este primitivo dispositivo presentaba una eficiencia de sólo un 1%.[2]​
La era moderna de la tecnología fotovoltaica no llegó hasta el año 1954 cuando los Laboratorios Bell descubrieron, de manera accidental, que los semiconductores de silicio dopado con ciertas impurezas eran muy sensibles a la luz. La producción industrial a gran escala de paneles fotovoltaicos comenzó en la década de los 80.
En 1903 Konstantin Tsiolkovsky publica “La exploración del espacio cósmico mediante dispositivos de reacción” (del ruso: Исследование мировых пространств реактивными приборами), lo que podría considerarse como el primer tratado académico sobre cohetes.[3]​ Tsiolkovsky llegó a la conclusión de que para alcanzar la velocidad de escape de la Tierra sería necesario un cohete multifase (con varios módulos de propulsión) con combustible de oxígeno e hidrógeno líquido.[4]​ Se le considera el creador de los vuelos espaciales tripulados[5]​ y el primero en concebir el ascensor espacial.[6]​ Publicó 500 trabajos sobre viajes espaciales y temas relacionados. Entre esos trabajos se encuentran diseños de cohetes con rotores directores, estaciones espaciales y cabinas despresurizadas.[7]​
En 1928 Herman Potočnik publicó su único trabajo “El problema del viaje espacial – El motor cohete” (del inglés The Problem of Space Travel - The Rocket Motor), en el que describió una hoja de ruta para lograr un gran avance en la carrera espacial. Concibió una estación espacial al detalle y calculó su órbita geoestacionaria.[8]​[9]​
En 1945 Arthur C. Clarke publicó el artículo “Mundo inalámbrico” (del inglés Wireless World) en el que concibió la posibilidad del uso de satélites de comunicaciones a gran escala, destacando su potencial en materia de comunicaciones. También sugirió que tres satélites bastarían para cubrir todo el globo terrestre.[10]​
La primera aplicación importante de células solares en el espacio fue la fuente auxiliar energética del satélite estadounidense Vanguard I, lanzado al espacio en 1958 (hoy en día el satélite más antiguo aún en órbita), que le permitió seguir transmitiendo durante siete años mientras que las baterías químicas se agotaron en solo 20 días.[11]​ Desde final de los años 60 la energía solar se ha consolidado como fuente para el suministro energético propio de los satélites.[12]​[13]​
La carrera espacial tuvo lugar durante la guerra fría entre la Unión Soviética y los Estados Unidos de América, y se inició con el lanzamiento del Sputnik 1 por parte de los soviéticos en 1957.[14]​ La década de los años 60 y parte de los 70 se vio marcada por los continuos hitos en la aventura espacial, que supusieron no sólo un potencial para la industria armamentística, sino también un arma propagandística. El lanzamiento del Sputnik 1 tuvo su continuidad con el lanzamiento de seres vivos. La perra Laika, a bordo de la nave soviética Sputnik 2 en 1957, fue el primer animal célebre en órbita. Pero no sería hasta 1960 cuando los soviéticos consiguieran por primera vez regresar a los animales con éxito de vuelta a la Tierra. Poco más tarde en 1961 Yuri Gagarin se convertiría en el primer cosmonauta lanzado en órbita. Pero el logro más importante en la historia de la aventura espacial lo consiguieron los estadounidenses con el alunizaje de la nave Apolo 11 capitaneada por Neil Armstrong en 1969, que se convirtió así en el primer humano en pisar suelo extraterrestre.
En 1968 el estadounidense Peter Glaser introdujo el concepto de un gran sistema de satélites receptores de energía solar en la órbita geosíncrona (situada a 36.000 km del ecuador) para la adquisición y conversión de energía proveniente del Sol y su transmisión posterior a grandes antenas receptoras situadas en la Tierra para satisfacer el consumo energético. Así nació el concepto de energía solar espacial.[15]​[16]​
En la década de 1970, tras la primera crisis del petróleo, el Departamento de Energía de los Estados Unidos y la NASA (agencia espacial de este mismo país) iniciaron el estudio del concepto de energía solar en el espacio. En 1979 propusieron una flota de satélites en órbita geoestacionaria, cada uno de los cuales mediría 5 x 10 km y produciría entre 5 y 10 GW. La construcción implicaba la creación de una gran factoría espacial donde trabajarían continuamente cientos de astronautas. Este gigantismo era típico de una época en la que se proyectaba la creación de grandes ciudades espaciales. Aparte de las dificultades técnicas, la propuesta fue desechada en 1981 por implicar un coste disparatado.[17]​
A mediados de los 80, con el petróleo de nuevo en precios bajos, el programa completo de energía solar espacial fue cancelado.[18]​
A finales de la década de 1980 comenzaron en Japón las actividades de investigación sobre energía solar espacial. Destacó en particular el programa "SPS 2000".[17]​
Entre 1995 y 1997 la NASA lanzó un nuevo estudio sobre la energía solar espacial y la tecnología necesaria para su implementación, encontrando que muchas de las tecnologías implicadas habían experimentado grandes avances desde la década anterior.[18]​ Se propusieron nuevos conceptos de satélites de capacidad más reducida como la "Torre Solar" (100 a 400 MW) o de diseño modular como el "Disco Solar".[17]​ En 1998 realizó otro estudio para definir el concepto de energía solar espacial identificando tanto los conceptos económicamente viables como los posibles riesgos.[19]​
En 1999 la NASA lanzó su “Programa exploratorio de investigación y tecnología sobre energía solar espacial” (del inglés Space Solar Power Exploratory Research and Technology program, SERT) con los objetivos de crear diseños para determinados conceptos de ensayo de vuelo, evaluar la viabilidad técnica, el diseño y los requisitos necesarios, crear diseños conceptuales de subsistemas que harían uso de esta tecnología para la mejora de futuras aplicaciones terrestres y espaciales, crear un plan preliminar de acción para los EE. UU. (y socios internacionales) para acometer una iniciativa tecnológica ambiciosa y crear hojas de ruta para el desarrollo tecnológico así como experimentos sobre componentes críticos de la energía solar espacial.[18]​
Algunas de las conclusiones del SERT fueron que la demanda global de energía continuaría creciendo durante décadas dando lugar a la construcción de numerosas centrales eléctricas. El impacto medioambiental de esas futuras centrales, así como su impacto en el abastecimiento mundial de energía y las relaciones geopolíticas, puede ser problemático mientras que las energías renovables son una alternativa convincente desde el punto de vista ético y tecnológico. Sin embargo, muchas fuentes de energía renovables se ven limitadas en su potencial porque precisan de recursos como el viento, la lluvia o el terreno. El estudio de viabilidad del concepto de energía solar espacial concluyó que se trata de una opción a considerar porque posee ventajas medioambientales en comparación con otras soluciones alternativas y las inversiones necesarias no representan el coste incalculable que podría haberse imaginado a priori. Según el estudio, la viabilidad económica de los sistemas de energía solar espacial dependerá del desarrollo de nuevas tecnologías, especialmente de la posibilidad de acceder al espacio a un coste reducido.[1]​
Los avances tecnológicos recientes han contribuido a hacer más factible la energía solar espacial. Por ejemplo, la eficiencia de las células fotovoltaicas ha aumentado significativamente[20]​ y se han producido avances en la transmisión de microondas. Sin embargo algunas de las tecnologías necesarias no están aún maduras y aún estamos lejos del equilibrio económico entre el beneficio y los costes.[21]​
La Estación Espacial Internacional (ISS, del inglés International Space Station), podría ser el primer campo de pruebas para este concepto, a pesar de encontrarse situada en una órbita baja terrestre. [cita requerida]
Los EE. UU. han sido los pioneros en energía solar espacial y han gastado unos 80 millones de dólares en su estudio. A finales de la primera década del siglo XXI no existe ningún programa público dedicado a este tema, quizás porque la SSP se encuentra en la frontera entre el campo del espacio (responsabilidad de la NASA) y el de la energía (responsabilidad del Departamento de Energía).[22]​
En octubre de 2007 la “Oficina Nacional de Seguridad Espacial” (National Security Space Office), una agencia del Departamento de Defensa, publicó un nuevo estudio general sobre la SSP, prestando atención a aspectos no considerados anteriormente como por ejemplo las posibles aplicaciones militares de la tecnología.[22]​ Las fuerzas armadas estadounidenses pagan su electricidad en zona de guerra a un precio muy alto (1 dólar/kWh en 2007), mucho mayor que el coste normal de la electricidad en EE. UU. Por ello podrían representar un primer mercado para la SSP.[22]​
La Agencia Espacial Europea (ESA) también ha estado estudiando el concepto de SSP en los últimos años, en parte en colaboración con Japón. La fase inicial, el estudio de viabilidad de diferentes soluciones, concluyó en 2004. La segunda fase comenzó en 2006 y comprende la identificación de áreas tecnológicas que requieren avances para que el concepto de SSP sea posible, así como su prioritización.[21]​
La JAXA, agencia espacial japonesa, se ha fijado el objetivo de poner en órbita un satélite SSP de 1 GW antes de 2030. Los científicos japoneses están investigando principalmente la transmisión inalámbrica de energía, tanto por microondas como por láser.[23]​
La energía solar (insolación total global) que llega a la superficie de la tierra consiste en luz directa y difusa.[24]​ 
Cuando la radiación solar alcanza la atmósfera, el 6% es reflectado y el 16% absorbido. Las diversas condiciones atmosféricas (nubes, polución, polvo, etc.) reducen la radiación solar en un 20% adicional debido a la reflexión y un 3% adicional por absorción. Estas condiciones atmosféricas no solo reducen la cantidad de energía que llega a la Tierra sino que también hacen difusa aproximadamente el 20% de la luz y filtran porciones de su espectro electromagnético.[25]​ 
Tras cruzar la atmósfera, aproximadamente la mitad de la radiación solar se encuentra en el espectro electromagnético visible mientras que la otra mitad se encuentra en el espectro infrarrojo (una pequeña porción es radiación ultravioleta). Debido a los efectos atmosféricos mencionados solo entre un 10% y un 13% del total de la energía que llega a la Tierra se puede aprovechar. En datos absolutos esto supone aproximadamente 0,1-0,2 kW/m².
La energía solar presenta una serie de ventajas y desventajas frente a otras fuentes energéticas que se explotan en la Tierra. 
Las ventajas principales son que no emite gases contaminantes a la atmósfera (salvo durante su fabricación, transporte e instalación); es una fuente energética inagotable a diferencia de los combustibles fósiles; puede adquirirse en casi cualquier parte del planeta sin necesidad de conexiones a otras redes energéticas, permitiendo así la creación de islas energéticas y realiza una contribución despreciable a la contaminación acústica a diferencia, por ejemplo, de los aerogeneradores.
Por otro lado, las principales desventajas de esta tecnología con respecto a otras son que el coste de inversión inicial es elevado; sólo es posible adquirir energía durante las horas de luz y su rendimiento se ve reducido por las condiciones meteorológicas o por la polución existente.[26]​
La energía solar extraterrestre es aquella que se adquiere fuera de la atmósfera de la Tierra. Gracias a la ausencia de gases atmosféricos o formaciones de nubes, en el espacio cercano a la tierra la radiación solar es un 35% superior a la que alcanza la superficie terrestre.[27]​
Además, seleccionando la órbita adecuada se puede conseguir luz solar aproximadamente el 96% del tiempo. Por ello un panel fotovoltaico en una órbita terrestre geoestacionaria (a una altitud de 36.000 km) recibiría una media de ocho veces más luz que en la superficie de la Tierra,[28]​[29]​ e incluso mayor a medida que el lugar de adquisición se aproxime al Sol (si bien los problemas de mantenimiento son también mayores por el incremento de la radiación solar).[28]​ Una ventaja adicional es el hecho de que en el espacio no existen problemas de peso o de corrosión atmosférica.
Por otro lado, la gran desventaja a día de hoy (2008) es su elevado coste, tal y como se detalla más abajo. Otra desventaja es el hecho de que la transmisión de la energía para consumo en la superficie de la Tierra originaría unas pérdidas energéticas de al menos 40-50%, con lo cual la cantidad de energía solar recuperada efectivamente sería solo entre 3 y 4 veces superior a la adquirida en la Tierra.[21]​
Los sistemas para la adquisición de energía solar espacial han de estar situados a una distancia de la Tierra superior a la órbita baja terrestre ya que las órbitas más cercanas son impracticables debido a la fuerza de atracción de la Tierra. La tecnología fotovoltaica podría emplearse para la conversión energética y las microondas o el láser para la transmisión inalámbrica desde el espacio. En la primera década del siglo XXI también se investiga sistemas termodinámicos de energía solar.[30]​ 
Los sistemas de conversión y transmisión de la energía solar podrían colocarse en satélites en órbitas geosíncronas y heliosíncronas (órbitas siempre encarando al Sol), sondas espaciales, la Luna u otros planetas.[31]​
Una célula fotoeléctrica es un dispositivo electrónico que permite transformar la energía lumínica (fotones) en energía eléctrica (electrones) mediante el efecto fotoeléctrico. Las células fotoeléctricas se agrupan en paneles fotovoltaicos que incluyen además circuitos para evacuar la electricidad producida. Habitualmente se asume que en la SSP la conversión de la energía solar en electricidad se realizaría mediante paneles fotovoltaicos. 
El esfuerzo de investigación que se viene llevando a cabo en esta disciplina ha resultado en un aumento continuo de la eficiencia a la vez que se reducían significativamente los costes. 
Hoy en día la tecnología más extendida es la que se conoce como de primera generación, que es una gran superficie de cristal simple con unión diodo p-n, capaz de generar energía eléctrica a partir de fuentes de luz con longitudes de onda similares a las que llegan a la superficie de la Tierra provenientes del Sol.[32]​
La segunda generación la constituyen las llamadas células de película delgada. Están basadas en el uso de finos depósitos epitaxiales de semiconductores sobre obleas en forma de malla diagonal. Hay dos tipos de de células fotovoltaicas, espaciales y terrestres. Las espaciales cuentan normalmente con una mayor eficiencia AM0 (Air Mass Zero) (28-30%), pero también mayores costes por vatio. Las terrestres, por otro lado, se fabrican con menores costes, pero también son menos eficientes (7-9% de eficiencia AM0). En el año 2008 había diferentes materiales con esta tecnología en producción o bajo investigación, ej. silicio amorfo (a-Si), diseleniuro de cobre e indio (CuInSe2), telururo de cadmio (CdTe), silicio policristalino y silicio microcristalino. Una de las ventajas de la tecnología ultrafina es su teorético peso, que sería reducido, permitiendo su colocación sobre materiales flexibles o ligeros, incluso sobre textiles. Esta segunda generación de células fotovoltaicas comprende un pequeño segmento del mercado terrestre, pero aproximadamente el 90% del espacial. El resto del mercado son células de la primera generación.
En la primera década del siglo XXI se trabaja en una tercera e incluso una cuarta generación de células. Las de tercera generación son muy diferentes de los dispositivos semiconductores de las generaciones anteriores, ya que realmente no presentan la tradicional unión p-n para separar los portadores de carga fotogenerados. Para aplicaciones espaciales, se están estudiando dispositivos de huecos cuánticos y dispositivos que incorporan nanotubos de carbono, con un potencial de más del 45% de eficiencia AM0. Para aplicaciones terrestres, se encuentran en fase de investigación dispositivos que incluyen células fotoelectroquímicas, células solares de polímeros, células solares de nanocristales y células solares de tintas sensibilizadas.[32]​
Una hipotética cuarta generación de células solares consistiría en una tecnología fotovoltaica compuesta en las que se mezclan, conjuntamente, nanopartículas con polímeros para fabricar una capa simple multiespectral. Posteriormente, varias capas delgadas multiespectrales se podrían apilar para fabricar las células solares multiespectrales definitivas, reduciendo así costes y aumentando la eficiencia.[32]​ La primera capa es la que convierte los diferentes tipos de luz, la segunda es para la conversión de energía y la última es una capa para el espectro infrarrojo. De esta manera se convierte algo del calor en energía aprovechable. El resultado es una excelente célula solar compuesta.
La investigación de base para esta cuarta generación se está supervisando y dirigiendo por parte de la Agencia para los Proyectos de Investigación Avanzada para la Defensa, es la organización central para la investigación y desarrollo del Departamento de Defensa (DoD) de EE. UU. (Defense Advanced Research Projects Agency) con el objetivo de determinar si esta tecnología es viable o no.[33]​
Las células fotovoltaicas utilizadas en el espacio han de cumplir con características diferentes de las de las células utilizadas hasta ahora en la Tierra, por lo que suelen tener un coste mayor. Debido a los altos costes de transporte al espacio, un factor muy importante es la energía específica (es decir, la energía generada dividida por la unidad de masa). 
La masa total del sistema de generación eléctrica es un aspecto importante. En los sistemas de la primera década del siglo XXI el peso del sustrato fotovoltaico es solo un cuarto del total mientras que la estructura del panel y los sistemas de control y distribución representan los restantes tres cuartos (excluyendo el almacenamiento de energía). Esta razón de tres cuartos aumenta si se incluye el sistema de conversión y transmisión de energía eléctrica en microondas.
Las células "ultrafinas" son muy flexibles y por ello más adecuadas para la construcción de paneles flexibles o semiflexibles capaces de desenrollarse o inflarse. De esta forma se consiguen importantes reducciones de volumen y peso. En la década de 1980 se dedicó mucho esfuerzo al desarrollo y comercialización de células fotovoltaicas ultrafinas para uso terrestre. La idea de este concepto es depositar láminas finas de material fotovoltaico sobre un substrato. Este método produce células con un rendimiento de conversión menor pero, gracias a la baja cantidad de material activo usado, cuenta con una energía eléctrica específica más alta.
Además de una masa reducida, se espera que las células fotovoltaicas ultrafinas tengan un coste sensiblemente menor, gracias a la reducida cantidad de material necesario y a que los costes de elaboración son menores. El uso de una capa de material ultrafino fotovoltaico depositado en un substrato flexible es por ello una opción a tener en cuenta.
Otra alternativa es el uso de un sistema concentrador que enfoque la luz en pequeñas células solares de alta eficiencia. Esta alternativa se ha ensayado en el espacio pero solo a pequeña escala. Usando concentradores se ha llegado a cifras de eficiencia en torno al 30% del potencial total de adquisición.[34]​ Esta solución no es sin embargo adecuada para planetas como Marte ya que en ellos la mayor parte de la luz solar es difusa y el sistema concentrador solo puede enfocar el componente directo de la radiación solar.[35]​
Para transmitir la electricidad captada por el satélite a la Tierra, se transformaría la energía en una radiación electromagnética de una longitud de onda adecuada para no ser absorbida por la atmósfera terrestre. Los dos tipos de radiaciones considerados hasta ahora son las microondas y el láser.[23]​ Los ensayos de radiación de energía a gran escala parecen imprescindibles para el desarrollo de la energía solar espacial y esta tecnología ha sido identificada como uno de los grandes retos para la industrialización del espacio.[27]​ Un aspecto clave a la hora de transmitir energía a gran distancia son las considerables pérdidas energéticas, tanto por absorción del entorno en forma de calor, así como por dispersión a lo largo de la trayectoria.[36]​
William C. Brown demostró en 1964 en la televisión estadounidense, cómo un helicóptero sin energía propia se mantenía en vuelo gracias a la energía que le era transmitida por microondas. Entre 1969 y 1975 Bill Brown fue el director técnico de un proyecto que llegó a radiar 30 kW a través de una distancia de algo más de 1,5 km con una eficiencia del 84%.[37]​
En 1973 el estadounidense Peter Glaser consiguió una patente por su método para la transmisión de energía a larga distancia (ej. desde el espacio) usando microondas desde un satélite con una antena de un diámetro estimado de 1 km hacia una antena de tamaño mucho mayor situada en la superficie de la Tierra a la que se denomina rectenna, abreviatura en inglés de antena rectificadora[38]​[39]​ (usada precisamente para la conversión directa de microondas en electricidad).[21]​[40]​
Los riesgos medioambientales asociados a la transmisión de energía por microondas son un tema controvertido. Es injustificado pensar que lo que se interponga en el camino de una radiación será incinerado, pues microondas similares se han venido utilizando de forma global por compañías de telecomunicaciones.[41]​[42]​ En la superficie de la Tierra la intensidad máxima de tales radiaciones de microondas podría llegar a un máximo en el centro de 23 mW/cm2, que es menos que la cuarta parte de la constante de irradiación solar.[43]​ Sin embargo, los partidarios de la SSP reconocen que se necesitan aún estudios para asegurarse de que el haz de microondas no dañe la flora y la fauna de la zona alrededor de la rectenna ni interfiera con los instrumentos de navegación de los aviones que, por error, se crucen en su camino.[27]​
Unos investigadores de la NASA trabajaron en la década de 1980 con la posibilidad de usar láseres para la radiación de energía entre dos puntos del espacio, concentrándose en el desarrollo de láseres basados en energía solar. En 1989 se sugirió que la radiación de energía de la Tierra al espacio también sería de utilidad. En 1991 se inició el proyecto SELENE (del inglés SpacE Laser ENErgy, “Energía Láser Espacial”), que comprendía, entre otras cosas, un estudio de radiación de energía por láser a una base lunar.
En 1988 Grant Logan propuso el uso de un láser colocado en la Tierra para proveer de energía a un rotor director para la propulsión espacial, proveyendo una serie de detalles técnicos en 1989. Pero su propuesta fue algo optimista en lo referente a la tecnología ya que propuso el uso de células solares de diamante operando a 300°C para convertir la luz láser ultravioleta, una tecnología que aún no ha podido ser demostrada en laboratorio, y a una longitud de onda que tendría problemas para atravesar la atmósfera. El proyecto SELENE continuó trabajando sobre este concepto pero con una tecnología más cercana a la práctica,[44]​ hasta que fue cancelado de forma oficial en 1993 tras dos años de investigación sin cumplir con la meta de realizar ensayos en el espacio, debido a los elevados costes de implementación.[44]​
Desde el nacimiento del concepto de SSP se han propuesto diversos diseños de satélites para alojar en órbita los módulos fotovoltaicos y la antena emisora.
El primer estudio importante de la NASA sobre la energía solar espacial (1976-1980) condujo a la formulación del denominado "Sistema SPS de Referencia 1979". Consistía en una gran estructura paralelepipédica de 5 x 10 x 0,5 km sobre la que se colocarían paneles fotovoltaicos. En su parte inferior se ubicaría la antena emisora, de 1 km de diámetro, que radiaría unos 5 GW de energía hacia la Tierra.[17]​
El estudio proponía la instalación en órbita geoestacionaria de 60 satélites de entre 5 y 10 GW cada uno. Para ello sería necesaria la construcción de una factoría espacial en una órbita de baja altitud en la que se ensamblarían módulos prefabricados lanzados desde tierra.[17]​
El concepto de Sun Tower ("Torre solar") fue propuesto en 1997 por la NASA. Consiste en una estructura lineal de unos 15 km de longitud a la que se enganchan parejas de módulos fotovoltaicos de 1 MW cada uno. En el extremo inferior de la estructura, que apunta a la Tierra, se sitúa la antena emisora, de unos 250 m de diámetro. La potencia total radiada por el sistema rondaría los 250 MW a una frecuencia de 5,8 GHz.[17]​
La propuesta preveía una constelación de torres solares que se ubicarían en una órbita heliosíncrona cercana a la Tierra (no geosíncrona). Irían radiando la energía a una red de antenas receptoras repartidas sobre la superficie del planeta, cada una de unos 4 km de diámetro.[17]​
El centro de investigación alemán DLR ideó en 1999 para la ESA (Agencia Espacial Europea) un satélite SSP llamado Sail Tower ("Torre de velas") y que se parece bastante al Sun Tower estadounidense. Consistía en una estructura lineal de 15 km de largo en la que se engancharían 60 pares de "velas", en realidad paneles solares de película delgada, de forma cuadrada y 150 m de lado. El satélite se colocaría en órbita geoestacionaria y captaría unos 450 MW, que serían radiados a la Tierra por una antena de 1 km de diámetro. La rectenna correspondiente tendría 10 km de diámetro.[45]​
Este concepto, también ideado por la NASA en 1997, consiste en un disco plano cubierto de módulos fotovoltaicos que rota sobre sí mismo a razón de una vuelta por hora. El centro del disco recibe toda la electricidad generada y está conectado mediante dos estructuras simétricas a una antena emisora que apunta a la Tierra. La antena gira también sobre sí misma a una vuelta por día en un eje perpendicular al eje de giro del disco.[17]​
La estructura del disco sería modular, de tal manera que el sistema pudiese comenzar con un tamaño y una capacidad de generación modestos para ir creciendo hasta unos 6 km de diámetro y generar unos 8 GW. El satélite se colocaría en órbita geoestacionaria y necesitaría una sola estación receptora de también unos 6 km de diámetro. La NASA estimó que el coste de un Disco Solar sería unas cinco veces inferior al del diseño de 1979, para la misma potencia generada.[17]​
El Sandwich Satellite ("Satélite Bocadillo") de SSP se estructuraría en tres partes: 1) un gran sistema de espejos que capta la luz solar y la redirige hacia una plataforma; 2) un conjunto de paneles fotovoltaicos ubicados sobre el lado iluminado de la plataforma y 3) una antena emisora colocada en el lado en sombra de la plataforma.
La ventaja de este sistema reside en que la electricidad generada tendría que recorrer una distancia muy corta, de pocos centímetros, entre las células fotovoltaicas y la antena emisora, lo cual mejoraría el rendimiento. Además se presta a un diseño modular que podría permitir una producción económica.[27]​
Según un estudio norteamericano de 2008, existen cuatro grandes retos tecnológicos que la SSP debe vencer para poder ser viable:[27]​
Tanto las células fotovoltaicas como los componentes electrónicos de las antenas emisoras han visto su rendimiento mejorar sensiblemente en las últimas décadas. Sin embargo, todos ellos funcionan peor o no funcionan en absoluto a altas temperaturas.
La refrigeración de un satélite espacial es complicada porque al encontrarse más allá de la atmósfera no existe enfriamiento por convección, debiéndose evacuar todo el calor mediante radiadores. Un satélite SSP que estuviese expuesto continuamente al Sol alcanzaría por ello una temperatura de equilibrio sensiblemente más alta que una instalación fotovoltaica terrestre. Para conservar una eficiencia razonable es necesario por tanto desarrollar células y sistemas electrónicos resistentes a altas temperaturas.[27]​
La transmisión de energía entre el satélite y la rectenna en tierra plantea problemas de seguridad aún no resueltos. El haz de energía debe apuntar sólo a la rectenna, sin desviarse sobre otras zonas. También deben idearse sistemas que eviten interferencias con las aeronaves que puedan cruzarse en el camino del haz, así como realizar estudios para asegurarse de la ausencia de efectos nocivos de las microondas o del láser sobre la salud y el medio ambiente.[27]​
Por otro lado, la viabilidad económica de los sistemas SSP requiere que las estaciones de recepción sean lo más pequeñas posible. Para ello existen dos medios: aumentar el diámetro de la antena emisora o aumentar la frecuencia de la radiación transmitida. Sin embargo, una antena emisora mayor implica mayor peso a poner en órbita y una frecuencia más alta conduce a menores eficiencias de transmisión. También hay que tener presente que una radiación de frecuencia muy alta se convierte en ionizante, pudiendo generar trastornos ecológicos o biológicos al alcanzar la Tierra. En la primera década del siglo XXI no existe una solución clara a este problema, barajándose la posibilidad de repartir la energía de cada satélite entre varias estaciones receptoras simultáneamente.[27]​
Tradicionalmente, los sistemas espaciales (naves, satélites, misiones de exploración) han sido diseñados como obras de ingeniería únicas y muy complejas, con un coste económico muy alto.[27]​ Un ejemplo paradigmático es la Estación Espacial Internacional, cuyo coste total se estima en unos 100.000 millones de dólares incluyendo los costes de operación durante 10 años.[46]​ De este total, unos 35.000 millones corresponden al coste de los materiales y equipos.[27]​
Para rebajar el coste de los satélites de SSP se ha propuesto la idea de construirlos uniendo una gran cantidad de módulos pequeños e idénticos entre sí, que podrían ser fabricados en masa a bajo coste. El ensamblaje de los módulos y su mantenimiento serían dirigidos por un programa de inteligencia artificial instalado en el propio satélite, con lo que se minimizaría la necesidad de astronautas para la construcción y la operación del sistema.[27]​
En 2006 poner en órbita geoestacionaria un kilo de carga costaba entre 8.000 y 24.000 dólares (6.500 - 20.000 euros al cambio de 2006).[47]​ Sin embargo, se estima que haría falta reducir los costes a unos 600 a 700 €/kg para que las grandes estaciones de SSP empezasen a ser competitivas con la electricidad fotovoltaica terrestre.[21]​
Los altos costes en la primera década del siglo XXI se deben a varias causas. En primer lugar hace falta una gran inversión inicial. Por ejemplo, el desarrollo del cohete europeo Ariane 5 costó 6.000 millones de euros.[48]​ La inversión inicial se amortiza entre el número de misiones que se realicen: cuanto más se utilice el sistema, más barato resultará cada vuelo. Si la SSP se desarrollase, requeriría un gran número de lanzamientos, con lo que puede imaginarse que los costes bajarían.[27]​
Otra razón por la que los lanzamientos en la primera década del siglo XXI son muy caros es el hecho de que el cohete es de un solo uso, destruyéndose durante la misión. Un sistema reutilizable podría rebajar sustancialmente los costes. Por último, también resulta muy caro el personal (numeroso y muy cualificado) que opera las infraestructuras de lanzamiento.[27]​
La NASA realizó a finales de los años 1990 un estudio sobre los sistemas de lanzamiento reutilizables en el que se compararon varios diseños conceptuales que permitirían reducir los costes de lanzamiento a unos 500 dólares por kg. Entre los conceptos de mayor aceptación figuraron los motores ramjet (y derivados como el scramjet) así como la idea de suministrar el primer impulso a las naves mediante sistemas de aceleración terrestres.[49]​[50]​
Un concepto de propulsión terrestre es el denominado MagLifter, que consiste en una plataforma horizontal sobre la que se instalaría el transbordador espacial o alguna otra nave reutilizable con forma de avión. Mediante un sistema de propulsión magnética similar al de los trenes de levitación magnética el MagLifter se aceleraría hasta una velocidad de 885 km/h. En ese momento el transbordador encendería sus motores y despegaría. Este concepto, inspirado de las catapultas utilizadas en los portaaviones para facilitar el despegue de los aviones, eliminaría la necesidad de cohetes para el lanzamiento, que, además de no ser reutilizables, aumentan de forma muy importante el peso que debe ser levantado del suelo en el momento del despegue.[51]​
Otro concepto similar pero más extremo es el Star Tram: un tubo de 1500 km de longitud que estaría colocado en la superficie terrestre en sus 1300 km iniciales y levitando magnéticamente sobre el suelo de forma tangencial a la Tierra en sus 200 km restantes, llegando a alcanzar una altura de 22 km sobre el nivel del mar. En el interior del tubo se haría el vacío y se dispondría un sistema de levitación magnética que aceleraría la nave espacial hasta unos 29.000 km/h usando decenas de gigavatios de electricidad. Al salir del tubo la nave encendería sus motores, que la llevarían directamente a órbita. Según sus creadores, el Star Tram permitiría reducir los costes de lanzamiento a tan solo 250 $/kg.[51]​
El objetivo principal previsto para la energía solar espacial desde su invención en los años 60 es el suministro de electricidad a la Tierra a gran escala. A fin de satisfacer la demanda energética de la creciente población mundial, los diferentes estudios realizados han propuesto sistemas capaces de suministrar varios gigavatios de electricidad de forma constante, bien mediante unos pocos satélites gigantescos bien mediante constelaciones de satélites más pequeños.
En los años 2000 ha surgido además el interés por satélites SSP de menor escala, del orden de unos cuantos megavatios. Una de sus aplicaciones podría ser el suministro de electricidad a bases militares aisladas en países sin infraestructura energética. También se ha evocado la posibilidad de utilizar la SSP para suministrar electricidad de emergencia a zonas afectadas por catástrofes naturales y así facilitar las tareas de reconstrucción.[22]​
Un satélite SSP de tan solo unos 5 MW podría ser útil para el abastecimiento de unidades militares sobre un terreno de operaciones de acceso difícil. Además podría permitir el desarrollo de unidades y armas novedosas como por ejemplo aviones sin piloto de reconocimiento que podrían mantenerse indefinidamente en vuelo.[22]​
El ministerio de Defensa estadounidense estudia también la producción de combustibles sintéticos a partir de electricidad, la cual podría ser suministrada directamente a la zona de guerra mediante energía solar espacial.[22]​ Por el contrario, el Pentágono afirma que no planea utilizar los satélites SSP directamente como arma ofensiva debido a que la energía transmitida se distribuye sobre una zona amplia y por tanto el haz de microondas no tiene ni la capacidad destructiva ni la precisión de otras armas a comienzos del siglo XXI mucho más baratas como los misiles balísticos.[52]​
Además de radiar energía hacia la Tierra, los satélites SSP también podrían alimentar vehículos de exploración interplanetaria, telescopios espaciales y misiones tripuladas a Marte. Esto podría suponer una alternativa más segura que el transporte de reactores nucleares hasta el planeta rojo.[17]​ Otros sectores que podrían beneficiarse de la SSP serían el turismo espacial y los promotores de plantas industriales espaciales.[27]​
Un factor muy importante de los sistemas con la función de generar energía es el tiempo que se necesita para reponer la energía que ha sido necesaria para construirlos, incluyendo producción, lanzamiento y despliegue. A este tiempo se le denomina "tiempo de retorno energético".
En 2004 los paneles fotovoltaicos terrestres tenían un tiempo de retorno energético de entre 3 y 4 años.[53]​ Actualmente gracias a las mejoras tecnológicas se ha reducido a entre 0,5 y 1,5 años y se espera que siga reduciéndose.[54]​ En comparación, los paneles solares producidos en 2005 tendrían en el espacio un tiempo de retorno de entre 4 meses y 2 años, a pesar de la energía necesaria para el transporte fuera de la atmósfera.[21]​ A esta cifra habría que añadir el tiempo para recuperar la energía gastada en la fabricación de los paneles solares y de los otros componentes del sistema como el satélite y las antenas emisora y receptora.
La comunidad científica ha llegado a la conclusión de que, a pesar de la energía necesaria en el lanzamiento, el retorno energético es más rápido en sistemas espaciales que en sistemas terrestres.[21]​
Los satélites en órbitas geoestacionarias están situados más allá de los cinturones de Van Allen y expuestas a la radiación ionizante proveniente del Sol. Este fenómeno es especialmente acusado en períodos de alta exposición a partículas energéticas causadas por erupciones solares.[55]​
Esta carga contribuye a la reducción de la esperanza de vida de los paneles, en especial si se comparan con aquellos situados en la superficie terrestre. Este desgaste reduciría el rendimiento total al menos entre un 1-2% anual, y con ello la esperanza de vida de los paneles.[55]​ Para reducir este problema se podría diseñar algún sistema protector del satélite (salvo en la parte del panel expuesta directamente al Sol). 
Cabe también la posibilidad de que, llegado el momento, el mantenimiento del panel se realice en el espacio en lugar de relanzar un nuevo satélite. Sería factible el realizar una única misión espacial para las labores de mantenimiento de varios satélites a la vez, optimizando así los costes.
Beneficio ambiental: El posible beneficio ambiental sería importante. Para poder abastecer de energía a la creciente población del planeta se necesita una fuente limpia e inagotable de energía. Las microondas provenientes del espacio podrían calentar la atmósfera ligeramente (extremo no probado) pero la ausencia de emisiones dañinas (p. ej. CO2), que presentan otras fuentes energéticas, compensaría esa posible desventaja.
Flexibilidad y seguridad: La energía solar espacial eliminaría la necesidad de complejas redes eléctricas intercontinentales y reduciría también la cantidad de apagones, ya que una interrupción de una emisión de microondas es muy improbable. Otra ventaja es el hecho de que la fuente de energía se encontraría a una distancia de 36.000 km, haciéndolo muy inaccesible como objetivo terrorista. El sistema permitiría también intercambiar con facilidad una fuente transmisora por otra y reanudar el abastecimiento de forma inmediata en caso de interrupción.
Energía en caso de un invierno global: En esa situación la energía solar espacial podría ser la única forma de adquirir energía solar directa para complementar los combustibles fósiles, la energía nuclear y las otras energías renovables (hidráulica, eólica, geotérmica) bajo condiciones extremas, como por ejemplo en un invierno volcánico o en uno nuclear. Se cree que la erupción de alguno de los supervolcanes riolíticos existentes en unas pocas docenas de puntos calientes de la Tierra podría dar lugar a una glaciación repentina. En épocas geológicas relativamente recientes se han producido erupciones de tal escala. Entre ellas cabe destacar por partida doble la caldera de Yellowstone, en una ocasión hace 2,2 millones de años y en otra más reciente hace 640.000 años. En esta última expulsó 800 veces más materia que la despedida en 1980 por el monte Saint Helens. Las mayores erupciones conocidas fueron las de la caldera Garita en las montañas San Juan en Colorado (5 veces mayor que la caldera de Yellowstone) y la del Lago de Toba en Indonesia (3 veces mayor que la caldera de Yellowstone). Se estima que esta última erupción causó hace 75.000 años una glaciación global que pudo haber durado 1000 años y acabado con el 60% de la población global.
Costes económicos: Los costes económicos necesarios para desarrollar la SSP siguen siendo excesivamente elevados en la primera década del siglo XXI, de forma que solo serán rentables si se reducen los costes de lanzamientos al espacio; se encuentra la forma de fabricar satélites con materiales extraterrestres (ej. de la Luna); los costes energéticos convencionales se elevan drásticamente; o se renuncia al uso de los combustibles fósiles. Hasta que uno de estos extremos no sea realidad, las barreras económicas seguirán siendo un impedimento para su implementación.
Papel en el calentamiento global: La transmisión de energía desde un satélite espacial a la Tierra no se realiza con una eficiencia energética del 100%, sino de entre un 50 y un 80%.[56]​[57]​ La energía perdida se disipa en la atmósfera en forma de calor causando, en principio, un incremento de temperatura en la atmósfera. Esta afirmación es cierta pero debe ser puesta en contexto. Una central nuclear o de carbón generan un 50% más de calor que lo que se espera de la energía solar espacial. Por ello, si todas esas centrales fueran sustituidas por satélites solares el resultado sería una reducción del calentamiento global.[56]​
El subsuelo de la Luna contiene silicio y metales, que son las materias primas básicas para construir satélites SSP. Los paneles solares terrestres usan recursos terrestres, pero los satélites de energía solar podrían construirse exclusivamente con materiales lunares. Únicamente las antenas receptoras tendrían que construirse con materiales terrestres.[58]​ Enviar materiales desde la Luna hasta la órbita geosíncrona es mucho menos costoso energéticamente que propulsar materiales fuera de la gravedad de la Tierra. Estos argumentos han llevado a proponer el desarrollo experimental de las técnicas de minería lunar que permitan alimentar en el futuro la construcción de los satélites SSP en órbita.[59]​ Posteriormente, la base lunar podría proveer paneles solares para, por ejemplo, satélites, misiones a Marte y asteroides que se aproximen a la Tierra.[60]​ 
Otra opción por profundizar sería la colocación de estaciones generadoras en la Luna, la llamada “Energía Solar Lunar”, LSP (del inglés Lunar Solar Power). Colocando estaciones en puntos opuestos de la Luna y una antena emisora en la cara visible se podría enviar una corriente constante de energía hacia la Tierra.[61]​
Casi el 100% de la energía radiada por el Sol se propaga en direcciones diferentes de las que ocupa la Tierra. Quizás sea posible en un futuro lejano aprovechar de alguna forma tan vasta fuente de energía que hoy en día se pierde en el cosmos.
Se especula con que precisamente este tipo de tecnología podría ayudar en la búsqueda de vida extraterrestre, ya que se supone que una civilización avanzada podría ser capaz de hacer uso de una proporción importante de esta energía perdida de los cuerpos solares. Es muy difícil identificar planetas fuera del Sistema Solar capaces de albergar vida inteligente, pero identificando estrellas con luz modificada para aplicaciones de energía solar espacial a gran escala se podría señalar la existencia de civilizaciones extraterrestres avanzadas.[62]​
Andrzej Zwaniecki. «“Energía solar espacial tiene futuro, dicen investigadores de EE. UU.”». Archivado desde el original el 9 de julio de 2008. Consultado el 1 de julio de 2008. 
Ángel Díaz (diciembre de 2007). «EE. UU. impulsa un proyecto para obtener energía de paneles solares en el espacio». Diario el Mundo. Consultado el 1 de julio de 2008.  
Steve Price. «Energía del Espacio para el Planeta Tierra». Archivado desde el original el 1 de julio de 2008. Consultado el 1 de julio de 2008. 
Gil Knier; Dr. Tony Phillips (enero de 2002). «¿Hasta donde llega la luz solar?». Archivado desde el original el 1 de julio de 2008. Consultado el 1 de julio de 2008.  
«Energía solar espacial artículos de la NASA». Búsqueda en Google. Archivado desde el original el 29 de noviembre de 2015. Consultado el 1 de julio de 2008.
Tim Tyson (junio de 1999). «NASA Looks For New Ways to Harness Sun's Energy for Earth and Space» (en inglés). Archivado desde el original el 4 de julio de 2008. Consultado el 1 de julio de 2008.  
«Reinventing the Solar Power Satellite» (en inglés). de NASA. Archivado desde el original el 31 de octubre de 2007. Consultado el 1 de julio de 2008. 
«Space Solar Power - An Earth to Orbit Challenge» (en inglés). Archivado desde el original el 20 de julio de 2008. Consultado el 1 de julio de 2008. 
«Space-Based Solar Power Efforts» (en inglés). solarpanelinfo.com. Consultado el 1 de julio de 2008. 
Peter E. Glaser (febrero de 2000). «The World Needs Energy from Space» (en inglés). space.com. Archivado desde el original el 18 de agosto de 2000. Consultado el 1 de julio de 2008.  
«NSSO Backs Space Solar Power» (en inglés). Archivado desde el original el 6 de diciembre de 2010. Consultado el 1 de julio de 2008. 
«Conceptual Study of A Solar Power Satellite, SPS 2000» (en inglés). spacefuture.com. Consultado el 1 de julio de 2008. 
«Bringing launch costs down to earth» (en inglés). 1998. Archivado desde el original el 16 de junio de 2008. Consultado el 1 de julio de 2008. 
«Solar Energy - Photovoltaics» (en inglés). Archivado desde el original el 12 de octubre de 2008. Consultado el 20 de agosto de 2008. 
John C. Mankins (2000). «Statement of John C. Mankins Manager, Advanced Concepts Studies Office of Space Flight before the Subcommittee on Space and Aeronautics Committee on Science U.S. House of Representatives» (en inglés). Archivado desde el original el 27 de mayo de 2008. Consultado el 4 de julio de 2008. 
Steve Price (2001). «Beam it Down, Scotty!» (en inglés). Archivado desde el original el 16 de junio de 2008. Consultado el 1 de julio de 2008. 

La energía solar fotovoltaica es una fuente de energía que produce electricidad de origen renovable,[1]​ obtenida directamente a partir de la radiación solar mediante un dispositivo semiconductor denominado célula fotovoltaica,[2]​ o bien mediante una deposición de metales sobre un sustrato denominada célula solar de película fina.[3]​
Este tipo de energía se usa principalmente para producir electricidad a gran escala a través de redes de distribución, aunque también permite alimentar innumerables aplicaciones y aparatos autónomos, así como abastecer refugios de montaña o viviendas aisladas de la red eléctrica. Debido a la creciente demanda de energías renovables, la fabricación de células solares e instalaciones fotovoltaicas ha avanzado considerablemente en los últimos años.[4]​
[5]​ Comenzaron a producirse en masa a partir del año 2000, cuando medioambientalistas alemanes y la organización Eurosolar obtuvo financiación para la creación de diez millones de tejados solares.[6]​
Programas de incentivos económicos, primero, y posteriormente sistemas de autoconsumo fotovoltaico y balance neto sin subsidios,[7]​ han apoyado la instalación de la fotovoltaica en un gran número de países.[8]​ Gracias a ello la energía solar fotovoltaica se ha convertido en la tercera fuente de energía renovable más importante en términos de capacidad instalada a nivel global, después de las energías hidroeléctrica y eólica. A principios de 2017, se estima que hay instalados en todo el mundo cerca de 300 GW de potencia fotovoltaica.[9]​[10]​
La energía fotovoltaica no emite ningún tipo de polución durante su funcionamiento, contribuyendo a evitar la emisión de gases de efecto invernadero.[1]​ Su principal desventaja consiste en que su producción depende de la radiación solar, por lo que si la célula no se encuentra alineada perpendicularmente al Sol se pierde entre un 10-25 % de la energía incidente. Debido a ello, en las plantas de conexión a red se ha popularizado el uso de seguidores solares para maximizar la producción de energía.[11]​ La producción se ve afectada asimismo por las condiciones meteorológicas adversas, como la falta de sol, nubes o la suciedad que se deposita sobre los paneles.[12]​[13]​ Esto implica que para garantizar el suministro eléctrico es necesario complementar esta energía con otras fuentes de energía gestionables como las centrales basadas en la quema de combustibles fósiles, la energía hidroeléctrica o la energía nuclear.
Gracias a los avances tecnológicos, la sofisticación y la economía de escala, el coste de la energía solar fotovoltaica se ha reducido de forma constante desde que se fabricaron las primeras células solares comerciales,[14]​ aumentando a su vez la eficiencia, y logrando que su coste medio de generación eléctrica sea ya competitivo con las fuentes de energía convencionales[15]​ en un creciente número de regiones geográficas, alcanzando la paridad de red.[16]​
[18]​ Actualmente el coste de la electricidad producida en instalaciones solares se sitúa entre 0,05-0,10 $/kWh en Europa, China, India, Sudáfrica y Estados Unidos.[19]​ En 2015, se alcanzaron nuevos récords en proyectos de Emiratos Árabes Unidos (0,0584 $/kWh), Perú (0,048 $/kWh) y México (0,048 $/kWh). En mayo de 2016, una subasta solar en Dubái alcanzó un precio de 0,03 $/kWh.[19]​
El término «fotovoltaico» se comenzó a usar en Reino Unido en el año 1849.[20]​ Proviene del griego φώς: phos, que significa «luz», y de -voltaico, que proviene del ámbito de la electricidad, en honor al físico italiano Alejandro Volta.[nota 1]​
El efecto fotovoltaico fue reconocido por primera vez unos diez años antes, en 1839, por el físico francés Alexandre-Edmond Becquerel,[21]​[22]​ pero la primera célula solar no se fabricó hasta 1883. Su creador fue Charles Fritts, quien recubrió una muestra de selenio semiconductor con pan de oro para formar la unión. Este primitivo dispositivo presentaba una eficiencia menor del 1 %, pero demostró de forma práctica que, efectivamente, producir electricidad con luz era posible.[23]​ Los estudios realizados en el siglo XIX por Michael Faraday, James Clerk Maxwell, Nikola Tesla y Heinrich Hertz sobre inducción electromagnética, fuerzas eléctricas y ondas electromagnéticas, y sobre todo los de Albert Einstein en 1905, proporcionaron la base teórica al efecto fotoeléctrico,[24]​ que es el fundamento de la conversión de energía solar a electricidad.
Cuando un semiconductor dopado se expone a radiación electromagnética, se desprende del mismo un fotón, que golpea a un electrón y lo arranca, creando un hueco en el átomo. Normalmente, el electrón encuentra rápidamente otro hueco para volver a llenarlo, y la energía proporcionada por el fotón, por tanto, se disipa en forma de calor. El principio de una célula fotovoltaica es obligar a los electrones y a los huecos a avanzar hacia el lado opuesto del material en lugar de simplemente recombinarse en él: así, se producirá una diferencia de potencial y por lo tanto tensión entre las dos partes del material, como ocurre en una pila.
Para ello, se crea un campo eléctrico permanente, a través de una unión pn, entre dos capas dopadas respectivamente, p y n. En las células de silicio, que son mayoritariamente utilizadas, se encuentran por tanto:
La capa superior de la celda, que se compone de silicio dopado de tipo n.[nota 2]​ En esta capa, hay un número de electrones libres mayor que en una capa de silicio puro, de ahí el nombre del dopaje n, negativo. El material permanece eléctricamente neutro, ya que tanto los átomos de silicio como los del material dopante son neutros: pero la red cristalina tiene globalmente una mayor presencia de electrones que en una red de silicio puro.La capa inferior de la celda, que se compone de silicio dopado de tipo p.[nota 3]​Esta capa tiene por lo tanto una cantidad media de electrones libres menor que una capa de silicio puro. Los electrones están ligados a la red cristalina que, en consecuencia, es eléctricamente neutra pero presenta huecos, positivos (p). La conducción eléctrica está asegurada por estos portadores de carga, que se desplazan por todo el material.En el momento de la creación de la unión pn, los electrones libres de la capa n entran instantáneamente en la capa p y se recombinan con los huecos en la región p. Existirá así durante toda la vida de la unión, una carga positiva en la región n a lo largo de la unión (porque faltan electrones) y una carga negativa en la región en p a lo largo de la unión (porque los huecos han desaparecido); el conjunto forma la «Zona de Carga de Espacio» (ZCE) y existe un campo eléctrico entre las dos, de n hacia p. Este campo eléctrico hace de la ZCE un diodo, que sólo permite el flujo de corriente en una dirección: los electrones pueden moverse de la región p a la n, pero no en la dirección opuesta y por el contrario los huecos no pasan más que de n hacia p.
En funcionamiento, cuando un fotón arranca un electrón a la matriz, creando un electrón libre y un hueco, bajo el efecto de este campo eléctrico cada uno va en dirección opuesta: los electrones se acumulan en la región n (para convertirse en polo negativo), mientras que los huecos se acumulan en la región dopada p (que se convierte en el polo positivo). Este fenómeno es más eficaz en la ZCE, donde casi no hay portadores de carga (electrones o huecos), ya que son anulados, o en la cercanía inmediata a la ZCE: cuando un fotón crea un par electrón-hueco, se separaron y es improbable que encuentren a su opuesto, pero si la creación tiene lugar en un sitio más alejado de la unión, el electrón (convertido en hueco) mantiene una gran oportunidad para recombinarse antes de llegar a la zona n. Pero la ZCE es necesariamente muy delgada, así que no es útil dar un gran espesor a la célula.[nota 4]​ Efectivamente, el grosor de la capa n es muy pequeño, ya que esta capa sólo se necesita básicamente para crear la ZCE que hace funcionar la célula. En cambio, el grosor de la capa p es mayor: depende de un compromiso entre la necesidad de minimizar las recombinaciones electrón-hueco, y por el contrario permitir la captación del mayor número de fotones posible, para lo que se requiere cierto mínimo espesor.
En resumen, una célula fotovoltaica es el equivalente de un generador de energía a la que se ha añadido un diodo. Para lograr una célula solar práctica, además es preciso añadir contactos eléctricos (que permitan extraer la energía generada), una capa que proteja la célula pero deje pasar la luz, una capa antireflectante para garantizar la correcta absorción de los fotones, y otros elementos que aumenten la eficiencia del misma.
El ingeniero estadounidense Russell Ohl patentó la célula solar moderna en el año 1946,[25]​ aunque otros investigadores habían avanzado en su desarrollado con anterioridad: el físico sueco Sven Ason Berglund había patentado en 1914 un método que trataba de incrementar la capacidad de las células fotosensibles, mientras que en 1931, el ingeniero alemán Bruno Lange había desarrollado una fotocélula usando seleniuro de plata en lugar de óxido de cobre.[26]​
La era moderna de la tecnología solar no llegó hasta el año 1954, cuando los investigadores estadounidenses Gerald Pearson, Calvin S. Fuller y Daryl Chapin, de los Laboratorios Bell,[27]​ descubrieron de manera accidental que los semiconductores de silicio dopado con ciertas impurezas eran muy sensibles a la luz. Estos avances contribuyeron a la fabricación de la primera célula solar comercial. Emplearon una unión difusa de silicio p–n, con una conversión de la energía solar de aproximadamente 6 %, un logro comparado con las células de selenio que difícilmente alcanzaban el 0,5 %.[28]​[29]​
Posteriormente el estadounidense Les Hoffman, presidente de la compañía Hoffman Electronics, a través de su división de semiconductores fue uno de los pioneros en la fabricación y producción a gran escala de células solares. Entre 1954 y 1960, Hoffman logró mejorar la eficiencia de las células fotovoltaicas hasta el 14 %, reduciendo los costes de fabricación para conseguir un producto que pudiera ser comercializado.[30]​
Al principio, las células fotovoltaicas se emplearon de forma minoritaria para alimentar eléctricamente juguetes y en otros usos menores, dado que el coste de producción de electricidad mediante estas células primitivas era demasiado elevado: en términos relativos, una célula que produjera un vatio de energía mediante luz solar podía costar 250 dólares, en comparación con los dos o tres dólares que costaba un vatio procedente de una central termoeléctrica de carbón.
Las células fotovoltaicas fueron rescatadas del olvido gracias a la carrera espacial y a la sugerencia de utilizarlas en uno de los primeros satélites puestos en órbita alrededor de la Tierra. La Unión Soviética lanzó su primer satélite espacial en el año 1957, y Estados Unidos le seguiría un año después. La primera nave espacial que usó paneles solares fue el satélite norteamericano Vanguard 1, lanzado en marzo de 1958 (hoy en día el satélite más antiguo aún en órbita). En el diseño de éste se usaron células solares creadas por Peter Iles en un esfuerzo encabezado por la compañía Hoffman Electronics.[31]​ El sistema fotovoltaico le permitió seguir transmitiendo durante siete años mientras que las baterías químicas se agotaron en sólo 20 días.[32]​
En 1959, Estados Unidos lanzó el Explorer 6. Este satélite llevaba instalada una serie de módulos solares, soportados en unas estructuras externas similares a unas alas, formados por 9600 células solares de la empresa Hoffman.[30]​ Este tipo de dispositivos se convirtió posteriormente en una característica común de muchos satélites. Había cierto escepticismo inicial sobre el funcionamiento del sistema, pero en la práctica las células solares demostraron ser un gran éxito, y pronto se incorporaron al diseño de nuevos satélites.
Pocos años después, en 1962, el Telstar se convirtió en el primer satélite de comunicaciones equipado con células solares, capaces de proporcionar una potencia de 14 W.[33]​ Este hito generó un gran interés en la producción y lanzamiento de satélites geoestacionarios para el desarrollo de las comunicaciones, en los que la energía provendría de un dispositivo de captación de la luz solar. Fue un desarrollo crucial que estimuló la investigación por parte de algunos gobiernos y que impulsó la mejora de los paneles fotovoltaicos.[34]​
Gradualmente, la industria espacial se decantó por el uso de células solares de arseniuro de galio (GaAs), debido a su mayor eficiencia frente a las células de silicio. En 1970 la primera célula solar con heteroestructura de arseniuro de galio y altamente eficiente se desarrolló en la Unión Soviética por Zhorés Alfiórov y su equipo de investigación.[35]​[36]​
A partir de 1971, las estaciones espaciales soviéticas del programa Salyut fueron los primeros complejos orbitales tripulados en obtener su energía a partir de células solares, acopladas en estructuras a los laterales del módulo orbital,[37]​ al igual que la estación norteamericana Skylab, pocos años después.[38]​
En la década de 1970, tras la primera crisis del petróleo, el Departamento de Energía de los Estados Unidos y la agencia espacial NASA iniciaron el estudio del concepto de energía solar en el espacio, que ambicionaba el abastecimiento energético terrestre mediante satélites espaciales. En 1979 propusieron una flota de satélites en órbita geoestacionaria, cada uno de los cuales mediría 5 x 10 km y produciría entre 5 y 10 GW. La construcción implicaba la creación de una gran factoría espacial donde trabajarían continuamente cientos de astronautas. Este gigantismo era típico de una época en la que se proyectaba la creación de grandes ciudades espaciales. Dejando aparte las dificultades técnicas, la propuesta fue desechada en 1981 por implicar un coste disparatado.[39]​A mediados de la década de 1980, con el petróleo de nuevo en precios bajos, el programa fue cancelado.[40]​
No obstante, las aplicaciones fotovoltaicas en los satélites espaciales continuaron su desarrollo. La producción de equipos de deposición química de metales por vapores orgánicos o MOCVD (Metal Organic Chemical Vapor Deposition)[41]​ no se desarrolló hasta la década de 1980, limitando la capacidad de las compañías en la manufactura de células solares de arseniuro de galio. La primera compañía que manufacturó paneles solares en cantidades industriales, a partir de uniones simples de GaAs, con una eficiencia del 17 % en AM0 (Air Mass Zero), fue la norteamericana Applied Solar Energy Corporation (ASEC). Las células de doble unión comenzaron su producción en cantidades industriales por ASEC en 1989, de manera accidental, como consecuencia de un cambio del GaAs sobre los sustratos de GaAs, a GaAs sobre sustratos de germanio.
La tecnología fotovoltaica, si bien no es la única que se utiliza, sigue predominando a principios del siglo XXI en los satélites de órbita terrestre.[42]​ Por ejemplo, las sondas Magallanes, Mars Global Surveyor y Mars Observer, de la NASA, usaron paneles fotovoltaicos,[43]​[44]​[45]​ así como el Telescopio espacial Hubble,[46]​ en órbita alrededor de la Tierra. La Estación Espacial Internacional, también en órbita terrestre, está dotada de grandes sistemas fotovoltaicos que alimentan todo el complejo espacial,[47]​[48]​ al igual que en su día la estación espacial Mir.[49]​ Otros vehículos espaciales que utilizan la energía fotovoltaica para abastecerse son la sonda Mars Reconnaissance Orbiter,[50]​ Spirit y Opportunity, los robots de la NASA en Marte.[51]​[52]​
La nave Rosetta, lanzada en 2004 en órbita hacia un cometa tan lejano del Sol como el planeta Júpiter (5,25 AU), dispone también de paneles solares;[53]​ anteriormente, el uso más lejano de la energía solar espacial había sido el de la sonda Stardust,[54]​ a 2 AU. La energía fotovoltaica se ha empleado también con éxito en la misión europea no tripulada a la Luna, SMART-1, proporcionando energía a su propulsor de efecto Hall.[55]​ La sonda espacial Juno será la primera misión a Júpiter en usar paneles fotovoltaicos en lugar de un generador termoeléctrico de radioisótopos, tradicionalmente usados en las misiones espaciales al exterior del Sistema Solar.[56]​
Actualmente se está estudiando el potencial de la fotovoltaica para equipar las naves espaciales que orbiten más allá de Júpiter.[57]​
Desde su aparición en la industria aeroespacial, donde se ha convertido en el medio más fiable para suministrar energía eléctrica en los vehículos espaciales,[58]​ la energía solar fotovoltaica ha desarrollado un gran número de aplicaciones terrestres. La primera instalación comercial de este tipo se realizó en 1966, en el faro de la isla Ogami (Japón), permitiendo sustituir el uso de gas de antorcha por una fuente eléctrica renovable y autosuficiente. Se trató del primer faro del mundo alimentado mediante energía solar fotovoltaica, y fue crucial para demostrar la viabilidad y el potencial de esta fuente de energía.[59]​
Las mejoras se produjeron de forma lenta durante las siguientes dos décadas, y el único uso generalizado se produjo en las aplicaciones espaciales, en las que su relación potencia a peso era mayor que la de cualquier otra tecnología competidora. Sin embargo, este éxito también fue la razón de su lento crecimiento: el mercado aeroespacial estaba dispuesto a pagar cualquier precio para obtener las mejores células posibles, por lo que no había ninguna razón para invertir en soluciones de menor costo si esto reducía la eficiencia. En su lugar, el precio de las células era determinado en gran medida por la industria de los semiconductores; su migración hacia la tecnología de circuitos integrados en la década de 1960 dio lugar a la disponibilidad de lingotes más grandes a precios relativamente inferiores. Al caer su precio, el precio de las células fotovoltaicas resultantes descendió en igual medida. Sin embargo, la reducción de costes asociada a esta creciente popularización de la energía fotovoltaica fue limitada, y en 1970 el coste de las células solares todavía se estimaba en 100 dólares por vatio ($/Wp).[60]​
A finales de la década de 1960, el químico industrial estadounidense Elliot Berman estaba investigando un nuevo método para la producción de la materia prima de silicio a partir de un proceso en cinta. Sin embargo, encontró escaso interés en su proyecto y no pudo obtener la financiación necesaria para su desarrollo. Más tarde, en un encuentro casual, fue presentado a un equipo de la compañía petrolera Exxon que estaban buscando proyectos estratégicos a 30 años vista. El grupo había llegado a la conclusión de que la energía eléctrica sería mucho más costosa en el año 2000, y consideraba que este aumento de precio haría más atractivas a las nuevas fuentes de energía alternativas, siendo la energía solar la más interesante entre estas. En 1969, Berman se unió al laboratorio de Exxon en Linden, Nueva Jersey, denominado Solar Power Corporation (SPC).[60]​
Su esfuerzo fue dirigido en primer lugar a analizar el mercado potencial para identificar los posibles usos que existían para este nuevo producto, y rápidamente descubrió que si el coste por vatio se redujera desde los 100 $/Wp a cerca de 20 $/Wp surgiría una importante demanda. Consciente de que el concepto del «silicio en cinta» podría tardar años en desarrollarse, el equipo comenzó a buscar maneras de reducir el precio a 20 $/Wp usando materiales existentes. La constatación de que las células existentes se basaban en el proceso estándar de fabricación de semiconductores supuso un primer avance, incluso aunque no se tratara de un material ideal. El proceso comenzaba con la formación de un lingote de silicio, que se cortaba transversalmente en discos llamados obleas. Posteriormente se realizaba el pulido de las obleas y, a continuación, para su uso como células, se dotaba de un recubrimiento con una capa anti reflectante. Berman se dio cuenta de que las obleas de corte basto ya tenían de por sí una superficie frontal anti reflectante perfectamente válida, y mediante la impresión de los electrodos directamente sobre esta superficie, se eliminaron dos pasos importantes en el proceso de fabricación de células.[60]​
Su equipo también exploró otras formas de mejorar el montaje de las células en matrices, eliminando los costosos materiales y el cableado manual utilizado hasta entonces en aplicaciones espaciales. Su solución consistió en utilizar circuitos impresos en la parte posterior, plástico acrílico en la parte frontal, y pegamento de silicona entre ambos, embutiendo las células. Berman se dio cuenta de que el silicio ya existente en el mercado ya era «suficientemente bueno» para su uso en células solares. Las pequeñas imperfecciones que podían arruinar un lingote de silicio (o una oblea individual) para su uso en electrónica, tendrían poco efecto en aplicaciones solares. Las células fotovoltaicas podían fabricarse a partir del material desechado por el mercado de la electrónica, lo que traería como consecuencia una gran mejora de su precio.[60]​
Poniendo en práctica todos estos cambios, la empresa comenzó a comprar a muy bajo coste silicio rechazado a fabricantes ya existentes. Mediante el uso de las obleas más grandes disponibles, lo que reducía la cantidad de cableado para un área de panel dado, y empaquetándolas en paneles con sus nuevos métodos, en 1973 SPC estaba produciendo paneles a 10 $/Wp y vendiéndolos a 20 $/Wp, disminuyendo el precio de los módulos fotovoltaicos a una quinta parte en sólo dos años.[60]​
SPC comenzó a contactar con las compañías fabricantes de boyas de navegación ofreciéndoles el producto, pero se encontró con una situación curiosa. La principal empresa del sector era Automatic Power, un fabricante de baterías desechables. Al darse cuenta de que las células solares podían comerse parte del negocio y los beneficios que el sector de baterías le producía, Automatic Power compró un prototipo solar de Hoffman Electronics para terminar arrinconándolo. Al ver que no había interés por parte de Automatic Power, SPC se volvió entonces a Tideland Signal, otra compañía suministradora de baterías formada por ex-gerentes de Automatic Power.[60]​ Tideland presentó en el mercado una boya alimentada mediante energía fotovoltaica y pronto estaba arruinando el negocio de Automatic Power.
El momento no podía ser más adecuado, el rápido aumento en el número de plataformas petrolíferas en alta mar y demás instalaciones de carga produjo un enorme mercado entre las compañías petroleras. Como Tideland había tenido éxito, Automatic Power comenzó entonces a procurarse su propio suministro de paneles solares fotovoltaicos. Encontraron a Bill Yerkes, de Solar Power International (SPI) en California, que estaba buscando un mercado donde vender su producto. SPI pronto fue adquirida por uno de sus clientes más importantes, el gigante petrolero ARCO, formando ARCO Solar. La fábrica de ARCO Solar en Camarillo (California) fue la primera dedicada a la construcción de paneles solares, y estuvo en funcionamiento continuo desde su compra por ARCO en 1977 hasta 2011 cuando fue cerrada por la empresa SolarWorld.[60]​
Esta situación se combinó con la crisis del petróleo de 1973. Las compañías petroleras disponían ahora de ingentes fondos debido a sus enormes ingresos durante la crisis, pero también eran muy conscientes de que su éxito futuro dependería de alguna otra fuente de energía. En los años siguientes, las grandes compañías petroleras comenzaron la creación de una serie de empresas de energía solar, y fueron durante décadas los mayores productores de paneles solares. Las compañías ARCO, Exxon, Shell, Amoco (más tarde adquirida por BP) y Mobil mantuvieron grandes divisiones solares durante las décadas de 1970 y 1980. Las empresas de tecnología también realizaron importantes inversiones, incluyendo General Electric, Motorola, IBM, Tyco y RCA.[61]​
En las décadas transcurridas desde los avances de Berman, las mejoras han reducido los costes de producción por debajo de 1 $/Wp, con precios menores de 2 $/Wp para todo el sistema fotovoltaico. El precio del resto de elementos de una instalación fotovoltaica supone ahora un mayor coste que los propios paneles.[62]​
A medida que la industria de los semiconductores se desarrolló hacia lingotes cada vez más grandes, los equipos más antiguos quedaron disponibles a precios reducidos. Las células crecieron en tamaño cuando estos equipos antiguos se hicieron disponibles en el mercado excedentario. Los primeros paneles de ARCO Solar se equipaban con células de 2 a 4 pulgadas (51 a 100 mm) de diámetro. Los paneles en la década de 1990 y principios de 2000 incorporaban generalmente células de 5 pulgadas (125 mm), y desde el año 2008 casi todos los nuevos paneles utilizan células de 6 pulgadas (150 mm).[63]​ También la introducción generalizada de los televisores de pantalla plana a finales de la década de 1990 y principios de 2000 llevó a una amplia disponibilidad de grandes láminas de vidrio de alta calidad, que se utilizan en la parte frontal de los paneles.[64]​
En términos de las propias células, solo ha habido un cambio importante. Durante la década de 1990, las células de polisilicio se hicieron cada vez más populares.[63]​ Estas células ofrecen menos eficiencia que aquellas de monosilicio, pero se cultivan en grandes cubas que reducen en gran medida el coste de producción.[63]​ A mediados de la década de 2000, el polisilicio dominaba en el mercado de paneles de bajo coste.[63]​
La producción industrial a gran escala de paneles fotovoltaicos despegó en la década de 1980, y entre sus múltiples usos se pueden destacar:
La energía solar fotovoltaica es ideal para aplicaciones de telecomunicaciones, entre las que se encuentran por ejemplo las centrales locales de telefonía, antenas de radio y televisión, estaciones repetidoras de microondas y otros tipos de enlaces de comunicación electrónicos. Esto es debido a que, en la mayoría de las aplicaciones de telecomunicaciones, se utilizan baterías de almacenamiento y la instalación eléctrica se realiza normalmente en corriente continua (DC). En terrenos accidentados y montañosos, las señales de radio y televisión pueden verse interferidas o reflejadas debido al terreno ondulado. En estos emplazamientos, se instalan transmisores de baja potencia (LPT) para recibir y retransmitir la señal entre la población local.[65]​
Las células fotovoltaicas también se utilizan para alimentar sistemas de comunicaciones de emergencia, por ejemplo en los postes de SOS (Teléfonos de emergencia) en carreteras, señalización ferroviaria, balizamiento para protección aeronáutica, estaciones meteorológicas o sistemas de vigilancia de datos ambientales y de calidad del agua.[60]​
La reducción en el consumo energético de los circuitos integrados, hizo posible a finales de la década de 1970 el uso de células solares como fuente de electricidad en calculadoras, tales como la Royal Solar 1, Sharp EL-8026 o Teal Photon.[66]​
También otros dispositivos fijos que utilizan la energía fotovoltaica han visto aumentar su uso en las últimas décadas, en lugares donde el coste de conexión a la red eléctrica o el uso de pilas desechables es prohibitivamente caro. Estas aplicaciones incluyen por ejemplo las lámparas solares, bombas de agua, parquímetros,[67]​[68]​ teléfonos de emergencia, compactadores de basura,[69]​ señales de tráfico temporales o permanentes, estaciones de carga[70]​[71]​ o sistemas remotos de vigilancia.
En entornos aislados, donde se requiere poca potencia eléctrica y el acceso a la red es difícil, las placas fotovoltaicas se emplean como alternativa económicamente viable desde hace décadas. Para comprender la importancia de esta posibilidad, conviene tener en cuenta que aproximadamente una cuarta parte de la población mundial todavía no tiene acceso a la energía eléctrica.[72]​
En los países en desarrollo, muchos pueblos se encuentran situados en áreas remotas, a varios kilómetros de la red eléctrica más próxima. Debido a ello, se está incorporando la energía fotovoltaica de forma creciente para proporcionar suministro eléctrico a viviendas o instalaciones médicas en áreas rurales. Por ejemplo, en lugares remotos de India un programa de iluminación rural ha provisto iluminación mediante lámparas LED alimentadas con energía solar para sustituir a las lámparas de queroseno. El precio de las lámparas solares era aproximadamente el mismo que el coste del suministro de queroseno durante unos pocos meses.[73]​ Cuba y otros países de Latinoamérica están trabajando para proporcionar energía fotovoltaica en zonas alejadas del suministro de energía eléctrica convencional.[74]​ Estas son áreas en las que los beneficios sociales y económicos para la población local ofrecen una excelente razón para instalar paneles fotovoltaicos, aunque normalmente este tipo de iniciativas se han visto relegadas a puntuales esfuerzos humanitarios.[75]​
También se emplea la fotovoltaica para alimentar instalaciones de bombeo para sistemas de riego, agua potable en áreas rurales y abrevaderos para el ganado,[76]​[77]​ o para sistemas de desalinización de agua.[60]​
Los sistemas de bombeo fotovoltaico (al igual que los alimentados mediante energía eólica) son muy útiles allí donde no es posible acceder a la red general de electricidad o bien supone un precio prohibitivo.[78]​ Su coste es generalmente más económico debido a sus menores costes de operación y mantenimiento, y presentan un menor impacto ambiental que los sistemas de bombeo alimentados mediante motores de combustión interna, que tienen además una menor fiabilidad.[79]​[80]​
Las bombas utilizadas pueden ser tanto de corriente alterna (AC) como corriente continua (DC). Normalmente se emplean motores de corriente continua para pequeñas y medianas aplicaciones de hasta 3 kW de potencia, mientras que para aplicaciones más grandes se utilizan motores de corriente alterna acoplados a un inversor que transforma para su uso la corriente continua procedente de los paneles fotovoltaicos. Esto permite dimensionar sistemas desde 0,15 kW hasta más de 55 kW de potencia, que pueden ser empleados para abastecer complejos sistemas de irrigación o almacenamiento de agua.[81]​[82]​
Debido al descenso de costes de la energía solar fotovoltaica, se está extendiendo asimismo el uso de sistemas híbridos solar-diésel, que combinan esta energía con generadores diésel para producir electricidad de forma continua y estable.[83]​ Este tipo de instalaciones están equipadas normalmente con equipos auxiliares, tales como baterías y sistemas especiales de control para lograr en todo momento la estabilidad del suministro eléctrico del sistema.[84]​
Debido a su viabilidad económica (el transporte de diésel al punto de consumo suele ser costoso) en muchos casos se sustituyen antiguos generadores por fotovoltaica, mientras que las nuevas instalaciones híbridas se diseñan de tal manera que permiten utilizar el recurso solar siempre que está disponible, minimizando el uso de los generadores, disminuyendo así el impacto ambiental de la generación eléctrica en comunidades remotas y en instalaciones que no están conectadas a la red eléctrica. Un ejemplo de ello lo constituyen las empresas mineras,[83]​[85]​ cuyas explotaciones se encuentran normalmente en campo abierto, alejadas de los grandes núcleos de población. En estos casos, el uso combinado de la fotovoltaica permite disminuir en gran medida la dependencia del combustible diésel, permitiendo ahorros de hasta el 70 % en el coste de la energía.[86]​
Este tipo de sistemas también puede utilizarse en combinación con otras fuentes de generación de energía renovable, tales como la energía eólica.[87]​
Aunque la fotovoltaica todavía no se utiliza de forma generalizada para proporcionar tracción en el transporte, se está utilizando cada vez en mayor medida para proporcionar energía auxiliar en barcos y automóviles. Algunos vehículos están equipados con aire acondicionado alimentado mediante paneles fotovoltaicos para limitar la temperatura interior en los días calurosos,[88]​ mientras que otros prototipos híbridos los utilizan para recargar sus baterías sin necesidad de conectarse a la red eléctrica.[89]​[90]​ Se ha demostrado sobradamente la posibilidad práctica de diseñar y fabricar vehículos propulsados mediante energía solar, así como barcos[91]​[92]​ y aviones,[93]​ siendo considerado el transporte rodado el más viable para la fotovoltaica.[94]​
El Solar Impulse es un proyecto dedicado al desarrollo de un avión propulsado únicamente mediante energía solar fotovoltaica. El prototipo puede volar durante el día propulsado por las células solares que cubren sus alas, a la vez que carga las baterías que le permiten mantenerse en el aire durante la noche.[95]​[96]​
La energía solar también se utiliza de forma habitual en faros, boyas y balizas de navegación marítima, vehículos de recreo, sistemas de carga para los acumuladores eléctricos de los barcos, y sistemas de protección catódica.[60]​ La recarga de vehículos eléctricos está cobrando cada vez mayor importancia.[94]​
Muchas instalaciones fotovoltaicas se encuentran a menudo situadas en los edificios: normalmente se sitúan sobre un tejado ya existente, o bien se integran en elementos de la propia estructura del edificio, como tragaluces, claraboyas o fachadas.[97]​
Alternativamente, un sistema fotovoltaico también puede ser emplazado físicamente separado del edificio, pero conectado a la instalación eléctrica del mismo para suministrar energía. En 2010, más del 80 % de los 9000 MW de fotovoltaica que Alemania tenía en funcionamiento por entonces, se habían instalado sobre tejados.[98]​
La fotovoltaica integrada en edificios (BIPV, en sus siglas en inglés) se está incorporando de forma cada vez más creciente como fuente de energía eléctrica principal o secundaria en los nuevos edificios domésticos e industriales,[99]​ e incluso en otros elementos arquitectónicos, como por ejemplo puentes.[100]​ Las tejas con células fotovoltaicas integradas son también bastante comunes en este tipo de integración.
Según un estudio publicado en 2011, el uso de imágenes térmicas ha demostrado que los paneles solares, siempre que exista una brecha abierta por la que el aire pueda circular entre los paneles y el techo, proporcionan un efecto de refrigeración pasiva en los edificios durante el día y además ayudan a mantener el calor acumulado durante la noche.[101]​
Una de las principales aplicaciones de la energía solar fotovoltaica más desarrollada en los últimos años, consiste en las centrales conectadas a red para suministro eléctrico,[102]​ así como los sistemas de autoconsumo fotovoltaico, de potencia generalmente menor, pero igualmente conectados a la red eléctrica.
Aunque los paneles solares suelen instalarse en tierra, es posible instalarlos flotando sobre aguas de embalses o lagos tranquilos.[103]​ Aunque es más caro, tiene muchas ventajas: reduce las pérdidas por evaporación del agua embalsada, mejora su calidad y facilita la refrigeración de los propios paneles.[103]​
Una planta solar fotovoltaica cuenta con distintos elementos que permiten su funcionamiento, como son los paneles fotovoltaicos para la captación de la radiación solar, y los inversores para la transformación de la corriente continua en corriente alterna.[104]​ Existen otros, los más importantes se mencionan a continuación:
Generalmente, un módulo o panel fotovoltaico consiste en una asociación de células, encapsulada en dos capas de EVA (etileno-vinilo-acetato), entre una lámina frontal de vidrio y una capa posterior de un polímero termoplástico (frecuentemente se emplea el tedlar) u otra lámina de cristal cuando se desea obtener módulos con algún grado de transparencia.[105]​ Muy frecuentemente este conjunto es enmarcado en una estructura de aluminio anodizado con el objetivo de aumentar la resistencia mecánica del conjunto y facilitar el anclaje del módulo a las estructuras de soporte.[105]​
Las células más comúnmente empleadas en los paneles fotovoltaicos son de silicio, y se puede dividir en tres subcategorías:
Las células de silicio monocristalino están constituidas por un único cristal de silicio, normalmente manufacturado mediante el proceso Czochralski.[106]​ Este tipo de células presenta un color azul oscuro uniforme.
Las células de silicio policristalino (también llamado multicristalino) están constituidas por un conjunto de cristales de silicio, lo que explica que su rendimiento sea algo inferior al de las células monocristalinas.[63]​ Se caracterizan por un color azul más intenso.
Las células de silicio amorfo. Son menos eficientes que las células de silicio cristalino pero también menos costosas. Este tipo de células es, por ejemplo, el que se emplea en aplicaciones solares como relojes o calculadoras.[107]​
La corriente eléctrica continua que proporcionan los módulos fotovoltaicos se puede transformar en corriente alterna mediante un aparato electrónico llamado inversor[104]​ e inyectar en la red eléctrica (para venta de energía) o bien en la red interior (para autoconsumo).
En plantas de potencia inferior a 100 kW se inyecta la energía directamente a la red de distribución en baja tensión (400 V en trifásico o 230 V en monofásico).
Y para potencias superiores a los 100 kW se utiliza un transformador para elevar la energía a media tensión (hasta 36 kV) y se inyecta en las redes de transporte para su posterior suministro.En las etapas iniciales del desarrollo de los inversores fotovoltaicos, los requisitos de los operadores de las redes eléctricas a la que se conectaban solicitaban únicamente el aporte de energía activa y la desconexión del inversor de la red si ésta excedía de unos ciertos límites de tensión y frecuencia. Con el progresivo desarrollo de estos equipos y la cada vez mayor importancia de las redes eléctricas inteligentes, los inversores son ya capaces de proveer energía reactiva e incluso aportar estabilidad a la red eléctrica.[108]​[109]​
El uso de seguidores a uno o dos ejes permite aumentar considerablemente la producción solar, en torno al 30 % para los primeros y un 6 % adicional para los segundos, en lugares de elevada radiación directa.[110]​[111]​
Los seguidores solares son bastante comunes en aplicaciones fotovoltaicas.[112]​ Existen de varios tipos:
En un eje polar: la superficie gira sobre un eje orientado al sur e inclinado un ángulo igual a la latitud. El giro se ajusta para que la normal a la superficie coincida en todo momento con el meridiano terrestre que contiene al Sol.
En un eje azimutal: la superficie gira sobre un eje vertical, el ángulo de la superficie es constante e igual a la latitud. El giro se ajusta para que la normal a la superficie coincida en todo momento con el meridiano local que contiene al Sol.
En un eje horizontal: la superficie gira en un eje horizontal y orientado en dirección norte-sur. El giro se ajusta para que la normal a la superficie coincida en todo momento con el meridiano terrestre que contiene al Sol.
Es el elemento que transporta la energía eléctrica desde su generación, para su posterior distribución y transporte. Su dimensionamiento viene determinado por el criterio más restrictivo entre la máxima caída de tensión admisible y la intensidad máxima admisible. Aumentar las secciones de conductor que se obtienen como resultado de los cálculos teóricos aporta ventajas añadidas como:
Otro tipo de tecnología en las plantas fotovoltaicas son las que utilizan una tecnología de concentración llamada CPV por sus siglas en inglés (Concentrated Photovoltaics)[113]​ para maximizar la energía solar recibida por la instalación, al igual que en una central térmica solar. Las instalaciones de concentración fotovoltaica se sitúan en emplazamientos de alta irradiación solar directa, como son los países a ambas riberas del Mediterráneo, Australia, Estados Unidos, China, Sudáfrica, México, etc. Hasta el año 2006 estas tecnologías formaban parte del ámbito de investigación, pero en los últimos años se han puesto en marcha instalaciones de mayor tamaño como la de ISFOC (Instituto de Sistemas Solares Fotovoltaicos de Concentración) en Puertollano (Castilla La Mancha) con 3 MW suministrando electricidad a la red eléctrica.[114]​[115]​[116]​
La idea básica de la concentración fotovoltaica es la sustitución de material semiconductor por material reflectante o refractante (más barato). El grado de concentración puede alcanzar un factor de 1000,[113]​ de tal modo que, dada la pequeña superficie de célula solar empleada, se puede utilizar la tecnología más eficiente (triple unión, por ejemplo). Por otro lado, el sistema óptico introduce un factor de pérdidas que hace recuperar menos radiación que la fotovoltaica plana. Esto, unido a la elevada precisión de los sistemas de seguimiento, constituye la principal barrera a resolver por la tecnología de concentración.
Recientemente se ha anunciado el desarrollo de plantas de grandes dimensiones (por encima de 1 MW).[117]​ Las plantas de concentración fotovoltaica utilizan un seguidor de doble eje para posibilitar un máximo aprovechamiento del recurso solar durante todo el día.
Entre los años 2001 y 2016 se ha producido un crecimiento exponencial de la producción fotovoltaica, duplicándose aproximadamente cada dos años.[118]​ La potencia total fotovoltaica instalada en el mundo (conectada a red) ascendía a 16 gigavatios (GW) en 2008, 40 GW en 2010, 100 GW en 2012, 180 GW en 2014 y 300 GW en 2016.[119]​[120]​[121]​[122]​[123]​[9]​
Históricamente, Estados Unidos lideró la instalación de energía fotovoltaica desde sus inicios hasta 1996, cuando su capacidad instalada alcanzaba los 77 MW, más que cualquier otro país hasta la fecha. En los años posteriores, fueron superados por Japón, que mantuvo el liderato hasta que a su vez Alemania la sobrepasó en 2005, manteniendo el liderato desde entonces. A comienzos de 2016, Alemania se aproximaba a los 40 GW instalados.[126]​ Sin embargo, por esas fechas China, uno de los países donde la fotovoltaica está experimentando un crecimiento más vertiginoso superó a Alemania, convirtiéndose desde entonces en el mayor productor de energía fotovoltaica del mundo.[126]​ Se espera que multiplique su potencia instalada actual hasta los 200 GW en 2020.[124]​[127]​[128]​
La capacidad total instalada supone ya una fracción significativa del mix eléctrico en la Unión Europea, cubriendo de media el 3,5 % de la demanda de electricidad y alcanzando el 7 % en los períodos de mayor producción.[123]​ En algunos países, como Alemania,[129]​[130]​ Italia,[131]​[132]​[133]​[nota 5]​ Reino Unido[134]​ o España,[135]​ alcanza máximos superiores al 10 %, al igual que en Japón[136]​ o en algunos estados soleados de Estados Unidos, como California.[137]​ La producción anual de energía eléctrica generada mediante esta fuente de energía a nivel mundial equivalía en 2015 a cerca de 184 TWh, suficiente para abastecer las necesidades energéticas de millones de hogares y cubriendo aproximadamente un 1 % de la demanda mundial de electricidad.[123]​
La energía fotovoltaica se ha convertido en una de las mayores industrias de la República Popular China. El país asiático es líder mundial por capacidad fotovoltaica, con una potencia instalada a principios de 2019 superior a los 170 GW.[138]​ Cuenta además con unas 400 empresas fotovoltaicas, entre las que destacan Trina Solar, Jinko Solar y JA Solar, gigantes mundiales en la fabricación de paneles solares. En 2014 producía aproximadamente la mitad de los productos fotovoltaicos que se fabrican en el mundo (China y Taiwán juntos suman más del 60 % de cuota). La producción de paneles y células fotovoltaicas en China se ha incrementado notablemente durante la última década: en 2001 mantenía una cuota inferior al 1 % del mercado mundial, mientras que por las mismas fechas, Japón y Estados Unidos sumaban más del 70 % de la producción mundial. Sin embargo, la tendencia se ha invertido y en la actualidad China supera ampliamente al resto de productores.
La capacidad de producción de paneles solares chinos prácticamente se cuadruplicó entre los años 2009 y 2011, superando incluso la demanda mundial. Como resultado, la Unión Europea acusó a la industria china de estar realizando dumping, es decir vendiendo sus paneles a precios por debajo de coste, imponiendo aranceles a la importación de este material.[139]​[140]​
La instalación de energía fotovoltaica se ha desarrollado espectacularmente en el país asiático en años recientes, superando incluso las previsiones iniciales. Debido a tan rápido crecimiento, las autoridades chinas se han visto obligadas a revaluar en varias ocasiones su objetivo de potencia fotovoltaica.
La potencia total instalada en China creció hasta los 77 GW a finales de 2016, tras conectar 36 GW en el último año, de acuerdo a las estadísticas oficiales del país.[141]​ En 2017, China había superado el objetivo marcado por el gobierno para 2020, una potencia fotovoltaica de 100 GW.[142]​ Por ello a finales de 2018 se anunció que China podría elevar su objetivo solar para 2020 a más de 200 GW.[143]​
Este crecimiento refleja el abrupto descenso de costes de la energía fotovoltaica, que actualmente comienza a ser una opción más barata que otras fuentes de energía, tanto a precios minoristas como comerciales. Fuentes del gobierno chino han afirmado que la fotovoltaica presentará precios más competitivos que el carbón y el gas (aportando además una mayor independencia energética) a finales de esta década.[144]​
Estados Unidos es desde 2010 uno de los países con mayor actividad en el mercado fotovoltaico, cuenta con grandes empresas del sector, como First Solar o SolarCity, así como numerosas plantas de conexión a red. A principios de 2017, Estados Unidos superaba los 40 GW de potencia fotovoltaica instalada,[145]​ suficiente para proporcionar electricidad a más de 8 millones de hogares, tras duplicar su capacidad solar en menos de dos años.[146]​
Aunque Estados Unidos no mantiene una política energética nacional uniforme en todo el país en lo referente a fotovoltaica, muchos estados han fijado individualmente objetivos en materia de energías renovables, incluyendo en esta planificación a la energía solar en diferentes proporciones. En este sentido, el gobernador de California Jerry Brown ha firmado una legislación requiriendo que el 33 % de la electricidad del estado se genere mediante energías renovables a finales de 2020.[147]​ Estas medidas se han visto apoyadas desde el gobierno federal con la adopción del Investment Tax Credit (ITC), una exención fiscal establecida en 2006 para promover el desarrollo de proyectos fotovoltaicos, y que ha sido extendida recientemente hasta 2023.[148]​
Un informe privado[149]​ recoge que la energía solar fotovoltaica se ha expandido rápidamente durante los últimos 8 años, creciendo a una media del 40 % cada año. Gracias a esta tendencia, el coste del kWh producido mediante energía fotovoltaica se ha visto enormemente reducido, mientras que el coste de la electricidad generada mediante combustibles fósiles no ha dejado de incrementar. Como resultado, el informe concluye que la fotovoltaica alcanzará la paridad de red frente a las fuentes de energía convencionales en muchas regiones de Estados Unidos en 2015. Pero para alcanzar una cuota en el mercado energético del 10 %, prosigue el informe, las compañías fotovoltaicas necesitarán estilizar aún más las instalaciones, de forma que la energía solar se convierta en una tecnología directamente enchufable («plug-and-play»). Es decir, que sea sencillo adquirir los componentes de cada sistema y su interconexión sea simple, al igual que su conexión a la red.[149]​
Actualmente la mayoría de las instalaciones son conectadas a red y utilizan sistemas de balance neto que permiten el consumo de electricidad nocturno de energía generada durante el día. Nueva Jersey lidera los Estados con la ley de balance neto menos restrictiva,[150]​ mientras California lidera el número total de hogares con energía solar. Muchos de ellos fueron instalados durante la iniciativa million solar roof (un millón de tejados solares).[151]​
La tendencia y el ritmo de crecimiento actuales indican que en los próximos años se construirán un gran número de plantas fotovoltaicas en el sur y suroeste del país, donde el terreno disponible es abundante, en los soleados desiertos de California, Nevada y Arizona. Las empresas están adquiriendo cada vez en mayor medida grandes superficies en estas zonas, con la intención de construir mayores plantas a gran escala.[152]​
La energía fotovoltaica en Japón, se ha expandido rápidamente desde la década de 1990. El país es uno de los líderes en la fabricación de módulos fotovoltaicos y se encuentra entre los primeros puestos en términos de potencia instalada, con más de 23 GW a finales de 2014, la mayor parte conectada a red.[153]​[154]​[155]​ La irradiación en Japón es óptima, situándose entre 4,3 y 4,8 kWh·m²·día, convirtiéndolo en un país idóneo para el desarrollo de este tipo de energía.
La venta de módulos fotovoltaicos para proyectos comerciales ha crecido rápidamente tras la introducción por parte del Gobierno japonés en julio de 2012 de una tarifa para el incentivo de la fotovoltaica tras el accidente nuclear de Fukushima y la paralización de la mayoría de las centrales nucleares que tiene el país.
La mayoría de módulos procede de fabricantes locales, entre los que destacan Kyocera, Sharp Corporation, Mitsubishi o Sanyo, mientras que una pequeña parte son importados, según se desprende de los datos de la Asociación Japonesa de Energía Fotovoltaica (Japan Photovoltaic Energy Association, JPA).[156]​ Tradicionalmente, el mercado fotovoltaico ha estado muy desplazado al segmento residencial, copando hasta el 97 % de la capacidad instalada en todo el país hasta 2012.[157]​ Aunque esta tendencia se está invirtiendo, todavía más del 75 % de las células y módulos vendidos en Japón a principios de 2012 tuvieron como destino proyectos residenciales, mientras que cerca del 9 % se emplearon en instalaciones fotovoltaicas comerciales.[158]​
En 2014, la potencia total fotovoltaica instalada en el país se situaba en torno a los 23 GW, que contribuían aproximadamente en un 2,5 % a la demanda eléctrica del país.[123]​ Durante el verano de 2015, se informó que la producción fotovoltaica en Japón había cubierto en determinados momentos el 10 % de la demanda total nacional.[136]​ Dos años después, en 2016, se sitúa en torno a 42 GW,[145]​ y la previsión apunta a que el mercado fotovoltaico japonés crecerá aún más en los próximos años.[159]​
Alemania dispone a principios de 2016 de una potencia instalada cercana a los 40 GW.[126]​ Sólo en 2011, Alemania instaló cerca de 7,5 GW,[160]​ y la fotovoltaica produjo 18 TW·h de electricidad, el 3 % del total consumido en el país.[161]​[130]​
El mercado fotovoltaico en Alemania ha crecido considerablemente desde principios del siglo XXI gracias a la creación de una tarifa regulada para la producción de energía renovable, que fue introducida por la «German Renewable Energy Act», ley publicada el año 2000. Desde entonces, el coste de las instalaciones fotovoltaicas ha descendido más del 50 % en cinco años, desde 2006.[162]​ Alemania se ha marcado el objetivo de producir el 35 % de la electricidad mediante energías renovables en 2020 y alcanzar el 100 % en 2050.[163]​
En 2012, las tarifas introducidas costaban a Alemania unos 14 000 millones de euros por año, tanto para las instalaciones eólicas como solares. Este coste es repartido entre todos los contribuyentes mediante un sobrecoste de 3,6 céntimos de € por kWh[164]​ (aproximadamente el 15 % del coste total de la electricidad para el consumidor doméstico).[165]​
La considerable potencia instalada en Alemania ha protagonizado varios récords durante los últimos años. Durante dos días consecutivos de mayo de 2012, por ejemplo, las plantas solares fotovoltaicas instaladas en el país produjeron 22 000 MWh en la hora del mediodía, lo que equivale a la potencia de generación de veinte centrales nucleares trabajando a plena capacidad.[166]​[nota 6]​ Alemania pulverizó este récord el 21 de julio de 2013, con una potencia instantánea de 24 GW a mediodía.[167]​[168]​ Debido al carácter altamente distribuido de la fotovoltaica alemana, aproximadamente 1,3-1,4 millones de pequeños sistemas fotovoltaicos contribuyeron a esta nueva marca. Aproximadamente el 90 % de los paneles solares instalados en Alemania se encuentran situados sobre tejado.[169]​
En junio de 2014, la fotovoltaica alemana volvió a batir récords durante varios días, al producir hasta el 50,6 % de toda la demanda eléctrica durante un sólo día, y superar el anterior récord de potencia instantánea hasta los 24,24 GW.[170]​[171]​[172]​
A comienzos de verano de 2011, el Gobierno alemán anunció que el esquema actual de tarifas reguladas concluiría cuando la potencia instalada alcanzase los 52 GW. Cuando esto suceda, Alemania aplicará un nuevo esquema de tarifas de inyección cuyos detalles no se conocen todavía.[173]​
No obstante, consciente de que el almacenamiento de energía mediante baterías es indispensable para el despliegue masivo de renovables como la energía eólica o la fotovoltaica, dada su intermitencia, el 1 de mayo de 2013 Alemania puso en marcha un nuevo programa de ayudas para incentivar sistemas fotovoltaicos con baterías de almacenamiento.[174]​ De esta manera, se financia a las instalaciones fotovoltaicas menores de 30 kW que instalen baterías y acumulen electricidad, con 660 euros por cada kW de almacenamiento de batería. El programa está dotado con 25 millones de euros anuales repartidos en 2013 y 2014, y de esta forma se logra disponer de la energía cuando el recurso no esté disponible —no haya viento o sea de noche—,[174]​ además de facilitar la estabilidad del sistema eléctrico.[175]​
India está densamente poblada y tiene también una gran irradiación solar, lo que hace del país uno de los mejores candidatos para el desarrollo de la fotovoltaica. En 2009, India anunció un programa para acelerar el uso de instalaciones solares en los edificios gubernamentales, al igual que en hospitales y hoteles.[176]​
La caída en el precio de los paneles fotovoltaicos ha coincidido con un incremento del precio de la electricidad en la India. El apoyo del gobierno y la abundancia del recurso solar han ayudado a impulsar la adopción de esta tecnología.[177]​
El parque solar Charanka, de 345 MW (uno de los mayores del mundo) fue puesto en servicio en abril de 2012 y ampliado en 2015, junto a un total de 605 MW en la región de Gujarat.[178]​ La construcción de otros grandes parques solares ha sido anunciada en el estado de Rajasthan.[179]​ También el parque solar de Dhirubhai Ambani, de 40 MW, fue inaugurado en 2012.[180]​
En enero de 2015, el gobierno indio incrementó de forma significativa su planes de desarrollo solar, estableciendo un objetivo de inversiones por valor de 100 000 millones de dólares y 100 GW de capacidad solar para 2022.[181]​[182]​
A comienzos de 2017, la potencia total instalada en India se situaba por encima de los 10 GW.[183]​ India espera alcanzar rápidamente los 20 GW instalados,[184]​ cumpliendo su objetivo de crear 1 millón de puestos de trabajo[185]​ y alcanzar 100 GW en 2022.[186]​[187]​
Italia se encuentra entre los primeros países productores de electricidad procedente de energía fotovoltaica, gracias al programa de incentivos llamado Conto Energia.[188]​ El crecimiento ha sido exponencial en los últimos años: la potencia instalada se triplicó en 2010 y se cuadruplicó en 2011, llegando a producir en 2012 el 5,6 % de la energía total consumida en el país.[131]​
Este programa contaba con un presupuesto total de 6700 millones de €, alcanzado dicho límite el Gobierno ha dejado de incentivar las nuevas instalaciones, al haberse alcanzado la paridad de red. Un informe publicado en 2013 por el Deutsche Bank concluía que efectivamente la paridad de red se había alcanzado en Italia y otros países del mundo.[189]​ El sector ha llegado a proporcionar trabajo a unas 100 000 personas, especialmente en el sector del diseño e instalación de dichas plantas solares.[190]​
Desde mediados de 2012 está vigente una nueva legislación que obliga a registrar todas las plantas superiores a 12 kW; las de potencia menor (fotovoltaica de tejado en residencias) están exentas de registro.[191]​ A finales de 2016, la potencia total instalada se situaba por encima de 19 GW,[145]​ suponiendo una producción energética tan importante que varias centrales de gas operaban a mitad de su potencial durante el día.
La energía solar en Reino Unido, aunque relativamente desconocida hasta hace poco,[192]​ ha despegado muy rápidamente en años recientes, debido a la drástica caída del precio de los paneles fotovoltaicos y la introducción de tarifas reguladas a partir de abril de 2010.[193]​ En 2014, había censadas ya unas 650 000 instalaciones solares en las islas británicas, con una capacidad total cercana a los 5 GW.[194]​ La planta solar más grande del país se encuentra en Southwick Estate, cerca de Fareham, y cuenta con una potencia de 48 MW. Fue inaugurada en marzo de 2015.[195]​
En 2012, el gobierno británico de David Cameron se comprometió a abastecer cuatro millones de hogares mediante energía solar en menos de ocho años,[196]​ lo que equivale a instalar unos 22 GW de capacidad fotovoltaica antes de 2020.[193]​ A principios de 2016, Reino Unido había instalado más de 10 GW de energía solar fotovoltaica.[197]​
Entre los meses de abril y septiembre de 2016, la energía solar produjo en Reino Unido más electricidad (6964 GWh) que la producida mediante carbón (6342 GWh), ambas se sitúan en torno a un 5 % de la demanda.[134]​
El mercado francés es el cuarto más importante dentro de la Unión Europea, tras los mercados de Alemania, Italia y Reino Unido. A finales de 2014 contaba con más de 5 GW instalados, y mantiene actualmente un crecimiento sostenido, estimándose que en 2015 conectará a la red eléctrica 1 GW adicional a la capacidad actual.[198]​ Recientemente, el país galo incrementó el cupo de sus subastas para energía fotovoltaica de 400 a 800 MW, como consecuencia del reconocimiento gubernamental a la cada vez mayor competitividad de la energía solar.[198]​
La planta fotovoltaica más grande de Europa, un proyecto de 300 MW llamado Cestas,[199]​ se encuentra en territorio francés. Su entrada en funcionamiento tuvo lugar a finales de 2015, proporcionando al sector fotovoltaico un ejemplo a seguir por el resto de la industria europea.[199]​
España es uno de los países de Europa con mayor irradiación anual.[42]​ Esto hace que la energía solar sea en este país más rentable que en otros. Regiones como el norte de España, que generalmente se consideran poco adecuadas para la energía fotovoltaica, reciben más irradiación anual que la media en Alemania, país que mantiene desde hace años el liderazgo en la promoción de la energía solar fotovoltaica.[42]​
Desde principios de la década de 2000, en concordancia con las medidas de apoyo a las energías renovables que se estaban llevando a cabo en el resto de Europa, se había venido aprobando la regulación que establece las condiciones técnicas y administrativas, y que supuso el inicio de un lento despegue de la fotovoltaica en España. En 2004, el gobierno español eliminó las barreras económicas para la conexión de las energías renovables a la red eléctrica. El Real Decreto 436/2004 igualó las condiciones para su producción a gran escala, y garantizó su venta mediante primas a la generación.[200]​
Gracias a esta regulación, y el posterior RD 661/2007,[201]​ España fue en el año 2008 uno de los países con más potencia fotovoltaica instalada del mundo, con 2708 MW instalados en un sólo año. Sin embargo, posteriores modificaciones en la legislación del sector[202]​ ralentizaron la construcción de nuevas plantas fotovoltaicas, de tal forma que en 2009 se instalaron tan sólo 19 MW, en 2010, 420 MW, y en 2011 se instalaron 354 MW, correspondiendo al 2 % del total de la Unión Europea.[129]​ 
En términos de producción energética, en 2010 la energía fotovoltaica cubrió en España aproximadamente el 2 % de la generación de electricidad, mientras que en 2011 y 2012 representó el 2,9 %, y en 2013 el 3,1 % de la generación eléctrica según datos del operador, Red Eléctrica.[203]​[204]​[205]​
A principios de 2012, el Gobierno español aprobó un Real Decreto Ley por el que se paralizó la instalación de nuevas centrales fotovoltaicas y demás energías renovables.[206]​ A finales de 2015 la potencia fotovoltaica instalada en España ascendía a 4667 MW.[207]​ En 2017, España cayó por primera vez de la lista de los diez países con mayor capacidad fotovoltaica instalada, al ser superado por Australia y Corea del Sur.[208]​ Sin embargo, en julio de 2017, el Gobierno organizó una subasta que adjudicó más de 3500 MW de nuevas plantas de energía fotovoltaica,[209]​ que permitirán a España alcanzar los objetivos de generación de energía renovable establecidos por la Unión Europea para 2020. Como novedad, ni la construcción de las plantas adjudicadas ni su operación supondrá algún coste para el sistema, excepto en el caso de que el precio de mercado baje de un suelo establecido en la subasta. La gran bajada de costes de la energía fotovoltaica ha permitido que grandes empresas hayan licitado a precio de mercado.[210]​
En Latinoamérica, la fotovoltaica ha comenzado a despegar en los últimos años. Se ha propuesto la construcción de un buen número de plantas solares en diversos países, a lo largo de toda la región.[211]​
México es el país latinoamericano con mayor capacidad instalada, y tiene aun un enorme potencial en lo que respecta a energía solar.[212]​[213]​ Un 70 % de su territorio presenta una irradiación superior a 4,5 kWh/m²/día, lo que lo convierte en un país muy soleado, e implica que utilizando la tecnología fotovoltaica actual, una planta solar de 25 km² en cualquier lugar del estado de Chihuahua o el desierto de Sonora (que ocuparía el 0,01 % de la superficie de México) podría proporcionar toda la electricidad demandada por el país.[214]​ 
El proyecto Aura Solar, situado en La Paz (Baja California Sur), inaugurado a principios de 2014, tenía previsto generar 82 GWh al año, suficiente para abastecer el consumo de 164 000 habitantes (65 % de la población de La Paz), pero fue arrasado por el huracán Odile en septiembre del mismo año y la planta no opera desde entonces.[215]​ La instalación cubría una superficie de 100 hectáreas con 131 800 módulos policristalinos sobre seguidores de un eje.[214]​[216]​
Otra planta fotovoltaica de 47 MW se encuentra en fase de planificación en Puerto Libertad (Sonora).[217]​La planta, originalmente diseñada para albergar 39 MW, se amplió para permitir la generación de 107 GWh/año.[218]​
México cuenta ya con más de 3000 MW instalados. Se espera que experimente un mayor crecimiento en los próximos años, con el fin de alcanzar el objetivo de cubrir el 35 % de su demanda energética a partir de energías renovables en 2024, según una ley aprobada por el gobierno mexicano en 2012.[219]​[220]​
Chile lideraba hasta hace unos años la producción solar en latinoamérica. La primera planta solar fotovoltaica en Chile fue El Aguila, de 2.2 MWp ubicada en Arica, terminada de conectar en 2012. Este país inauguró en junio de 2014 una central fotovoltaica de 100 MW, que se convirtió en la mayor realizada hasta la fecha en latinoamérica.[221]​ El elevado precio de la electricidad y los altos niveles de radiación que existen en el norte de Chile, han promovido la apertura de un importante mercado libre de subsidios.[222]​ A finales de 2018, el país andino contaba con 2427 MW fotovoltaicos en operación. Chile cuenta con un potencial de más de 1800 GW de energía solar posible en el desierto de Atacama, según un estudio realizado por la GIZ Alemana en Chile (German International Cooperation Agency, 2014). El desierto de Atacama es el lugar con mayor irradiación del mundo con niveles de irradiación global (GHI), por sobre los 2700 kWh/m2 año.
Otros países sudamericanos han comenzado a instalar plantas fotovoltaicas a gran escala, entre ellos Perú.[223]​ Brasil en cambio está experimentando un crecimiento más lento del sector, en parte debido a la elevada generación mediante energía hidráulica en el país,[224]​ aunque el estado de Minas Gerais lidera el esfuerzo, tras la aprobación por parte del gobierno brasileño de una fábrica de células y paneles fotovoltaicos en dicha región.[225]​[224]​
En la siguiente tabla se muestra el detalle de la potencia mundial instalada, desglosada por cada país, desde el año 2002 hasta 2018:
Se estima que la potencia fotovoltaica instalada ha crecido unos 75 GW en 2016,[125]​ y China ha tomado el liderato frente a Alemania siendo ya el mayor productor de energía fotovoltaica. Para 2019, se estima que la potencia total alcanzará en todo el mundo 396 GW (escenario moderado) o incluso 540 GW (escenario optimista).
La consultora Frost & Sullivan estima que la potencia fotovoltaica se incrementará hasta los 446 GW para 2020, siendo China, India y Estados Unidos los países con un mayor crecimiento, mientras Europa verá duplicada su capacidad respecto a los niveles actuales.[297]​ La firma Grand View Research, consultora y analista de mercados radicada en San Francisco, publicó sus estimaciones para el sector en marzo de 2015. El potencial fotovoltaico de países como Brasil, Chile y Arabia Saudí todavía no se ha desarrollado conforme a lo esperado, y se espera que sea desarrollado durante los próximos años. Además de ello, el aumento de la capacidad de manufactura en China se prevé que siga ayudando a disminuir aún más los precios en descenso. La consultora estima que la capacidad fotovoltaica mundial alcance los 490 GW en 2020.[298]​
La organización PV Market Alliance (PVMA), un consorcio formado por varias entidades de investigación, calcula que la capacidad global estará entre los 444-630 GW en 2020. En el escenario más pesimista, prevé que el ritmo de instalación anual se sitúe entre los 40 y 50 gigavatios al finalizar la década, mientras que en el escenario más optimista estima que se instalen entre 60 y 90 GW anuales durante los próximos cinco años. El escenario intermedio estima que se sitúen entre 50 y 70 GW, para alcanzar 536 GW en 2020.[299]​[300]​ Las cifras de PVMA concuerdan con las publicadas anteriormente por Solar Power Europe. En junio de 2015, Greentech Media (GTM) publicó su informe Global PV Demand Outlook para 2020, que estima que las instalaciones anuales se incrementarán de 40 a 135 GW, alcanzando una capacidad total global de casi 700 GW en 2020. La estimación de GTM es la más optimista de todas las publicadas hasta la fecha, estimando que se instalarán 518 GW entre 2015 y 2020, lo que supone más del doble que otras estimaciones.[301]​
Por su parte, EPIA también calcula que la energía fotovoltaica cubrirá entre un 10 y un 15 % de la demanda de Europa en 2030.
Un informe conjunto de esta organización y Greenpeace publicado en 2010 muestra que para el año 2030, un total de 1845 GW fotovoltaicos podrían generar aproximadamente 2646 TWh/año de electricidad en todo el mundo. Combinado con medidas de eficiencia energética, esta cifra representaría cubrir el consumo de casi un 10 % de la población mundial. Para el año 2050, se estima que más del 20 % de la electricidad mundial podría ser cubierto por la energía fotovoltaica.[302]​
En Europa y en el resto del mundo se han construido un gran número de centrales fotovoltaicas a gran escala.[102]​ A finales de 2018, las plantas fotovoltaicas más grandes del mundo eran, de acuerdo a su capacidad de producción:[102]​
En 2019, las mayores plantas solares del mundo se encuentran situadas en China e India. Kurnool Solar, en el estado indio de Andhra Pradesh alberga 1 GW de capacidad, equivalente en potencia a una central nuclear. La planta Yanchi Solar, en la provincia de Qinghai (China) cuenta asimismo con dicha capacidad. Entre los primeros puestos se encuentra también Longyangxia Hydro-Solar PV Station, situada junto a la presa de Longyangxia en China. Consiste en un macrocomplejo hidroeléctrico de 1280 MW, al que posteriormente se le añadió una central fotovoltaica de 320 MW, completada en 2013. A finales de 2015 se inauguró una segunda fase de 530 MW, lo que elevó la potencia total de la planta solar hasta los 850 MW.[303]​[304]​[305]​
Otros proyectos de gran escala se encuentran situados en Estos Unidos. Solar Star, tiene una potencia de 579 MW y se encuentra en California.[306]​[307]​ Las plantas Topaz Solar Farm y Desert Sunlight Solar Farm en Riverside County, también en California, tiene asimismo una potencia de 550 MW.[308]​[309]​ El proyecto Blythe Solar Power consiste en una planta fotovoltaica de 500 MW, situada igualmente en Riverside County, cuya construcción está prevista próximamente.[310]​ En Europa, el proyecto de mayor envergadura se llama Cestas Solar Power Plant, ubicado en la localidad de Cestas (Francia), que cuenta con una capacidad de 300 MW y entró en operación a finales de 2015.[311]​[312]​
Hay otras muchas plantas de gran escala en construcción. El McCoy Solar Energy Project,[313]​[314]​ en Estados Unidos, tendrá una potencia de 750 MW una vez completado.[315]​ En los últimos años, se ha propuesto la construcción de varias plantas de potencias superiores a los 1000 MW en diferentes lugares del mundo. La planta Quaid-e-Azam Solar Park, situada en Pakistán y cuya primera fase ya se encuentra operativa con 100 MW,[316]​[317]​[318]​ tiene previsto ampliar su capacidad hasta los 1500 MW.[319]​ Los Emiratos Árabes Unidos planean también la construcción de una planta de 1000 MW.[320]​[321]​[322]​ El Ordos Solar Project,[323]​ situado en China, alcanzará los 2000 MW.[324]​ El proyecto Westlands Solar Park tiene una capacidad prevista de 2700 MW,[325]​ a ser completado en varias fases. El proyecto de Ladakh, en India, planea albergar 5 GW de capacidad fotovoltaica.[326]​
En lo que respecta a instalaciones fotovoltaicas sobre tejado, la mayor instalación se encuentra en las instalaciones de Renault Samsung Motors en Busan (Corea del Sur), y cuenta con 20 MW distribuidos sobre las diferentes cubiertas, parkings e infraestructuras del complejo. Inaugurada en 2013, proporciona energía a la fábrica y miles de hogares cercanos.[327]​
El almacenamiento de energía se presenta como un reto importante para permitir contar con un suministro continuo de energía, dado que la energía solar no se puede generar por la noche. Las baterías recargables se han usado tradicionalmente para almacenar el exceso de electricidad en sistemas aislados. Con la aparición de los sistemas conectados a red, el exceso de electricidad puede transportarse mediante la red eléctrica a los puntos de consumo. Cuando la producción de energía renovable supone una pequeña fracción de la demanda, otras fuentes de energía pueden ajustar su producción de forma apropiada para prestar un respaldo a la variabilidad de las fuentes renovables, pero con el crecimiento de estas últimas, se hace necesario un control más adecuado para el equilibrio de la red.
Con el declive de los precios, las centrales fotovoltaicas comienzan a disponer de baterías para controlar la potencia de salida o almacenar el exceso de energía para que pueda ser empleado durante las horas en que las centrales renovables no pueden generar directamente. Este tipo de baterías permite estabilizar la red eléctrica al suavizar los picos de demanda durante minutos u horas. Se prevé que en el futuro estas baterías jugarán un papel importante en la red eléctrica, ya que pueden ser cargadas durante los períodos cuando la generación excede la demanda y verter dicha energía en la red cuando la demanda es mayor que la generación.
Por ejemplo, en Puerto Rico un sistema con una capacidad de 20 megavatios durante 15 minutos (5 megavatios hora) se emplea para estabilizar la frecuencia de la red en la isla. Otro sistema de 27 megavatios durante 15 minutos (6,75 megavatios hora) con baterías de níquel-cadmio fue instalado en Fairbanks (Alaska) en 2003 para estabilizar la tensión de las líneas de transmisión.[328]​
La mayoría de estos bancos de baterías se encuentran localizados junto a las propias plantas fotovoltaicas. Los mayores sistemas en Estados Unidos incluyen la batería de 31,5 MW en la planta Grand Ridge Power en Illinois, y la batería de 31,5 MW en Beech Ridge, Virginia.[329]​ Entre los proyectos más destacados se sitúan el sistema de 400 MWh (100 MW durante cuatro horas) del proyecto Southern California Edison y un proyecto de 52 MWh en Kauai (Hawaii), que permite desplazar por completo la producción de una planta de 13MW para su uso tras la puesta del sol.[330]​ Otros proyectos se sitúan en Fairbanks (40 MW para 7 minutos mediante baterías de níquel-cadmio)[331]​ y en Notrees (Texas) (36 MW para 40 minutos usando baterías de plomo-ácido).[332]​
En 2015, se instaló un total de 221 MW con almacenamiento de baterías en Estados Unidos, y se estima que la potencia total de este tipo de sistemas crezca hasta los 1,7 GW en 2020. La mayoría instalada por las propias compañías mayoristas del mercado estadounidense.[333]​
El autoconsumo fotovoltaico consiste en la producción individual a pequeña escala de electricidad para el propio consumo, a través de paneles fotovoltaicos. Ello se puede complementar con el balance neto. Este esquema de producción, que permite compensar el consumo eléctrico mediante lo generado por una instalación fotovoltaica en momentos de menor consumo, ya ha sido implantado con éxito en muchos países. Fue propuesto en España por la Asociación de la Industria Fotovoltaica (ASIF) para promover la electricidad renovable sin necesidad de apoyo económico adicional,[334]​ y estuvo en fase de proyecto por el IDAE.[335]​ Posteriormente se recogió en el Plan de Energías Renovables 2011-2020,[336]​ pero todavía no ha sido regulado.
Sin embargo, en los últimos años, debido al creciente auge de pequeñas instalaciones de energía renovable, el autoconsumo con balance neto ha comenzado a ser regulado en diversos países del mundo, siendo una realidad en países como Alemania, Italia, Dinamarca, Japón, Australia, Estados Unidos, Canadá y México, entre otros.
Con el abaratamiento de los sistemas de autoconsumo y el encarecimiento de las tarifas eléctricas, cada vez es más rentable que uno mismo produzca su propia electricidad.[17]​
Los sistemas de autoconsumo fotovoltaicos utilizan la energía solar, una fuente gratuita, inagotable, limpia y respetuosa con el medioambiente.
Se genera un sistema distribuido de generación eléctrica que reduce la necesidad de invertir en nuevas redes y reduce las pérdidas de energía por el transporte de la electricidad a través de la red.[337]​
Se evitan problemas para abastecer toda la demanda en hora punta, conocidos por los cortes de electricidad y subidas de tensión.
Las empresas reducen sus costes energéticos, mejoran su imagen y refuerzan su compromiso con el medio ambiente. [338]​En el caso del autoconsumo fotovoltaico, el tiempo de retorno de la inversión se calcula sobre la base de cuánta electricidad se deja de consumir de la red, debido al empleo de paneles fotovoltaicos.
Por ejemplo, en Alemania, con precios de la electricidad en 0,25 €/kWh y una insolación de 900 kWh/kWp, una instalación de 1 kWp ahorra unos 225 € al año, lo que con unos costes de instalación de 1700 €/kWp significa que el sistema se amortizará en menos de 7 años.[339]​ Esta cifra es aún menor en países como España, con una irradiación superior a la existente en el norte del continente europeo.[42]​
Las eficiencias de las células solares varían entre el 6 % de aquellas basadas en silicio amorfo hasta el 46 % de las células multiunión.[341]​[342]​ Las eficiencias de conversión de las células solares que se utilizan en los módulos fotovoltaicos comerciales (de silicio monocristalino o policristalino) se encuentran en torno al 16-22 %.[343]​[344]​
El coste de las células solares de silicio cristalino ha descendido desde 76,67 $/Wp en 1977 hasta aproximadamente 0,36 $/Wp en 2014.[345]​[340]​ Esta tendencia sigue la llamada ley de Swanson, una predicción similar a la conocida Ley de Moore, que establece que los precios de los módulos solares descienden un 20 % cada vez que se duplica la capacidad de la industria fotovoltaica.[346]​
En 2014, el precio de los módulos solares se había reducido en un 80 % desde el verano de 2008,[347]​[348]​ colocando a la energía solar por primera vez en una posición ventajosa respecto al precio de la electricidad pagado por el consumidor en un buen número de regiones soleadas.[349]​ En este sentido, el coste medio de generación eléctrica de la energía solar fotovoltaica es ya competitivo con el de las fuentes convencionales de energía en una creciente lista de países,[350]​ particularmente cuando se considera la hora de generación de dicha energía, ya que la electricidad es usualmente más cara durante el día.[351]​ Se ha producido una dura competencia en la cadena de producción, y asimismo se esperan mayores caídas del coste de la energía fotovoltaica en los próximos años, lo que supone una creciente amenaza al dominio de las fuentes de generación basadas en las energías fósiles.[352]​ Conforme pasa el tiempo, las tecnologías de generación renovable son generalmente más baratas,[353]​[354]​ mientras que las energías fósiles se vuelven más caras:
Cuanto más desciende el coste de la energía solar fotovoltaica, más favorablemente compite con las fuentes de energía convencionales, y más atractiva es para los usuarios de electricidad en todo el mundo. La fotovoltaica a pequeña escala puede utilizarse en California a precios de 100 $/MWh (0,10 $/kWh) por debajo de la mayoría de otros tipos de generación, incluso aquellos que funcionan mediante gas natural de bajo coste. Menores costes en los módulos fotovoltaicos también suponen un estímulo en la demanda de consumidores particulares, para los que el coste de la fotovoltaica se compara ya favorablemente al de los precios finales de la energía eléctrica convencional.[355]​
En 2011, el coste de la fotovoltaica había caído bastante por debajo del de la energía nuclear,[356]​ y se espera que siga cayendo:[357]​
Para instalaciones a gran escala, ya se han alcanzado precios por debajo de 1 $/vatio. Por ejemplo, en abril de 2012 se publicó un precio de módulos fotovoltaicos a 0,60 Euros/Vatio (0,78 $/Vatio) en un acuerdo marco de 5 años.[358]​
En algunas regiones, la energía fotovoltaica ha alcanzado la paridad de red, que se define cuando los costes de producción fotovoltaica se encuentran al mismo nivel, o por debajo, de los precios de electricidad que paga el consumidor final (aunque en la mayor parte de las ocasiones todavía por encima de los costes de generación en las centrales de carbón o gas, sin contar con la distribución y otros costes inducidos). La energía fotovoltaica se genera durante un período del día muy cercano al pico de demanda (lo precede) en sistemas eléctricos que hacen gran uso del aire acondicionado. Más generalmente, es evidente que, con un precio de carbón de 50 $/tonelada, que eleva el precio de las plantas de carbón a 5 cent./kWh, la energía fotovoltaica será competitiva en la mayor parte de los países. El precio a la baja de los módulos fotovoltaicos se ha reflejado rápidamente en un creciente número de instalaciones, acumulando en todo 2011 unos 23 GW instalados ese año. Aunque se espera cierta consolidación en 2012, debido a recortes en el apoyo económico en los importantes mercados de Alemania e Italia, el fuerte crecimiento muy probablemente continuará durante el resto de la década. De hecho, ya en un estudio se mencionaba que la inversión total en energías renovables en 2011 había superado las inversiones en la generación eléctrica basada en el carbón.[357]​
La tendencia es que los precios disminuyan aún más con el tiempo una vez que los componentes fotovoltaicos han entrado en una clara y directa fase industrial.[359]​[360]​ A finales de 2012, el precio medio de los módulos fotovoltaicos había caído a 0,50 $/Wp, y las previsiones apuntan que su precio seguirá reduciéndose hasta los 0,36 $/Wp en 2017.[361]​
En 2015, el Instituto alemán Fraunhofer especializado en energía solar (ISE) realizó un estudio que concluía que la mayoría de los escenarios previstos para el desarrollo de la energía solar infravaloran la importancia de la fotovoltaica.[362]​ El estudio realizado por el instituto Fraunhofer estimaba que el coste levelizado (LCOE) de la energía solar fotovoltaica para plantas de conexión a red se situará a largo plazo entre 0,02 y 0,04 €/kWh, niveles inferiores a los de las fuentes de energía convencionales.[363]​
Extracto de las conclusiones del estudio de Fraunhofer ISE: Current and Future Cost of Photovoltaics. Long-term Scenarios for Market Development, System Prices and LCOE of Utility-Scale PV Systems (Coste actual y futuro de la energía fotovoltaica. Escenarios a largo plazo para el desarrollo del mercado, sistemas de precios y LCOE de sistemas fotovoltaicos de conexión a red)— Febrero de 2015:[363]​
La energía solar fotovoltaica ya es actualmente una tecnología de generación renovable de bajo coste. El coste de las plantas fotovoltaicas a gran escala conectadas a red cayó en Alemania desde valores superiores a 0,40 €/kWh en 2005 hasta los 0,09 €/kWh en 2014. Se han publicado costes incluso menores en otras regiones más soleadas del resto del mundo, dado que una buena parte de los componentes de las plantas fotovoltaicas se comercializan en los mercados globales.
La energía solar pronto se convertirá en la fuente de energía más barata en muchas regiones del mundo. Incluso suponiendo proyecciones conservadoras y considerando que no se producirán avances tecnológicos importantes, no se espera un parón en la reducción de costes que se está produciendo actualmente. Dependiendo de la irradiación anual del emplazamiento elegido, el coste de la fotovoltaica se situará entre los 0,04-0,06 €/kWh para 2025, alcanzando 0,02-0,04 €/kWh antes de 2050 (estimación conservadora).
El ambiente financiero y regulatorio serán la clave para las futuras reducciones de coste de esta tecnología. El coste de los componentes en los mercados globales descenderá independientemente de las condiciones locales de cada país. Pero una regulación inadecuada pueden suponer un incremento de coste de hasta el 50 % debido al mayor coste de financiación. Esto puede incluso llegar a compensar negativamente el hecho de contar con un mayor recurso solar en algunas zonas.
La mayoría de los escenarios previstos para el desarrollo de la energía solar infravaloran la importancia de la fotovoltaica. Basados en estimaciones de costes desactualizadas, la mayor parte de las proyecciones para el futuro de los sistemas energéticos domésticos, regionales y globales prevén tan sólo una pequeña producción de energía solar. Los resultados de nuestro análisis indican que se hace necesaria una revisión fundamental de este aspecto para lograr una optimización de los costes.
Otra alternativa de bajo coste a las células de silicio cristalino es la energía fotovoltaica de capa o película fina que está basada en las células solares de tercera generación.[365]​ Consisten en una célula solar que se fabrica mediante el depósito de una o más capas delgadas (película delgada) de material fotovoltaico en un sustrato.
Las células solares de película delgada suelen clasificarse según el material fotovoltaico utilizado:
Células solares sensibilizadas por colorante (DSC)[369]​ y otras células solares orgánicas.[370]​La Conferencia Internacional Energía Solar de Bajo Costo de Sevilla, realizada en febrero de 2009, fue el primer escaparate en España de las mismas.[371]​ Esta tecnología causó grandes expectativas en sus inicios. Sin embargo, la fuerte caída en el precio de las células y los módulos de silicio policristalino desde finales de 2011 ha provocado que algunos fabricantes de capa fina se hayan visto obligados a abandonar el mercado, mientras que otros han visto muy reducidos sus beneficios.[372]​
La cantidad de energía solar que alcanza a la superficie terrestre es enorme, cerca de 122 petavatios (PW), y equivale a casi 10 000 veces más que los 13 TW consumidos por la humanidad en 2005.[373]​ Esta abundancia sugiere que no pasará mucho tiempo antes de que la energía solar se convierta en la principal fuente de energía de la humanidad.[374]​ Adicionalmente, la generación eléctrica mediante fotovoltaica presenta la mayor densidad energética (una media global de 170 W/m2) de todas las energías renovables.[373]​
A diferencia de las tecnologías de generación de energía basadas en combustibles fósiles, la energía solar fotovoltaica no produce ningún tipo de emisiones nocivas durante su funcionamiento,[1]​ aunque la producción de los paneles fotovoltaicos presenta también un cierto impacto ambiental. Los residuos finales generados durante la fase de producción de los componentes, así como las emisiones de las factorías, pueden gestionarse mediante controles de contaminación ya existentes. Durante los últimos años también se han desarrollado tecnologías de reciclaje para gestionar los diferentes elementos fotovoltaicos al finalizar su vida útil,[375]​ y se están llevando a cabo programas para incrementar el reciclaje entre los productores fotovoltaicos.[376]​
La tasa de retorno energético de esta tecnología, por su parte, es cada vez mayor. Con la tecnología actual, los paneles fotovoltaicos recuperan la energía necesaria para su fabricación en un período comprendido entre 6 meses y 1 año y medio; teniendo en cuenta que su vida útil media es superior a 30 años, producen electricidad limpia durante más del 95 % de su ciclo de vida.
Las emisiones de gases de efecto invernadero a lo largo del ciclo de vida para la fotovoltaica son cercanas a los 46 g/kWh, pudiendo reducirse incluso hasta 15 g/kWh en un futuro próximo.[378]​
En comparación, un planta de gas de ciclo combinado emite entre 400-599 g/kWh,[379]​ un planta de gasoil 893 g/kWh,[379]​ una planta de carbón 915-994 g/kWh[380]​ o con tecnología de captura de carbono unos 200 g/kWh (excluyendo las emisiones durante la extracción y el transporte de carbón), y una planta de energía geotérmica de alta temperatura, entre 91-122 g/kWh.[379]​ La intensidad de las emisiones para el ciclo de vida de la energía hidráulica, eólica y la energía nuclear es menor que la de la energía fotovoltaica, según los datos publicados por el IPCC en 2011.[379]​
Al igual que todas las fuentes de energía cuyas emisiones dependen principalmente de las fases de construcción y transporte, la transición hacia una economía de bajo carbono podría reducir aún más las emisiones de dióxido de carbono durante la fabricación de los dispositivos solares.
Un sistema fotovoltaico de 1 kW de potencia ahorra la combustión de aproximadamente 77 kg (170 libras) de carbón, evita la emisión a la atmósfera de unos 136 kg (300 libras) de dióxido de carbono, y ahorra mensualmente el uso de unos 400 litros (105 galones) de agua.[381]​
Una instalación fotovoltaica puede operar durante 30 años o más[382]​ con escaso mantenimiento o intervención tras su puesta en marcha, por lo que tras el coste de inversión inicial necesario para construir una instalación fotovoltaica, sus costes de operación son muy bajos en comparación con el resto de fuentes energéticas existentes. Al finalizar su vida útil, la mayor parte de los paneles fotovoltaicos puede ser tratada. Gracias a las innovaciones tecnológicas que se han desarrollado en los últimos años, se puede recuperar hasta el 95 % de ciertos materiales semiconductores y el vidrio, así como grandes cantidades de metales ferrosos y no ferrosos utilizados en los módulos.[383]​ Algunas empresas privadas[384]​ y organizaciones sin fines de lucro, como por ejemplo PV CYCLE en la Unión Europea, están trabajando en las operaciones de recogida y reciclaje de paneles al final de su vida útil.[385]​
Paneles de silicio: Los marcos de aluminio y las cajas de conexión son desmantelados manualmente al comienzo del proceso. El panel se tritura y las diferentes fracciones se separan: vidrio, plásticos y metales.[386]​ Es posible recuperar más de 80 % del peso entrante[387]​ y, por ejemplo, el cristal mixto extraído es fácilmente aceptado por las industrias de la espuma de vidrio y del aislamiento. Este proceso puede ser realizado por los recicladores de vidrio plano ya que la morfología y composición de un panel fotovoltaico es similar al cristal plano utilizado en la industria de la construcción y del automóvil.
Paneles de otros materiales: Hoy en día se cuenta con tecnologías específicas para el reciclaje de paneles fotovoltaicos que no contienen silicio, algunas técnicas utilizan baños químicos para separar los diferentes materiales semiconductores.[388]​ Para los paneles de teluro de cadmio, el proceso de reciclaje empieza por aplastar el módulo y, posteriormente, separar las diferentes partes. Este proceso de reciclaje está diseñado para recuperar hasta un 90 % del vidrio y 95 % de los materiales semiconductores.[389]​ En los últimos años, algunas empresas privadas han puesto en marcha instalaciones de reciclaje a escala comercial.[390]​Desde 2010 se celebra una conferencia anual en Europa que reúne a productores, recicladores e investigadores para debatir el futuro del reciclaje de módulos fotovoltaicos. En 2012 tuvo lugar en Madrid.[391]​[392]​
Balfour, John R., Shaw, M. y Jarosek, S. (2011). Introduction to Photovoltaics (en inglés). Ed. Jones & Bartlett. p. 218. ISBN 978-1-4496-2473-6. 
Boxwell, M. (2013). Solar Electricity Handbook: A Simple Practical Guide to Solar Energy (en inglés). Greenstream Publishing. p. 200. ISBN 978-1-907670-28-2. 
Castañer, L. y Markvart, T. (2003). Practical handbook of photovoltaic: fundamentals and applications (en inglés). Ed. Elsevier. ISBN 1-85617-390-9. 
Fernández Salgado, José M. (2008). Guía completa de la energía solar fotovoltaica. A. Madrid Vicente. p. 296. ISBN 978-84-96709-12-6. 
Hegedus, S. y Luque, A. (2011). Handbook of Photovoltaic Science and Engineering (en inglés) (2ª edición). John Wiley and Sons. p. 1132. ISBN 978-0-470-72169-8. 
Kennedy, Danny (2012). Rooftop Revolution: How Solar Power Can Save Our Economy-and Our Planet-from Dirty Energy (en inglés). Berrett-Koehler Publishers. p. 192. ISBN 978-1609946647. 
Komp, Richard J. (2002). Practical Photovoltaics: Electricity from Solar Cells (en inglés). Ed. Aatec. p. 218. ISBN 978-0-937948-11-8. 
Lorenzo, Eduardo (2006). Radiación solar y dispositivos fotovoltaicos. Progensa. ISBN 84-95693-31-3. 
Lynn, Paul A. (2010). Electricity from Sunlight: An Introduction to Photovoltaics (en inglés). John Wiley and Sons Ltd. p. 238. ISBN 978-0-470-74560-1. 
Perlin, John (1999). From Space to Earth: The Story of Solar Electricity (en inglés). Harvard University Press. p. 224. ISBN 978-0-937948-14-9. 
Rapp, D. (1981). Solar Energy (en inglés). Englewood Cliffs, N.Y., EEUU.: Prentice Hall, Inc. p. 198. ISBN 0-13-822213-4. 
Solanki, C. S. (2009). Solar Photovoltaics: Fundamentals Technologies And Applications (en inglés). Ed. Phi Learning Pvt. Ltd. p. 478. ISBN 978-81-203-4386-3. 
VVAA (2000). Fundamentos, dimensionado y aplicaciones de la energía solar fotovoltaica. Madrid: Ed. CIEMAT (Centro de Investigaciones Energéticas, Medioambientales y Tecnológicas. ISBN 84-7834-371-7. 
VVAA (2004). Photovoltaics Design And Installation Manual: Renewable Energy Education for a Sustainable Future (en inglés). Solar Energy International - New Society Publishers. p. 317. ISBN 978-0-86571-520-2. 
Wenham, Stuart R. (2007). Applied Photovoltaics (en inglés). Ed. Earthscan. p. 323. ISBN 978-1-84407-401-3.
Página web de UNEF (Unión Española Fotovoltaica) Principal asociación del sector fotovoltaico en España
