
The Metallurgical Laboratory (or Met Lab) was a scientific laboratory at the University of Chicago that was established in February 1942 to study and use the newly discovered chemical element plutonium. It researched plutonium's chemistry and metallurgy, designed the world's first nuclear reactors to produce it, and developed chemical processes to separate it from other elements. In August 1942 the lab's chemical section was the first to chemically separate a weighable sample of plutonium, and on 2 December 1942, the Met Lab produced the first controlled nuclear chain reaction, in the reactor Chicago Pile-1, which was constructed under the stands of the university's old football stadium, Stagg Field.
The Metallurgical Laboratory was established as part of the Metallurgical Project, also known as the "Pile" or "X-10" Project, headed by Arthur H. Compton, a Nobel Prize laureate. In turn, this was part of the Manhattan Project – the Allied effort to develop the atomic bomb during World War II. The Metallurgical Laboratory was successively led by Richard L. Doan, Samuel K. Allison, Joyce C. Stearns and Farrington Daniels. Scientists who worked there included Enrico Fermi, James Franck, Eugene Wigner and Glenn Seaborg. At its peak on 1 July 1944, it had 2,008 staff.
Chicago Pile-1 was soon moved by the lab to a more remote site in the Argonne Forest, where its original materials were used to build an improved Chicago Pile-2. Another reactor, Chicago Pile-3, was built at the Argonne site in early 1944. This was the world's first reactor to use heavy water as a neutron moderator. It went critical in May 1944, and was first operated at full power in July 1944. The Metallurgical Laboratory also designed the X-10 Graphite Reactor at the Clinton Engineer Works in Oak Ridge, Tennessee, and the B Reactor at the Hanford Engineer Works in the state of Washington.
As well as the work on reactor development, the Metallurgical Laboratory studied the chemistry and metallurgy of plutonium, and worked with DuPont to develop the bismuth phosphate process used to separate plutonium from uranium. When it became certain that nuclear reactors would involve radioactive materials on a gigantic scale, there was considerable concern about the health and safety aspects, and the study of the biological effects of radiation assumed greater importance. It was discovered that plutonium, like radium, was a bone seeker, making it especially hazardous. The Metallurgical Laboratory became the first of the national laboratories, the Argonne National Laboratory, on 1 July 1946.  The work of the Met Lab also led to the creation of the Enrico Fermi Institute and the James Franck Institute at the university.
The discovery of nuclear fission in uranium by German chemists Otto Hahn and Fritz Strassmann in December 1938, and its theoretical explanation (and naming) by Lise Meitner and Otto Frisch soon after, opened up the possibility that neutrons produced by fission could create a controlled nuclear chain reaction. At Columbia University, Enrico Fermi and Leo Szilard began exploring how this might be achieved. In August 1939, Szilard drafted a confidential letter to the President of the United States, Franklin D. Roosevelt, warning of the possibility of a German nuclear weapon project, and convinced his old friend and collaborator Albert Einstein to co-sign it. This resulted in support for research into nuclear fission by the U.S. government.In April 1941, the National Defense Research Committee (NDRC), asked Arthur Compton, a Nobel-Prize-winning physics professor at the University of Chicago, to report on the uranium program. Niels Bohr and John Wheeler theorized that heavy isotopes with odd atomic numbers, such as plutonium-239, were fissile. Emilio Segrè and Glenn Seaborg at the University of California produced 28 μg of plutonium in the 60-inch cyclotron there in May 1941, and found that it had 1.7 times the thermal neutron capture cross section of uranium-235. While minute quantities of plutonium-239 could be created in cyclotrons, it was not feasible to produce a large quantity that way. Compton conferred with Eugene Wigner from Princeton University about how plutonium might be produced in a nuclear reactor, and with Robert Serber from the University of Illinois about how the plutonium produced in a reactor might then be chemically separated from uranium it was bred from.On 20 December, soon after the Japanese attack on Pearl Harbor that brought the United States into the war, Compton was placed in charge of the plutonium project. Its objectives were to produce reactors to convert uranium to plutonium, to find ways to chemically separate the plutonium from the uranium, and to design and build an atomic bomb. Although a successful reactor had not yet been built, the scientists had already produced several different but promising design concepts. It fell to Compton to decide which of these should be pursued. He proposed an ambitious schedule that aimed to achieve a controlled nuclear chain reaction by January 1943, and to have a deliverable atomic bomb by January 1945.Compton felt that having teams at Columbia, Princeton, the University of Chicago and the University of California created too much duplication and not enough collaboration, and he resolved to concentrate the work in one location. Nobody wanted to move, and everybody argued in favor of their own location. In January 1942, soon after the United States entered World War II, Compton decided to concentrate the work at his own location, the University of Chicago, where he knew he had the unstinting support of university administration, whereas Columbia was engaged in uranium enrichment efforts and was hesitant to add another secret project. Other factors contributing to the decision were Chicago's central location and the availability of scientists, technicians and facilities in the Midwest that had not yet been taken away by war work. Housing was more readily available, and an inland city was less vulnerable to enemy attack.
The new research establishment was formed in February 1942, and named the "Metallurgical Laboratory" or "Met Lab". Some real metallurgy was carried out, but the name was intended as a cover for its activities. The University of Chicago had been considering establishing a research institute into metals, and indeed would do so after the war, so its creation attracted little attention. Compton's plutonium project then became known as the Metallurgical Project. The Metallurgical Laboratory was administered by the University of Chicago under contract to the Office of Scientific Research and Development (OSRD).Over 5,000 people in 70 research groups participated in Compton's Metallurgical Project, also known as the "Pile" or "X-10" Project, of whom some 2,000 worked in the Metallurgical Laboratory in Chicago. Despite the good salaries being offered, recruiting was difficult. There was competition for scientists and engineers from other defense-related projects, and Chicago was expensive compared with university towns.Norman Hilberry was associate director of the Metallurgical Project, and Richard L. Doan was appointed the Director of the Metallurgical Laboratory. While Doan was an able administrator, he had difficulty being accepted as the head of the laboratory, since he was not an academic. On 5 May 1943, Compton replaced him with Samuel K. Allison, and appointed Henry D. Smyth as associate director. Initially there were three physics groups, headed by Allison, Fermi and Martin D. Whitaker. Frank Spedding was in charge of the Chemistry Division. He was later succeeded by Herbert McCoy, and then by James Franck. Compton placed Robert Oppenheimer in charge of the bomb design effort in June 1942. In November 1942, this became a separate project, known as Project Y, which was located in Los Alamos, New Mexico.After the United States Army Corps of Engineers took over the Manhattan Project in August 1942, the Manhattan District coordinated the work. From 17 February 1943, Compton reported to the director of the Manhattan Project, Brigadier General Leslie R. Groves, Jr., instead of the OSRD S-1 Section.  The Manhattan District assumed full responsibility for the Metallurgical Laboratory contract on 1 May 1943. Captain J. F. Grafton was appointed the Chicago Area Engineer in August 1942. He was succeeded by Captain Arthur V. Peterson in December 1942. Peterson remained until October 1944. Captain J. F. McKinley became Chicago Area Engineer on 1 July 1945.
At first, most of the Laboratory office space was provided by the University of Chicago. The physicists took over space under the North and West Stands of Stagg Field and in the Service Building, where there was a cyclotron. The chemists took over the George Herbert Jones Laboratory and the Kent Chemical Laboratory. The health group took space in the Anatomy Building, Drexel House, Billings Hospital and the Killis Laboratory and the administrative offices went into Eckhart Hall. Szilard later wrote that "the morale of the scientists could almost be plotted in a graph by counting the number of lights burning after dinner in the offices at Eckhart Hall." When the project outgrew its space in Eckhart Hall, it moved into the nearby Ryerson Hall. The Metallurgical Laboratory eventually occupied 205,000 square feet (19,000 m2) of campus space. About $131,000 worth of alterations were made to buildings occupied by the laboratory but the University of Chicago also had to make alterations for users displaced by it.
The University of Chicago made a 0.73-acre (0.30 ha) site occupied by tennis courts available to the Manhattan District on a one dollar lease, for the construction of a new chemistry building with 20,000 square feet (1,900 m2) of space. Stone and Webster commenced work on this in September 1942 and it was completed in December. It was soon found to be too small and an adjacent 0.85-acre (0.34 ha) plot was added to the lease, on which a 30,000-square-foot (2,800 m2) annex was built and completed in November 1943. Extensive work was then carried out on the ventilation system to allow the laboratory to work with plutonium more safely. A site containing an ice house and stables owned by the University in Chicago was made available in April 1943. Known as Site B, it was remodeled to provide 62,670 square feet (5,822 m2) of laboratories and workshops for the health and metallurgy groups. The 124th Field Artillery Armory was leased from the state of Illinois to provide more space in March 1944 and about 360,000 square feet (33,000 m2) of space was leased or built, at a cost of $2 million.For reasons of safety and security, it was not desirable to locate the facilities for experiments with nuclear reactors in densely populated Chicago. Compton selected a site in the Argonne Forest, part of the Forest Preserve District of Cook County, about 20 miles (32 km) southwest of Chicago, which became known as Site A. The War Department leased 1,088 acres (440 ha) of land there from Cook County for the duration of the war plus one year for a dollar. Construction of facilities including laboratories and service buildings and an access road was commenced in September 1942 and completed in early 1943. Compton appointed Fermi as the first director of the Argonne Laboratory.
Between 15 September and 15 November 1942, groups under Herbert L. Anderson and Walter Zinn constructed sixteen experimental reactors (known at the time as "piles") under the Stagg Field stands. Fermi designed a new uranium and graphite pile that could be brought to criticality in a controlled, self-sustaining nuclear reaction. Construction at Argonne fell behind schedule due to Stone & Webster's difficulty recruiting enough skilled workers and obtaining the required building materials. This led to an industrial dispute, with union workers taking action over the recruitment of non-union labor. When it became clear that the materials for Fermi's new pile would be on hand before the new structure was completed, Compton approved a proposal from Fermi to build the pile under the stands at Stagg Field.Construction of the reactor, known as Chicago Pile-1 (CP-1), began on the morning of 16 November 1942. The work was carried out in twelve-hour shifts, with a day shift under Zinn and a night shift under Anderson. When completed, the wooden frame supported an elliptical-shaped structure, 20-foot (6.1 m) high, 6-foot (1.8 m) wide at the ends and 25 feet (7.6 m) across the middle. It contained 6 short tons (5.4 t) of uranium metal, 50 short tons (45 t) of uranium oxide and 400 short tons (360 t) of graphite, at an estimated cost of $2.7 million. On 2 December 1942, it achieved the first controlled self-sustaining nuclear reaction. On 12 December 1942, CP-1's power output was increased to 200 W, enough to power a light bulb. Lacking shielding of any kind, it was a radiation hazard for everyone in the vicinity. Thereafter, testing was continued at the lower power of 0.5 W.
The operation of Chicago Pile-1 was terminated on 28 February 1943. It was dismantled and moved to Argonne, where the original materials were used to build Chicago Pile-2 (CP-2). Instead of being spherical, the new reactor was built in a cube-like shape, about 25 feet (7.6 m) tall with a base approximately 30 feet (9.1 m) square. It was surrounded by concrete walls 5 feet (1.5 m) thick that acted as a radiation shield, and with overhead protection from 6 inches (15 cm) of lead and 50 inches (130 cm) of wood. More uranium was used, so it contained 52 short tons (47 t) of uranium and 472 short tons (428 t) of graphite. No cooling system was provided as it only ran at a few kilowatts. CP-2 became operational in March 1943.
A second reactor, known as Chicago Pile-3, or CP-3, was built at the Argonne site in early 1944. This was the world's first reactor to use heavy water as a neutron moderator. It had been unavailable when CP-1 was built, but was now becoming available in quantity thanks to the Manhattan Project's P-9 Project. The reactor was a large aluminum tank, 6 feet (1.8 m) in diameter, which was filled with heavy water, which weighed about 6.5 short tons (5.9 t). The cover was pierced by regularly spaced holes through which 121 uranium rods sheathed in aluminum projected into the heavy water. The tank was surrounded by a graphite neutron reflector, which in turn was surrounded by a lead shield, and by concrete. Shielding on the top of the reactor consisted of layers of 1-foot (30 cm) square removable bricks composed of layers of iron and masonite. The heavy water was cooled with a water-cooled heat exchanger. As well as the control rods, there was an emergency mechanism for dumping the heavy water into a tank below. Construction began on 1 January 1944. The reactor went critical in May 1944, and was first operated at full power of 300 kW in July 1944.During the war Zinn allowed it to be run around the clock, and its design made it easy to conduct experiments. This included tests to investigate the properties of isotopes such as tritium and determine the neutron capture cross section of elements and compounds that might be used to construct future reactors, or occur in impurities. They were also used for trials of instrumentation, and in experiments to determine thermal stability of materials, and to train operators.
The design of the reactors for plutonium production involved several problems, not just in nuclear physics but in engineering and construction. Issues such as the long-term effect of radiation on materials received considerable attention from the Metallurgical Laboratory. Two types of reactors were considered: homogeneous, in which the moderator and fuel were mixed together, and heterogeneous, in which the moderator and fuel were arranged in a lattice configuration. By late 1941, mathematical analysis had shown that the lattice design had advantages over the homogeneous type, and so it was chosen for CP-1, and for the later production reactors as well. For a neutron moderator, graphite was chosen on the basis of its availability compared with beryllium or heavy water.
The decision of what coolant to use attracted more debate. The Metallurgical laboratory's first choice was helium, because it could be both a coolant and a neutron moderator. The difficulties of its use were not overlooked. Large quantities would be required, and it would have to be very pure, with no neutron-absorbing impurities. Special blowers would be required to circulate the gas through the reactor, and the problem of leakage of radioactive gases would have to be solved. None of these problems were regarded as insurmountable. The decision to use helium was conveyed to DuPont, the company responsible for building the production reactors, and was initially accepted.In early 1943, Wigner and his Theoretical Group that included Alvin Weinberg, Katharine Way, Leo Ohlinger, Gale Young and Edward Creutz produced a design for a production reactor with water cooling. The choice of water as a coolant was controversial, as it was known to absorb neutrons, thereby reducing the efficiency of the reactor, but Wigner was confident that his group's calculations were correct and that with the purer graphite and uranium that was now available, water would work, while the technical difficulties involved in using helium as a coolant would delay the project.The design used a thin layer of aluminum to protect the uranium from corrosion by the cooling water. Cylindrical uranium slugs with aluminum jackets would be pushed through channels through the reactor and drop out the other side into a cooling pond. Once the radioactivity subsided, the slugs would be taken away and the plutonium extracted. After reviewing the two designs, the DuPont engineers chose the water-cooled one. In 1959 a patent for the reactor design would be issued in the name of Creutz, Ohlinger, Weinberg, Wigner, and Young.The use of water as a coolant raised the problem of corrosion and oxidation of the aluminum tubing. The Metallurgical Laboratory tested various additives to the water to determine their effect. It was found that corrosion was minimized when the water was slightly acidic, so dilute sulfuric acid was added to the water to give it a pH of 6.5. Other additives such as sodium silicate, sodium dichromate and oxalic acid were also introduced to the water to prevent a build up of film that could inhibit the circulation of the cooling water. The fuel slugs were given a jacket of aluminum to protect the uranium metal from corrosion that would occur if it came into contact with the water, and to prevent the venting of gaseous radioactive fission products that might be formed when they were irradiated. Aluminum was chosen because the cladding had to transmit heat but not absorb too many neutrons. The aluminum canning process was given close attention, as ruptured slugs could jam or damage the channels in the reactor, and the smallest holes could vent radioactive gases. The Metallurgical Laboratory investigated production and testing regimes for the canning process.An important area of research concerned the Wigner effect. Under bombardment by neutrons, the carbon atoms in the graphite moderator can be knocked out of the graphite's crystalline structure. Over time, this causes the graphite to heat and swell. Investigation of the problem would take most of 1946 before a fix was found.
Metallurgical work concentrated on uranium and plutonium. Although it had been discovered over a century before, little was known about uranium, as evidenced by the fact that many references gave a figure for its melting point that was off by nearly 500 °F (280 °C). Edward Creutz investigated it and discovered that at the right temperature range, uranium could be hammered and rolled, and drawn into the rods required by the production reactor design. It was found that when uranium was cut, the shavings would burst into flame. Working with Alcoa and General Electric, the Metallurgical Laboratory devised a method of soldering the aluminum jacket to the uranium slug.The metallurgy of plutonium was completely unknown, for it had only recently been discovered. In August 1942, Seaborg's team chemically isolated the first weighable amount of plutonium from uranium irradiated in the Jones Laboratory. Until reactors became available, minuscule amounts of plutonium were produced in the cyclotron at Washington University in St. Louis. The chemistry division worked with DuPont to develop the bismuth phosphate process used to separate plutonium from uranium.
The dangers of radiation poisoning had become well known due to the experience of the radium dial painters. When it became certain that nuclear reactors would involve radioactive materials on a gigantic scale, there was considerable concern about the health and safety aspects. Robert S. Stone, who had worked with Ernest Lawrence at the University of California, was recruited to head the Metallurgical Project's health and safety program. Simeon Cutler, a radiologist, assumed responsibility for radiation safety in Chicago, before moving on to head the program at the Hanford Site. Groves appointed Stafford L. Warren from the University of Rochester as head of the Manhattan Project's Medical Section. Over time, the study of the biological effects of radiation assumed greater importance. It was discovered that plutonium, like radium, was a bone seeker, making it especially hazardous.The Metallurgical Laboratory's Health Division set standards for radiation exposure. Workers were routinely tested at University of Chicago clinics, but this could be too late. Personal quartz fiber dosimeters were procured, as were film badge dosimeters, which recorded cumulative dosage. Stone's Health Division worked closely with William P. Jesse's Instrumentation Group in the Physics Division to develop detectors, including portable Geiger counters. Herbert M. Parker created a metric for radiation exposure he called the roentgen equivalent man or rem. After the war, this replaced the roentgen as the standard measure of radiation exposure. Work to assess the toxicity of plutonium got under way when the plutonium semiworks at the Clinton Engineer Works began producing it in 1943. The project set a limit of 5 micrograms (μg) in the body, and work practices and workplaces at Chicago and Clinton were modified to ensure that this standard was met.
During 1943 and 1944, the Metallurgical Laboratory focused on first getting the X-10 Graphite Reactor at the Clinton Engineer Works up and running, and then the B Reactor at the Hanford Site. By the end of 1944, the focus had switched to training operators. Much of the chemistry division moved to Oak Ridge in October 1943, and many personnel were transferred to other Manhattan Project sites in 1944, particularly Hanford and Los Alamos. Fermi became a division head at Los Alamos in September 1944, and Zinn became the director of the Argonne Laboratory. Allison followed in November 1944, taking with him many of the Metallurgical Laboratory's staff, including most of the instrument section. He was replaced by Joyce C. Stearns. Farrington Daniels, who became associate director on 1 September 1944, succeeded Stearns as director on 1 July 1945.
Where possible, the University of Chicago attempted to re-employ workers who had been transferred from the Metallurgical Laboratory to other projects once their work had ended. Replacing staff was nearly impossible, as Groves had ordered a staffing freeze. The only division to grow between November 1944 and March 1945 was the health division; all the rest lost 20 percent or more of their staff. From a peak of 2,008 staff on 1 July 1944, the number of people working at the Metallurgical Laboratory fell to 1,444 on 1 July 1945.The end of the war did not end the flow of departures. Seaborg left on 17 May 1946, taking much of what remained of the chemistry division with him. On 11 February 1946, the Army reached an agreement with University President Robert Hutchins for the staff and equipment of the Metallurgical Project to be taken over by a regional laboratory based at Argonne, which the university still manages. On 1 July 1946, the Metallurgical Laboratory became Argonne National Laboratory, the first designated national laboratory, with Zinn as its first director. The new laboratory had 1,278 staff on 31 December 1946, when the Manhattan Project ended, and responsibility for the national laboratories passed to the Atomic Energy Commission, which replaced the Manhattan Project on 1 January 1947. The work of the Metallurgical Laboratory also led to the founding of the Enrico Fermi Institute, as well as the James Franck Institute, at the University of Chicago.Payments made to the University of Chicago under the original 1 May 1943 non-profit contract totaled $27,933,134.83, which included $647,671.80 in construction and remodeling costs. The contract expired on 30 June 1946, and was replaced by a new contract, which ended on 31 December 1946. A further $2,756,730.54 was paid under this contract, of which $161,636.10 was spent on construction and remodeling. An additional $49,509.83 was paid to the University of Chicago for the restoration of its facilities.In 1974, the United States government began cleaning up the old Manhattan Project sites under the Formerly Utilized Sites Remedial Action Program (FUSRAP). This included those used by the Metallurgical Laboratory. Stagg Field had been demolished in 1957, but 23 locations in Kent Laboratory were decontaminated in 1977, and another 99 at the Eckhart, Ryerson, and the Jones Laboratory in 1984. About 600 cubic feet (17 m3) of solid and three 55-gallon drums of liquid waste were collected and shipped to various sites for disposal. The Atomic Energy Commission terminated its lease on the Armory site in 1951, and it was restored to the state of Illinois. Testing in 1977, 1978 and 1987 indicated residual levels of radioactivity that exceeded Department of Energy guidelines, so decontamination was carried out in 1988 and 1989, after which the site was declared suitable for unrestricted use.
Video of west stands of Stagg Field, Institute for the Study of Metals (Metallurgical Laboratory), Enrico Fermi, and an active experiment using CP-1
The meteorological history of Hurricane Dean began in the second week of August 2007 when a vigorous tropical wave moved off the west coast of Africa into the North Atlantic ocean.  Although the wave initially experienced strong easterly wind shear, it quickly moved into an environment better suited for tropical development and gained organization.  On the morning of August 13, the National Hurricane Center recognized the system's organization and designated it Tropical Depression Four while it was still more than 1,500 mi (2,400 km) east of the Lesser Antilles.
A deep layered ridge to its north steered the system west as it moved rapidly towards the Caribbean and into warmer waters. On August 14 the depression gained strength and was upgraded to Tropical Storm Dean. By August 16, the storm had intensified further and attained hurricane status. Hurricane Dean continued to intensify as it tracked westward through the Lesser Antilles. Once in the Caribbean Sea, the storm rapidly intensified to a Category 5 hurricane on the Saffir-Simpson Hurricane Scale. Weakening slightly, it brushed the southern coast of Jamaica on August 19 as a Category 4 hurricane and continued towards the Yucatán Peninsula through even warmer waters.  The favorable conditions of the western Caribbean Sea allowed the storm to intensify and it regained Category 5 status the next day before making landfall in southern Quintana Roo.
Hurricane Dean was one of two storms in the 2007 Atlantic hurricane season to make landfall as a Category 5 hurricane and was the seventh most intense Atlantic hurricane ever recorded, tied with Camille and Mitch. After its first landfall, Hurricane Dean crossed the Yucatán Peninsula and emerged, weakened, into the Bay of Campeche. It briefly restrengthened in the warm waters of the bay before making a second landfall in Veracruz. Dean progressed to the northwest, weakening into a remnant low which finally dissipated over the southwestern United States.
On August 11, 2007, a vigorous tropical wave moved off the west coast of Africa, producing disorganized showers and thunderstorms. It encountered conditions favorable for gradual development, and on August 12 it gained organization and became a low. Strong upper-level easterly winds slowed development, but on August 13 the tropical wave gained enough organization that the National Hurricane Center designated it Tropical Depression Four. At this time it was centered about 520 mi (835 km) west-southwest of Cape Verde.The depression was already exhibiting persistent deep convection in the western portion of its circulation. It moved quickly westward, south of a deep layered ridge, escaping the easterly wind shear that had been slowing its development and moving over warmer waters. At 1500 UTC on August 14, the depression was upgraded to Tropical Storm Dean while still 1450 mi (2300 km) east of Barbados. Even as its convection waned slightly that afternoon, its intensity grew, and convection flared in the center that night. Dry air and cooler air inflow from the north slowed structural development; nevertheless, ragged bands began to form on August 15. By mid-morning, a rough banding eye had formed, and by the next morning a full eye developed. The storm was upgraded to Hurricane Dean at 0900 UTC August 16, 550 mi (890 km) east of Barbados.A strong ridge of high pressure continued to push the system west, towards the Caribbean Sea. That afternoon, convective banding and increasing upper-level outflow strengthened the storm to a Category 2 hurricane on the Saffir-Simpson Hurricane Scale. The eye disappeared briefly overnight, possibly as part of a diurnal fluctuation, but returned by the morning of August 17.
At 0930 UTC on August 17, the center of Hurricane Dean passed into the Caribbean Sea through the Saint Lucia Channel between the islands of Martinique and St. Lucia. The northern eyewall passed over Martinique where a weather station in the island's capital of Fort-de-France reported 13 in (33 cm) of rainfall. By this time the eyewall had closed, forming a distinct eye, and in an environment of low wind shear and increasing ocean temperature the hurricane began to intensify rapidly. Hurricane Dean strengthened to a Category 3 hurricane by the evening of August 17. Satellite imagery showed that a well defined eye and numerous cyclonically curved convective bands remained over the Lesser Antilles. That evening, another reconnaissance aircraft reached the hurricane and discovered that it had strengthened into a Category 4 hurricane, and by 0600 UTC on August 18, Dean reached Category 5 intensity for the first time with 165 mph (270 km/h) winds. The storm's wind radii increased in all quadrants as the storm grew in both intensity and size. At 0800 UTC August 18, Hurricane Dean passed directly over NOAA sea buoy 42059 which reported a significant wave height (average size of the largest 33% of waves) of 33 ft (10 m). On August 18, Hurricane Dean developed a double eyewall, indicating that an eyewall replacement cycle was taking place and causing short term fluctuations in intensity as Dean weakened back to a Category 4 hurricane. That afternoon the hurricane continued to improve its outflow, and its numerous spiral bands gave it a well defined satellite presentation. Hurricane Dean finished the eyewall replacement cycle early on August 19 with some trochiodal wobbles.
On the morning of August 19, the storm remained slightly weakened from its peak strength. As a Category 4 hurricane with wind speeds between 140 mph (220 km/h) and 145 mph (230 km/h), the center of Hurricane Dean passed 90 mi (150 km) south of Haiti, and that evening passed 25 mi (40 km) south of Jamaica. Two weather stations on the island of Jamaica, one at Ingleside and the other at Morant Bay, both reported in excess of 13 in (33 cm) of rainfall. In contrast, the weather station at Les Cayes, Haiti recorded only 1.18 in (3 cm) of rainfall.
Hurricane Dean intensified through the night of August 19 and reinforced its completed eyewall replacement cycle by forming a tight single-walled eye. At 0100 UTC August 20, the storm passed 120 mi (190 km) to the south of Sea Buoy 42056, which recorded a significant wave height of 36 ft (11 m). A concentric eyewall was briefly observed again on the morning of August 20, but it did not last long. In conditions of low wind shear, Hurricane Dean moved westward over waters with increasingly high heat content, and the storm exhibited a classic upper-tropospheric outflow pattern. The high pressure system over the southeastern United States continued to steer the storm west towards the Yucatán Peninsula. The eyewall became even better defined throughout the day. The cloud tops cooled, the minimum central pressure fell, and its winds increased to 160 mph (260 km/h), making Hurricane Dean a Category 5 hurricane once again. This time, it was less than 210 mi (335 km) from its first landfall.Although many of the convective bands were already located over the Yucatán Peninsula, Hurricane Dean continued to intensify until the eye made landfall. As the eye moved over Mexico near the town of Majahual in the Costa Maya area, the NHC estimated surface level winds of 175 mph (280 km/h), making Dean the first storm to make landfall as a Category 5 hurricane in the Atlantic basin since Hurricane Andrew in 1992. At the same time, a dropsonde reading from the hurricane's eye estimated a central pressure of 905 mbar, making Dean the third most intense landfalling Atlantic storm in history (after the Labor Day Hurricane of 1935 and Hurricane Gilbert of 1988) and tying Dean with Camille and Mitch as the seventh most intense hurricane ever recorded in the Atlantic basin. The landfall itself occurred in a sparsely populated area of the Costa Maya region of the Mexican state of Quintana Roo near 18.7 N 87.8 W at 0900 UTC August 21 and brought with it a storm surge of 12–18 ft (3.7–5.5 m). A weather station at Chetumal (the capital of Quintana Roo, Mexico) reported 6.65 in (17 cm) of rainfall during Hurricane Dean's landfall. As expected, the landfall caused significant weakening of the storm; the eye filled and the cold cloud-tops warmed. The land severely disrupted the storm's organization, and by the time Dean crossed the Yucatán Peninsula it had weakened to a Category 1 hurricane.
Hurricane Dean emerged into the Bay of Campeche as a Category 1 hurricane on the afternoon of August 21. Its inner core was largely disrupted, so although a ragged eye reformed over the warm waters of the bay, the hurricane no longer had the structure to support its previous strength. Nevertheless, the warm waters of the bay proved conducive for some development and the eye contracted overnight, indicating that the hurricane was regaining structure. With better structure came stronger winds of 100 mph (160 km/h), and the storm was re-categorized as a Category 2 hurricane.The storm's strengthening pattern continued until Hurricane Dean made its second and final landfall at 1630 UTC August 22 near Tecolutla, Veracruz, just east of Gutiérrez Zamora and about 40 mi (65 km) south-southeast of Tuxpan. A weather station at Requetemu, San Luis Potosí, recorded 15.4 in (39 cm) of rainfall during the storm's second landfall. Dean weakened rapidly, losing its low level circulation within hours and its mid-level circulation the next day as it encountered the Sierra Madre Oriental mountain range. Its remnants passed over the mountains and into the eastern Pacific Ocean as a broad area of low pressure. Hurricane Dean's remnant low pressure system then drifted north into southern California, bringing thunderstorms to northern San Diego County, and more than 2 in (5 cm) of rain to Lake Wohlford. In Escondido almost 2 in (5 cm) of rain fell in 90 minutes. The remnant low pressure system weakened over western Arizona and southern California before finally dissipating on August 30.

Hurricane Gordon developed during a fourteen-day period along an erratic, persistent, and highly unusual path. The hurricane formed near Panama in the southwestern Caribbean on November 8, 1994. As a tropical depression, it brushed Nicaragua and spent several days in the waters off the country's coast. Strengthening slightly into a tropical storm, Gordon wound its way north into the Greater Antilles. Despite warm waters, persistent wind shear prevented significant strengthening. Executing a slow turn to the north and then the northwest, Gordon made two more landfalls, on eastern Jamaica and eastern Cuba, while delivering tremendous rains to western Hispaniola.
As Gordon made its fourth landfall crossing the Florida Keys, it interacted with a cyclone in the upper-troposphere  and a series of cyclonic lows which lent the storm some sub-tropical characteristics. After a few days as an unusual hybrid of a tropical and a subtropical system in the Gulf of Mexico, the storm re-claimed its fully tropical form and made yet another landfall, this time across the Florida peninsula, and continued into the Atlantic Ocean. In the Atlantic, Gordon rapidly strengthened to a Category 1 hurricane. Gordon's characteristic wandering briefly brought it near North Carolina, but ultimately the storm headed south, weakening into a minor tropical storm before making its sixth and final landfall on Florida's east coast.
Hurricane Gordon was the seventh named storm and third hurricane of the 1994 Atlantic hurricane season. Although it never made landfall as a hurricane, in its meandering course the storm included six separate landfalls: four as a tropical storm and two as a tropical depression. Three of its landfalls were in the U.S. state of Florida.
During the first week of November 1994 a large area of disturbed weather accumulated just north of Panama over the southwestern Caribbean Sea. A tropical wave passed through the area and gave it mild convection. A second wave passed through the area on November 6 and introduced cyclonic circulation to the disturbance. Over the next two days, the system gradually organized and sparked a deep convection off Nicaragua's southeast coast. This organization, with initial maximum sustained winds of 30 mph (45 km/h), was designated Tropical Depression Twelve. Moving northwest, the storm began to slowly strengthen and its upper-level  outflow became favorable to further development. Spots of convection flared on the morning of November 9;  banding features appeared  as its center made landfall on the northeastern Nicaraguan coast near Puerto Cabezas. A full day later a trough to the storm's northwest over the Gulf of Mexico moved the depression offshore, to the northeast, and over the warm waters of the western Caribbean Sea. Fueled by these warm waters, on the night of November 9, it strengthened into Tropical Storm Gordon with 40 mph (65 km/h) winds.Lacking firm movement because of weak steering currents, Gordon meandered north-northeast in the presence of mild west-southwesterly wind shear, unable to strengthen under the adverse conditions. By November 11, a trough prodded Gordon to the north-northeast at 8 mph (13 km/h), and it strengthened by 6 mph (9 km/h) as it moved through the central Caribbean Sea. The trough continued steering Gordon, bending it eastward towards Jamaica on the afternoon on November 12. Despite the warm waters, Gordon did not strengthen that day as strong upper-tropospheric shear hindered development, disorganized the upper-level circulation, and reduced its winds to 40 mph (65 km/h).
November 13 was an active day for Tropical Storm Gordon. The trough over southern Florida and the Gulf of Mexico continued to push Gordon eastward towards Jamaica. In the pre-dawn hours, the storm clipped the eastern edge of the island,  leaving 7.44 in (18.9 cm) of rainfall. Southwesterly wind shear kept the storm from developing beyond 45 mph (75 km/h), but neither the shear nor the landfall significantly disrupted the cyclone's organization. Accelerating, Gordon turned towards the northeast. Continued shear prevented the upper-level development needed for typical cyclonic organization, but a strong lower level circulation had formed. Its sustained winds were still only 40 mph (65 km/h), but as the system approached eastern Cuba a gust of 120 mph (192 km/h) was reported. The center crossed near Guantánamo Bay and the storm dumped heavy rainfall as it passed over the eastern portion of the island; even heavier rain fell in Haiti to the west, where 22.94 in (58.27 cm) of rain was recorded at Camp-Perrin.Meanwhile, the broad-scale circulation that was covering most of the Caribbean Sea (of which Tropical Storm Gordon was only a part) was interacting with an upper-tropospheric trough near the Straits of Florida. This trough strengthened the broad upper-level cyclone, which in turn strengthened Gordon and spawned several other low-level circulations in the western Caribbean Sea. When Gordon crossed eastern Cuba, the National Hurricane Center determined that it had become the most dominant of these low-level systems and had absorbed their convections.  (Meteorologist Jose Fernandez-Partagas voiced the minority opinion that Gordon's circulatory center had dissipated over Cuba and that a low-pressure system near the Bahamas was now the dominant system, which would have meant the demise of Tropical Storm Gordon and the emergence of a new tropical storm. While possible, this view was not accepted by the official hurricane summaries.) By nightfall of November 13, Gordon had not only made two landfalls and survived interactions with three competing systems but also, in assimilating the Bahamian low, had gained the cool central core typical of a subtropical cyclone.The deep-layered cyclone within which Gordon was embedded steered the storm west-northwest, south of Turks and Caicos and the Bahamas, on November 14. A large ridge of high-pressure near the U.S. Mid-Atlantic coast increased the pressure gradient around the storm, so although its sub-tropical elements (namely a lack of deep convection) precluded a core of strong winds immediately around the storm's nucleus, strong winds were supported  outside the storm's circulatory center. These winds inched up to 50 mph (85 km/h) but did not strengthen any further. The ridge continued to steer the hybrid Tropical/Subtropical Storm Gordon west-northwestward past the western Bahamas. This brought the southern portion of the storm's circulation over northern Cuba, while the strengthening northern circulation produced 60 mph (90 km/h) winds near Palm Beach. The storm's fourth landfall occurred on November 15 when Gordon passed over the Florida Keys near Key West, Florida. The storm then continued west over the lower Keys and into the Straights of Florida, where the storm's center began to warm and deep convection signaled the return of Gordon's purely tropical characteristics.
Steering currents remained weak giving the storm a chance to fully re-develop its deep convection while immobile at sea. During this time, Tropical Storm Gordon began to spawn tornadoes. As the storm center was well offshore most were probably unreported, but six tornadoes touched down on the Florida coast. Four of the tornadoes were rated F0 on the Fujita scale, two were rated F1, and one was given an F2 rating with estimated wind speeds of 113–157 mph (181–253 km/h).After stalling offshore for almost a day, a mid- to upper-tropospheric trough over the central U.S. slowly pulled Tropical Storm Gordon northward then north-northeastward towards Florida's west coast. The storm made landfall between Ft. Myers and Naples with 50 mph (85 km/h) winds. The eastward component of the storm's movement increased, and Gordon moved northeastward onto the Florida Peninsula at 10 mph (17 km/h). The storm barely weakened as it crossed the landmass keeping its 50 mph (85 km/h) winds. Crossing the peninsula in a mere six hours, the storm continued to pick up speed. Early on November 17, back over the open ocean, the storm's central pressure began to fall. Improved organization was not apparent and wind shear was pulling at the core of the deep convection when, on November 17, Gordon suddenly spawned 75 mph (120 km/h) winds and was upgraded to a Category 1 hurricane.
The shortwave trough that had been steering Gordon across Florida moved ahead of the storm and its influence was replaced by a mid-tropospheric ridge over the eastern United States. Under the influence of this new ridge, the storm, which had been speeding northeast at 25 mph (40 km/h), turned to the north late on November 17. The hurricane's loop continued, and as it moved to a west-northwesterly heading Gordon briefly threatened North Carolina's Outer Banks before stalling offshore once again. In the presence of weak steering currents once again, Gordon lost  strength and slipped back to tropical storm status with 70 mph (110 km/h) winds. On November 18, about 90 mi (150 km) off the Outer Banks, Gordon began a southward drift away from the North Carolina coast. In its brush with the Mid-Atlantic States, Gordon dropped 2–5 in (5–13 cm) with a maximum of 5.25 in (13.3 cm) recorded at Norfolk, Virginia. Warm waters improved its organization, but this did not result in stronger winds and the storm continued to weaken. Strong upper-level winds battered the storm from the northwest. They sheared away Gordon's upper-level convection while polluting the storm with colder and drier air that weakened its lower level convection.A high-pressure system over the central United States drifted east and added a westward component to Gordon's southward motion, pulling the storm southwest towards Florida. The persistent shear and a continued lack of deep convection eventually reduced the storm's winds to below tropical storm force, and on the morning on November 20, Gordon became a tropical depression. The high pressure system over the continent continued pulling the depression towards the west until it made its final landfall near Cape Canaveral that night with winds of 30 mph (45 km/h). Between its three Floridian landfalls, Hurricane Gordon dumped 5–10 in (13–25 cm) of rain on Florida, with a station at Cooperstown recording 16.1 in (40.9 cm). The storm moved northward across Florida, northeastward across Georgia, and finally merged with a frontal system over South Carolina.
Gordon's track was likened to Hurricane Dawn in 1972. The National Hurricane Center described the storm as "a complex system, [which] followed an unusual, erratic path over the western Caribbean Sea and islands, Florida and the southwestern Atlantic." Due to the path, the agency had difficulties in forecasting Gordon, and the forecast errors were 10% to 30% above the average of the previous decade.

The meteorological history of Hurricane Ivan, the longest tracked tropical cyclone of the 2004 Atlantic hurricane season, lasted from late August through late September. The hurricane developed from a tropical wave that moved off the coast of Africa on August 31. Tracking westward due to a ridge, favorable conditions allowed it to develop into Tropical Depression Nine on September 2 in the deep tropical Atlantic Ocean. The cyclone gradually intensified until September 5, when it underwent rapid deepening and reached Category 4 status on the Saffir-Simpson Hurricane Scale; at the time Ivan was the southernmost major North Atlantic hurricane on record.
Ivan quickly weakened due to dry air, but it gradually reorganized, passing just south of Grenada as a major hurricane on September 7. The hurricane attained Category 5 status in the central Caribbean Sea. Over the subsequent days its intensity fluctuated largely due to eyewall replacement cycles, and Ivan passed just south of Jamaica, the Cayman Islands, and western Cuba with winds at or slightly below Category 5 status. Turning northward and encountering unfavorable conditions, Ivan gradually weakened before making landfall just west of Gulf Shores, Alabama on September 16 with winds of 120 mph (195 km/h). The cyclone quickly weakened to tropical depression status as it turned to the northeast, and Ivan transitioned into an extratropical cyclone on September 18.
The remnant low of Ivan turned to the south and southwest, and after crossing Florida on September 21 it began to reacquire tropical characteristics. It became a tropical depression again on September 22 to the southeast of Louisiana, and Ivan reached winds of 60 mph (95 km/h) before weakening and moving ashore along southwestern Louisiana as a tropical depression; the circulation of Ivan dissipated after crossing into Texas on September 25. The cyclone broke several intensity records, and its duration was the tenth-longest on record for an Atlantic hurricane.
On August 31, a large tropical wave moved off the west coast of Africa. A tropical system along the wave axis contained a low pressure area as well as an impressive outflow pattern, though initially its convection was disorganized and limited. By September 1 a cyclonic circulation with a diameter of 690 miles (1115 km) was evident on satellite imagery, well to the southeast of the Cape Verde Islands. Several hurricane forecast models anticipated development and strengthening. As it tracked quickly westward, the convection organized and developed into rainbands – bands of showers and thunderstorms that spiral cyclonically toward the storm center – and late on September 1 meteorologists began tracking the system using the Dvorak technique. Low amounts of wind shear and favorable outflow allowed vigorous deep convection to develop and persist near the center, and by 1800 UTC on September 2 the system developed into Tropical Depression Nine about 450 miles (730 km) southwest of Praia, Cape Verde.Upon being classified as a tropical cyclone, the depression was embedded within a deep easterly steering current provided by a ridge to its north. Expected to track across sea surface temperatures greater than 82 °F (28 °C), the cyclone was forecast to gradually strengthen and within four days attain hurricane status; the Geophysical Fluid Dynamics Laboratory predicted the depression to reach Category 4 status on the Saffir–Simpson Hurricane Scale within three days. Increased northeasterly wind shear shifted the center to the northeastern edge of the deep convection, and despite the shear and its relatively low latitude of 9.7° N, the depression strengthened to attain tropical storm status early on September 3; upon reaching the intensity, the National Hurricane Center classified the system as Tropical Storm Ivan.Tropical Storm Ivan gradually became better organized as wind shear decreased, and its outflow expanded in all quadrants. Satellite imagery late on September 3 depicted a well-defined curved band wrapping around much of the circulation. The next day, the deep convection temporarily became ill-defined, before reorganizing and developing an eye feature. Convection strengthened further as the feature transitioned into an eye, and Ivan became a hurricane at around 0600 UTC on September 5. After reaching hurricane status, Ivan began to rapidly intensify with continued favorable conditions, and in an 18‑hour period the pressure dropped 39 mbar (1.15 inHg) as the winds increased by 60 mph (95 km/h); early on September 6 Ivan attained an initial peak intensity of 135 mph (215 km/h) while located about 825 miles (1330 km) east of the island of Tobago in the southern Lesser Antilles.While at major hurricane status, Ivan maintained very strong convection in its core with a well-defined eye. Operationally, the probability for further rapid strengthening was considered nearly nine times the average of a typical hurricane. Accordingly, Ivan was forecast to pass near Barbados with winds of about 150 mph (240 km/h). Shortly after attaining Category 4 status, the outer convection of the hurricane became ragged. Hurricane Hunters found a Saharan Air Layer in the northern portion of the eye, leaving the eyewall eroded which caused a marked decrease in winds; by late on September 6 Ivan weakened to winds of 105 mph (165 km/h). The inner eyewall dissipated as a 23-mile (37 km) outer eyewall became dominant, and concurrently the overall organization of the hurricane improved. Ivan again attained major hurricane status as it approached the Lesser Antilles, and at 2130 UTC on September 7 the cyclone passed 7 miles (11 km) south-southwest of the southern tip of Grenada, its closest approach to the island. At the time, the hurricane maintained an eye diameter of 12 miles (19 km), with the northern portion of the eyewall producing strong winds on the island. The hurricane brought strong winds to Grenada, and tropical storm force winds were reported as far north as Dominica.
Hurricane Ivan again reached Category 4 status as it entered the Caribbean Sea. Subsequently, it underwent an eyewall replacement cycle, and for about 18 hours the intensity remained constant as it paralleled the northern coast of Venezuela offshore. Another period of rapid deepening began late on September 8 as its motion turned to the west-northwest. Hurricane Hunters recorded flight-level sustained winds of 180 mph (290 km/h) to the north and northeast of the eye, and a dropsonde about 630 feet (190 m) above the surface recorded winds of 200 mph (325 km/h) and an extrapolated pressure of 916 mbar (27.05 inHg). Based on the reports, it is estimated Ivan attained Category 5 status at 0600 UTC on September 9, while located about 90 miles (145 km) north of Aruba. At the time, the cyclone was forecast to strike southern Florida as a major hurricane.After maintaining Category 5 status for about 12 hours, Ivan began a steady weakening trend due to another eyewall replacement cycle until reaching winds of 140 mph (225 km/h) on September 10. Early next day, the hurricane reorganized as it reached winds just shy of Category 5 status. However, weakening occurred again due to an eyewall replacement cycle, and at 0330 UTC on September 11 Ivan passed 23 miles (37 km) south of Portland Point, Jamaica, its closest approach, with winds of 150 mph (240 km/h). The hurricane was previously forecast to make landfall on the island, though the weakening and a turn to the west kept the strongest winds offshore; however, sustained winds of Category 4 status were reported. While passing to the south of the island, the hurricane dropped heavy rainfall, with several stations reporting over 2 feet (60 cm) of precipitation. Ivan's last-minute turn to the west was due to a mid-level high pressure system over the eastern Gulf of Mexico. A slight weakening trend continued after passing the island, due to its northern outflow being disrupted by an upper-level low over the Bahamas. As it tracked further away from Jamaica, Ivan again rapidly intensified to Category 5 status, and early on September 12 it reached its peak intensity of 165 mph (265 km/h) with a pressure of 910 mbar (26.87 inHg).
Shortly after peaking in intensity, the hurricane again weakened as it underwent an eyewall replacement cycle. At 1415 UTC on September 12 Ivan passed 25 miles (40 km) south-southwest of George Town, Cayman Islands, where sustained winds of 150 mph (240 km/h) were reported. The storm surge from the hurricane flooded all of Grand Cayman Island. After its eyewall became re-established Ivan attained Category 5 status for a third time early on September 13. Shortly thereafter, a trough created a weakness in the ridge to its north, causing the hurricane to turn to the northwest. The combination of enhanced outflow from the trough and very warm waters allowed Ivan to maintain Category 5 status for 30 hours. Early on September 14 the hurricane passed through the Yucatán Channel about 17 miles (28 km) southwest of Cabo San Antonio, Cuba, with the eastern portion of the eyewall crossing the western portion of the island. Only the extreme western portion of the island experienced hurricane-force winds, although rainfall from the hurricane was reported across the island.
After entering the southern Gulf of Mexico, Hurricane Ivan weakened to Category 4 status by 0600 UTC on September 14. As it gradually turned to the north, southwesterly flow from a large trough over the central United States increased wind shear over the hurricane. An eyewall replacement cycle, along with dry air and restricted outflow, contributed to the weakening. By late on September 14 the weakening trend ceased as the eyewall became better defined, and Ivan was expected to restrengthen slightly over an area of warmer water temperatures. The eye diameter expanded to 60 miles (95 km/h), though concurrently westerly wind shear and dry air continued to increase. As Ivan approached the Gulf Coast of the United States, Hurricane Hunters reported erosion of the southern portion of the eyewall, and cooler waters just offshore contributed to further weakening. At around 0650 UTC on September 16, Hurricane Ivan made landfall just west of Gulf Shores, Alabama with an intensity of 120 mph (195 km/h); the strongest winds occurred over a narrow area near the southern Alabama and western Florida border. Its landfall was accompanied by a 10–15 feet (3–4.5 m) storm surge from Destin, Florida westward to Mobile Bay.Upon moving ashore, the National Hurricane Center expected the forward path of Ivan to be blocked, and accordingly forecast the hurricane to stall in the southern Appalachian Mountains before dissipating. As the hurricane crossed Mobile Bay it turned to the north-northeast, and within twelve hours Ivan rapidly weakened to tropical storm status. The circulation became less-defined, and early on September 17 the cyclone deteriorated into a tropical depression over northeastern Alabama. Ivan accelerated to the northeast ahead of an approaching cold front, dropping heavy rainfall along its path and also producing a widespread tornado outbreak from Alabama through Maryland. Late on September 18, the remnants of Ivan transitioned into an extratropical low as it merged with the cold front over the Delmarva Peninsula.
After becoming an extratropical low, the remnants of Ivan turned to the southeast and emerged into the Atlantic Ocean, due to the building of an upper-level ridge to its east. As an extratropical cyclone, Ivan remained identifiable in both surface and upper-level data, and the system turned south and southwestward over the subsequent days. By September 20, the system was located off the east coast of Florida, producing scattered thunderstorms; unfavorable wind shear prevented tropical redevelopment, though forecasters indicated the possibility for more favorable conditions a few days later. On September 21 the low crossed southern Florida and emerged into the Gulf of Mexico, and as it moved across the warm waters of the region the low began to re-acquire tropical characteristics; the low-level circulation became increasingly better defined, and convection redeveloped over the center. Based on reports from Hurricane Hunters, it is estimated the low redeveloped into Tropical Depression Ivan late on September 22 while located about 175 miles (280 km) south-southeast of the mouth of the Mississippi River.In its first advisory on the re-developed cyclone, the National Hurricane Center classified the system Ivan "after considerable and sometimes animated in-house discussion of [its demise]... in the midst of a low-pressure and surface frontal system over the eastern United States... based primarily on the reasonable continuity observed in the analysis of the surface and low-level circulation." Despite unfavorable shear and its disorganized cloud structure, the cyclone intensified to tropical storm status early on September 23, based on reports by Hurricane Hunters. As an area of deep convection developed over the center, Ivan reached winds of 60 mph (95 km/h), though the winds decreased as thunderstorm activity diminished. Ivan weakened to a tropical depression at 0000 UTC on September 24, and two hours later it moved ashore near Holly Beach, Louisiana. Initial computer models forecast the low-level circulation to turn southwestward and re-emerge into the Gulf of Mexico. However, the storm rapidly weakened over land, and by 1200 UTC on September 24, Ivan degenerated into a remnant low pressure area over southeast Texas. The low turned to the south and the circulation dissipated early on September 25. The remnant trough reached the northwestern Gulf of Mexico later that day, briefly producing scattered thunderstorms before it diminished.
Reaching Category 3 status on the Saffir–Simpson Hurricane Scale at 10.2° N, Ivan became the southernmost major hurricane on record. Additionally, the hurricane attained Category 4 status further south than any other North Atlantic hurricane, at 10.6° N. At the time, Ivan was the sixth-most intense Atlantic hurricane on record; it has since dropped to eleventh. Throughout its duration, Ivan maintained winds of major hurricane status or greater for a total of 10 days, establishing an Atlantic hurricane record. Lasting as a tropical cyclone for a total of 450 hours, Ivan was the tenth-longest-tracked Atlantic hurricane on record.Upon making its two landfalls in the United States, the hurricane spawned a total of 120 tornadoes, which is the largest tornado outbreak associated with a tropical cyclone; this broke the previous record of 115 set by Hurricane Beulah in 1967.

The meteorological history of Hurricane Jeanne lasted for about two weeks in September 2004. Hurricane Jeanne was the eleventh tropical cyclone, tenth named storm, seventh hurricane, and sixth major hurricane  of the 2004 Atlantic hurricane season. It formed from a tropical wave on September 13 near the Lesser Antilles, and encountered favorable enough conditions to reach tropical storm status. Jeanne strengthened further in the eastern Caribbean Sea, becoming a strong tropical storm and developing an eye before striking Puerto Rico on September 15. Remaining well-organized, it attained hurricane status before hitting the eastern tip of the Dominican Republic on September 16.
Hurricane Jeanne steadily weakened while crossing eastern Hispaniola, and on September 17 it briefly weakened to tropical depression status after reaching open waters. Its original circulation dissipated as a new one reformed closer to the main area of thunderstorms. Turning northward, Jeanne slowly reorganized and again reached hurricane status on September 20. It executed a clockwise loop to the west, weakening due to upwelling upon reaching its path again. Jeanne encountered favorable conditions as it continued westward, and it reached major hurricane status before crossing the northern Bahamas on September 25. The next day, it struck Martin County, Florida in nearly the same location as Hurricane Frances just weeks before. Jeanne weakened over land while turning the northwest, deteriorating to tropical depression status over Georgia on September 27. It turned northeastward, becoming extratropical on September 28 before dissipating on September 29 after merging with a cold front.
The hurricane produced heavy rainfall across its path, including in Haiti where precipitation caused devastating mudslides; over 3,000 deaths were reported in the country. Heavy rainfall also occurred during its landfalls on Puerto Rico and Florida, resulting in river flooding. In its strongest landfall, the hurricane produced strong winds across an area earlier affected by Hurricane Frances and, in some locations, by Hurricane Charley. Late in its duration, the combination of moisture from Jeanne and cool air resulted in a tornado outbreak that extended from Georgia through the Mid-Atlantic states.
The origins of Hurricane Jeanne were from a tropical wave that moved off the coast of Africa on September 7. Containing a scattered area of moderate convection, the wave tracked westward at 12–17 mph (19–28 km/h), located to the south of a large ridge. The system initially showed no signs of development, with unfavorably dry air persisting across the region. On September 11, convection became slightly better organized, and the next day broad cyclonic turning became evident. However, overall development was hindered by upper-level wind shear from Hurricane Ivan in the Caribbean Sea, as well as from an upper-level low to the north of the wave.Late on September 12, while approaching the northern Lesser Antilles, convection increased and became better organized around an area of increased cyclonic turning. Environmental conditions became more favorable, allowing for the development of a low pressure area and for banding features to increase. Late on September 13, with the formation of a broad low-level circulation, it is estimated the system developed into Tropical Depression Eleven about 70 mi (110 km) east-southeast of Guadeloupe.
Upon first becoming a tropical cyclone, the depression was located to the south of the subtropical ridge, resulting in a west-northwest track which brought the center over Guadeloupe. The circulation was initially broad, and dry air temporarily entrained the northwest quadrant of the storm. However, environmental conditions were favorable enough for further development, with a deepening trough to its west providing beneficial flow. Banding features improved around the circulation, and the National Hurricane Center upgraded the depression to Tropical Storm Jeanne on September 13 about 135 mi (220 km) southeast of Saint Croix. While crossing the Lesser Antilles, the storm brought locally heavy rainfall, with a total of 12 inches (305 mm) reported in Guadeloupe.Tropical Storm Jeanne quickly organized over the eastern Caribbean Sea, developing a tight inner core and well-defined outflow as it tracked over warm water temperatures of about 84 °F (29 °C). Initially, the storm was forecast to attain hurricane status before crossing Puerto Rico. However, its organization deteriorated by early on September 15, with radar imagery tracking a low-level circulation moving away from the convection. The temporary weakening was due increased shear and dry air. At 1600 UTC on September 15, Jeanne made landfall near Guayama, Puerto Rico with winds of 70 mph (115 km/h), and as it moved ashore it was in the process of developing an eye. Across the territory, the storm produced heavy rainfall, peaking at 23.75 inches (605 mm) on Vieques Island. Rainfall across the region resulted in moderate to severe river flooding, with several river stations in Puerto Rico reporting historical levels. Light winds, generally around tropical storm force, affected the region as well.
Tropical Storm Jeanne remained over Puerto Rico for about eight hours, during which it maintained its eye feature and well-defined inner core of convection. It intensified over the Mona Passage, and attained hurricane status as it struck the eastern tip of the Dominican Republic on September 16. Continuing slowly west-northwestward near the coast, Jeanne quickly weakened to tropical storm status, and by 24 hours after landfall its convection had deteriorated as the eye feature dissipated. Late on September 17, it emerged into the Atlantic Ocean as a tropical depression, after having dropped torrential rainfall across Hispaniola. Catastrophic flooding and mudslides were experienced in Haiti, including in the coastal city of Gonaïves, and over 3,000 deaths were reported in the country.On September 17, while it was over Hispaniola, the National Hurricane Center issued a forecast that predicted Jeanne to make landfall near Savannah, Georgia in about five days. However, the forecast noted uncertainty in regards to the steering currents, which depended on the movement of the remnants of Hurricane Ivan and a ridge building behind it. After it left the nation as a tropical depression, the original center of circulation tracked westward away from the convection and dissipated. However, a new circulation developed closer to the convection, and Jeanne regained tropical storm status on September 18. By then, the mid-level circulation associated with Hurricane Ivan had combined with a trough to weaken the ridge located across the western Atlantic Ocean; this caused Jeanne to track northward through the Turks and Caicos Islands.As it tracked northward, the storm failed to organize at first, due to the influence of an upper-level low to its south. The circulation became broad and elongated, as well as removed from the deepest convection. However, after moving away from the low, the convection became better organized and more associated with the convection. After some initial slow organization continued, an area of deep convection developed over the center midday on September 20. An eye developed within the convection, and late on September 20 Jeanne re-attained hurricane status about 350 mi (570 km) east-northeast of the Abaco Islands in the Bahamas.While intensifying as a tropical storm, the National Hurricane Center faced difficulties in the future track of Jeanne, based on two major divergences between computer hurricane models. One scenario involved the storm accelerating east-northeastward to the south of a trough, following the path of Hurricane Karl to its east. The other scenario involved Jeanne turning southeastward and looping westward due to a building ridge. By early on September 20, the official forecast followed the first scenario, though later that day, officials changed the forecast to indicate the turn to the south.
Hurricane Jeanne steadily intensified as it turned eastward, developing a 52 mi (83 km) wide eye. A motion to the southeast began on September 22, and around the same time it reached winds of 100 mph (160 km/h), making it a Category 2 hurricane on the Saffir-Simpson scale. At the same time, the National Hurricane Center forecast to turn westward and later northwestward, with its projected five-day track within 60 mi (100 km) of Cape Fear, North Carolina. The westernmost outlier during one model run was the NOGAPS model, which predicted a continued westward motion across central Florida. The official forecast changed early on September 23 to bring Jeanne across northeastern Florida, though initially the cyclone was predicted to turn northeastward and hit South Carolina as a hurricane.By September 23, Jeanne had begun a slow westward motion, with its previously well-defined eye becoming ragged. It moved slowly over waters it traversed just four days prior, causing upwelling; this is the process in which a stationary storm causes the water temperatures to decrease by bringing the cooler, deeper waters to the surface. As a result, Jeanne weakened to a minimal hurricane midday on September 23, though it was forecast to re-intensify and attain major hurricane status. By early on September 24, the winds had decreased to 80 mph (130 km/h); its convection weakened in intensity, and the eyewall eroded due to dry air entrainment. However, as Jeanne moved toward an area of warmer waters, deep convection redeveloped around the eye. Its favorable upper-level environment allowed the outflow to become better defined, with a large eye and nearby dry air being the primary restraining factors for development. At 1200 UTC on September 25, Jeanne attained major hurricane status, and two hours later it made landfall on Abaco Island.
After it had been previously forecast to turn northwestward and track along the northeastern Florida coast, the forecast shifted 24 hours prior to moving ashore to a landfall point in the east-central portion of the state; the change was due to the persistence of the ridge to its north. The hurricane moved over Grand Bahama Island, and in the Bahamas it produced wind gusts of up to 130 mph (210 km/h). As it approached the Florida coastline it did not strengthen much further, due to an eyewall replacement cycle; this is the process in which an outer eyewall forms, causing the original eye to shrink and dissipate due to lack of moisture. At 0400 UTC on September 26, Jeanne made landfall with peak winds of 120 mph (195 km/h) on the southern end of Hutchinson Island near Stuart, Florida, with an eye 50 mi (85 km) in diameter. The hurricane moved ashore in almost the same location as Hurricane Frances, which made landfall 21 days prior.Upon moving inland in east-central Florida, the hurricane produced a storm tide of up to 10 feet (3 m) in St. Lucie County. In New Smyrna Beach, the storm tide washed away much of the beach to the east of the city seawall. Overall impact from the storm tide was less than expected, due to the storm hitting at low tide. Jeanne produced peak winds of 120 mph (195 km/h) in a very small north of the center near Sebastian, though the National Hurricane Center noted the possibility of the strongest winds remaining over water. The National Weather Service office in Melbourne recorded sustained winds of 91 mph (147 km/h), which was the strongest official sustained wind reading; stronger readings were not available due to widespread power outages along its track. Wind gusts peaked at 128 mph (206 km/h) in Fort Pierce. In addition to the winds, the hurricane dropped heavy rainfall in the vicinity of its eyewall, peaking at 11.97 inches (304 mm) in Kenansville. The rainfall caused freshwater flooding, as well as increased levels along the St. Johns River. The hurricane also produced several eyewall mesovortices and tornadoes near where it moved ashore.
As Hurricane Jeanne moved inland, its inner eyewall dissipated, and its outer eyewall quickly became less distinct. It turned west-northwestward over the state, curving around the western periphery of the ridge to its northeast. By 14 hours after landfall, Jeanne weakened to tropical storm status near the Tampa Bay area. In western Florida, offshore winds produced a tide of 4.5 feet (1.4 m) below normal in Cedar Key; however, after the storm passed the area, the onshore winds produced above normal tides. Despite initial forecasts that it would emerge into the Gulf of Mexico, the storm remained over land and continued to slowly weaken. Early on September 27, dry air became entrained into the southern periphery of the circulation, which diminished the thunderstorms to the south. After turning northward, Jeanne entered southern Georgia and weakened into a tropical depression.As it moved northward, Jeanne continued to drop moderate to heavy rainfall, including over 7 inches (175 mm) in southern Georgia. A cold front across the region caused the depression to accelerate northeastward, combining moisture from the Gulf of Mexico with cool and stable air over the Carolinas. This combination produced severe thunderstorms across the region, spawning six tornadoes in Georgia, eight in South Carolina, and eight in North Carolina.After crossing into Virginia, Jeanne transitioned into an extratropical cyclone by September 29 near Washington, D.C. In Wilmington, Delaware, the storm spawned an F2 tornado. Across the Mid-Atlantic and New England, moisture from the storm produced light to heavy rainfall, with totals of over 7 inches (175 mm) near Philadelphia and Nantucket. Subsequent to becoming extratropical, the remnants of Jeanne turned eastward, exited into the Atlantic Ocean, and merged with a cold front.

Hurricane Katrina was an extremely destructive Category 5 hurricane that affected the majority of the Gulf Coast. Its damaging trek began on August 23, 2005 when it originated as Tropical Depression Twelve near the Bahamas. The next day, the tropical depression strengthened to a tropical storm, and was named Katrina; it proceeded to make landfall on the southern tip of the U.S. state of Florida as a minimal hurricane.
In passing across Florida, Katrina did not attain any more strength but did manage to maintain hurricane status. After passing over Florida, the warm waters of the Gulf of Mexico allowed it to rapidly intensify to the sixth-strongest Atlantic hurricane in recorded history. Afterward, Katrina made landfall as a Category 3 storm near Buras-Triumph, Louisiana, and once more near the Mississippi/Louisiana border. Katrina progressed northward through the central United States and finally dissipated near the Great Lakes on August 31, when it was absorbed by a cold front.
Tropical Depression Twelve formed over the southeastern Bahamas at 5:00 p.m. EDT (2100 UTC) on August 23, 2005, partially from the remains of Tropical Depression Ten, which had dissipated due to the effects of a nearby upper tropospheric trough. While the normal standards for numbering tropical depressions in the Atlantic indicate that the old name/number is retained when a depression dissipates and regenerates, satellite data indicated that a second tropical wave combined with Tropical Depression Ten north of Puerto Rico to form a new, much more advanced system, which was then designated as Tropical Depression Twelve. Simultaneously, the trough in the upper troposphere weakened, causing the wind shear in the area to relax, thereby allowing the new tropical depression to develop. In a later re-analysis, it was determined that the low-level circulation of Ten had completely detached and dissipated, with only the remnant mid-level circulation moving on and merging with the aforementioned second tropical wave. As a result, the criteria for keeping the same name and identity were not met.
As the atmospheric conditions surrounding Tropical Depression Twelve were favorable for tropical development, the system began to intensify and was upgraded to Tropical Storm Katrina on the morning of August 24. A burst of convection allowed Katrina to become the fifth hurricane of the 2005 season on August 25, only two hours before it made landfall around 6:30 p.m. EST (2230 UTC) between Hallandale Beach and Aventura, Florida. Katrina struck the peninsula with 80-mile-per-hour (130-kilometre-per-hour) winds, and had a well-defined eye on NEXRAD weather radar, which remained intact throughout its passage over Florida. Parts of the Florida Keys experienced tropical storm winds throughout August 26, with the Dry Tortugas briefly experiencing hurricane-force winds.
The initial National Hurricane Center forecasts predicted that Katrina would begin turning northward after landfall, eventually to hit the Florida Panhandle approximately three to four days later. Katrina, however, continued a westerly and west-southwesterly track, which eventually shifted the forecast track westward to New Orleans.
Immediately after the storm entered the Gulf of Mexico, the low wind shear, good upper-level outflow, and the warm sea surface temperatures of the Gulf Loop Current caused Katrina to intensify rapidly. On August 27, the storm was upgraded to Category 3 intensity, becoming the third major hurricane of the season. An eyewall replacement cycle disrupted the intensification of maximum winds for about 18 hours, but almost doubled the radius of the storm. A second period of rapid intensification started by 7:00 p.m. CDT on August 27, and by 12:40 a.m. CDT on August 28, Katrina was upgraded to a Category 4 hurricane with maximum sustained winds of 145 mph (233 km/h). It became a Category 5 (the first in the Gulf of Mexico since Hurricane Allen 25 years prior) storm by 7:00 a.m. CDT, twelve hours after the beginning of the second round of rapid intensification, and reached its peak intensity at 1:00 p.m. CDT with maximum sustained winds of 175 mph (282 km/h), gusts of 215 mph (346 km/h) and a central pressure of 902 millibars. The minimum pressure made Katrina, at the time, the fourth-most intense Atlantic hurricane on record (Hurricanes Rita and Wilma would later surpass Katrina that same year).  As the hurricane approached New Orleans, the Weather Forecast Office in Slidell, Louisiana issued two strongly worded warnings of the storm's danger.
By the afternoon of August 28, the storm was large enough that some areas of the Gulf Coast were already experiencing tropical storm-force winds. The center of Katrina was about 180 statute miles (290 km) from the mouth of the Mississippi River, but tropical storm-force winds extended 230 miles (370 km) from the center of the storm, and hurricane-force winds extended about 105 miles (170 km) away. Overnight on August 29, and into the morning of the next day, Katrina quickly weakened (in terms of maximum sustained winds) as it began to enter another eyewall replacement cycle. The inner eyewall deteriorated before an outer eyewall had fully formed, playing an important role in the weakening. In 18 hours, the hurricane's maximum sustained winds decreased from 170 mph (270 km/h) to 125 mph (201 km/h). However, storm surge remained high at landfall because large waves greater than 30 feet (9.1 metres) in height were generated beforehand (with a buoy recording a 55-foot (17-metre) wave at sea), when Katrina was at Categories 4 and 5 on the Saffir–Simpson hurricane scale. The waves then combined with the storm surge of the large Category 3 hurricane.
Katrina made its second landfall at 6:10 a.m. CDT on August 29 as a Category 3 hurricane with sustained winds of 125 miles per hour (201 km/h) near Buras-Triumph, Louisiana. Because Katrina had just weakened from Category 4 and due to the shape of the coastline, sustained Category 4 winds likely existed on land while the eye was over water. At landfall, hurricane-force winds extended 120 miles (190 kilometres) from the center, the storm's pressure was 920 millibars (27 inches of mercury), and its forward speed was 15 mph (24 km/h). As it made its way up the eastern Louisiana coastline, most communities in Plaquemines, St. Bernard Parish, and Slidell in St. Tammany Parish were severely damaged by storm surge and the strong winds of the eyewall, which also grazed eastern New Orleans, causing in excess of $1 billion worth of damage to the city (see Effect of Hurricane Katrina on New Orleans).
Original estimates indicated that Katrina had made this landfall as a Category 4 hurricane, with 135-mile-per-hour (217-kilometre-per-hour) winds; however, as indicated above, the storm weakened just before landfall to Category 3 intensity. The reasons for this weakening are not completely known yet; while the eye-wall replacement cycle played a part, slightly increasing shear, dropping sea-surface temperatures, dry air on the western semicircle of the storm, and interaction with the continental landmass also may have played a role in weakening the cyclone. This follows the trend of previous strong cyclones in the Gulf of Mexico: most cyclones with minimum central pressures of 973 millibars (28.7 inHg) or less have weakened over the 12 hours before making landfall in the Gulf Coast of the United States.
A few hours later, after weakening slightly, Katrina made its third landfall near the Louisiana–Mississippi border with 125-mile-per-hour (201-kilometre-per-hour) sustained winds and 928-millibar (27.4 inHg) pressure, still at Category 3 intensity. Its minimum pressure at its second landfall was 920 mbar (27 inHg), making Katrina the fourth-strongest hurricane on record to make landfall on the United States, behind Hurricane Michael's 919-millibar (27.138 inHg) reading, Hurricane Camille's 900-millibar (27 inHg) reading in 1969, and the 1935 Labor Day Hurricane's 892-millibar (26.3 inHg) record.Because the storm was so large, highly destructive eye-wall winds and the strong northeastern quadrant of the storm pushed record storm surges onshore, smashing the entire Mississippi Gulf Coast, including towns in Mississippi such as Waveland, Bay St. Louis, Pass Christian, Long Beach, Gulfport, Biloxi, Ocean Springs, Gautier and Pascagoula, and, in Alabama, Bayou La Batre. The surges peaked at 28 feet (8.5 m) in Bay St. Louis, Mississippi, and at 13 ft (4.0 m) as far away as Mobile, Alabama, which saw its highest storm surge since 1917. Storm surge was particularly high due to the hydrology of the region, the hurricane's extreme size, and the fact that it weakened only shortly before landfall. As Katrina moved inland diagonally over Mississippi, high winds cut a swath of damage that affected almost the entire state.
Katrina maintained hurricane strength well into Mississippi, but weakened thereafter, losing hurricane strength more than 150 miles (240 km) inland, near Meridian, Mississippi. It was downgraded to a tropical depression near Clarksville, Tennessee and broke in half. One half continued to race northward, affecting the Central United States along its path, and was last distinguishable in the eastern Great Lakes region on August 31. On August 31, Katrina merged with a frontal boundary and became a powerful extratropical low, causing 1.97–6.69 inches (50–170 mm) of rain in 12 hours, as well as gale-force wind gusts from 31 to 61 mph (50 to 98 km/h) in southeastern Quebec and northern New Brunswick. In the region of Saguenay and Côte-Nord, rain caused breakdowns and failure in roads. The Côte-Nord region was isolated from the rest of Quebec for at least 1 week. The other half of Katrina broke off in the eastern part of the Appalachians, primarily leading to a significant tornado outbreak in the area from central Georgia to central Pennsylvania, killing two people and causing millions of dollars in additional damage. At 11:00 p.m. EDT on August 31, the center of the remnant low of what was Katrina had been completely absorbed by a frontal boundary in southeastern Canada, with no discernible circulation.

Hurricane Patricia was the most intense tropical cyclone ever recorded in the Western Hemisphere and the second-most intense worldwide in terms of barometric pressure. It also featured the highest one-minute maximum sustained winds ever recorded in a tropical cyclone. Originating from a sprawling disturbance near the Gulf of Tehuantepec in mid-October 2015, Patricia was first classified a tropical depression on October 20. Initial development was slow, with only modest strengthening within the first day of its classification. The system later became a tropical storm and was named Patricia, the twenty-fourth named storm of the annual hurricane season. Exceptionally favorable environmental conditions fueled explosive intensification on October 22. A well-defined eye developed within an intense central dense overcast and Patricia grew from a tropical storm to a Category 5 hurricane in just 24 hours—a near-record pace. The magnitude of intensification was poorly forecast and both forecast models and meteorologists suffered from record-high prediction errors.
On October 23, two Hurricane Hunter missions both revealed the storm to have acquired maximum sustained winds of 205 mph (335 km/h) and a pressure of 879 mbar (hPa; 25.96 inHg). Since the peak intensity was assessed to have occurred between the missions, the National Hurricane Center ultimately estimated Patricia to have acquired winds of 215 mph (345 km/h) and pressure of 872 mbar (hPa; 25.75 inHg). This ranked it just below Typhoon Tip of 1979 as the most intense tropical cyclone on record. Patricia's exceptional intensity prompted the retirement of its name in April 2016. Late on October 23, Patricia made landfall in a significantly weakened state near Cuixmala, Jalisco. Despite weakening greatly, it was the strongest landfalling hurricane on record along the Pacific coast of Mexico with winds estimated at 150 mph (240 km/h). Interaction with the mountainous terrain of Mexico induced dramatic weakening, faster than the storm had intensified. Within 24 hours of moving ashore, Patricia degraded into a tropical depression and dissipated soon thereafter late on October 24.
On October 11, 2015, an area of disturbed weather traversed Central America and emerged over the eastern Pacific Ocean. The disturbance moved slowly over the next few days, and coalesced into a Central American gyre—a broad monsoonal circulation. A tropical wave crossed the Caribbean Sea and eventually reached Central America on October 15; the two systems merged the following day near the Gulf of Tehuantepec. A concurrent Tehuantepec gap wind event on the western side of the gyre, complimented by anticyclonic flow behind a cold front, enhanced vorticity and spurred the formation of an elongated area of low pressure on October 17. The broad system spanned several hundred miles from the Yucatán Peninsula into the eastern Pacific. A large, disorganized area of convection—showers and thunderstorms—accompanied the system, increasing in coverage substantially throughout the day. A strong pulse in the Madden–Julian oscillation—a propagating climate pattern associated with increased tropical cyclogenesis—may have aided in creating favorable conditions for further development.Moving south of the Gulf of Tehuantepec on October 18, the system consolidated and developed a small, defined circulation. Associated convection became more concentrated around its center. Another gap wind event soon impacted the system, temporarily delaying development of the disturbance into a tropical depression. The low soon relocated to the northeast, aligning itself east of the gap wind event which aided in development. A small, well-defined circulation formed by early on October 20 within a broader cyclonic circulation. With increasing deep convection, the system is estimated to have become a tropical depression, assigned the identifier Twenty-E, by 06:00 UTC. Upon its designation, the depression was situated roughly 205 mi (335 km) south-southeast of Salina Cruz, Mexico.
Located south of a mid-level ridge and the continuing gap wind event, the nascent depression moved slowly west-southwest on October 20. Initial environmental conditions were modestly favorable, allowing for steady intensification. The depression achieved tropical storm status by 00:00 UTC on October 21; the National Hurricane Center (NHC) assigned it the name Patricia accordingly. Throughout much of October 21, Patricia moved through a region of drier, more stable air and over relatively cool sea surface temperatures. Both of these factors served to delay intensification of the cyclone. The system unraveled substantially, with banding features dissipating and the low-level circulation becoming poorly defined. Once clear of the hindering factors, convection blossomed over Patricia late on October 21 and a central dense overcast formed over the center. Simultaneously, the storm accelerated west-northwest.Exceptionally favorable atmospheric conditions, consisting of little wind shear, anomalously high sea surface temperatures of 87 to 88 °F (30.5 to 31 °C), and high moisture levels yielded an environment highly conducive to rapid intensification. Consequently, Patricia commenced explosive intensification late on October 21. Patricia reached hurricane strength shortly after 00:00 UTC on October 22, featuring prominent outflow, well-defined banding features, and a developing eye. Upon becoming a hurricane, Patricia was located 230 mi (370 km) south of Acapulco, Mexico. In the following 12 hours, a well-defined 12 mi (19 km) wide eye formed within a ring of intense convection—with cloud tops of −80 to −90 °C (−112 to −130 °F)—forming "an almost perfectly symmetric [central dense overcast]". Data from NOAA Hurricane Hunters investigating the cyclone indicated Patricia to have reached Category 4 status on the Saffir–Simpson hurricane wind scale by 18:00 UTC; maximum sustained winds were estimated at 130 mph (215 km/h) alongside a barometric pressure of 957 mbar (hPa; 28.26 inHg) at this time.
The rapid intensification of Patricia was well-anticipated but poorly forecast. Meteorologists at the NHC indicated the possibility of such in the system's first advisory as a tropical depression. They noted the only inhibiting factor would be how quickly the storm could organize an inner core. Just before the onset of rapid intensification, the agency was unable to utilize the Statistical Hurricane Intensity Prediction Scheme rapid intensification guidance due to technical errors. This likely contributed to even greater errors in the agency's forecast. Initial forecasts were consistently conservative with intensity and dramatic strengthening was not explicitly shown until rapid intensification was already underway.At 03:00 UTC on October 22, the NHC forecast Patricia to achieve major hurricane status in 36 hours; less than 15 hours later, the system exceeded their forecast peak. Strengthening into a Category 5 hurricane was not forecast at all until Patricia had already reached such intensity, although in the intermediate advisory immediately before Patricia's upgrade to Category 5, the NHC noted that "Patricia could become a category 5 hurricane overnight", and in the preceding tropical weather discussion, noted that "Patricia could ... reach Category 5 intensity". This trend continued throughout the rapid intensification period, resulting in some of the largest errors on record through 48 hours; they were the worst-ever for the Eastern Pacific since the NHC took over operations for the basin in 1988. All forecast models saw enormous errors, most of which performed worse than the official NHC forecasts. No model accurately prognosticated the magnitude nor rate of the intensification. The EMXI—an output from the European Centre for Medium-Range Weather Forecasts—saw the largest average error with 98.5 mph (158.5 km/h) at 48 hours.
During the overnight hours of October 22–23, Patricia turned northwest and decelerated slightly as it reached the western edge of the mid-level ridge. Rapid development continued into October 23, and the hurricane reached Category 5 status by 00:00 UTC, with winds estimated at 175 mph (280 km/h). Convection cooled even further, with cloud tops colder than −130 °F (−90 °C) surrounding an 8 mi (13 km) wide eye by 03:00 UTC. In a 24-hour span, Patricia's winds increased by 120 mph (195 km/h) and its central pressure fell by 95 mbar (hPa; 2.81 inHg). Around 06:00 UTC, an Air Force Reserve reconnaissance aircraft measured flight-level winds of 221 mph (356 km/h) and the aircraft's stepped frequency microwave radiometer (SFMR) observed surface winds of 210 mph (340 km/h). Furthermore, the final dropsonde observation from that mission at about 06:45 UTC indicated a central pressure of 879 mbar (hPa; 25.96 inHg). Rapid development continued after the aircraft left the hurricane, as the three pressure readings during the mission indicated that the pressure fell at a rate of more than 7 mbar (hPa; 0.21 inHg) per hour. Their findings also revealed an extraordinarily tight pressure gradient of 24 mbar (hPa; 0.71 inHg) per nautical mile, among the steepest gradients on record.Based on continued improvement of the hurricane's satellite appearance, Patricia is assessed to have achieved its peak intensity around 12:00 UTC on October 23; the storm was situated about 150 mi (240 km) southwest of Manzanillo, Mexico. Maximum winds are estimated at 215 mph (345 km/h) alongside a pressure of 872 mbar (hPa; 25.75 inHg), making Patricia the second-most intense tropical cyclone ever observed. It is possible that Patricia surpassed the all-time record of 870 mbar (hPa; 25.69 inHg) set by Typhoon Tip in 1979 given the rate of deepening observed during the early morning mission; due to a lack of direct observation at the time of Patricia's peak, no concrete determination of such could be made. The violent, compact core of Patricia was roughly 25 mi (40 km) wide with the radius of maximum winds extending only 7 mi (11 km).Little change in strength took place for the next six hours; a shortwave trough crossing the Baja California Peninsula turned Patricia to the northeast and induced acceleration. Another reconnaissance mission around 18:00 UTC recorded a central pressure of 879 mbar (hPa; 25.96 inHg). The aircraft was battered by severe turbulence (the result of updrafts and downdrafts) and the crew experienced maximum g-forces of +3.0 and -1.5.
Late on October 23, radar imagery depicted the formation of a secondary outer eyewall, indicative of an eyewall replacement cycle. By 20:30 UTC, the final pass by reconnaissance, the hurricane's flight-level winds fell by 60 mph (95 km/h) and its central pressure rose at 8 mbar (hPa; 0.24 inHg) per hour. Coinciding with the eyewall replacement cycle was an increase in southwesterly wind shear, a factor that further accelerated Patricia's degradation. The hurricane's eye soon became cloud-filled and rapid weakening ensued at an unprecedented pace.At 23:00 UTC, the cyclone made landfall at Cuixmala in the municipality of La Huerta, Jalisco—about 55 mi (85 km) west-northwest of Manzanillo—with winds of 150 mph (240 km/h) and an estimated pressure of 932 mbar (hPa; 27.49 inHg). This made Patricia the strongest hurricane to strike Mexico's Pacific coast, exceeding an unnamed storm in 1959 and Madeline in 1976 (the latter of which has not been reanalyzed). Although Patricia was operationally thought to have made landfall as a Category 5 hurricane with winds of 165 mph (270 km/h) and a pressure of 920 mbar (hPa; 27.17 inHg), reanalysis of available data suggested that the hurricane weakened more rapidly than originally thought: an automated station in Cuixmala measured a pressure of 934.2 mbar (hpa; 27.54 inHg), while storm chasers in Emiliano Zapata, just inside the eye of Patricia, measured a pressure of 937.8 mbar (hPa; 27.70 inHg). Their observations also indicated a pressure gradient of 11 mbar (hPa; 0.32 inHg) per nautical mile.Patricia's winds at landfall are relatively uncertain, and the 150 mph (240 km/h) value is based upon the Knaff-Zehr-Courtney pressure-wind relationship and an extrapolation of a 54 mbar (hPa; 1.59 inHg) filling using the Dvorak Technique. An additional equation stemming from work by Willoughby (1993) yielded a landfall intensity of 147 mph (237 km/h). A NOAA automated weather station at the Chamela-Cuixmala Biosphere Reserve, at an elevation of 280 ft (85 m), recorded sustained winds of 185 mph (298 km/h) and a maximum gust of 211 mph (340 km/h). Further raw data from this station indicated unrealistically high sustained winds of 266 mph (428 km/h) and a maximum gust of 1,138 mph (1,831 km/h). Based on the station's distance from Patricia's eye, outside the radius of maximum winds, the observations from this station are considered unreliable. The highest reliably measured winds of 98 mph (158 km/h) occurred in Pista between 22:30 and 23:00 UTC on October 23 before the anemometer failed.
Even faster weakening ensued through October 24 as the hurricane traversed the Sierra Madre mountains; its eye disappeared from satellite imagery within hours of moving ashore. The system weakened below hurricane strength by 03:00 UTC as it passed west of Guadalajara. Patricia accelerated inland between a trough over Northwestern Mexico and the ridge over the Gulf of Mexico. Convection dramatically decreased in organization and the low- and mid- to upper-level circulation centers of the cyclone soon decoupled. The system degraded into a tropical depression by 12:00 UTC as little organized convection remained, and the storm dissipated shortly thereafter over central Mexico. Unimpeded by the mountains of Mexico, the mid- to upper-level circulation of Patricia, accompanied by considerable moisture, continued northeast and interacted with a cold front over the western Gulf of Mexico. The new system produced flooding rains across large areas of Arkansas, Louisiana, Mississippi, and Texas.
With maximum sustained winds of 215 mph (345 km/h) and a minimum pressure of 872 mbar (hPa; 25.75 inHg), Hurricane Patricia is the second-most intense tropical cyclone ever observed, just shy of Typhoon Tip in 1979 which had a minimum pressure of 870 mbar (hPa; 25.69 inHg). It is also the strongest tropical cyclone ever recorded in the Western Hemisphere. It exceeded the previous sustained wind record of 190 mph (305 km/h) set by Hurricane Allen in 1980 and the pressure record of 882 mbar (hPa; 26.05 inHg) set by Hurricane Wilma in 2005, both in the Atlantic basin. In the Eastern Pacific basin, north of the equator and east of the International Dateline, the previous basin record-holder was Hurricane Linda in 1997 with winds of 185 mph (295 km/h) and a pressure of 902 mbar (hPa; 26.64 inHg). Reconnaissance also found a pressure gradient of 24 mbar (hPa; 0.71 inHg) per nautical mile early on October 23, among the steepest gradients ever observed in a tropical cyclone.
On a global scale, Patricia's one-minute maximum sustained winds rank as the highest ever reliably observed or estimated globally in a tropical cyclone, surpassing Typhoon Haiyan of 2013, although the intensity of Haiyan was only estimated via satellite imagery (T8.0, the highest rating on the Dvorak scale). Since no aircraft reconnaissance was available for Haiyan, the record set by Patricia is uncertain and comparing the intensities of the two storms is problematic. According to the World Meteorological Organization, Typhoon Nancy of 1961 also produced 215 mph (345 km/h) sustained winds; however, it is widely accepted that Western Pacific reconnaissance during the 1940s to 1960s overestimated cyclone intensity and Nancy's record is considered questionable. The most powerful wind gust produced by a tropical cyclone, as well as the highest non-tornadic winds ever recorded, is still retained by Cyclone Olivia in 1996: 253 mph (407 km/h) was observed on Barrow Island, Western Australia.The magnitude of Patricia's rapid intensification is among the fastest ever observed. In a 24-hour period, 06:00–06:00 UTC October 22–23, its maximum sustained winds increased from 85 mph (140 km/h) to 205 mph (335 km/h). This represents a record increase of 120 mph (195 km/h). During the same period, Patricia's central pressure fell by 95 mbar (hPa; 2.81 inHg). This fell just short of the world-record intensification set by Typhoon Forrest in 1983, which featured a pressure drop of 100 mbar (hPa; 2.95 inHg) in just under 24 hours. With a pressure of 932 mbar (hPa; 27.52 inHg), Patricia is the strongest landfalling Pacific hurricane on record. The previous record was 941 mbar (hPa; 27.73 inHg) set by Hurricane Odile in 2014. Similarly, the hurricane featured the fastest weakening while still over water in NHC's area of responsibility, with a pressure rise of 54 mbar (hPa; 1.59 inHg) in the five hours before it made landfall. Furthermore, a dropsonde observed a 700 mbar height temperature of 32.2 °C (90.0 °F) in the eye of Patricia. This is one of the warmest temperatures ever observed in a tropical cyclone's eye worldwide.

Hurricane Wilma was the most intense tropical cyclone in the Atlantic basin on record, with an atmospheric pressure of 882 hPa (mbar, 26.05 inHg). Wilma's destructive journey began in the second week of October 2005. A large area of disturbed weather developed across much of the Caribbean Sea and gradually organized to the southeast of Jamaica. By late on October 15, the system was sufficiently organized for the National Hurricane Center to designate it as Tropical Depression Twenty-Four.
The depression drifted southwestward, and under favorable conditions, it strengthened into Tropical Storm Wilma on October 17. Initially, development was slow due to its large size, though convection steadily organized. From October 18, and through the following day, Wilma underwent explosive deepening over the open waters of the Caribbean; in a 30-hour period, the system's central atmospheric pressure dropped from 982 mbar (29.00 inHg) to the record-low value of 882 mbar (26.05 inHg), while the winds increased to 185 mph (298 km/h). At its peak intensity, the eye of Wilma was about 2.3 miles (3.7 km) in diameter, the smallest known eye in an Atlantic hurricane. After the inner eye dissipated due to an eyewall replacement cycle, Hurricane Wilma weakened to Category 4 status, and on October 21, it made landfall on Cozumel and on the Mexican mainland with winds of about 150 mph (240 km/h).
Wilma weakened over the Yucatán Peninsula, and reached the southern Gulf of Mexico before accelerating northeastward. Despite increasing amounts of vertical wind shear, the hurricane re-strengthened to hit Cape Romano, Florida, as a major hurricane. Wilma weakened as it quickly crossed the state, and entered the Atlantic Ocean near Jupiter, Florida. The hurricane again re-intensified before cold air and wind shear penetrated the inner core of convection.  By October 26, it transitioned into an extratropical cyclone, and the next day, the remnants of Wilma were absorbed by another extratropical storm over Atlantic Canada.
During the second week of October, an unusually large, monsoon-like lower-level circulation and a broad area of disturbed weather developed over much of the Caribbean Sea. The system was enhanced by diffluence from an upper-level low across the southwestern Atlantic. By October 13, a broad area of low pressure developed and persisted about 150 miles (240 km) southeast of Jamaica, possibly aided by the passage of tropical waves through the area at the time. Convection increased and became slightly better organized, though upper-level wind shear initially prevented development. The system drifted westward, and early on October 14 the convection became more concentrated and a little better organized as upper-level wind shear lessened slightly.Later on October 14, the system became much better defined, with increasingly organized shower and thunderstorm activity, as conditions in the upper levels of the atmosphere became significantly more favorable. It was then that the National Hurricane Center first indicated that it was possible for a tropical depression to develop in the area. Dvorak classifications were initiated on October 15. The system continued to organize, with the National Hurricane Center remarking the system could ultimately become a hurricane. By late on October 15, the surface circulation became defined well enough, with sufficiently organized deep convection, for the National Hurricane Center to designate the system as Tropical Depression Twenty-Four while it was located about 220 miles (350 km) east-southeast of Grand Cayman.The depression tracked slowly westward, a motion due to weak steering currents caused by a high pressure area to its north across the Gulf of Mexico. Initially, the center of circulation was broad without a defined inner core; forecaster Lixion Avila remarked, "The area of minimum pressure could [have been] anywhere within 60 miles (97 km) of its [initial advisory position]." Initially, the tropical depression was forecast to drift west-southwestward before turning to the north; within five days of the forecast's issuance, the system was predicted to be located about 80 miles (130 km) south of the Isle of Youth as a 105 mph (169 km/h) hurricane. However, the National Hurricane Center noted in the first advisory on the depression that there were "all indications that there could a dangerous hurricane in the northwestern Caribbean Sea in 3 to 5 days." This was due to the depression being located within an environment very conducive for development, specifically low amounts of wind shear and very warm water temperatures.As Tropical Depression Twenty-Four drifted southwestward, it steadily organized; by early on October 16, rainbands began to gradually consolidate with well-established outflow, and a large upper-level anticyclone developed over the depression. Although deep convection and banding features increased, mid-level dry air from the north prevented significant organization, and the convection was split into two primary areas. Surface buoy reports indicated that, due to its large size, the system failed to strengthen beyond tropical depression status, even though it received tropical storm strength Dvorak classifications from The National Hurricane Center's Tropical Analysis and Forecast Branch and the National Oceanic and Atmospheric Administration's Satellite Analysis Branch. Continued reconnaissance flights reported peak winds of about 30 mph (48 km/h).
By early on October 17, the outer rainbands, which had previously dominated the structure of the cyclone, dissipated, while deep convection developed near and to the south of the center. Computer models predicted steady strengthening as the depression tracked westward before turning to the north. Of the intensity models, the Geophysical Fluid Dynamics Laboratory predicted an intensity of 135 mph (217 km/h) within 36 hours, with other forecasts being more conservative in their predictions. Deep convection continued to develop to the south of the center, and the depression intensified into Tropical Storm Wilma at 0600 UTC on October 17, while located about 200 miles (320 km) southeast of Grand Cayman. Upon becoming a tropical storm, the National Hurricane Center predicted Wilma to track west-northwestward, reaching winds of 105 mph (169 km/h) before striking the northeastern portion of the Yucatán Peninsula.The storm continued to the southwest while deep convection persisted near the center. National Hurricane Center forecaster James Franklin remarked, "Confidence at the later ranges [of the forecast track] was unusually low", due to wide divergences between computer models. Late on October 17, a Hurricane Hunters flight into Wilma recorded winds of 50 mph (80 km/h), but an unusually low pressure of 989 mbar (29.21 inHg), which would be more typical of a minimal hurricane. This was due to unusually low pressures across the region, which resulted in a lesser pressure gradient and thus lighter winds. Convection continued to develop near the center and became much more symmetrical.
Tropical Storm Wilma began to turn to the west-northwest on October 18, during which the storm developed a small, intermittent and ragged eye feature. It continued to intensify, and at 1200 UTC on October 18, Wilma attained hurricane status while located about 225 miles (362 km) south-southeast of Grand Cayman. Shortly after reaching hurricane strength, the hurricane began undergoing explosive deepening, after the development of a "pinhole" eye 9 miles (14 km) in diameter. This small eye was surrounded by a ring of deep convection, with cloud-top temperatures of about −125 °F (−87 °C).Early on October 19, Wilma attained major hurricane status while continuing to rapidly intensify, and by 0600 UTC, the storm's maximum sustained winds increased to 165 mph (266 km/h), making Wilma a dangerous Category 5 storm on the Saffir-Simpson Hurricane Scale. In the span of just 24 hours, Wilma had intensified from a 70 mph (110 km/h) tropical storm to a 175 mph (282 km/h) Category 5 hurricane, an unprecedented event for an Atlantic hurricane. The eye continued to contract to a diameter of about 2 nautical miles (3.7 km), the smallest known eye in an Atlantic hurricane, and at 1200 UTC on October 19, Wilma attained peak winds of 185 mph (298 km/h). The central pressure rapidly dropped 54 mbar (1.65 inHg) from 0000 to 0600 UTC, and at 0800 UTC, a Hurricane Hunters flight recorded a minimum central pressure of 884 mbar (26.10 inHg) in a dropsonde near the center of the extremely small eye. As the dropsonde did not reach the calm winds in the center, the pressure was estimated at 882 mbar (26.05 inHg), the lowest pressure in an Atlantic hurricane on record. The pressure continued to fall as the Hurricane Hunters left the hurricane, and it is possible the pressure was slightly lower. Operationally, the peak intensity was estimated at 175 mph (282 km/h). At the time of its peak intensity, hurricane-force winds extended only 50 miles (80 km) from the small center of Wilma, with tropical storm force winds extending only about 160 miles (260 km).
Shortly after peaking in intensity, the coldest cloud tops surrounding the eye warmed slightly and an outer eyewall began to develop, signifying an eyewall replacement cycle was occurring. By late on October 19, the winds in Hurricane Wilma decreased to 160 mph (260 km/h) as the inner 5-mile (8 km) wide eye weakened and the wind field expanded. Early on October 20 the hurricane weakened to Category 4 status after the small, inner eye dissipated and the 45-mile (72 km) wide outer eyewall became the dominant eye. At the time, the pressure measured 892 mbar (26.34 inHg), the second-lowest known pressure for a Category 4 hurricane (Super Typhoon Judy had an 887 mb pressure at peak intensity), and Wilma retained the large eyewall as it turned northwestward. Initially, the hurricane was forecast to re-intensify into a Category 5 hurricane, with one forecast predicting it to make landfall on the Yucatán Peninsula with winds of 165 mph (266 km/h), though Wilma remained a strong Category 4 hurricane as it tracked northwestward.Steering currents remained weak, though a series of troughs eroded the high pressure system across the Gulf of Mexico, resulting in a turn towards the north-northwest. Environmental conditions remained favorable, with the eye becoming more distinct early on October 21. At about 2145 UTC on October 21, Wilma made landfall on the island of Cozumel with winds of 150 mph (240 km/h). It weakened slightly as it continued northwestward, and struck the Mexican mainland near Puerto Morelos, Quintana Roo, at 0330 UTC on October 22, with winds of 135 mph (217 km/h) and gusts of up to 170 mph (270 km/h).
On October 22, the mid-level ridge to the north of Wilma essentially dissipated, leaving the hurricane drifting northward across the northeastern Yucatán Peninsula. As the hurricane moved further inland, the eye became cloud-filled as the deepest convection began to warm, and the winds gradually weakened during its passage over land. About 26 hours after making landfall on Cozumel, Wilma emerged into the southern Gulf of Mexico near Cabo Catoche with winds of about 100 mph (160 km/h). Upon reaching open waters, Reconnaissance Aircraft reported the remains of an inner eyewall and an outer eyewall oscillating between 70 and 90 miles (110 and 140 km) in diameter. Convection deepened around the eyewalls, and the inner core of convection, which had previously become disrupted over land, became slightly better defined.
A powerful eastward-moving mid-level trough across the central United States turned the hurricane northeastward and caused it to gradually accelerate. Vertical wind shear increased as strong upper-level southwesterly flow increased, though in spite of the shear Wilma continued to intensify. Early on October 24, Wilma attained major hurricane status while located about 120 miles (190 km) west-southwest of Key West, Florida. It gradually became better organized, with the large 50 miles (80 km) eye becoming very distinct on satellite and radar imagery. Wilma was able to retain its strength because large eyes in tropical cyclones are more stable and more resistant to vertical wind shear. Despite wind shear values of about 30 mph (48 km/h), Wilma strengthened further to reach winds of 125 mph (201 km/h). It weakened slightly as it approached Florida, and made landfall at Cape Romano with winds of 120 mph (190 km/h) at around 1030 UTC on October 24.Hurricane Wilma crossed the Florida peninsula in about 4.5 hours while continuing to accelerate northeastward, and emerged into the Atlantic Ocean as a weakened 110 mph (180 km/h) hurricane near Jupiter. A vigorous cold front associated with the mid-level trough moved across the area to the west of Wilma, yet the cooler and drier air behind the front could not fully penetrate the inner core of the hurricane to weaken it. Shortly after exiting the Florida coastline, Wilma began to re-intensify, believed to be due to a reduction of friction of the eyewall and warm waters of the Gulf Stream. Early on October 25, the hurricane reached a secondary peak intensity of 125 mph (201 km/h) while located about 340 miles (550 km) east of Jacksonville, Florida. During the time, the large circulation of Wilma absorbed the much smaller Tropical Depression Alpha over the Bahamas.Shortly after its secondary peak intensity, the wind shear, combined with its rapid forward motion of 50 mph (80 km/h), resulted in a steady weakening trend. The overall cloud pattern began to deteriorate, with the eye becoming less distinct and the convection less symmetric. By 1117 UTC on October 25, the center was located to the northwest of the primary convection as cold air from the southwest entrained the circulation. The remaining convection continued to diminish, and by late on October 25 Wilma transitioned into an extratropical cyclone while located about 230 miles (370 km) southeast of Halifax, Nova Scotia, and still at Category 1 intensity. The weakening extratropical remnant turned to the east-northeast before being absorbed by another extratropical storm over Atlantic Canada on October 27.

Metroid Prime 2: Echoes is a first person action-adventure video game developed by Retro Studios and published by Nintendo for the GameCube video game console. It is the seventh published game in the Metroid series, a sequel to Metroid Prime, and the first game in the series with a multiplayer feature. Echoes was released in North America, Europe, and Australia in 2004; and in Japan under the name Metroid Prime 2: Dark Echoes in May 2005.
The story of Echoes follows bounty hunter Samus Aran after she is sent to rescue Galactic Federation Marines from a ship near Aether, a planet inhabited by a race known as the Luminoth. There, she discovers that the troops were slaughtered by the Ing, a race that came from an alternate dimension of Aether. Samus must travel to three temples to ensure the destruction of the Ing, while battling Space Pirates and her mysterious doppelgänger called Dark Samus.
Retro decided to make the game different from its predecessor by adding more focus on storyline and including new gameplay elements. Nintendo launched a viral marketing campaign to promote the game that included several websites written as if taking place in the Metroid universe. Echoes' single player mode and graphics were praised by critics, while its steep difficulty level and multiplayer components were met less positively. Since its release, Echoes has received several video game industry awards, as well as spots on "top games" lists by Nintendo Power and IGN. Over 800,000 copies of the game were sold worldwide. In 2009, an enhanced version was released for Wii as a standalone game in Japan and as part of Metroid Prime: Trilogy internationally.
Metroid Prime 2: Echoes is an action-adventure game in which the player controls the protagonist Samus Aran from a first-person perspective, and it takes place in an open-ended world with interconnected regions. Gameplay revolves around solving puzzles to uncover secrets, platform jumping, and shooting enemies. Progress through the game requires both dimensions to be explored, using power-ups that Samus acquires over time. Equipment players collect include the Screw Attack, which allows Samus to somersault in midair and off certain surfaces, and new beam weapons that have limited ammunition.The game's head-up display simulates the inside of Samus's helmet and features a radar, map, missile ammunition meter and health meter. Several visors are available, and each performs a different function. One, also seen in the previous game, is a scanner that searches for enemy weaknesses, interfaces with mechanisms such as force fields and elevators and retrieves text entries from certain sources. The others reveal and highlight interdimensional objects or cloaked enemies, and create a visual representation of sound.Echoes feature two parallel dimensions, Light Aether and Dark Aether, where changes in either dimension often reflect changes in the other. Although the maps in both dimensions have the same general layout, rooms often vary in their designs, creatures, and objects. Dark Aether's atmosphere is caustic and damages Samus's Power Suit, requiring the player to move between designated "safe zones" that allow Samus's health to be regained slowly. Safe zones are either permanent, or need to be activated by firing certain beam weapons at force field generators. Power Suit upgrades can reduce or nullify damage caused by the atmosphere.Echoes also features a multiplayer mode that allows up to four players to engage in combat using a split screen. It has six arenas and two modes: Deathmatch, in which players attempt to kill their opponents as many times as possible within a set amount of time; and Bounty, which focuses on collecting coins that injured characters drop. Multiplayer in Echoes features the same control scheme as the single-player mode, including the lock-on system for circle strafing while targeting.
Echoes takes place on a rogue planet in the Dasha region, Aether, inhabited by a race known as the Luminoth. The Luminoth lived peacefully, protecting the planet's pure natural energy, which they call the "Light of Aether". Five decades before the game's events, a Phazon meteor collides into the planet and leaves a scar causing environmental damage and splitting the planetary energy. The split creates another planet in an alternate dimension, Dark Aether, a mirror version of Aether that is dark, arid, and has a poisonous atmosphere. Dark Aether becomes home to the Ing, cruel shapeshifting creatures who intend to destroy the Luminoth, and are able to possess bodies of the living, the dead, and the artificially intelligent. Eventually, the Ing and the Luminoth engage in a war over the planet's energy—whichever race controls it is capable of destroying the other.Around this time, Space Pirates set up a base on Aether after detecting the mutagenic substance Phazon on the planet. A Galactic Federation Marine Corps patrol ship encounters one of the Pirates' supply ships leaving the planet and an altercation follows. Both ships suffer heavy damage, and after the Federation loses contact with the Marines, they call the bounty hunter Samus Aran to investigate.
While looking for the Marines near Aether, Samus's ship is damaged by severe lightning storms from the planet. Said storms have caused electromagnetic interference that prevented the Marines from communicating with the Federation. Samus finds the troops dead and surrounded by hive creatures called Splinters. The deceased Marines suddenly rise and attack her, apparently possessed, and she fights them off. Samus then encounters her evil doppelgänger, Dark Samus, for the first time, and after a small skirmish Dark Samus jumps through a portal. Samus decides to follow her through it and ends up on Dark Aether, a vile trans-dimensional duplicate of Aether, where she is attacked by a group of dark creatures called Ing, who capture Samus and after stealing the weapons from her suit throw her back through the portal.Upon returning to Aether, Samus learns that the Marines were attacked and killed by Ing-possessed Splinters, and decides to enter a nearby alien temple structure to look for clues. When she reaches the structure, she meets U-Mos, the last remaining sentinel of the Luminoth, an alien race that have fought against the Ing for decades. They are now on the verge of defeat. He tells Samus that after a meteor struck Aether, the impact was so devastating, it created "Dark Aether", from which the Ing spawned. He also tells Samus that the Ing have taken virtually all of the 'Light of Aether', the entire collective planetary energy for Aether that keeps the planet stable, and begs her to retrieve it, for if either world gains all this energy, the other will perish.Samus goes to three regions—the Agon Wastes, a parched, rocky, desert wasteland region; Torvus Bog, a drenched swamp area that houses a partially submerged hydrosubstation; and the Sanctuary Fortress, a highly advanced cliffside fortress built by the Luminoth filled with corrupted robots that serves as the Ing hive in Dark Aether—to retrieve the Light of Aether and return it to the Luminoth temples. Samus fights Space Pirates, Dark Samus, and monstrous Ing guardians on her mission. After Samus retrieves three pieces of the Light of Aether, she enters the Ing's Sky Temple and faces the Emperor Ing, the strongest Ing who guards the remaining Light of Aether. Samus defeats the creature and retrieves the last remaining energy, causing Dark Aether to become critically unstable and collapse; however, her path out of the temple is blocked by a horribly altered and unstable Dark Samus. After defeating her foe, Samus escapes as the dark world disappears around her.Returning to U-Mos, Samus finds that the Luminoth were in a state of hibernation but have now awakened. After a brief celebration, Samus leaves Aether in her repaired gunship. If the player completes the game with all of the items obtained, Dark Samus is shown reforming herself above Aether.
After the critical and commercial success of Metroid Prime, Nintendo asked Retro Studios to produce a sequel. The developers decided against recycling the features of the first game, and instead used new sound models, weapon effects, and art designs. They also implemented the Screw Attack and wall jumping features seen in previous Metroid games, which were not incorporated in the first Prime due to time constraints. Another element considered for the previous game was the multiplayer component. Since the game was a first-person adventure and its deathmatch mode could not easily replicate other shooters in the market, Retro just tried to "make a multiplayer experience that fans of Metroid games would instantly know and recognise".The staff opted for a more immersive storyline, with increased use of cut scenes and a plot that focused less on the Space Pirates and Metroids that permeate the rest of the series. Retro decided that the game would follow a theme of light and dark, which originated from "something that everyone understands: the conflict between good and evil". Mike Wikan, the game's senior designer, elaborated on the theme: "We wanted a push and pull, the whole game is pushing and pulling you back and forth between the dark and the light. It ended up being that we wanted something that would feed into that dichotomy, that conflict between the two, and how the player's basic abilities reflect that." The developers asked the producers of The Legend of Zelda: A Link to the Past, another Nintendo game, for advice because the game also used the theme of parallel worlds.In developing Dark Samus, Retro wanted to create a character that was similar to Samus and be the same size, as opposed to the enormous monsters of Metroid Prime. One of the inspirations for the character was a boss battle in Metroid: Zero Mission, where Samus fights a mirror image of herself. The developers considered Dark Samus a "natural choice" for the game because it fit in well with the "dramatic feel of dark and light".Retro decided to make the game more challenging than Metroid Prime—which was supposed to familiarize players with the control scheme—and felt that "with the second Prime, we had the ability or the freedom" to do so. They wanted Echoes to be focused towards a hardcore audience by making the player "always worried about his health", so more mini-bosses were added to provide unique boss fights. After the game's release, the developers admitted that it was more difficult to develop than they first imagined, and Michael Kelbaugh, Retro Studios' president, commented: "We wanted to expand and add to the title, and not just slam out a sequel. Nintendo doesn't do things that way." Retro tried to include some extras, such as a hidden version of Super Metroid, but were halted by the short development time. Producer Kensuke Tanabe later revealed that the game was just about thirty percent complete three months before the strict deadline Nintendo had set for a release in the 2004 holiday season.The music for Metroid Prime 2: Echoes was composed by Kenji Yamamoto. The themes used for areas on Dark Aether are dark variations of the themes used for the same areas on Light Aether. Some remixes of music from the previous Metroid games were also used, with the escape theme being a remix of Metroid's "Escape" theme, the "Hunters" multiplayer theme taking on Super Metroid's "Upper Brinstar" theme, and the theme for the underwater Torvus region, the "Lower Brinstar" theme from the same game.
Metroid Prime 2: Echoes was originally released for the GameCube in North America on November 15, 2004, Europe on November 26, and in Australia on December 2. The PAL version of Echoes have lacked the standard 50 Hz mode, and offered 60 Hz mode only. In Japan, it was later released on May 26, 2005, titled Metroid Prime 2: Dark Echoes.
Nintendo launched several websites to initiate a viral marketing campaign for Echoes, with inspiration drawn from Halo 2's alternate reality game I Love Bees. The websites included Luminoth Temple, an Internet forum; Channel 51, a conspiracy theory website that featured grainy QuickTime videos of Metroid Prime 2 as if it were footage of extraterrestrials; Orbis Labs, which sold a "self-contained armored machine" called "Battle Sphere", similar to the Morph Ball; and Athena Astronautics, which advertised sending women into space, featured a blog, and offered job positions for bounty hunters on Monster.com. Athena Astronautics gave a random selection of 25 people who replied to the offer an "interactive training manual", which was in fact a free copy of Metroid Prime 2: Echoes.A Metroid-related spoof of "I Love Bees" appeared online in October 2004, to which Nintendo reacted by stating that it was not involved with it. The campaign featured similarly named domain names such as ilovebeams.com, which each had an image of Samus with the caption: "All your bees are belong to us. Never send a man to do a woman's job."
Echoes was released in Japan in 2009 for the Wii console, as part of the New Play Control! series. It has revamped controls that use the Wii Remote's pointing functionality, similar to those of Metroid Prime 3: Corruption. The credit system from Corruption is also included to unlock the original bonus content, as well as the ability to take snapshots of gameplay. The difficulty of the boss battles in Echoes was also lowered. The Wii version of Echoes was later released in North America on August 24, 2009, as part of Metroid Prime: Trilogy, a single-disc compilation that also includes Metroid Prime and Metroid Prime 3: Corruption. Both Prime and Echoes contain all of the enhancements found in their Japanese New Play Control! counterparts. The compilation was re-released on the Wii U's Nintendo eShop on January 29, 2015.
Metroid Prime 2: Echoes was critically acclaimed upon release. When comparing it to its predecessor, Metroid Prime, GameSpot's Brad Shoemaker said that Echoes was as good as its predecessor, and delivered everything he expected. IGN's Matt Casamassina called the gameplay "superb" and "nearly flawless", and Vicious Sid of GamePro praised Echoes as "an extraordinary return to form". Echoes was considered one of the best single-player experiences on the GameCube by Kristan Reed of Eurogamer, who also considered the story to be "intricately designed and elaborately constructed into a coherent environment". GameSpot and IGN praised the campaign as a lengthy and rewarding adventure and appreciated the minimum 20 hours required to complete the game. The game was considered suitable for players of any age by Computer and Video Games, which called Echoes essential for anyone who owned a GameCube. The theme's dynamics between dark and light was lauded by GamePro, along with the "simple, quirky, and ridiculously addictive" multiplayer mode.Echoes's graphics and design received significant praise; GameSpot considered it some of the best on the GameCube, and IGN called it "gorgeous" and "one of the prettiest GameCube titles". The Guardian's Nick Gillett found the game entertaining and stated that its maps, terrain, and bestiary made the game an amazing epic space adventure. Bryn Williams from GameSpy complimented the game's controls and level design, commenting that the game was challenging but fair.A major criticism of Echoes focused on the game's high difficulty, with Game Informer declaring that "not only are the boss fights unforgiving, the environment is sometimes difficult to follow". Some reviewers found it difficult to search for the Sky Temple keys. GameSpot criticized this mechanism and called it "a scavenger hunt much tougher than the rest of the game", and 1UP.com said that the only purpose it served was to artificially extend the game's length. The game's multiplayer mode was also considered unsatisfying. GameSpy called it a "secondary feature", The Age's Jason Hill called it "bland and dull" and Eurogamer said that the single-player features did not translate well to that mode. Game Informer criticized the multiplayer mode because of its inclusion of the lock-on mechanism, considering it a feature that made multiplayer too simple.IGN was critical of Echoes' graphics and noted that the textures sometimes blurred when viewed up close, and the frame rate occasionally decreased. Publications including IGN and The Independent considered the gameplay too similar to Metroid Prime, while GamePro was unhappy that the game did not have a customizable control scheme. Computer and Video Games and The Age were disappointed that Echoes was not as innovative in terms of gameplay as Metroid Prime. The Age's review also found the control scheme "unwieldy" and the difficulty "unforgiving". Serge Pennings of The Observer noted there were too few opportunities to save the game while playing, an aspect X-Play also criticized by saying that most of the game's difficulty was "because the save system is poorly implemented and downright cheap".
Echoes won an award in almost every category it was nominated for at the 2004 Nintendo Power Awards, and won awards for Best GameCube Game of 2004 from IGN, Electronic Gaming Monthly, and GameSpy. It was rated the 174th best game made on a Nintendo system in Nintendo Power's Top 200 Games list, the 74th best game by GameFAQs users, the 15th best GameCube game by IGN, and the 13th best by GameSpy.
Echoes sold 470,000 copies in North America in December 2004. It was the ninth best-selling game in its debut month in Japan with 16,105 copies sold, ranking it behind Yu Yu Hakusho Forever and Hanjuku Hero 4: 7-Jin no Hanjuku Hero. By August 2009, 800,000 copies had sold worldwide.

Metroid Prime 3: Corruption is a first-person action-adventure video game developed by Retro Studios and published by Nintendo for the Wii video game console. A part of the science fiction Metroid series, it is the third main installment in the Metroid Prime series. It was released in North America and Europe in 2007 and in Japan the following year. 
The story of Corruption is set six months after the events of Metroid Prime 2: Echoes. It follows Samus Aran as she confronts the Space Pirates, who have launched an attack on the Galactic Federation naval base on Norion. While fending off a Space Pirate assault, Samus and her fellow bounty hunters are infected with Phazon by her doppelgänger Dark Samus. After losing contact with the other hunters, the Federation sends Samus on a mission to determine what happened to them. During the course of the game, Samus works to prevent the Phazon from spreading from planet to planet while being slowly corrupted by the Phazon herself. 
The player controls Samus using the Wii Remote and Nunchuk devices; the remote is used for jumping, aiming, and firing weapons, while the Nunchuk enables actions such as moving Samus and locking onto enemies. Corruption  introduces features new to the Prime series, such as Hypermode, which allows Samus to use more powerful attacks, and the ability to command her gunship. The new control scheme featured in Corruption took a year to develop and caused the game's release to be delayed several times. The game was first shown to the public at the E3 2005 trade show.
Reception to Corruption has been positive, with several reviews specifically praising the gameplay. More than one million copies of the game were sold in 2007. It was re-released in August 2009 as part of Metroid Prime: Trilogy, a Wii compilation of the three main games of the Prime series with Wii Remote controls. Retro announced that Corruption would be the closing chapter of the Prime series; however, the next main installment, Metroid Prime 4, was announced in June 2017 and is currently in development.
Metroid Prime 3: Corruption is a first-person action-adventure game. The player controls the protagonist, Samus Aran, using the Wii Remote and Nunchuk devices. The Nunchuk enables the player to perform actions such as moving Samus and locking on to enemies and targets. The Wii Remote allows the player to execute actions such as jumping, aiming, and firing weapons.Corruption is a large, open-ended game that takes place across several planets, each with regions connected by elevators, rail systems and bridges. Each region has rooms separated by doors that can be opened when shot with the correct weapon. The gameplay revolves around solving puzzles to uncover secrets, jumping on platforms, and shooting enemies with the help of a "lock-on" mechanism that allows Samus to move in a circle while staying aimed on an enemy. The "lock-on" mechanism also allows Samus to use the Grapple Beam to attach onto and pull objects, such as enemy shields or certain doors. The game uses a first-person view, except in Morph Ball mode, in which Samus's suit transforms into an armored ball and the game uses a third-person camera. The third person camera is also used in conjunction with the Screw Attack power-up: in this case Samus's suit emits strange energy waves as she performs a continuous jump.The game's heads-up display simulates the inside of Samus' helmet, and features a radar, map, ammunition gauge and health meter. The player can change visors to enable new abilities such as X-ray vision, collecting information on many items, creatures and enemies, and interfacing with certain mechanisms such as force fields and elevators. Corruption also includes a hint system that periodically displays on-screen instructions and navigation assistance. The game also has the addition of the Hypermode, a feature in which health is drained to give temporary invincibility and more powerful attacks. After a certain amount of time, the player will enter Corrupt Hypermode, and if not stopped leads to a non-standard game over due to Samus being overtaken by Phazon. Another new feature is the Command Visor, which allows Samus to summon remotely her gunship from a suitable landing site to save the game, or travel to another destination quickly. During the progress of the game, new abilities can be obtained to allow it to perform aerial attacks against enemy targets and transport heavy objects.
The events in Metroid Prime 3: Corruption take place six months after Metroid Prime 2: Echoes. The game's protagonist, Samus Aran, is a bounty hunter hired to assist the Galactic Federation during its ongoing conflict with the Space Pirates. After facing initial defeat on the planet Zebes during the events of the first Metroid, the Space Pirates sought to gain power by using a newly discovered mutagen called Phazon. However, Samus managed to disrupt their operations throughout the Prime trilogy and ultimately allowed the Galactic Federation to confiscate and replicate their Phazon armaments.The Space Pirates' operation was left in disarray following defeat in Metroid Prime 2: Echoes. In their desperation, they turned to Dark Samus, Samus's sinister doppelgänger, for aid. Dark Samus strengthened the Space Pirates' forces, while also slowly indoctrinating them into mindless servants. Their combined forces seek to corrupt the universe with Phazon by first executing a series of methodical attacks on three Federation planets: Norion, Bryyo, and Elysia. The game is primarily centered on these planets and three other locations that become accessible after completing certain in-game tasks.
Fleet Admiral Castor Dane, the commander of a Galactic Federation flagship Olympus, calls for a meeting with Samus Aran and three other bounty hunters—Rundas, Ghor, and Gandrayda. The bounty hunters receive orders to clear a computer virus from several organic supercomputers called "Aurora Units", located throughout the galaxy. The meeting ends abruptly when Space Pirates attack the Federation fleet. Samus and the other bounty hunters are deployed to the planet Norion, where the Space Pirates are concentrating an attack on the Federation base. While suppressing the attack, Samus learns that a Phazon meteoroid, called a Leviathan Seed, will soon collide into Norion. Samus and the other bounty hunters attempt to activate the base's defense systems, when they are suddenly attacked by Dark Samus. With the other bounty hunters knocked out, a severely wounded Samus manages to activate the system just in time to destroy the Leviathan Seed before she falls unconscious.A month later, Samus awakens aboard Olympus, where she learns that Dark Samus's Phazon-based attacks have corrupted her. The Federation equips her suit with a Phazon Enhancement Device (PED) that enables her to harness the Phazon energy within herself. She is informed that her fellow bounty hunters, also corrupted with Phazon and equipped with PEDs, have gone missing during their missions to investigate several planets embedded with Leviathan Seeds. Samus is first sent to the planet Bryyo and later Elysia to determine what happened to her missing comrades. She soon discovers that both planets and their inhabitants are slowly being corrupted by the Leviathan Seeds and that she must destroy the seeds to reverse this. Samus encounters heavy resistance from the Space Pirates, Phazon-corrupted monstrosities, and her fellow bounty hunters who have been corrupted by Dark Samus.Throughout her mission, which eventually takes her to the Space Pirate homeworld, Samus slowly becomes further Phazon-corrupted. She manages to stop the Space Pirate assault with the assistance of the Federation troops. After stealing a Leviathan battleship, Samus and the Federation fleet use it to create a wormhole that leads to the planet Phaaze, the origin point of Phazon. Samus travels to the planet's core, where she finally defeats Dark Samus and then the corrupted Aurora Unit 313. As a result, Dark Samus is obliterated, and Phaaze explodes, rendering all Phazon in the galaxy inert. The Federation fleet escapes Phaaze's destruction, but loses contact with Samus in the process. Samus eventually appears in her gunship, and reports that the mission is accomplished before flying off into space.Samus returns to Elysia, where she mourns the loss of her fellow bounty hunters. If the player completes the game with all of the items obtained, Samus is seen flying into hyperspace, with Sylux's spaceship following her.
Retro Studios intended to give Metroid Prime 3: Corruption larger environments than Metroid Prime 2: Echoes, and enable the game to run at 60 frames per second. The developers were also interested in using the WiiConnect24 feature to provide additional content for the game that would be accessible from the Internet. Retro announced that Corruption would be the final chapter of the Prime series and would have a plot "about closure, told against the backdrop of an epic struggle". After the Wii Remote was revealed, Nintendo demonstrated how Metroid Prime 3 would take advantage of the controller's special abilities with a version of Echoes modified for the Wii and shown at the Tokyo Game Show in 2005. At the Media Summit held by Nintendo during the week of May 21, 2007, Nintendo of America president Reggie Fils-Aimé said that Metroid games "never played this way before" when referring to Corruption. He also noted that Nintendo employees who had seen the game in action claimed that it "will reinvent the control scheme for a first-person shooter".Game director Mark Pacini stated that the biggest concern Retro had during production was the controls, which had "too many functions for the amount of buttons". Pacini also said the Wii Zapper, a gun shell peripheral, was never considered because it was announced when the game's development was almost done. Retro president Michael Kelbaugh said that the delays for the game's release gave them more time to tune the controller, which took a year. He also stated that while Retro did "a great job on the multiplayer in Metroid Prime 2", focus was centered on the single player portion of the game, which was considered to be "the core strength of the franchise". Art director Todd Keller declared the graphics to be focused in both texture detail and variety, with every single texture being hand-made and trying to "make every room its own custom stage". During development, the Nintendo EAD team involved with Corruption suggested Retro to turn Hypermode into the core of the game, saying it would enhance the tension as it made players powerful but if used excessively would lead to a game over. Retro initially disagreed, saying it would be difficult to implement the feature without dampening the entertainment value, but after discussion decided to turn Hyper Mode into a regular functionality of the game.The soundtrack for Metroid Prime 3: Corruption was composed by Kenji Yamamoto, Minako Hamano and Masaru Tajima. The game took advantage of the increase in the amount of RAM that took place when the series switched from the GameCube to the Wii; this allowed for higher quality audio samples to be used and thus allowing a better overall audio quality. Yamamoto used Hirokazu Tanaka's musical design of the original Metroid in Corruption, by keeping the music and themes dark and scary until the very end, when uplifting music is played during the credits. Corruption is the first Metroid game to feature a significant amount of voice acting, compared to previous games in the series in which Samus "[acted] alone [... and] always came across as a lone wolf". The producers decided to include voices to create a stronger connection between players and the characters. The characters' voices were performed by Timothy Patrick Miller, Lainie Frasier, Christopher Sabat, Edwin Neal, Claire Hamilton, Brian Jepson, Gray Haddock, Clayton Kjas and Ken Webster.
The game was first shown to the public at the Electronic Entertainment Expo (E3) 2005 in a short pre-rendered trailer. It was later announced during Nintendo's press conference at the E3 2006. Nintendo revealed in May 2006 that Corruption would be released as a launch game for the Wii console, but a few months later it was delayed to 2007. In April 2007, Fils-Aimé stated in an interview that Corruption was "not going to ship by June" and set it at a summer 2007 release date at the earliest. Later he opined, "when we release it, it will be perfect. And if that's a little later than folks would have liked, I'm hoping they're going to be happy." In late April 2007, IGN editor Matt Casamassina revealed that Corruption would be shown in detail during May of that year, and that the game would be released on August 20, 2007, in the United States. Nintendo of America later announced to have moved the release date to August 27, 2007, but Nintendo finally announced an "in stores" date of August 28, 2007. The game was later released in Europe on October 26, 2007, and in Japan on March 6, 2008. In the Japanese version, the game's difficulty level is decided by answering to "a questionnaire from the Galactic Federation", in contrast to the North American version where the difficulty level is chosen directly by the player. Metroid Prime series producer Kensuke Tanabe said that an idea for a questionnaire came from Retro Studios.Casamassina initially criticized Nintendo for its minimal marketing campaign for Corruption and compared it to the larger campaign for the original Metroid Prime, which included its own live action advertisement. He concluded that the campaign was the result of Nintendo's new focus on casual games for their console. When questioned on the company's actions, Nintendo of America responded by saying, "Nintendo fans will be surprised by the quantity and quality of Metroid Prime 3: Corruption information that becomes available before the game launches on Aug. 27. Your patience will be rewarded (or Corrupted)." Following this promise, Nintendo released the "Metroid Prime 3 Preview" channel on August 10, 2007, in North America and on October 15, 2007, in Europe. The channel, available as a free download via the Wii Shop Channel, allowed Wii owners to view preview videos of the game that included a battle sequence and previously unannounced details on new characters. The Preview channel was the first in a series of new downloadable content including videos made available in North America. The "month of Metroid", as named by Nintendo, included Virtual Console versions of Metroid, available on August 13, 2007, and Super Metroid, available on August 20, 2007.
Metroid Prime 3 was rereleased on August 24, 2009 in North America, alongside Metroid Prime and Metroid Prime 2: Echoes, as a single-disc compilation, Metroid Prime: Trilogy. Prime and Echoes feature the motion controls and achievement systems introduced in Corruption. The compilation was later rereleased on the Wii U's Nintendo eShop on January 29, 2015.
Metroid Prime 3: Corruption received critical acclaim. Nintendo Power commented, "The stunning visuals and immersive gameplay of the finale to the Prime series proves that the Wii is ready for the mainstream gamer." IGN awarded the game an Editor's Choice Award, and noted that the game was beautifully designed and the best looking game for the Wii. They also praised the inclusion of "well-done" voice acting, in contrast to the lack of any voice acting in most other Nintendo games. Despite stating that Metroid Prime 3 was too similar to its predecessors, the review concluded that it was the best game in the Prime trilogy. IGN also said that it could be worthy of the same score as the original Metroid Prime (9.8), had it not been for the aforementioned reason. X-Play claimed that the game was enjoyable, but it had a few awkward control mechanics and was a little difficult to control on the Wii. They also said that although it was fun, there were problems that lead to odd lock-on mechanics and painful wrists from continuous motions.Shane Satterfield from GameTrailers praised the more user-friendly and action-packed nature of the game compared to Metroid Prime and Echoes. Satterfield also praised the superior motion-sensitive controls, stating, "After playing Metroid Prime 3 you'll never want to play a shooter with dual analog controls again, it's that good." He further added that those elements make Corruption "far superior to the original Metroid Prime". 1UP.com was enthusiastic about the new control system and said the graphics were "some of the best visuals in gaming, period". Electronic Gaming Monthly gave Corruption a Silver award and named it one of the Games of the Month. GameSpot stated the game had enjoyable puzzles, boss battles, atmospheric levels, and smooth gameplay. It also explained that the game was more like a traditional shooter video game than an adventure shooter, and stated that the motion activated actions were too unresponsive.GamesRadar named Metroid Prime 3: Corruption the 10th best Wii game of all time out of a list of 25, stating that "Metroid Prime 3 is the ultimate achievement of the series. The formula, which was repeated several times by Corruption, has been tweaked and pruned to its most perfect point, with some of the best shooting on the system." In IGN's Best of 2007 Awards, Corruption received the awards for Best Wii Adventure Game, Best Artistic Design, and Best Overall Adventure Game. GameSpy ranked it as the second best Wii game of the year, behind Super Mario Galaxy, and honored it as the Best Innovation on the Wii. Australian website MyWii named Prime 3 as the second best Wii game currently available, behind Super Mario Galaxy. Despite being released on August 27, Corruption was the fifth best-selling game of the month, with 218,100 copies sold. It also debuted at the fifth spot of the Japanese charts, with 34,000 units in the first week of release. More than one million copies of the game were sold in 2007, and as of March 2008, 1.31 million copies of the game were sold worldwide.
Metroid Prime: Federation Force, a Nintendo 3DS game developed by Next Level Games, was announced at E3 2015; Metroid Prime series producer Kensuke Tanabe said that "this time around we're doing a story on the Galactic Federation." Regarding the Corruption's ending, Tanabe wanted to create a story that centers on Samus and Sylux, noting that "[t]here's something going on between them. I want to make a game that touches upon [it]." Tanabe added that Nintendo had no plans on releasing the next Metroid Prime game for the Wii U, stating "it would likely now be on Nintendo's NX console."On June 13, 2017, Nintendo announced during their Nintendo Spotlight presentation at E3 2017 that Metroid Prime 4 is currently in development for the Nintendo Switch. The game was initially announced to be developed by an entirely new team overseen by series producer Kensuke Tanabe, instead of Retro Studios. Eurogamer reported in February 2018 that Bandai Namco Singapore was working on the game alongside Nintendo and that the project included some staff members who worked on the cancelled Star Wars 1313 game. However, in a January 2019 development update posted on their YouTube channel, Nintendo announced that development of Metroid Prime 4 was restarted and the project would be handled by Retro Studios once again.

Metroid Prime is a first-person action-adventure game developed by Retro Studios and Nintendo for the GameCube video game console. It was released in North America on November 17, 2002, and in Japan and Europe the following year. Metroid Prime is the fifth main installment in the Metroid series, and the first Metroid game to use 3D computer graphics. Because exploration takes precedence over combat, Nintendo classifies the game as a first-person adventure rather than a first-person shooter. On the same day as its North American release, Nintendo also released the Game Boy Advance game Metroid Fusion, marking the return of the Metroid series after an eight-year hiatus following Super Metroid (1994).Metroid Prime is the first of the three-part Prime storyline, which takes place between the original Metroid and Metroid II: Return of Samus. Like previous games in the series, Metroid Prime has a science fiction setting in which players control the bounty hunter Samus Aran. The story follows Samus as she battles the Space Pirates and their biological experiments on the planet Tallon IV. The game was a collaboration between Retro's staff in Austin, Texas, and Japanese Nintendo employees, including producer Shigeru Miyamoto, who suggested the project after visiting Retro's headquarters in 2000.
The game garnered critical praise and commercial success, selling more than a million units in North America alone. It won a number of Game of the Year awards, and it is considered by many critics and gamers to be one of the greatest video games ever made, remaining one of the highest-rated games on Metacritic. In 2009, an enhanced version was released for the Wii as a standalone game in Japan, and as part of the Metroid Prime Trilogy compilation internationally.
As in previous Metroid games, Metroid Prime takes place in a large, open-ended world in which regions are connected by elevators. Each region has a set of rooms separated by doors that can be opened with a shot from the correct beam. The gameplay involves solving puzzles to reveal secrets, platform jumping, and shooting foes with the help of a "lock-on" mechanism that allows circle strafing while staying aimed at the enemy. Metroid Prime is the first game in the Metroid series to use a first-person view instead of side-scrolling, except in Morph Ball mode, when Samus' suit transforms into an armored ball and the game uses a third-person camera.The protagonist, Samus Aran, must travel through the world of Tallon IV searching for twelve Chozo Artifacts that will open the path to the Phazon meteor impact crater, while collecting power-ups that let her reach new areas. The Varia Suit, for example, protects Samus' armor against high temperatures, allowing her to enter volcanic regions. Some items are obtained after boss fights. Items must be collected in a specific order; for example, players cannot access certain areas until they find a certain Beam to open doors, or discover new ordnance with which to beat bosses. Like the rest of the series, players are incentivized to explore to find upgrades such as ammunition packs and extra health.The heads-up display, which simulates the inside of Samus' helmet, features a radar display, a map, ammunition for missiles, a health meter, a danger meter for negotiating hazardous landscape or materials, and a health bar and name display for bosses. The display can be altered by exchanging visors; one uses thermal imaging, another has x-ray vision, and another features a scanner that searches for enemy weaknesses and interfaces with mechanisms such as force fields and elevators. Metroid Prime introduces a hint system that provides the player with clues about ways to progress through the game.
Throughout the game, players must find and collect items that improve Samus's arsenal and suit, including weapons, armor upgrades for Samus's Power Suit and items that grant abilities—including the Morph Ball, which allows Samus to compress herself into a ball in order to roll into narrow passages and drop energy bombs, and the Grapple Beam, which works by latching onto special hooks called grapple points, allowing Samus to swing across gaps. Unlike those in earlier games in the series, the beam weapons in Metroid Prime have no stacking ability, in which the traits of each beam merge. Instead, the player must cycle the four beam weapons; there are charge combos with radically different effects for each. Other upgrades include boots that allow Samus to double-jump and a Spider Ball upgrade that allows her to climb magnetic rails.Items from previous Metroid games appear with altered functions. Art galleries and different endings are unlockable if the player collects a high percentage of items and Scan Visor logs. Prime is one of the first Metroid games to address the reason Samus does not start with power-ups acquired in previous games; she begins the game with some upgrades, including the Varia Suit, Missiles and Grapple Beam, but they are lost during an explosion on the Space Pirate frigate Orpheon. The producers stated that starting with some power-ups was a way to give the player "different things to do" and to learn the functions of these items before settling into the core gameplay.Players can gain two features by connecting Prime with Metroid Fusion using a GameCube – Game Boy Advance link cable: cosmetic use of the Fusion Suit that Samus wears in Fusion and the ability to play the original Metroid.
Metroid Prime is the first of the three-part Prime storyline. Retro Studios wrote an extensive storyline for Metroid Prime, which was considered a major difference from previous Metroid games. Short cutscenes appear before important battles, and a scanner in the heads-up display extracts backstory-related information from objects. The Prime trilogy is set between the events of  Metroid and Metroid II, but according to some sources, including Brazil's former Nintendo distributor Gradiente and the Nintendo Power comics adaptation of Metroid Prime, the events in the Prime games occur after Super Metroid. The Brazilian publicity states that the Phazon meteor is a piece of Zebes, which was destroyed after Super Metroid. However, one of the logbook entries from Metroid Prime 3: Corruption reveals that the meteor was a "Leviathan" from the planet Phaaze.The game takes place on the planet Tallon IV, formerly inhabited by the Chozo race. Five decades before the game's events, the Chozo race fell after a meteor crashed onto Tallon IV. This meteor contaminated the planet with a corruptive, mutagenic substance that the Space Pirates later named "Phazon", and also brought with it a creature known to the Chozo as "The Worm". A large containment field emitter of the "Artifact Temple" in the Tallon Overworld area was designed as a seal to the meteor's energies and influence within the crater where it landed, which the Space Pirates attempt to disable or bypass in order to gain better access in order to extract the Phazon. The containment field is controlled by twelve Chozo artifacts that are scattered around the planet. The player assumes the role of the bounty hunter Samus Aran, who receives a distress signal from the Space Pirate frigate Orpheon and travels to Tallon IV to investigate and stop the Space Pirate activity she found. Her investigation leads her to stop the Space Pirates from exploiting Phazon and stop the spread of Phazon on Tallon IV.
Samus intercepts a distress signal from the Space Pirate frigate Orpheon, whose crew have been slaughtered by the Pirates' own genetically modified, experimental subjects. At the ship's core, she battles with the Parasite Queen—a giant version of the tiny parasites aboard the ship. The Parasite Queen is defeated and falls into the ship's reactor core, initiating the destruction of the ship. While Samus is escaping from the doomed frigate, she encounters a cybernetic version of Ridley called Meta-Ridley. During her escape, an electrical surge and explosion damages her Varia Suit, which reverts to her original Power Suit. Samus escapes the frigate and chases her nemesis in her gunship towards the nearby planet Tallon IV.Samus initially lands on Tallon IV at a rain forest location referred to as "Tallon Overworld". After a brief period of exploring, she discovers the Chozo Ruins, the remains of the Chozo civilization. After further investigation, Samus learns that many years ago, the planet was struck by a meteor, which carried with it a substance the Chozo call the "Great Poison", commonly known as "Phazon". The meteor also contained a creature called "the Worm". The Chozo built an Artifact Temple over the crater to contain "the Worm" and to stop the Phazon from spreading over the planet. The temple's sealed entrance is controlled by twelve Chozo artifacts, which must be found to gain access to the crater. After re-obtaining the Varia Suit in the ruins, Samus finds her way to the Magmoor Caverns, a series of magma-filled underground tunnels, which are used by the Space Pirates as a source of geothermal power and connect the game's areas together. Following the tunnels, Samus travels to the Phendrana Drifts, a cold, mountainous location which is home to an ancient Chozo ruin and Space Pirate research labs used to study Metroids, as well as ice caves and valleys home to electrical and ice-creatures. After obtaining the Gravity Suit in Phendrana, Samus explores the interior of the crashed Orpheon, then infiltrates the Phazon Mines—the mining and research complex which is the center of the Space Pirates' Tallon IV operations. Here she battles Phazon-enhanced Space Pirates and obtains the Phazon Suit after defeating the monstrous, Phazon-mutated Omega Pirate.During her exploration of Tallon IV, Samus finds the twelve keys to the Artifact Temple and lore recorded by the Chozo and the Space Pirates, providing insight into the history of the planet and the two races' colonization of it. As Samus puts the final key in place, Meta-Ridley appears and attacks her. Samus defeats him with help from the temple's defensive artillery. The Chozo Artifacts and Phazon Suit allow Samus to enter the Impact Crater, where she finds the so-called "Worm": Metroid Prime, the source of the Phazon on Tallon IV. After she defeats it, all the Phazon on Tallon IV disappears, but Metroid Prime itself absorbs Samus's Phazon Suit in a final effort to survive, reverting her armor to the Gravity Suit. Samus escapes the collapsing crater and leaves Tallon IV in her ship. In a post-credits scene, only viewable if the player has collected all of the items, Metroid Prime uses the Phazon Suit to construct a new body, becoming the entity known in future sequels as Dark Samus.
According to producer Shigeru Miyamoto, Nintendo did not develop a Metroid game for the Nintendo 64 (N64) as Nintendo "couldn't come out with any concrete ideas". Metroid co-creator Yoshio Sakamoto said he could not imagine how the N64 controller could be used to control Samus. Nintendo approached another company to make an N64 Metroid, but the offer was declined, supposedly because the developers thought they could not equal Super Metroid.Metroid Prime was a collaboration between Nintendo EAD and R&D1 and the American company Retro Studios. Retro was created in 1998 by an alliance between Nintendo and Iguana Entertainment founder Jeff Spangenberg. The studio would create games for the forthcoming GameCube targeted at a mature demographic. After establishing its offices in Austin, Texas in 1999, Retro worked on four GameCube projects. When Miyamoto visited Retro in 2000, he suggested a new Metroid game after seeing their prototype first-person shooter engine. In 2000 and early 2001, four games in development at Retro were canceled, including an RPG, Raven Blade, leaving Prime the only game in development. During the last nine months of development, Retro's staff worked 80- to 100-hour weeks to reach Nintendo's deadline.
Nintendo created the music, Retro handled art and engineering, and both teams worked on the overall design. The Japanese crew, which included producers Miyamoto, Kensuke Tanabe, Kenji Miki and designer and Metroid co-creator Sakamoto, communicated with Retro through e-mails, telephone conferences and personal gatherings. The game was planned to use a third-person perspective, but after Miyamoto intervened this was changed to first-person perspective and almost everything already developed was scrapped. The change was prompted by camera problems experienced by Rare, which was developing the N64 game Jet Force Gemini. According to director Mark Pacini, Miyamoto "felt that shooting in third person was not very intuitive"; Pacini also said that exploration is easier using first-person. Pacini said that after picking that perspective, the crew decided not to make a traditional first-person shooter. He said, "We weren't trying to fit in that genre. We had to break down the stereotypes of what a first-person game is and make a fun Metroid game."Pacini stated that Retro tried to design the game so that the only difficult parts would be boss battles and players would not be afraid to explore because "the challenge of the game was finding your way around". Senior designer Mike Wikan said that the focus on exploration led the team to spend time making the platform jumping "approachable to the player", and to ensure the gameplay had "shooting [as] a very important, though secondary, consideration". Retro developed the storyline under the supervision of Yoshio Sakamoto, who verified that the ideas were consistent with the lore of the earlier games. The developers intended that Kraid, a boss from Metroid and Super Metroid, would appear in Prime, and designer Gene Kohler modeled and skinned him for that purpose, but he was cut for time reasons. The team considered implementing the Speed Booster power-up from Super Metroid but concluded it would not work well because of the first-person perspective and "limitations imposed by the scale of our environment".The first public appearance of the game was a ten-second video at SpaceWorld 2000. In November of the same year, Retro Studios confirmed its involvement with the game in the "job application" part of its website. In February 2001, the game was confirmed by Nintendo, which also announced that because of its emphasis on exploration and despite the first-person perspective, Metroid Prime would be a first-person adventure rather than a first-person shooter. In May 2001, the game was showcased at E3 2001, with its title confirmed as Metroid Prime.
Kenji Yamamoto, assisted by Kouichi Kyuma, composed the music for Prime. The soundtrack contains arrangements of tracks from previous games in the series because Yamamoto wanted "to satisfy old Metroid fans. It's like a present for them", he said. The initial Tallon Overworld theme is a reinterpretation of Metroid's Brinstar theme, the music heard in Magmoor Caverns is a new version of the music from Super Metroid's Lower Norfair area, and the music heard during the fight with Meta Ridley is a fast-paced reimagining of the Ridley boss music first featured in Super Metroid—which has reappeared in most Metroid games since. Tommy Tallarico Studios initially provided sound effects for the game, but Shigeru Miyamoto thought they were not yet good enough for an extended presentation at SpaceWorld 2001. The game supports Dolby Pro Logic II setups and can be played in surround sound. The official soundtrack to the game was released on an album called Metroid Prime & Fusion Original Soundtracks, which was published by Scitron on June 18, 2003.
Metroid Prime was released for the GameCube in North America on November 17, 2002, and in Japan and Europe the following year on February 28, 2003 and March 21, 2003, respectively.Prime was released for the GameCube in five versions. The original North American and Japanese NTSC versions and the second North American version, which contained minor changes, all used a loader that sometimes caused the game to freeze in specific rooms. The European PAL version resolved these glitches and contained altered elements of the gameplay to prevent sequence breaking, a slower loader that prevented the occasional crashes, slightly different story details, and narration in the opening and closing scenes. Some of these changes were carried over from the PAL version to the NTSC region's Player's Choice re-release, along with additional changes not made in other releases. This version, which was bundled with a silver GameCube, also contained a second disc featuring a preview trailer and a demo for Metroid Prime 2: Echoes, a timeline of Metroid games, and an art gallery.
Metroid Prime was rereleased in Japan in 2009 for the Wii as part of the New Play Control! series. It has improved controls that use the Wii Remote's pointing functionality. The credit system from Metroid Prime 3: Corruption is also included to unlock the original bonus content and the ability to take snapshots of gameplay. Internationally, the Wii version was released in Metroid Prime: Trilogy, a single-disc compilation containing Prime, Echoes, and Corruption for Wii. On January 29, 2015, the compilation became available for download from the Wii U's Nintendo eShop.
Metroid Prime became one of the best-selling games on the GameCube. It was the second best-selling game of November 2002 in North America, behind Grand Theft Auto: Vice City; 250,000 units were sold in the first week of its release. As of  July 2006, the game had sold more than 1.49 million copies in the U.S. alone, and had earned more than US$50 million. It was also the eighth best-selling GameCube game in Australia. More than 78,000 copies were sold in Japan, and Nintendo added the game to its Player's Choice line in the PAL region.Metroid Prime was met with critical acclaim. Electronic Gaming Monthly awarded the game a perfect review score. It won numerous Game of the Year awards and was praised for its detailed graphics, special effects, varied environments, moody soundtrack and sound effects, level design, immersive atmosphere and innovative gameplay centered on exploration in contrast with action games such as Halo, while staying faithful to the Metroid formula. Criticisms included the unusual control scheme, lack of focus on the story, and repetitive backtracking. Game Informer considered the control scheme awkward, Entertainment Weekly compared the game to a "1990s arcade game, filled with over the top battle sequences, spectacular visual effects—and a pretty weak plot", and GamePro stated that inexperienced players "might find it exhausting to keep revisiting the same old places over and over and over". In 2004, the video game countdown show Filter said Metroid Prime had the best graphics of all time.Metroid Prime appeared on several lists of best games; it was ranked 23rd in IGN's Top 100, 29th in a 100-game list chosen by GameFAQs users, and 10th in Nintendo Power's "Top 200 Nintendo Games Ever".  IGN named Metroid Prime the best GameCube game, while GameSpy ranked it third in a similar list, behind The Legend of Zelda: The Wind Waker and Resident Evil 4. Nintendo Power also ranked Metroid Prime as the sixth-best game of the 2000s. Wired ranked the game 10th in its list of "The 15 Most Influential Games of the Decade" for popularizing "exploration, puzzle-solving, platforming and story" among first-person shooters, saying that the game was "breaking the genre free from the clutches of Doom". Wired's writer continued; "This GameCube title took one massive stride forward for first-person games." Metroid Prime also became popular among players for speedrunning;  specialized communities were formed to share these speedruns.
After Metroid Prime,  three more games in the first-person perspective and a pinball spin-off were released. The sequel Metroid Prime 2: Echoes - in which Samus travels to planet Aether and discovers that a Phazon meteor crashed there, creating an alternate reality, and Samus fights a mysterious enemy called Dark Samus - was released in November 2004 for the GameCube. It was followed by Metroid Prime Pinball, a spin-off game featuring the locations and bosses of Metroid Prime, developed by Fuse Games and released in 2005 for the Nintendo DS.The next game released was Metroid Prime: Hunters for the Nintendo DS; its storyline takes place between the events of Prime and Echoes. A demo of the game, titled Metroid Prime: Hunters - First Hunt, was bundled with the Nintendo DS, and the full game was released on March 20, 2006 in North America, and May 5, 2006 in Europe. In its narrative, Samus tries to discover an "ultimate power" while facing six rival bounty hunters. Hunters was not developed by Retro Studios, but by Nintendo's Redmond-based subsidiary Nintendo Software Technology. The game contains more first-person shooter aspects than Prime and Echoes, with removal of assisted aiming, more action-oriented gameplay, and various multiplayer modes.Metroid Prime's second full sequel is Metroid Prime 3: Corruption, which closes the Prime series. It was released on August 27, 2007 for the Wii console. In Corruption's story, Samus is corrupted by Phazon after being attacked by Dark Samus, who has become the leader of a Space Pirate group and is sending Phazon Seeds to corrupt planets. Corruption's gameplay differs from that of Prime and Echoes; the assisted aiming is replaced with free aiming with the Wii Remote, and the interchangeable beams are replaced with a stackable upgrade system.
A fourth game in the series, Metroid Prime 4, was announced at Nintendo's E3 2017 Spotlight livestream, and is currently under development for the Nintendo Switch. The game was initially announced to be developed by an entirely new team overseen by series producer Kensuke Tanabe, instead of Retro Studios. Eurogamer reported in February 2018 that Bandai Namco Singapore was working on the game alongside Nintendo and that the project included some staff members who worked on the cancelled Star Wars 1313 game. However, in a January 2019 development update posted on their YouTube channel, Nintendo announced that development of Metroid Prime 4 was restarted and the project would be handled by Retro Studios.Elements of Metroid Prime have appeared in other games, such as Super Smash Bros. Brawl in which the Frigate Orpheon is a playable stage, featuring the Parasite Queen in the background and several music tracks from Metroid Prime as background music. This stage later returned in Super Smash Bros. Ultimate. Metroid Prime's style of gameplay and HUDs also influenced and was compared to later first-person shooters, such as Geist and Star Wars: Republic Commando.

The Metropolitan Railway (also known as the Met) was a passenger and goods railway that served London from 1863 to 1933, its main line heading north-west from the capital's financial heart in the City to what were to become the Middlesex suburbs. Its first line connected the main-line railway termini at Paddington, Euston, and King's Cross to the City. The first section was built beneath the New Road using the "cut-and-cover" method between Paddington and King's Cross and in tunnel and cuttings beside Farringdon Road from King's Cross to near Smithfield, near the City. It opened to the public on 10 January 1863 with gas-lit wooden carriages hauled by steam locomotives, the world's first passenger-carrying designated underground railway.The line was soon extended from both ends, and northwards via a branch from Baker Street. It reached Hammersmith in 1864, Richmond in 1877 and completed the Inner Circle in 1884, but the most important route was the line north into the Middlesex countryside, where it stimulated the development of new suburbs. Harrow was reached in 1880, and the line eventually extended to Verney Junction in Buckinghamshire, more than 50 miles (80 kilometres) from Baker Street and the centre of London.
Electric traction was introduced in 1905 and by 1907 electric multiple units operated most of the services, though electrification of outlying sections did not occur until decades later. Unlike other railway companies in the London area, the Met developed land for housing, and after World War I promoted housing estates near the railway using the "Metro-land" brand. On 1 July 1933, the Met was amalgamated with the Underground Electric Railways Company of London and the capital's tramway and bus operators to form the London Passenger Transport Board.
Former Met tracks and stations are used by the London Underground's Metropolitan, Circle, District, Hammersmith & City, Piccadilly, Jubilee and Victoria lines, and by Chiltern Railways and Great Northern.
In the first half of the 19th century the population and physical extent of London grew greatly. The increasing resident population and the development of a commuting population arriving by train each day led to a high level of traffic congestion with huge numbers of carts, cabs, and omnibuses filling the roads and up to 200,000 people entering the City of London, the commercial heart, each day on foot. By 1850 there were seven railway termini around the urban centre of London: London Bridge and Waterloo to the south, Shoreditch and Fenchurch Street to the east, Euston and King's Cross to the north, and Paddington to the west. Only Fenchurch Street station was within the City.The congested streets and the distance to the City from the stations to the north and west prompted many attempts to get parliamentary approval to build new railway lines into the City. None were successful, and the 1846 Royal Commission investigation into Metropolitan Railway Termini banned construction of new lines or stations in the built-up central area. The concept of an underground railway linking the City with the mainline termini was first proposed in the 1830s. Charles Pearson, Solicitor to the City, was a leading promoter of several schemes and in 1846 proposed a central railway station to be used by multiple railway companies. The scheme was rejected by the 1846 commission, but Pearson returned to the idea in 1852 when he helped set up the City Terminus Company to build a railway from Farringdon to King's Cross. The plan was supported by the City, but the railway companies were not interested and the company struggled to proceed.The Bayswater, Paddington, and Holborn Bridge Railway Company was established to connect the Great Western Railway's (GWR's) Paddington station to Pearson's route at King's Cross. A bill was published in November 1852 and in January 1853 the directors held their first meeting and appointed John Fowler as its engineer. After successful lobbying, the company secured parliamentary approval under the name of the "North Metropolitan Railway" in mid-1853. The bill submitted by the City Terminus Company was rejected by Parliament, which meant that the North Metropolitan Railway would not be able to reach the City: to overcome this obstacle, the company took over the City Terminus Company and submitted a new bill in November 1853. This dropped the City terminus and extended the route south from Farringdon to the General Post Office in St. Martin's Le Grand. The route at the western end was also altered so that it connected more directly to the GWR station. Permission was sought to connect to the London and North Western Railway (LNWR) at Euston and to the Great Northern Railway (GNR) at King's Cross, the latter by hoists and lifts. The company's name was also to be changed again, to Metropolitan Railway. Royal assent was granted to the North Metropolitan Railway Act on 7 August 1854.
Construction of the railway was estimated to cost £1 million. Initially, with the Crimean War under way, the Met found it hard to raise the capital. While it attempted to raise the funds it presented new bills to Parliament seeking an extension of time to carry out the works. In July 1855, an Act to make a direct connection to the GNR at King's Cross received royal assent. The plan was modified in 1856 by the Metropolitan (Great Northern Branch and Amendment) Act and in 1860 by the Great Northern & Metropolitan Junction Railway Act.The GWR agreed to contribute £175,000 and a similar sum was promised by the GNR, but sufficient funds to make a start on construction had not been raised by the end of 1857. Costs were reduced by cutting back part of the route at the western end so that it did not connect directly to the GWR station, and by dropping the line south of Farringdon. In 1858, Pearson arranged a deal between the Met and the City of London Corporation whereby the Met bought land it needed around the new Farringdon Road from the City for £179,000 and the City purchased £200,000 worth of shares. The route changes were approved by Parliament in August 1859, meaning that the Met finally had the funding to match its obligations and construction could begin.
Despite concerns about undermining and vibrations causing subsidence of nearby buildings and compensating the thousands of people whose homes were destroyed during the digging of the tunnel construction began in March 1860. The line was mostly built using the "cut-and-cover" method from Paddington to King's Cross; east of there it continued in a 728 yards (666 m) tunnel under Mount Pleasant, Clerkenwell then followed the culverted River Fleet beside Farringdon Road in an open cutting to near the new meat market at Smithfield.The trench was 33 feet 6 inches (10.2 m) wide, with brick retaining walls supporting an elliptical brick arch or iron girders spanning 28 feet 6 inches (8.7 m). The tunnels were wider at stations to accommodate the platforms. Most of the excavation work was carried out manually by navvies; a primitive earth-moving conveyor was used to remove excavated spoil from the trench.Within the tunnel, two lines were laid with a 6-foot (1.8 m) gap between. To accommodate both the standard gauge trains of the GNR and the broad gauge trains of the GWR, the track was three-rail mixed gauge, the rail nearest the platforms being shared by both gauges. Signalling was on the absolute block method, using electric Spagnoletti block instruments and fixed signals.Construction was not without incident. In May 1860, a GNR train overshot the platform at King's Cross and fell into the workings. Later in 1860, a boiler explosion on an engine pulling contractor's wagons killed the driver and his assistant. In May 1861, the excavation collapsed at Euston causing considerable damage to the neighbouring buildings. The final accident occurred in June 1862 when the Fleet sewer burst following a heavy rainstorm and flooded the excavations. The Met and the Metropolitan Board of Works managed to stem and divert the water and the construction was delayed by only a few months.Trial runs were carried out from November 1861 while construction was still under way. The first trip over the whole line was in May 1862 with William Gladstone among the guests. By the end of 1862 work was complete at a cost of £1.3 million.
Board of Trade inspections took place in late December 1862 and early January 1863 to approve the railway for opening. After minor signalling changes were made, approval was granted and a few days of operating trials were carried out before the grand opening on 9 January 1863, which included a ceremonial run from Paddington and a large banquet for 600 shareholders and guests at Farringdon. Charles Pearson did not live to see the completion of the project; he died in September 1862.
The 3.75-mile (6 km) railway opened to the public on Saturday 10 January 1863. There were stations at Paddington (Bishop's Road) (now Paddington), Edgware Road, Baker Street, Portland Road (now Great Portland Street), Gower Street (now Euston Square), King's Cross (now King's Cross St Pancras), and Farringdon Street (now Farringdon).The railway was hailed a success, carrying 38,000 passengers on the opening day, using GNR trains to supplement the service. In the first 12 months 9.5 million passengers were carried and in the second 12 months this increased to 12 million.The original timetable allowed 18 minutes for the journey. Off-peak service frequency was every 15 minutes, increased to ten minutes during the morning peak and reduced 20 minutes in the early mornings and after 8 pm. From May 1864, workmen's returns were offered on the 5:30 am and 5:40 am services from Paddington at the cost of a single ticket (3d).Initially the railway was worked by GWR broad-gauge Metropolitan Class steam locomotives and rolling stock. Soon after the opening disagreement arose between the Met and the GWR over the need to increase the frequency, and the GWR withdrew its stock in August 1863. The Met continued operating a reduced service using GNR standard-gauge rolling stock before purchasing its own standard-gauge locomotives from Beyer, Peacock and rolling stock.The Metropolitan initially ordered 18 tank locomotives, of which a key feature was condensing equipment which prevented most of the steam from escaping while trains were in tunnels; they have been described as "beautiful little engines, painted green and distinguished particularly by their enormous external cylinders." The design proved so successful that eventually 120 were built to provide traction on the Metropolitan, the District Railway (in 1871) and all other 'cut and cover' underground lines. This 4-4-0 tank engine can therefore be considered as the pioneer motive power on London's first underground railway; ultimately, 148 were built between 1864 and 1886 for various railways, and most kept running until electrification in 1905.
In the belief that it would be operated by smokeless locomotives, the line had been built with little ventilation and a long tunnel between Edgware Road and King's Cross. Initially the smoke-filled stations and carriages did not deter passengers and the ventilation was later improved by making an opening in the tunnel between Gower Street and King's Cross and removing glazing in the station roofs. With the problem continuing after the 1880s, conflict arose between the Met, who wished to make more openings in the tunnels, and the local authorities, who argued that these would frighten horses and reduce property values. This led to an 1897 Board of Trade report, which reported that a pharmacist was treating people in distress after having travelled on the railway with his 'Metropolitan Mixture'. The report recommended more openings be authorised but the line was electrified before these were built.
With connections to the GWR and GNR under construction and connections to the Midland Railway and London, Chatham and Dover Railway (LC&DR) planned, the Met obtained permission in 1861 and 1864 for two additional tracks from King's Cross to Farringdon Street and a four-track eastward extension to Moorgate. The Met used two tracks: the other two tracks, the City Widened Lines, used mainly by other railway companies.A pair of single-track tunnels at King's Cross connecting the GNR to the Met opened on 1 October 1863 when the GNR began running services, the GWR returning the same day with through suburban trains from such places as Windsor. By 1864 the Met had sufficient carriages and locomotives to run its own trains and increase the frequency to six trains an hour.On 1 January 1866, LC&DR and GNR joint services from Blackfriars Bridge began operating via the Snow Hill tunnel under Smithfield market to Farringdon and northwards to the GNR. The extension to Aldersgate Street and Moorgate Street (now Barbican and Moorgate) had opened on 23 December 1865 and all four tracks were open on 1 March 1866.The new tracks from King's Cross to Farringdon were first used by a GNR freight train on 27 January 1868. The Midland Railway junction opened on 13 July 1868 when services ran into Moorgate Street before its St Pancras terminus had opened. The line left the main line at St Paul's Road Junction, entering a double-track tunnel and joining the Widened Lines at Midland Junction.
In November 1860, a bill was presented to Parliament, supported by the Met and the GWR, for a railway from the GWR's main line a mile west of Paddington to the developing suburbs of Shepherd's Bush and Hammersmith, with a connection to the West London Railway at Latimer Road. Authorised on 22 July 1861 as the Hammersmith and City Railway (H&CR), the 2 miles 35 chains (3.9 km) line, constructed on a 20-foot (6.1 m) high viaduct largely across open fields, opened on 13 June 1864 with a broad-gauge GWR service from Farringdon Street,  with stations at Notting Hill (now Ladbroke Grove), Shepherd's Bush (replaced by the current Shepherd's Bush Market in 1914) and Hammersmith. The link to the West London Railway opened on 1 July that year, served by a carriage that was attached or detached at Notting Hill for Kensington (Addison Road). Following an agreement between the Met and the GWR, from 1865 the Met ran a standard-gauge service to Hammersmith and the GWR a broad-gauge service to Kensington. In 1867, the H&CR became jointly owned by the two companies. The GWR began running standard-gauge trains and the broad gauge rail was removed from the H&CR and the Met in 1869. In 1871, two additional tracks parallel to the GWR between Westbourne Park and Paddington were brought into use for the H&CR and in 1878 the flat crossing at Westbourne Park was replaced by a diveunder. In August 1872, the GWR Addison Road service was extended over the District Railway via Earl's Court to Mansion House. This became known as the Middle Circle and ran until January 1905; from 1 July 1900 trains terminated at Earl's Court. Additional stations were opened at Westbourne Park (1866), Latimer Road (1868), Royal Oak (1871), Wood Lane (1908) and Goldhawk Road (1914).
Between 1 October 1877 and 31 December 1906 some services on the H&CR were extended to Richmond over the London and South Western Railway (L&SWR) via its station at Hammersmith (Grove Road).
The early success of the Met prompted a flurry of applications to Parliament in 1863 for new railways in London, many of them competing for similar routes. To consider the best proposals, the House of Lords established a select committee, which issued a report in July 1863 with a recommendation for an "inner circuit of railway that should abut, if not actually join, nearly all of the principal railway termini in the Metropolis". A number of railway schemes were presented for the 1864 parliamentary session that met the recommendation in varying ways and a Joint Committee of the Parliament of the United Kingdom was set up to review the options.Proposals from the Met to extend south from Paddington to South Kensington and east from Moorgate to Tower Hill were accepted and received royal assent on 29 July 1864. To complete the circuit, the committee encouraged the amalgamation of two schemes via different routes between Kensington and the City, and a combined proposal under the name Metropolitan District Railway (commonly known as the District railway) was agreed on the same day.
Initially, the District and the Met were closely associated and it was intended that they would soon merge. The Met's chairman and three other directors were on the board of the District, John Fowler was the engineer of both companies and the construction works for all of the extensions were let as a single contract. The District was established as a separate company to enable funds to be raised independently of the Met.
Starting as a branch from Praed Street junction, a short distance east of the Met's Paddington station, the western extension passed through fashionable districts in Bayswater, Notting Hill, and Kensington. Land values here were higher and, unlike the original line, the route did not follow an easy alignment under existing roads. Compensation payments for property were much higher. In Leinster Gardens, Bayswater, a façade of two five-storey houses was built at Nos. 23 and 24 to conceal the gap in a terrace created by the railway passing through. To ensure adequate ventilation, most of the line was in cutting except for a 421-yard (385 m) tunnel under Campden Hill. Construction of the District proceeded in parallel with the work on the Met and it too passed through expensive areas. Construction costs and compensation payments were so high that the cost of the first section of the District from South Kensington to Westminster was £3 million, almost three times as much as the Met's original, longer line.The first section of the Met extension opened to Brompton (Gloucester Road) (now Gloucester Road) on 1 October 1868, with stations at Paddington (Praed Street) (now Paddington), Bayswater, Notting Hill Gate, and Kensington (High Street) (now High Street Kensington). Three months later, on 24 December 1868, the Met extended eastwards to a shared station at South Kensington and the District opened its line from there to Westminster, with other stations at Sloane Square, Victoria, St James's Park, and Westminster Bridge (now Westminster).The District also had parliamentary permission to extend westward from Brompton and, on 12 April 1869, it opened a single-track line to West Brompton on the WLR. There were no intermediate stations and at first this service operated as a shuttle from Gloucester Road. By mid-1869 separate tracks had been laid between South Kensington and Brompton and from Kensington (High Street) to a junction with the line to West Brompton. During the night of 5 July 1870 the District secretly built the disputed Cromwell curve connecting Brompton and Kensington (High Street).East of Westminster, the next section of the District's line ran in the new Victoria Embankment built by the Metropolitan Board of Works along the north bank of the River Thames. The line opened from Westminster to Blackfriars on 30 May 1870 with stations at Charing Cross (now Embankment), The Temple (now Temple) and Blackfriars.On its opening the Met operated the trains on the District, receiving 55 per cent of the gross receipts for a fixed level of service. Extra trains required by the District were charged for and the District's share of the income dropped to about 40 per cent. The District's level of debt meant that the merger was no longer attractive to the Met and did not proceed, so the Met's directors resigned from the District's board. To improve its finances, the District gave the Met notice to terminate the operating agreement. Struggling under the burden of its very high construction costs, the District was unable to continue with the remainder of the original scheme to reach Tower Hill and made a final extension of its line just one station east from Blackfriars to a previously unplanned City terminus at Mansion House.
On Saturday 1 July 1871 an opening banquet was attended by Prime Minister William Gladstone, who was also a shareholder. The following Monday, Mansion House opened and the District began running its own trains. From this date, the two companies operated a joint Inner Circle service between Mansion House and Moorgate Street via South Kensington and Edgware Road every ten minutes, supplemented by a District service every ten minutes between Mansion House and West Brompton and H&CR and GWR suburban services between Edgware Road and Moorgate Street. The permissions for the railway east of Mansion House were allowed to lapse. At the other end of the line, the District part of South Kensington station opened on 10 July 1871  and Earl's Court station opened on the West Brompton extension on 30 October 1871.In 1868 and 1869, judgements went against the Met in a number of hearings, finding financial irregularities such as the company paying a dividend it could not afford and expenses being paid out of the capital account. In 1870, its directors were found guilty of a breach of trust and ordered to compensate the company. They all appealed and were allowed in 1874 to settle for a much lower amount, but to restore shareholders' confidence the directors had all been replaced by October 1872 and Edward Watkin appointed chairman. Watkin was an experienced railwayman and already on the board of several railway companies, including the South Eastern Railway (SER), and had an aspiration to construct a line from the north through London to that railway.Due to the cost of land purchases, the Met's eastward extension from Moorgate Street was slow to progress and it had to obtain an extension of the Act's time limit in 1869. The extension was begun in 1873, but after construction exposed burials in the vault of a Roman Catholic chapel, the contractor reported that it was difficult to keep the men at work. The first section opened to the Great Eastern Railway's (GER's) recently opened terminus at Liverpool Street on 1 February 1875. For a short time, while the Met's station was being built, services ran into the GER station via a 3.5-chain (70 m) curve, the Met opening its station later that year on 12 July and this curve not being used again by regular traffic. During the extension of the railway to Aldgate several hundred cartloads of bullocks' horn were discovered in a layer 20 ft (6.1 m) below the surface. A terminus opened at Aldgate on 18 November 1876, initially for a shuttle service to Bishopsgate before all Met and District trains worked through from 4 December.
Conflict between the Met and the District and the expense of construction delayed further progress on the completion of the inner circle. In 1874, frustrated City financiers formed the Metropolitan Inner Circle Completion Railway Company with the aim of finishing the route. This company was supported by the District and obtained parliamentary authority on 7 August 1874. The company struggled to raise the funding and an extension of time was granted in 1876. A meeting between the Met and the District was held in 1877 with the Met now wishing to access the SER via the East London Railway (ELR). Both companies promoted and obtained an Act of Parliament in 1879 for the extension and link to the ELR, the Act also ensuring future co-operation by allowing both companies access to the whole circle. A large contribution was made by authorities for substantial road and sewer improvements. In 1882, the Met extended its line from Aldgate to a temporary station at Tower of London. Two contracts to build joint lines were placed, from Mansion House to the Tower in 1882 and from the circle north of Aldgate to Whitechapel with a curve onto the ELR in 1883. From 1 October 1884, the District and the Met began working trains from St Mary's via this curve onto the ELR to the SER's New Cross station. After an official opening ceremony on 17 September and trial running a circular service started on Monday 6 October 1884. On the same day the Met extended some H&CR services over the ELR to New Cross, calling at new joint stations at Aldgate East and St Mary's. Joint stations opened on the circle line at Cannon Street, Eastcheap (Monument from 1 November 1884) and Mark Lane. The Met's Tower of London station closed on 12 October 1884 after the District refused to sell tickets to the station. Initially, the service was eight trains an hour, completing the 13 miles (21 kilometres) circle in 81–84 minutes, but this proved impossible to maintain and was reduced to six trains an hour with a 70-minute timing in 1885. Guards were permitted no relief breaks during their shift until September 1885, when they were permitted three 20-minute breaks.
In April 1868, the Metropolitan & St John's Wood Railway (M&SJWR) opened a single-track railway in tunnel to Swiss Cottage from new platforms at Baker Street (called Baker Street East). There were intermediate stations at St John's Wood Road and Marlborough Road, both with crossing loops, and the line was worked by the Met with a train every 20 minutes. A junction was built with the Inner Circle at Baker Street, but there were no through trains after 1869.The original intention of the Metropolitan & St. John's Wood Railway was to run to underground north-east to Hampstead Village, and indeed this appeared on some maps. This was not completed in full and the line was built in a north-western direction instead; a short heading of tunnel was built north of Swiss Cottage station in the direction of Hampstead. This is still visible today when travelling on a southbound Metropolitan line service.
In the early 1870s, passenger numbers were low and the M&SJWR was looking to extend the line to generate new traffic. Recently placed in charge of the Met, Watkin saw this as the priority as the cost of construction would be lower than in built-up areas and fares higher; traffic would also be fed into the Circle. In 1873, the M&SJWR was given authority to reach the Middlesex countryside at Neasden, but as the nearest inhabited place to Neasden was Harrow it was decided to build the line 3.5 miles (5.6 km) further to Harrow and permission was granted in 1874. To serve the Royal Agricultural Society's 1879 show at Kilburn, a single line to West Hampstead opened on 30 June 1879 with a temporary platform at Finchley Road. Double track and a full service to Willesden Green started on 24 November 1879 with a station at Kilburn & Brondesbury (now Kilburn). The line was extended 5 miles 37.5 chains (8.80 km) to Harrow, the service from Baker Street beginning on 2 August 1880. The intermediate station at Kingsbury Neasden (now Neasden) was opened the same day. Two years later, the single-track tunnel between Baker Street and Swiss Cottage was duplicated and the M&SJWR was absorbed by the Met.In 1882, the Met moved its carriage works from Edgware Road to Neasden. A locomotive works was opened in 1883 and a gas works in 1884. To accommodate employees moving from London over 100 cottages and ten shops were built for rent. In 1883, a school room and church took over two of the shops; two years later land was given to the Wesleyan Church for a church building and a school for 200 children.
In 1868, the Duke of Buckingham opened the Aylesbury and Buckingham Railway (A&BR), a 12.75-mile (20.5 km) single track from Aylesbury to a new station at Verney Junction on the Buckinghamshire Railway's Bletchley to Oxford line. At the beginning lukewarm support had been given by the LNWR, which worked the Bletchley to Oxford line, but by the time the line had been built the relationship between the two companies had collapsed. The Wycombe Railway built a single-track railway from Princes Risborough to Aylesbury and when the GWR took over this company it ran shuttles from Princes Risborough through Aylesbury to Quainton Road and from Quainton Road to Verney Junction.The A&BR had authority for a southern extension to Rickmansworth, connecting with the LNWR's Watford and Rickmansworth Railway. Following discussions between the Duke and Watkin it was agreed that this line would be extended south to meet the Met at Harrow and permission for this extension was granted in 1874 and Watkin joined the board of the A&BR in 1875. Money was not found for this scheme and the Met had to return to Parliament in 1880 and 1881 to obtain permission for a railway from Harrow to Aylesbury. Pinner was reached in 1885 and an hourly service from Rickmansworth and Northwood to Baker Street started on 1 September 1887. By then raising money was becoming very difficult although there was local support for a station at Chesham. Authorised in 1885, double track from Rickmansworth was laid for 5 miles (8.0 km), then single to Chesham. Services to Chesham calling at Chorley Wood and Chalfont Road (now Chalfont & Latimer) started on 8 July 1889.The Met took over the A&BR on 1 July 1891 and a temporary platform at Aylesbury opened on 1 September 1892 with trains calling at Amersham, Great Missenden, Wendover and Stoke Mandeville. In 1894, the Met and GWR joint station at Aylesbury opened. Beyond Aylesbury to Verney Junction, the bridges were not strong enough for the Met's locomotives. The GWR refused to help, so locomotives were borrowed from the LNWR until two D Class locomotives were bought. The line was upgraded, doubled and the stations rebuilt to main-line standards, allowing a through Baker Street to Verney Junction service from 1 January 1897, calling at a new station at Waddesdon Manor, a rebuilt Quainton Road, Granborough Road and Winslow Road.From Quainton Road, the Duke of Buckingham had built a 6.5-mile (10.5 km) branch railway, the Brill Tramway. In 1899, there were four mixed passenger and goods trains each way between Brill and Quainton Road. There were suggestions of the Met buying the line and it took over operations in November 1899, renting the line for £600 a year. The track was relaid and stations rebuilt in 1903. Passenger services were provided by A Class and D Class locomotives and Oldbury rigid eight-wheeled carriages.In 1893, a new station at Wembley Park was opened, initially used by the Old Westminsters Football Club, but primarily to serve a planned sports, leisure and exhibition centre. A 1,159-foot (353 m) tower (higher than the recently built Eiffel Tower) was planned, but the attraction was not a success and only the 200-foot (61 m) tall first stage was built. The tower became known as "Watkin's Folly" and was dismantled in 1907 after it was found to be tilting.
Around 1900, there were six stopping trains an hour between Willesden Green and Baker Street. One of these came from Rickmansworth and another from Harrow, the rest started at Willesden Green. There was also a train every two hours from Verney Junction, which stopped at all stations to Harrow, then Willesden Green and Baker Street. The timetable was arranged so that the fast train would leave Willesden Green just before a stopping service and arrived at Baker Street just behind the previous service.
Watkin was also director of the Manchester, Sheffield and Lincolnshire Railway (MS&LR) and had plans for a 99-mile (159 km) London extension to join the Met just north of Aylesbury. There were suggestions that Baker Street could be used as the London terminus, but by 1891–2 the MS&LR had concluded it needed its own station and goods facilities in the Marylebone area. An Act for this railway was passed in 1893, but Watkin became ill and resigned his directorships in 1894. For a while after his departure the relationship between the companies turned sour.In 1895, the MS&LR put forward a bill to Parliament to build two tracks from Wembley Park to Canfield Place, near Finchley Road station, to allow its express trains to pass the Met's stopping service. The Met protested before it was agreed that it would build the lines for the MS&LR's exclusive use. When rebuilding bridges over the lines from Wembley Park to Harrow for the MS&LR, seeing a future need the Met quadrupled the line at the same time and the MS&LR requested exclusive use of two tracks. The MS&LR had the necessary authority to connect to the Circle at Marylebone, but the Met suggested onerous terms. At the time the MS&LR was running short of money and abandoned the link.Because of the state of the relationship between the two companies the MS&LR was unhappy being wholly reliant on the Met for access to London and, unlike its railway to the north, south of Aylesbury there were several speed restrictions and long climbs, up to 1 in 90 in places. In 1898, the MS&LR and the GWR jointly presented a bill to Parliament for a railway (the Great Western and Great Central Joint Railway) with short connecting branches from Grendon Underwood, north of Quainton Road, to Ashendon and from Northolt to Neasden. The Met protested, claiming that the bill was 'incompatible with the spirit and terms' of the agreements between it and the MS&LR. The MS&LR was given authority to proceed, but the Met was given the right to compensation. A temporary agreement was made to allow four MS&LR coal trains a day over the Met lines from 26 July 1898. The MS&LR wished these trains to also use the GWR route from Aylesbury via Princes Risborough into London, whereas the Met considered this was not covered by the agreement. A train scheduled to use the GWR route was not allowed access to the Met lines at Quainton Road in the early hours of 30 July 1898 and returned north. A subsequent court hearing found in the Met's favour, as it was a temporary arrangement.The MS&LR changed its name to the Great Central Railway (GCR) in 1897 and the Great Central Main Line from London Marylebone to Manchester Central opened for passenger traffic on 15 March 1899. Negotiations about the line between the GCR and the Met took several years and in 1906 it was agreed that two tracks from Canfield Place to Harrow would be leased to the GCR for £20,000 a year and the Metropolitan and Great Central Joint Railway was created, leasing the line from Harrow to Verney Junction and the Brill branch for £44,000 a year, the GCR guaranteeing to place at least £45,000 of traffic on the line. Aylesbury station, which had been jointly run by the GWR and the Met, was placed with a joint committee of the Great Western & Great Central and Metropolitan & Great Central Joint Committees, and generally known as Aylesbury Joint Station. The Met & GC Joint Committee took over the operation of the stations and line, but had no rolling stock. The Met provided the management and the GCR the accounts for the first five years before the companies switched functions, then alternating every five years until 1926. The Met maintained the line south of milepost 28.5 (south of Great Missenden), the GCR to the north.
At the start of the 20th century, the District and the Met saw increased competition in central London from the new electric deep-level tube lines. With the opening in 1900 of the Central London Railway from Shepherd's Bush to the City with a flat fare of 2d, the District and the Met together lost four million passengers between the second half of 1899 and the second half of 1900. The polluted atmosphere in the tunnels was becoming increasingly unpopular with passengers and conversion to electric traction was seen as the way forward. Electrification had been considered by the Met as early as the 1880s, but such a method of traction was still in its infancy, and agreement would be needed with the District because of the shared ownership of the Inner Circle. A jointly owned train of six coaches ran an experimental passenger service on the Earl's Court to High Street Kensington section for six months in 1900. This was considered a success, tenders were requested and in 1901 a Met and District joint committee recommended the Ganz three-phase AC system with overhead wires. This was accepted by both parties until the Underground Electric Railways Company of London (UERL) took control of the District. The UERL was led by the American Charles Yerkes, whose experience in the United States led him to favour DC with a third rail similar to that on the City & South London Railway and Central London Railway. After arbitration by the Board of Trade a DC system with four rails was taken up and the railways began electrifying using multiple-unit stock and electric locomotives hauling carriages.
In 1904, the Met opened a 10.5 MW coal-fired power station at Neasden, which supplied 11 kV 33.3 Hz current to five substations that converted this to 600 V DC using rotary converters.Meanwhile, the District had been building a line from Ealing to South Harrow and had authority for an extension to Uxbridge. In 1899, the District had problems raising the finance and the Met offered a rescue package whereby it would build a branch from Harrow to Rayners Lane and take over the line to Uxbridge, with the District retaining running rights for up to three trains an hour. The necessary Act was passed in 1899 and construction on the 7.5 miles (12.1 km) long branch started in September 1902, requiring 28 bridges and a 1.5-mile (2.4 km) long viaduct with 71 arches at Harrow. As this line was under construction it was included in the list of lines to be electrified, together with the railway from Baker Street to Harrow, the inner circle and the joint GWR and Met H&C. The Met opened the line to Uxbridge on 30 June 1904 with one intermediate station at Ruislip, initially worked by steam. Wooden platforms the length of three cars opened at Ickenham on 25 September 1905, followed by similar simple structures at Eastcote and Rayners Lane on 26 May 1906.
Electric multiple units began running on 1 January 1905 and by 20 March all local services between Baker Street and Harrow were electric. The use of six-car trains was considered wasteful on the lightly used line to Uxbridge and in running an off-peak three-car shuttle to Harrow the Met aroused the displeasure of the Board of Trade for using a motor car to propel two trailers. A short steam train was used for off-peak services from the end of March while some trailers were modified to add a driving cab, entering service from 1 June.On 1 July 1905, the Met and the District both introduced electric units on the inner circle until later that day a Met multiple unit overturned the positive current rail on the District and the Met service was withdrawn. An incompatibility was found between the way the shoe-gear was mounted on Met trains and the District track and Met trains were withdrawn from the District and modified. Full electric service started on 24 September, reducing the travel time around the circle from 70 to 50 minutes.The GWR built a 6 MW power station at Park Royal and electrified the line between Paddington and Hammersmith and the branch from Latimer Road to Kensington (Addison Road). An electric service with jointly owned rolling stock started on the H&CR on 5 November 1906. In the same year, the Met suspended running on the East London Railway, terminating instead at the District station at Whitechapel until that line was electrified in 1913. The H&CR service stopped running to Richmond over the L&SWR on 31 December 1906; GWR steam rail motors ran from Ladbroke Grove to Richmond until 31 December 1910.The line beyond Harrow was not electrified so trains were hauled by an electric locomotive from Baker Street, changed for a steam locomotive en route. From 1 January 1907, the exchange took place at Wembley Park. From 19 July 1908, locomotives were changed at Harrow. GWR rush hour services to the city continued to operate, electric traction taking over from steam at Paddington from January 1907, although freight services to Smithfield continued to be steam hauled throughout.In 1908, Robert Selbie was appointed General Manager, a position he held until 1930.
In 1909, limited through services to the City restarted. Baker Street station was rebuilt with four tracks and two island platforms in 1912. To cope with the rise in traffic the line south of Harrow was quadrupled, in 1913 from Finchley Road to Kilburn, in 1915 to Wembley Park; the line from Finchley Road to Baker Street remained double track, causing a bottleneck.
To promote travel by the underground railways in London a joint marketing arrangement was agreed. In 1908, the Met joined this scheme, which included maps, joint publicity and through ticketing. UNDERGROUND signs were used outside stations in Central London. Eventually the UERL controlled all the underground railways except the Met and the Waterloo & City and introduced station name boards with a red disc and a blue bar. The Met responded with station boards with a red diamond and a blue bar.
Further coordination in the form of a General Managers' Conference faltered after Selbie withdrew in 1911 when the Central London Railway, without any reference to the conference, set its season ticket prices significantly lower than those on the Met's competitive routes. Suggestions of merger with the Underground Group were rejected by Selbie, a press release of November 1912 noting the Met's interests in areas outside London, its relationships with main-line railways and its freight business.
After the Met and the District had withdrawn from the ELR in 1906, services were provided by the South Eastern Railway, the London, Brighton, and South Coast Railway (LB&SCR) and the Great Eastern Railway. Both the Met and the District wanted to see the line electrified, but could not justify the whole cost themselves. Discussions continued, and in 1911 it was agreed that the ELR would be electrified with the UERL providing power and the Met the train service. Parliamentary powers were obtained in 1912 and through services restarted on 31 March 1913, the Met running two trains an hour from both the SER's and the LB&SCR's New Cross stations to South Kensington and eight shuttles an hour alternately from the New Cross stations to Shoreditch.
The Great Northern & City Railway (GN&CR) was planned to allow trains to run from the GNR line at Finsbury Park directly into the City at Moorgate. The tunnels were large enough to take a main-line train with an internal diameter of 16 feet (4.9 m), in contrast to those of the Central London Railway with a diameter less than 12 feet (3.7 m). The GNR eventually opposed the scheme, and the line opened in 1904 with the northern terminus in tunnels underneath GNR Finsbury Park station.Concerned that the GNR would divert its Moorgate services over the City Widened Lines to run via the GN&CR, the Met sought to take over the GN&CR. A bill was presented in 1912–13 to allow this with extensions to join the GN&CR to the inner circle between Moorgate and Liverpool Street and to the Waterloo & City line. The takeover was authorised, but the new railway works were removed from the bill after opposition from City property owners. The following year, a bill was jointly presented by the Met and GNR with amended plans that would have also allowed a connection between the GN&CR and GNR at Finsbury Park. Opposed, this time by the North London Railway, this bill was withdrawn.
On 28 July 1914 World War I broke out and on 5 August 1914 the Met was made subject to government control in the form of the Railway Executive Committee. It lost significant numbers of staff who volunteered for military service and from 1915 women were employed as booking clerks and ticket collectors. The City Widened Lines assumed major strategic importance as a link between the channel ports and the main lines to the north, used by troop movements and freight. During the four years of war the line saw 26,047 military trains which carried 250,000 long tons (254,000 t) of materials; the sharp curves prevented ambulance trains returning with wounded using this route. Government control was relinquished on 15 August 1921.
Unlike other railway companies, which were required to dispose of surplus land, the Met was in a privileged position with clauses in its acts allowing it to retain such land that it believed was necessary for future railway use. Initially, the surplus land was managed by the Land Committee, made up of Met directors. In the 1880s, at the same time as the railway was extending beyond Swiss Cottage and building the workers' estate at Neasden, roads and sewers were built at Willesden Park Estate and the land was sold to builders. Similar developments followed at Cecil Park, near Pinner and, after the failure of the tower at Wembley, plots were sold at Wembley Park.In 1912, Selbie, then General Manager, thought that some professionalism was needed and suggested a company be formed to take over from the Surplus Lands Committee to develop estates near the railway. World War I delayed these plans and it was 1919, with expectation of a housing boom, before Metropolitan Railway Country Estates Limited (MRCE) was formed. Concerned that Parliament might reconsider the unique position the Met held, the railway company sought legal advice, which was that the Met had authority to hold land, but had none to develop it. A new company was created; all but one of its directors were also directors of the Met. MRCE developed estates at Kingsbury Garden Village near Neasden, Wembley Park, Cecil Park and Grange Estate at Pinner, and the Cedars Estate at Rickmansworth, and created places such as Harrow Garden Village.The term Metro-land was coined by the Met's marketing department in 1915 when the Guide to the Extension Line became the Metro-land guide, priced at 1d. This promoted the land served by the Met for the walker, visitor and later the house-hunter. Published annually until 1932, the last full year of independence, the guide extolled the benefits of "The good air of the Chilterns", using language such as "Each lover of Metroland may well have his own favourite wood beech and coppice — all tremulous green loveliness in Spring and russet and gold in October". The dream promoted was of a modern home in beautiful countryside with a fast railway service to central London.From about 1914 the company promoted itself as "The Met", but after 1920 the commercial manager, John Wardle, ensured that timetables and other publicity material used "Metro" instead. Land development also occurred in central London when in 1929 Chiltern court, a large, luxurious block of apartments, opened at Baker Street, designed by the Met's architect Charles Walter Clark, who was also responsible for the design of a number of station reconstructions in outer "Metro-land" at this time.
To improve outer passenger services, powerful 75 mph (121 km/h) H Class steam locomotives were introduced in 1920, followed in 1922–23 by new electric locomotives with a top speed of 65 mph (105 km/h). The generating capacity of the power station at Neasden was increased to approximately 35 MW and on 5 January 1925 electric services reached Rickmansworth, allowing the locomotive change over point to be moved.In 1924 and 1925, the British Empire Exhibition was held on the Wembley Park Estate and the adjacent Wembley Park station was rebuilt with a new island platform with a covered bridge linking to the exhibition. The Met exhibited an electric multiple unit car in 1924, which returned the following year with electric locomotive No. 15, subsequently to be named "Wembley 1924". A national sports arena, Wembley Stadium was built on the site of Watkin's Tower. With a capacity of 125,000 spectators it was first used for the FA Cup Final on 28 April 1923 where the match was preceded by chaotic scenes as crowds in excess of capacity surged into the stadium. In the 1926 Metro-land edition, the Met boasted that that had carried 152,000 passengers to Wembley Park on that day.In 1925, a branch opened from Rickmansworth to Watford. There had been a railway station in Watford since 1837, but in 1895 the Watford Tradesmen's Association had approached the Met with a proposal for a line to Watford via Stanmore. They approached again in 1904, this time jointly with the local District Council, to discuss a new plan for a shorter branch from Rickmansworth. A possible route was surveyed in 1906 and a bill deposited in 1912 seeking authority for a joint Met & GCR line from Rickmansworth to Watford town centre that would cross Cassiobury Park on an embankment. There was local opposition to the embankment and the line was cut back to a station with goods facilities just short of the park. The amended Act was passed on 7 August 1912 and the Watford Joint Committee formed before the start of World War I in 1914 delayed construction. After the war, the Trade Facilities Act 1921 offered government financial guarantees for capital projects that promoted employment, and taking advantage of this construction started in 1922. During construction the Railways Act 1921 meant that in 1923 the London and North Eastern Railway (LNER) replaced the GCR. Where the branch met the extension line two junctions were built, allowing trains access to Rickmansworth and London. Services started on 3 November 1925 with one intermediate station at Croxley Green (now Croxley), with services provided by Met electric multiple units to Liverpool Street via Moor Park and Baker Street and by LNER steam trains to Marylebone. The Met also ran a shuttle service between Watford and Rickmansworth. During 1924–5 the flat junction north of Harrow was replaced with a 1,200 feet (370 m) long diveunder to separate Uxbridge and main-line trains. Another attempt was made in 1927 to extend the Watford branch across Cassiobury Park to the town centre, the Met purchasing a property on Watford High Street with the intention of converting it to a station. The proposals for tunnelling under the park proved controversial and the scheme was dropped.
There remained a bottleneck at Finchley Road where the fast and slow tracks converged into one pair for the original M&SJWR tunnels to Baker Street. In 1925, a plan was developed for two new tube tunnels, large enough for the Met rolling stock that would join the extension line at a junction north of Kilburn & Brondesbury station and run beneath Kilburn High Street, Maida Vale and Edgware Road to Baker Street. The plan included three new stations, at Quex Road, Kilburn Park Road and Clifton Road, but did not progress after Ministry of Transport revised its Requirements for Passenger Lines requiring a means of exit in an emergency at the ends of trains running in deep-level tubes – compartment stock used north of Harrow did not comply with this requirement. Edgware Road station had been rebuilt with four platforms and had train destination indicators including stations such as Verney Junction and Uxbridge.In the 1920s, off-peak there was a train every 4–5 minutes from Wembley Park to Baker Street. There were generally two services per hour from both Watford and Uxbridge that ran non-stop from Wembley Park and stopping services started from Rayners Lane, Wembley Park, and Neasden; most did not stop at Marlborough Road and St John's Wood Road. Off-peak, stations north of Moor Park were generally served by Marylebone trains. During the peak trains approached Baker Street every 2.5–3 minutes, half running through to Moorgate, Liverpool Street or Aldgate. On the inner circle a train from Hammersmith ran through Baker Street every 6 minutes, and Kensington (Addison Road) services terminated at Edgware Road. Maintaining a frequency of ten trains an hour on the circle was proving difficult and the solution chosen was for the District to extend its Putney to Kensington High Street service around the circle to Edgware Road, using the new platforms, and the Met to provide all the inner circle trains at a frequency of eight trains an hour.Construction started in 1929 on a branch from Wembley Park to Stanmore to serve a new housing development at Canons Park, with stations at Kingsbury and Canons Park (Edgware) (renamed Canons Park in 1933). The government again guaranteed finance, this time under the Development Loans Guarantees & Grants Act, the project also quadrupling the tracks from Wembley Park to Harrow. The line was electrified with automatic colour light signals controlled from a signal box at Wembley Park and opened on 9 December 1932.
Unlike the UERL, the Met profited directly from development of Metro-land housing estates near its lines; the Met had always paid a dividend to its shareholders. The early accounts are untrustworthy, but by the late 19th century it was paying a dividend of about 5 per cent. This dropped from 1900 onwards as electric trams and the Central London Railway attracted passengers away; a low of ​1⁄2 per cent was reached in 1907–8. Dividends rose to 2 per cent in 1911–13 as passengers returned after electrification; the outbreak of war in 1914 reduced the dividend to 1 per cent. By 1921 recovery was sufficient for a dividend of ​2 1⁄4 per cent to be paid and then, during the post-war housing boom, for the rate to steadily rise to 5 per cent in 1924–5. The 1926 General Strike reduced this to 3 per cent; by 1929 it was back to 4 per cent.In 1913, the Met had refused a merger proposal made by the UERL and it remained stubbornly independent under the leadership of Robert Selbie. The Railways Act 1921, which became law on 19 August 1921, did not list any of London's underground railways among the companies that were to be grouped, although at the draft stage the Met had been included. When proposals for integration of public transport in London were published in 1930, the Met argued that it should have the same status as the four main-line railways, and it was incompatible with the UERL because of its freight operations; the government saw the Met in a similar way to the District as they jointly operated the inner circle. After the London Passenger Transport Bill, aimed primarily at co-ordinating the small independent bus services, was published on 13 March 1931, the Met spent £11,000 opposing it. The bill survived a change in government in 1931 and the Met gave no response to a proposal made by the new administration that it could remain independent if it were to lose its running powers over the circle. The directors turned to negotiating compensation for its shareholders; by then passenger numbers had fallen due to competition from buses and the depression. In 1932, the last full year of operation, a ​1 5⁄8 per cent dividend was declared. On 1 July 1933, the London Passenger Transport Board (LPTB), was created as a public corporation and the Met was amalgamated with the other underground railways, tramway companies and bus operators. Met shareholders received £19.7 million in LPTB stock.
The Met became the Metropolitan line of London Transport, the Brill branch closing in 1935, followed by the line from Quainton Road to Verney Junction in 1936. The LNER took over steam workings and freight. In 1936, Metropolitan line services were extended from Whitechapel to Barking along the District line. The New Works Programme meant that in 1939 the Bakerloo line was extended from Baker Street in new twin tunnels and stations to Finchley Road before taking over the intermediate stations to Wembley Park and the Stanmore branch. The branch transferred to the Jubilee line when that line opened in 1979. The Great Northern and City Railway remained isolated and was managed as a section of the Northern line until being taken over by British Railways in 1976.
Steam locomotives were used north of Rickmansworth until the early 1960s when they were replaced following the electrification to Amersham and the introduction of electric multiple units, London Transport withdrawing its service north of Amersham. In 1988, the route from Hammersmith to Aldgate and Barking was branded as the Hammersmith & City line, and the route from the New Cross stations to Shoreditch became the East London line, leaving the Metropolitan line as the route from Aldgate to Baker Street and northwards to stations via Harrow.
After amalgamation in 1933 the "Metro-land" brand was rapidly dropped. In the mid-20th century, the spirit of Metro-land was remembered in John Betjeman's poems such as "The Metropolitan Railway" published in the A Few Late Chrysanthemums collection in 1954 and he later reached a wider audience with his television documentary Metro-land, first broadcast on 26 February 1973. The suburbia of Metro-land is one locale of Julian Barnes' Bildungsroman novel Metroland, first published in 1980. A film based on the novel, also called Metroland, was released in 1997.
On 18 June 1925, electric locomotive No. 4 collided with a passenger train at Baker Street station when a signal was changed from green to red just as the locomotive was passing it. Six people were injured.
Until 1880 the Met ran no goods trains, but goods trains ran over its tracks from 20 February 1866 when the GNR began a service to the LC&DR via Farringdon Street, followed by a service from the Midland Railway from July 1868. The GNR, the GWR and the Midland all opened goods depots in the Farringdon area, accessed from the City Widened Lines. Goods traffic was to play an important part of Met traffic on the extension line out of Baker Street. In 1880, the Met secured the coal traffic of the Harrow District Gas Co., worked from an exchange siding with the Midland at Finchley Road to a coal yard at Harrow. Goods and coal depots were provided at most of the stations on the extension line as they were built. Goods for London were initially handled at Willesden, with delivery by road or by transfer to the Midland. The arrival of the GCR gave connections to the north at Quainton Road and south via Neasden, Acton and Kew.
In 1909, the Met opened Vine Street goods depot near Farringdon with two sidings each seven wagons long and a regular service from West Hampstead. Trains were electrically hauled with a maximum length of 14 wagons and restricted to 250 long tons (254 t) inwards and 225 long tons (229 t) on the return. In 1910, the depot handled 11,400 long tons (11,600 t), which rose to 25,100 long tons (25,500 t) in 1915. In 1913, the depot was reported above capacity, but after World War I motor road transport became an important competitor and by the late 1920s traffic had reduced to manageable levels.Coal for the steam locomotives, the power station at Neasden and local gasworks were brought in via Quainton Road. Milk was conveyed from Vale of Aylesbury to the London suburbs and foodstuffs from Vine Street to Uxbridge for Alfred Button & Son, wholesale grocers. Fish to Billingsgate Market via the Met and the District joint station at Monument caused some complaints, leaving the station approaches in an "indescribably filthy condition". The District suggested a separate entrance for the fish, but nothing was done. The traffic reduced significantly when the GCR introduced road transport to Marylebone, but the problem remained until 1936, being one reason the LPTB gave for abolishing the carrying of parcels on Inner Circle trains.Initially private contractors were used for road delivery, but from 1919 the Met employed its own hauliers. In 1932, before it became part of London Underground, the company owned 544 goods vehicles and carried 162,764 long tons (165,376 t) of coal, 2,478,212 long tons (2,517,980 t) of materials and 1,015,501 long tons (1,031,797 t) tons of goods.
Concern about smoke and steam in the tunnels led to new designs of steam locomotive. Before the line opened, in 1861 trials were made with the experimental "hot brick" locomotive nicknamed Fowler's Ghost. This was unsuccessful and the first public trains were hauled by broad-gauge GWR Metropolitan Class condensing 2-4-0 tank locomotives designed by Daniel Gooch. They were followed by standard-gauge GNR locomotives until the Met received its own 4-4-0 tank locomotives, built by Beyer Peacock of Manchester. Their design is frequently attributed to the Met's Engineer John Fowler, but the locomotive was a development of one Beyer had built for the Spanish Tudela to Bilbao Railway, Fowler specifying only the driving wheel diameter, axle weight and the ability to navigate sharp curves. Eighteen were ordered in 1864, initially carrying names, and by 1870 40 had been built. To reduce smoke underground, at first coke was burnt, changed in 1869 to smokeless Welsh coal.From 1879, more locomotives were needed, and the design was updated and 24 were delivered between 1879 and 1885. Originally they were painted bright olive green lined in black and yellow, chimneys copper capped with the locomotive number in brass figures at the front and domes of polished brass. In 1885, the colour changed to a dark red known as Midcared, and this was to remain the standard colour, taken up as the colour for the Metropolitan line by London Transport in 1933. When in 1925 the Met classified its locomotives by letters of the alphabet, these were assigned A Class and B Class. When the M&SJWR was being built, it was considered that they would struggle on the gradients and five Worcester Engine 0-6-0 tank locomotives were delivered in 1868. It was soon found that A and B Classes could manage trains without difficulty and the 0-6-0Ts were sold to the Taff Vale Railway in 1873 and 1875.From 1891, more locomotives were needed for work on the extension line from Baker Street into the country. Four C Class (0-4-4) locomotives, a development of South Eastern Railway's 'Q' Class, were received in 1891. In 1894, two D Class locomotives were bought to run between Aylesbury and Verney Junction. These were not fitted with the condensing equipment needed to work south of Finchley Road. Four more were delivered in 1895 with condensing equipment; these were prohibited working south of Finchley Road. In 1896, two E Class (0-4-4) locomotives were built at Neasden works, followed by one in 1898 to replace the original Class A No. 1, damaged in an accident. Four more were built by Hawthorn Leslie & Co in 1900 and 1901. To cope with the growing freight traffic on the extension line, the Met received four F Class (0-6-2) locomotives in 1901, similar to the E Class except for the wheel arrangement and without steam heat. In 1897 and 1899, the Met received two 0-6-0 saddle tank locomotives to a standard Peckett design. Unclassified by the Met, these were generally used for shunting at Neasden and Harrow.Many locomotives were made redundant by the electrification of the inner London lines in 1905–06. By 1907, 40 of the class A and B locomotives had been sold or scrapped and by 1914 only 13 locomotives of these classes had been retained for shunting, departmental work and working trains over the Brill Tramway. The need for more powerful locomotives for both passenger and freight services meant that, in 1915, four G Class (0-6-4) locomotives arrived from Yorkshire Engine Co. Eight 75 mph (121 km/h) capable H Class (4-4-4) locomotives were built in 1920 and 1921 and used mainly on express passenger services. To run longer, faster and less frequent freight services in 1925 six K Class (2-6-4) locomotives arrived, rebuilt from 2-6-0 locomotives manufactured at Woolwich Arsenal after World War I. These were not permitted south of Finchley Road.Two locomotives survive: A Class No. 23 (LT L45) at the London Transport Museum, and E Class No. 1 (LT L44) at the Buckinghamshire Railway Centre. No.1 ran in steam as part of the Met's 150th anniversary celebrations during 2013.
The Met opened with no stock of its own, with the GWR and then the GNR providing services. The GWR used eight-wheeled compartment carriages constructed from teak. By 1864, the Met had taken delivery of its own stock, made by the Ashbury Railway Carriage & Iron Co., based on the GWR design but standard gauge. Lighting was provided by gas — two jets in first class compartments and one in second and third class compartments, and from 1877 a pressurised oil gas system was used. Initially the carriages were braked with wooden blocks operated by hand from the guards' compartments at the front and back of the train, giving off a distinctive smell. This was replaced in 1869 by a chain that operated brakes on all carriages. The operation of the chain brake could be abrupt, leading to some passenger injuries, and it was replaced by a non-automatic vacuum brake by 1876. In the 1890s, a mechanical 'next station' indicator was tested in some carriages on the circle, triggered by a wooden flap between the tracks. It was considered unreliable and not approved for full installation.
In 1870, some close-coupled rigid-wheelbase four-wheeled carriages were built by Oldbury. After some derailments in 1887, a new design of 27 feet 6 inches (8.38 m) long rigid-wheelbase four-wheelers known as Jubilee Stock was built by the Cravens Railway Carriage and Wagon Co. for the extension line. With the pressurised gas lighting system and non-automatic vacuum brakes from new, steam heating was added later. More trains followed in 1892, but all had been withdrawn by 1912. By May 1893, following an order by the Board of Trade, automatic vacuum brakes had been fitted to all carriages and locomotives. A Jubilee Stock first class carriage was restored to carry passengers during the Met's 150th anniversary celebrations.Bogie stock was built by Ashbury in 1898 and by Cravens and at Neasden Works in 1900. This gave a better ride quality, steam heating, automatic vacuum brakes, electric lighting and upholstered seating in all classes. The Bluebell Railway has four 1898–1900 Ashbury and Cravens carriages and a fifth, built at Neasden, is at the London Transport Museum.Competition with the GCR on outer suburban services on the extension line saw the introduction of more comfortable Dreadnought Stock carriages from 1910. Ninety-two of these wooden compartment carriages were built, fitted with pressurised gas lighting and steam heating. Electric lighting had replaced the gas by 1917 and electric heaters were added in 1922 to provide warmth when hauled by an electric locomotive. Later formed into rakes of five, six or seven coaches, conductor rail pick-ups on the leading and trailing guard coaches were joined by a bus line and connected to the electric locomotive to help prevent gapping. Two rakes were formed with a Pullman coach that provided a buffet service for a supplementary fare. The Vintage Carriages Trust has three preserved Dreadnought carriages.From 1906, some of the Ashbury bogie stock was converted into electric multiple units. Some Dreadnought carriages were used with electric motor cars, and two-thirds remained in use as locomotive hauled stock on the extension line.
After electrification, the outer suburban routes were worked with carriage stock hauled from Baker Street by an electric locomotive that was exchanged for a steam locomotive en route. The Met ordered 20 electric locomotives from Metropolitan Amalgamated with two types of electrical equipment. The first ten, with Westinghouse equipment, entered service in 1906. These 'camel-back' bogie locomotives had a central cab, weighed 50 tons, and had four 215 hp (160 kW) traction motors The second type were built to a box car design with British Thomson-Houston equipment, replaced with the Westinghouse type in 1919.In the early 1920s, the Met placed an order with Metropolitan-Vickers of Barrow-in-Furness for rebuilding the 20 electric locomotives. When work started on the first locomotive, it was found to be impractical and uneconomical and the order was changed to building new locomotives using some equipment recovered from the originals. The new locomotives were built in 1922–23 and named after famous London residents. They had four 300 hp (220 kW) motors, totalling 1,200 hp (890 kW) (one-hour rating), giving a top speed of 65 mph (105 km/h).No. 5 "John Hampden" is preserved as a static display at the London Transport Museum and No. 12 "Sarah Siddons" has been used for heritage events, and ran during the Met's 150th anniversary celebrations.
The first order for electric multiple units was placed with Metropolitan Amalgamated in 1902 for 50 trailers and 20 motor cars with Westinghouse equipment, which ran as 6-car trains. First and third class accommodation was provided in open saloons, second class being withdrawn from the Met. Access was at the ends via open lattice gates and the units were modified so that they could run off-peak as 3-car units. For the joint Hammersmith & City line service, the Met and the GWR purchased 20 × 6-cars trains with Thomson-Houston equipment. In 1904, a further order was placed by the Met for 36 motor cars and 62 trailers with an option for another 20 motor cars and 40 trailers. Problems with the Westinghouse equipment led to Thomson-Houston equipment being specified when the option was taken up and more powerful motors being fitted. Before 1918, the motor cars with the more powerful motors were used on the circle with three trailers. The open lattice gates were seen as a problem when working above ground and all of the cars had gates replaced with vestibules by 1907. Having access only through the two end doors became a problem on the busy circle and centre sliding doors were fitted from 1911.From 1906, some of the Ashbury bogie stock was converted into multiple units by fitting cabs, control equipment and motors. In 1910, two motor cars were modified with driving cabs at both ends. They started work on the Uxbridge-South Harrow shuttle service, being transferred to the Addison Road shuttle in 1918. From 1925 to 1934 these vehicles were used between Watford and Rickmansworth.In 1913, an order was placed for 23 motor cars and 20 trailers, saloon cars with sliding doors at the end and the middle. These started work on the circle, including the new service to New Cross via the ELR.  In 1921, 20 motor cars, 33 trailers and six first-class driving trailers were received with three pairs of double sliding doors on each side. These were introduced on the circle.
Between 1927 and 1933 multiple unit compartment stock was built by the Metropolitan Carriage and Wagon and Birmingham Railway Carriage and Wagon Co. for services from Baker Street and the City to Watford and Rickmansworth. The first order was only for motor cars; half had Westinghouse brakes, Metro-Vickers control systems and four MV153 motors; they replaced the motor cars working with bogie stock trailers. The rest of the motor cars had the same motor equipment but used vacuum brakes, and worked with converted 1920/23 Dreadnought carriages to form 'MV' units. In 1929, 'MW' stock was ordered, 30 motor coaches and 25 trailers similar to the 'MV' units, but with Westinghouse brakes. A further batch of 'MW' stock was ordered in 1931, this time from the Birmingham Railway Carriage & Wagon Co. This was to make seven 8-coach trains, and included additional trailers to increase the length of the previous 'MW' batch trains to eight coaches. These had GEC WT545 motors, and although designed to work in multiple with the MV153, this did not work well in practice. After the Met became part of London Underground, the MV stock was fitted with Westinghouse brakes and the cars with GEC motors were re-geared to allow them to work in multiple with the MV153-motored cars. In 1938, nine 8-coach and ten 6-coach MW units were re-designated T Stock. A trailer coach built in 1904/5 is stored at London Transport Museum's Acton Depot; it has been badly damaged by fire, and the Spa Valley Railway is home to two T stock coaches.
Metropolitan & Great Central Railway Joint Committee Survey Created by the Metropolitan & Great Central Joint Committee in 1907 for their own use, the ten hand-coloured station and crossover plans illustrate the line from Harrow-on-the-Hill Station to Amersham and Chesham.
