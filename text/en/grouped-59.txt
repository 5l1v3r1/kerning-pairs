
Arlington is a city in northern Snohomish County, Washington, United States, part of the Seattle metropolitan area. The city lies on the Stillaguamish River in the western foothills of the Cascade Range, adjacent to the city of Marysville. It is approximately 10 miles (16 km) north of Everett, the county seat, and 40 miles (64 km) north of Seattle, the region's largest city. As of the 2010 U.S. census, Arlington has a population of 17,926.
Arlington was established in the 1880s by settlers and the area was platted as two towns, Arlington and Haller City. Haller City was absorbed by the larger Arlington, which was incorporated as a city in 1903. During the Great Depression of the 1930s, the Arlington area was the site of major projects undertaken for employment under the direction of federal relief agencies, including construction of a municipal airport that would serve as a naval air station during World War II. Beginning in the 1980s, Arlington was affected by suburbanization due to the expansion of Seattle, growing by more than 450 percent by 2000 and annexing the unincorporated area of Smokey Point to the southwest.
The economy of the Arlington area historically relied on timber and agriculture. In the early 21st century, it has transitioned to a service economy, with some aviation industry jobs near the municipal airport. The city is governed by a mayorâ€“council government, electing a mayor and seven city councilmembers. The municipal government maintains the city's parks system and water and wastewater utilities. Other services, including public utilities, public transportation, and schools, are contracted to regional or county-level agencies and companies.
Prior to American settlement in the 19th century, the Puget Sound region was inhabited by indigenous Coast Salish peoples. The Stillaguamish and Sauk peoples had prominent camps at the confluence of the two forks of the Stillaguamish River when they followed fish runs; the Stillaguamish named the campsite Skabalko. Arlington was later developed at this site. They also had a major village at Chuck-Kol-Che upriver near modern-day Trafton.American exploration of the area began in 1851, when prospector Samuel Hancock was led by Indian guides on a canoe up the Stillaguamish River. The area was opened to logging after the signing of the Treaty of Point Elliott in 1855 between the United States government and the Stillaguamish tribe, who were relocated to trust lands and the Tulalip Indian Reservation.The U.S. Army built a military road connecting Fort Steilacoom to Fort Bellingham, crossing the Stillaguamish River near the confluence. In the 1880s, wagon roads were constructed to this area from the towns of Marysville to the south and Silvana to the west, bringing entrepreneurs to the logging camps, informally named "The Forks". The area's first store was opened in 1888 by Nels K. Tvete and Nils C. Johnson, and was followed by a hotel with lodging and meals for loggers.
Two settlements were established on the south side of the confluence in anticipation of the Seattle, Lake Shore & Eastern Railroad building a track through the area. G. Morris Haller, son of Colonel Granville O. Haller, founded a settlement on the banks of the Stillaguamish River in 1883, naming it "Haller City".The Seattle, Lake Shore & Eastern Railroad chose to build its depot on higher ground to the south of Haller City, leading contractors Earl & McLeod to establish a new town at the depot on March 15, 1890. The new town was named "Arlington" after Lord Henry Arlington, member of the cabinet of King Charles II of England. Arlington and Haller City were platted within a month of each other in 1890, quickly developing a rivalry that would continue for several years.Arlington and Haller City grew rapidly in their first years, reaching a combined population of 500 by 1893, relying on agriculture, dairy farming and the manufacturing of wood shingles as their main sources of income. Both towns established their own schools, post offices, saloons, general stores, churches, social clubs, and hotels. The two towns were separated by a 40-acre (16 ha) tract claimed by two settlers in 1891, preventing either town from fully absorbing the other. During the late 1890s, the claim dispute was settled and merchants began moving to the larger, more prosperous Arlington, signalling the end for Haller City. Today, Haller City is memorialized in the name of a park in downtown Arlington, as well as a middle school operated by the Arlington School District.
Arlington was incorporated as a fourth-class city on May 20, 1903, including the remnants of Haller City (located north of modern-day Division Street). The incorporation came after a referendum on May 5, in which 134 of 173 voters approved the city's incorporation. The new city elected shingle mill owner John M. Smith as its first mayor. In the years following incorporation, Arlington gained a local bank, a cooperative creamery, a city park, a library, electricity, and telephone service.During the early 20th century, Arlington's largest employers remained its shingle mills and saw mills. Other industries, including dairy processing, mechanical shops, stores, and factories, became prominent after World War I, during a period of growth for the city. The Great Depression of the 1930s forced all but one of the mills to close, causing unemployment to rise in Arlington and neighboring cities. The federal government established a Civilian Conservation Corps (CCC) camp near Darrington to create temporary jobs; the young men built structures and conducted firefighting in the Mount Baker National Forest. The Works Progress Administration and Civil Works Administration funded the construction of the city's sidewalks, a high school, and a municipal airport that opened in 1934.The entry of the United States into World War II brought the U.S. Navy to Arlington, resulting in the conversion of the municipal airport into a naval air station in 1943. The Navy constructed new runways and hangars and, beginning in 1946, the municipal government was allowed to operate civilian and commercial services. Ownership of the airport was formally transferred from the federal government back to the city of Arlington in 1959.On October 19, 1959, a Boeing 707-227 crashed on the banks of the Stillaguamish River's North Fork during a test flight, killing four of eight occupants. The plane, being flown by Boeing test pilots instructing personnel from Braniff International Airways, lost three engines and suffered a fire in the fourth after a dutch roll had been executed beyond maximum bank restrictions. The plane made an emergency landing in the riverbed while unsuccessfully trying to reach a nearby open field.
The completion of Interstate 5 and State Route 9 in the late 1960s brought increased residential development in Arlington, forming a bedroom community for commuters who worked in Everett and Seattle. Suburban housing developments began construction in the 1980s and 1990s, driving a 450 percent increase in Arlington's population to 15,000 by 2007. In 1999, Arlington annexed the community of Smokey Point, located along Interstate 5 to the southwest of the city, after a lengthy court battle with Marysville, which instead was permitted to annex Lakewood to the west. The city began developing a large business park around the municipal airport in the 1990s, bringing the city's number of jobs to a total of 11,000 by 2003.The city of Arlington celebrated its centennial in 2003 with a parade, a festival honoring the city's history, sporting events, and musical and theatrical performances. The centennial celebrations culminated in the dedication of the $44 million Arlington High School campus, attended by an all-class reunion of the old school. In 2007, the city of Arlington renovated six blocks of downtown's Olympic Avenue at a cost of $4.4 million, widening sidewalks, improving street foliage, and adding new street lights. The project was credited with helping revitalize the city's downtown, turning Olympic Avenue into a gathering place for residents and a venue for festivals.On March 22, 2014, a large landslide near Oso dammed the North Fork of the Stillaguamish River, with mud and debris covering an area of one square mile (2.6 km2). A total of 43 people were killed and nearly 50 structures destroyed. The landslide closed State Route 530 to Darrington, cutting the town off, leaving Arlington as the center of the coordinated emergency response to the disaster. Arlington was recognized for its role in aiding victims of the disaster and hosted U.S. President Barack Obama during his visit to the site in April.
According to the United States Census Bureau, the city of Arlington has a total area of 9.26 square miles (23.98 km2), of which 9.25 square miles (23.96 km2) is land and 0.01 square miles (0.03 km2) is water. The city is in the northwestern part of Snohomish County in Western Washington, and is considered part of the Seattle metropolitan area. It is approximately 41 miles (66 km) north of Seattle and 10 miles (16 km) north of Everett. Arlington's city limits are generally defined to the south by Marysville at State Route 531 (172nd Street NE) and roughly 165th Street NE, to the west by Interstate 5, to the north by the Stillaguamish River valley, and to the east by the Cascade Range foothills. The city's urban growth boundary includes 10.3 square miles (27 km2) within and outside of city limits.The city lies on a glacial terrace formed during the Pleistocene epoch by the recession of the Cordilleran ice sheet. Arlington covers a series of hills that sit at an elevation of 100 to 200 feet (30 to 61 m) above sea level. Downtown Arlington is situated on a bluff above the confluence of the Stillaguamish River and its North and South Forks. Most of Arlington sits in the watersheds of the Stillaguamish River, Portage Creek, and Quilceda Creek. From various points in Arlington, the Olympic Mountains,
Mount Pilchuck, and Mount Rainier are visible on the horizon.The Stillaguamish River valley and floodplain, including Arlington, lies in a lahar hazard zone 60 miles (97 km) downstream from Glacier Peak, an active stratovolcano in the eastern part of the county. During an eruption 13,000 years ago, several eruption-generated lahars deposited more than 7 feet (2 m) of sediment on modern-day Arlington.
The city of Arlington publishes a decennial comprehensive plan, which divides the urban growth area into ten planning subareas, each containing neighborhoods and subdivisions.
Old Town consists of downtown Arlington and surrounding residential neighborhoods built during the early 20th century. The northern reaches of Old Town include commercial areas developed during the post-war period that are distinct from older buildings along Olympic Avenue.
Arlington Bluff is a residential area between the Stillaguamish River floodplain and the Arlington Municipal Airport industrial center.
Kent Prairie, a residential area south of Old Town, was developed in the early post-war period. The subarea also includes retail stores centered around the intersection of State Route 9 and 204th Street NE. The area was once home to a Stillaguamish village, as well as Arlington's first schoolhouse, built in 1884.
The designated Manufacturing Industrial Center is an industrial district southwest of Old Town, surrounding the Arlington Municipal Airport and the city's only active railroad.
Hilltop consists of Arlington's largest planned residential subdivisions, including Gleneagle, Crown Ridge, and the Magnolias. It is south of Kent Prairie on a large terrace on the west side of State Route 9. Gleneagle is Arlington's largest single development, with over 1,000 homes and a private golf course.
The Brekhus/Beach subarea, also known as Burn Hill, is a residential area southeast of Old Town and is centered along Burn Road.The West Arlington Subarea, designated in 2011, combines several neighborhoods annexed by Arlington in the 1990s and 2000s, including Smokey Point and Island Crossing.
Smokey Point, annexed by Arlington in 1999, is a major commercial and residential area at the junction of Interstate 5 and State Route 531, southwest of Arlington. Portions of Smokey Point extend south and west into the city of Marysville, which annexed the area in the 2000s.
Island Crossing, at the junction of Interstate 5 and State Route 530, is a rural community with a cluster of retail stores. It was annexed by Arlington in 2008, and has been re-designated for commercial development.
The proposed King-Thompson subarea is northwest of Smokey Point and lies outside of Arlington's city limits and urban growth boundary. It has been identified as a potential area for extensive residential development. The municipal government applied to annex the area into the city's urban growth area in 2013, but withdrew the application in 2016.
Arlington has a general climate similar to most of the Puget Sound lowlands, with dry summers and mild, rainy winters moderated by a marine influence from the Pacific Ocean. The majority of the region's precipitation arrives during the winter and early spring, and Arlington averages 181 days of precipitation per year. Arlington's location in the foothills of the Cascade Range brings additional precipitation compared to nearby communities, with 46 inches (1,200 mm) annually compared to 33 inches (840 mm) in Everett. Arlington rarely receives significant snowfall, with an average of 7 inches (18 cm) per year since 1922.July is Arlington's warmest month, with average high temperatures of 73.6 Â°F (23.1 Â°C), while January is the coolest, at an average high of 44.5 Â°F (6.9 Â°C). The highest recorded temperature, 98 Â°F (37 Â°C), occurred on October 1, 1923, and the lowest, 7 Â°F (âˆ’14 Â°C), occurred on January 1, 1979. According to the KÃ¶ppen climate classification system, Arlington has a warm-summer Mediterranean climate (Csb).
The city of Arlington had a population of 17,926 people at the time of the 2010 U.S. census, making it the ninth largest of eighteen cities in Snohomish County. From 1980 to 2010, Arlington's population increased by over 450 percent, fueled by the construction of suburban housing and annexations of outlying areas. The United States Census Bureau estimates the city's 2016 population at 19,112. In 2005, the Arlington city council projected that the city's population would double from 15,000 to 30,528 by 2025.
As of the 2010 census, there were 17,926 people, 6,563 households, and 4,520 families residing in the city. The population density was 1,937.9 inhabitants per square mile (748.2/km2). There were 6,929 housing units at an average density of 749.1 per square mile (289.2/km2). The racial makeup of the city was 85.6% White, 1.2% African American, 1.4% Native American, 3.3% Asian, 0.3% Pacific Islander, 3.9% from other races, and 4.2% from two or more races. Hispanic or Latino of any race were 9.5% of the population.There were 6,563 households of which 40.3% had children under the age of 18 living with them, 50.7% were married couples living together, 12.6% had a female householder with no husband present, 5.6% had a male householder with no wife present, and 31.1% were non-families. 24.0% of all households were made up of individuals and 10.2% had someone living alone who was 65 years of age or older. The average household size was 2.70 and the average family size was 3.21.The median age in the city was 34.3 years. 28.3% of residents were under the age of 18; 8.7% were between the ages of 18 and 24; 29.2% were from 25 to 44; 22.4% were from 45 to 64; and 11.3% were 65 years of age or older. The gender makeup of the city was 48.6% male and 51.4% female.
As of the 2000 census, there were 11,713 people, 4,281 households, and 3,097 families residing in the city. The population density was 1,548.4 people per square mile (598.2/kmÂ²). There were 4,516 housing units at an average density of 597.0 per square mile (230.6/kmÂ²). The racial makeup of the city was 90.0% White, 1.1% African American, 1.0% Native American, 2.2% Asian, 0.3% Pacific Islander, 2.5% from other races, and 2.8% from two or more races. Hispanic or Latino of any race were 5.8% of the population.There were 4,281 households out of which 42.6% had children under the age of 18 living with them, 56.7% were married couples living together, 11.5% had a female householder with no husband present, and 27.7% were non-families. 22.7% of all households were made up of individuals and 9.3% had someone living alone who was 65 years of age or older. The average household size was 2.72 and the average family size was 3.19.In the city, the age distribution of the population shows 31.5% under the age of 18, 8.0% from 18 to 24, 32.6% from 25 to 44, 18.4% from 45 to 64, and 9.6% who were 65 years of age or older. The median age was 32 years. For every 100 females, there were 93.3 males. For every 100 females age 18 and over, there were 91.2 males.The median income for a household in the city was $40,000, and the median income for a family was $51,941. Males had a median income of $41,517 versus $26,912 for females. The per capita income for the city was $19,146. About 5.8% of families and 7.2% of the population were below the poverty line, including 9.2% of those under the age of 18 and 10.4% of those age 65 and older.
As of  2015, Arlington has an estimated 9,481 residents who were in the workforce, either employed or unemployed. The average one-way commute for Arlington workers in 2015 was approximately 30 minutes; 85 percent of workers drove alone to their workplace, while 7 percent carpooled, and 2 percent used public transit. As of  2015, only 12 percent of employed Arlington residents work within city limits, while approximately 17 percent commute to Everett, 9 percent to Seattle, 8 percent to Marysville, 3 percent to Bellevue, 2 percent to Renton, and 49 percent to other cities, each of which accounted for less than 2 percent. The largest industry of employment for Arlington workers are educational services and health care, with approximately 19 percent, followed by manufacturing (18%), retail (11%), and food services (10%).Arlington's early economy relied heavily on timber harvesting and processing, notably the production of red cedar wood shingles at mills that closed during the Great Depression of the 1930s. Locally, Arlington was known as the "Shingle Capital of the World", although mills in Everett and Ballard produced more shingles at the time. Agriculture and dairy farming emerged as significant industries to Arlington during the early 20th century, with farms lining the floodplain of the Stillaguamish River. A major cooperative creamery and condensery was established in Arlington during the 1910s, but later moved to Mount Vernon after World War II.The transformation of Arlington into a bedroom community for Everett and Seattle during the 1980s and 1990s came with it a move towards a service economy. Among the largest employers of Arlington residents are the Boeing Everett Factory and Naval Station Everett. The expansion of the aerospace industry in the Seattle region led Arlington to develop its own municipal airport into an aerospace job center, which includes a high concentration of Boeing subcontractors. As of  2012, the airport has 130 on-site businesses that employ 590 people, with an annual economic output of $94.5 million.The city of Arlington plans to increase the number of jobs within the city to over 20,000 by 2035, bolstered by the proposed designation of the Arlington-Marysville Manufacturing Industrial Center by the Puget Sound Regional Council. The industrial center, located between the two cities near Smokey Point, already includes major distribution centers and other light industry.
Arlington is defined as a non-charter code city and operates under a mayorâ€“council government, with an elected mayor and an elected city council. The mayor serves a four-year term and has no term limits. The current mayor of Arlington is Barbara Tolbert, who was elected in 2011 and re-elected to a second term in 2015. Tolbert's predecessors included John and Margaret Larson, who both served as mayor from 1980 to 1990 and 2003 to 2011, respectively.The city council is composed of seven residents who are elected in at-large, non-partisan elections to four-year terms. The council also appoints a city administrator to oversee city operations. The council meets twice per month on Mondays in a chamber at city hall in downtown Arlington. According to the Washington State Auditor, Arlington's municipal government employs 128 people full-time and operates on an annual budget of $50 million. The city government switched to a biennial budget in 2017, after an ordinance was passed by the city council in 2016. The municipal government provides emergency services, as well as water and sewage utilities, street maintenance, parks and recreation, an airport, and a cemetery. Arlington was proposed as the county seat of the secessionist Freedom County in the 1990s and 2000s, but the proposal was struck down by state courts.At the federal level, Arlington is part of Washington's 2nd congressional district, which has been represented by Democrat Rick Larsen since 2001. At the state level, the city is part of the 39th legislative district, represented by senator Kirk Pearson, and representatives Dan Kristiansen and Carolyn Eslick. Arlington is wholly part of the Snohomish County Council's 1st district, represented by Nate Nehring, son of Marysville mayor Jon Nehring, since his appointment in 2017.During the 2016 U.S. presidential election, 50.6 percent of Arlington voters chose Republican Donald Trump, while 39.5 percent voted for Democrat Hillary Clinton. During the same year's gubernatorial election, 42.9 percent of Arlington voters preferred incumbent Democrat Jay Inslee, while 56.8 percent voted for Republican Bill Bryant. During the 2012 presidential election, Democrat Barack Obama won Arlington narrowly with 50.6 percent of votes.
Public art has been mandated for public construction projects in Arlington since a 2007 ordinance setting 1 percent of the budget for new artworks. The Arlington Arts Council, a volunteer organization established in 2004, has acquired 30 sculptures and murals that form the city's Sculpture Walk in downtown Arlington and along the Centennial Trail. The Arlington High School campus has a performing arts venue, the Byrnes Performing Arts Center, which opened in 2007. The city is also located near the Pilchuck Glass School, a rural art school that focuses on glass art.
Arlington has 17 city-maintained parks with over 257 acres (104 ha) of public open space within its city limits and urban growth boundary. Park facilities include nature preserves, neighborhood parks, sports fields, playgrounds, boat launches, and gardens. The Arlington School District also has 59.3 acres (24.0 ha) of sports fields and playgrounds that are open to public use during non-school hours.Arlington's largest park is the County Charm Park and Conservation Area, located east of downtown Arlington along the South Fork Stillaguamish River. The 150-acre (61 ha) park was purchased from the Graafstra family in 2010, and is planned to be developed into sports fields, hiking trails, camping areas, and a swimming beach, in addition to a 40-acre (16 ha) riparian habitat. Across the South Fork is Twin Rivers Park, Arlington's second-largest park, a 50-acre (20 ha) park with sports fields that is owned by Snohomish County but maintained by the city of Arlington. The city's third-largest park, Bill Quake Memorial Park, consists of soccer and baseball fields on 13 acres (5.3 ha) near Arlington Municipal Airport.The county government also owns the Portage Creek Wildlife Area, a 157-acre (64 ha) wildlife reserve located outside of city limits near downtown Arlington. The reserve was originally a dairy farm that was restored into wetland habitat in the 1990s and 2000s.Arlington is at the intersection of two major county trails used by cyclists, pedestrians, and horseback riders: the Centennial Trail, which runs 29 miles (47 km) from Bryant to Snohomish; and the Whitehorse Trail, which will run 27 miles (43 km) east from Arlington to Darrington. Both trails use right of way acquired by Snohomish County after they were abandoned by the Burlington Northern Railroad in the late 20th century. The city of Arlington also maintains a 6-mile (9.7 km) unpaved walking trail around the Arlington Municipal Airport.
The Arlington Municipal Airport hosts the annual "Arlington Fly-In" air show during the weekend after Independence Day. The Fly-In has operated annually since 1969 and is the third-largest event of its kind in the United States, with over 50,000 visitors and 1,600 planes participating.The Downtown Arlington Business Association hosts several annual events in downtown Arlington, including a car show in June, a street fair on Olympic Avenue in July, and a Viking festival in October. Legion Park hosts a weekend farmers' market from June to September and is also used as a staging ground for holiday parades. The Stillaguamish Tribe hosts an annual powwow and festival of the river at River Meadows County Park on the South Fork of the Stillaguamish River in August.
Arlington has one weekly newspaper, The Arlington Times, which has been published in the Arlington area since 1890. It has been under common ownership with the Marysville Globe since 1964, and both were acquired by Sound Publishing in 2007. The Herald in Everett serves the entire county, including Arlington, and prints daily editions. Arlington is also part of the Seattleâ€“Tacoma media market, and is served by Seattle-based media outlets including The Seattle Times; broadcast television stations KOMO-TV, KING-TV, KIRO-TV, and KCPQ-TV; and various radio stations.Arlington has been part of the Sno-Isle Libraries system, which operates public libraries in Island and Snohomish counties, since its inception in 1962. A 5,055-square-foot (469.6 m2) library was built near downtown Arlington in 1981 and holds over 54,000 items, but has been in need of replacement or renovation since the 2000s. Sno-Isle identified the Arlington Library as a top priority for renovation and expansion in 2016, while also emphasizing the need for a new library to serve Smokey Point. A pilot library for Smokey Point opened in January 2018, using a leased retail space. Arlington had a single-screen, 381-seat movie theater, the Olympic Theatre in downtown Arlington, that operated from 1939 to 2014.
The volunteer-operated Stillaguamish Valley Pioneer Museum, southwest of downtown Arlington, opened in 1997. The museum overlooks the Stillaguamish River and features preserved household items, logging equipment, and vehicles, historic newspapers and images from the Arlington area, and a model railroad.The Arlington area has two properties listed on the National Register of Historic Places (NRHP). The Trafton School in Trafton was built in 1888 and re-built in 1912 after a fire. It was listed as a historic place in 2006, shortly before it was closed by the Arlington School District. The Arlington Naval Auxiliary Air Station (part of the modern-day Arlington Municipal Airport) was listed as a historic place in 1995.
Public schools in Arlington are operated by the Arlington School District, which covers most of the incorporated city and also includes the outlying areas of Arlington Heights, Bryant, Getchell, and Sisco Heights. The district had an enrollment of approximately 5,528 students in 2014 and has nine total schools, including one high school, two middle schools, four elementary schools, and two alternative learning facilities. In the early 2000s, the school district opened four new schools to replace other facilities as part of a $54 million bond measure passed by Arlington voters in 2000. The Smokey Point neighborhood is served by the Lakewood School District, which is in unincorporated North Lakewood and served the area prior to its annexation by Arlington.Arlington is located approximately 15 miles (24 km) away from the Everett Community College, its nearest post-secondary education institution, situated in northern Everett. The college has offered basic skills and job training courses at Arlington's Weston High School since 2016, including a branch of its Advanced Manufacturing Training & Education Center.In 1966, the Smokey Point area was proposed as the location of a four-year public college, with 645 acres (261 ha) offered by the city of Arlington to the state government. The Washington State Legislature decided to build the college instead in Olympia, becoming The Evergreen State College. The Smokey Point area was again offered by Arlington and Marysville as the site of a University of Washington branch campus in the 2000s, but the project was put on hold and later declined by the state legislature in favor of a Washington State University branch campus in Everett.
Downtown Arlington is located near the junction of State Route 9 and State Route 530, which serve as the main highways to the city. From Arlington, State Route 9 travels north into Skagit County and south to Snohomish; and State Route 530 travels west to an interchange with Interstate 5, the main northâ€“south highway between Seattle and Vancouver, British Columbia, and east to Darrington. Within the city is an additional state highway, State Route 531, which connects Smokey Point, the municipal airport, and Gleneagle to Interstate 5 and State Route 9 in the southern part of the city. Other major arterial roads include Smokey Point Boulevard and 67th Avenue NE, which serve as northâ€“south thoroughfares within Arlington.Public transportation in Arlington is provided by Community Transit, a public transit authority that operates in most of Snohomish County. Community Transit runs all-day local bus service on one route from Downtown Arlington to Smokey Point, as well as four other routes to Marysville, Everett, Lake Stevens, Lynnwood, and Stanwood from a transit center in Smokey Point. During peak hours, Community Transit also provides local service from Darrington, and commuter service to the Boeing Everett Factory from a park and ride in downtown Arlington.Arlington has one active railroad, a 6.9-mile-long (11.1 km) spur line from Marysville to downtown Arlington operated by BNSF Railway (the successor to Burlington Northern). As part of the development of the Arlington Airport business park, BNSF Railway will build two rail spurs leading to the airport in the near future. Arlington does not have passenger rail service, but is near Amtrak stations in Everett and Stanwood.Historically, Arlington developed along several railroads that have since been abandoned or re-purposed. The Seattle, Lake Shore and Eastern Railway, which spurred the establishment of Arlington in the 1880s, ran northâ€“south through Arlington on its main line between Snohomish and the Canadaâ€“United States border. In 1892, it was acquired by the Northern Pacific Railway, which was acquired by Burlington Northern in 1970. Burlington Northern abandoned the railroad in 1972, favoring a parallel route to the west through Marysville, and it was converted into the Centennial Trail in the 1990s and 2000s. A Northern Pacific branch to Darrington, following the modern-day State Route 530, was built in 1901 and abandoned in 1990; the county government plans to use the right of way for the Whitehorse Trail, a multi-purpose trail.The city of Arlington owns the Arlington Municipal Airport, located 3 miles (4.8 km) southwest of downtown Arlington. The airport is primarily used for general aviation and light business, and is home to 475 aircraft, including 10 helicopters, 20 gliders, and 23 ultra-light aircraft. Approximately 130 businesses are located on airport property, of which one-quarter are involved in aviation-related uses directly impacting the airport. In the 1990s, the airport was explored as a candidate for expansion into a regional airport to relieve Seattleâ€“Tacoma International Airport. The plan was ultimately abandoned by 1996, as the Puget Sound Regional Council instead chose to construct a third runway at Seattleâ€“Tacoma International Airport.
Electric power in Arlington is provided by the Snohomish County Public Utility District (PUD), a consumer-owned public utility that purchases most of its electricity from the federal Bonneville Power Administration (BPA). The BPA operates the region's system of electrical transmission lines, including Path 3, a major national transmission corridor running along the eastern side of Arlington towards British Columbia. Cascade Natural Gas and Puget Sound Energy provide natural gas to Arlington residents and businesses north and south of State Route 531, respectively; two major northâ€“south gas pipelines run through Arlington and are maintained by the Olympic Pipeline Company, a subsidiary of BP, and the Northwest Pipeline Company, a subsidiary of Williams Companies. Arlington is served by three telephone companies and internet service providers: Comcast (Xfinity), Frontier Communications (including Verizon FiOS), and Wave Broadband.The city of Arlington provides water and water treatment to approximately 5,548 customers within a 25.3 square miles (66 km2) service area within the city limits and some surrounding areas. The city's water is sourced from groundwater deposits near Haller Park on the Stillaguamish River and near Arlington Municipal Airport, as well as water purchased from the Snohomish County PUD that is sourced from Spada Lake. The Smokey Point neighborhood is served by the City of Marysville's water system.Wastewater and stormwater are collected and treated by the municipal government before being discharged into the Stillaguamish River basin. Arlington's municipal solid waste and single-stream recycling collection and disposal services are contracted by the municipal government to Waste Management; the Snohomish County government and Republic Services also operate a transfer station in Arlington.
Arlington is part of the Snohomish Public Hospital District No. 3, which operates the Cascade Valley Hospital, a 48-bed general hospital. The hospital was established in 1909 and was the last independent hospital in Snohomish County at the time of its acquisition in 2016. The city is also served by community clinics operated by Cascade Valley (and Skagit Regional Health) as well as The Everett Clinic and the Community Health Center of Snohomish County.

The Iowa-class battleships were the most heavily armed gunships the United States Navy has ever put to sea due to the continual development of their onboard weaponry. The first Iowa-class ship was laid down in June 1940; in their World War II configuration, each of the Iowa-class battleships had a main battery of 16-inch (406 mm) guns that could hit targets nearly 20 statute miles (32 km) away with a variety of artillery shells designed for anti-ship or bombardment work. The secondary battery of 5-inch (127 mm) guns could hit targets nearly 9 statute miles (14 km) away with solid projectiles or proximity fuzed shells, and were equally adept in an anti-aircraft role and for damaging smaller ships. Each of the four battleships carried a wide array of 20 mm and 40 mm anti-aircraft guns for defense against enemy aircraft.
When reactivated and modernized in the 1980s each battleship retained the original battery of nine 16-inch (406 mm) guns, but the secondary battery on each battleship was reduced from ten twin-gun mounts and twenty guns to six twin-gun mounts with 12 guns to allow for the installation of two platforms for the Tomahawk missiles. Each battleship also received four Harpoon missile magazines, Phalanx anti-aircraft/anti-missile Gatling gun systems, and electronic warfare suites.
The primary armament of an Iowa-class battleship consisted of nine breech-loading 16 inch (406 mm)/50-caliber Mark 7 naval guns, which were housed in three 3-gun turrets: two forward and one aft in a configuration known as "2-A-1". The guns were 66 feet (20 m) long (50 times their 16-inch (410 mm) bore, or 50 calibers, from breechface to muzzle). About 43 feet (13 m) protruded from the gun house. Each gun weighed about 239,000 pounds (108 000 kg) without the breech, or 267,900 pounds with the breech. They fired 2,700 pounds (1,225 kg) armor-piercing projectiles at a muzzle velocity of 2,500 ft/s (762 m/s), or 1,900 pounds (862 kg) high-capacity projectiles at 2,690 ft/s (820 m/s), up to 24 miles (21 nmi; 39 km).Each gun rested within an armored turret, but only the top of the turret protruded above the main deck. The turret extended either four decks (Turrets 1 and 3) or five decks (Turret 2) down. The lower spaces contained the equipment required to rotate the turret and to elevate the guns attached to each turret. At the bottom of the turret were rooms which were used for handling the projectiles and storing the powder bags used to fire them. All of the compartments within the turrets were separated by flameproof bulkheads to prevent any flame or lethal gas from spreading throughout the turret. Each turret required a crew of 77â€“94 men to operate. The turrets were not actually attached to the ship, but sat on rollers, which meant that if the ship were to capsize the turrets would fall out. Each turret cost US$1.4 million, but this number did not include the cost of the guns themselves.The turrets were "three-gun," not "triple," because each barrel could be elevated and fired independently. The ship could fire any combination of its guns, including a broadside of all nine.
The guns could be elevated from âˆ’5Â° to +45Â°, moving at up to 12Â° per second. The turrets could be rotated about 300Â° at a rate of about four degrees per second and can even be fired back beyond the beam, which is sometimes called "over the shoulder." The guns were never fired horizontally forward (in the 1980s refit, a satellite up-link antenna was mounted at the bow). To distinguish between the rounds fired from different battleships the Iowa class used dye bags which allowed artillery observers to determine which rounds had been fired by which ship. Iowa, New Jersey, Missouri, and Wisconsin were assigned the colors orange, blue, red and green, respectively.Within each turret, a red stripe on the interior wall, inches from the railing, marked the boundary of the barrel's recoil, warning the crew to keep back.
When brought into service during World War II the guns had a barrel life of roughly 290 rounds, limited in large part by the nitrated cellulose (NC) propellant. After World War II the Navy switched to smokeless powder diphenylamine (SPD), a cooler-burning propellant, which increased the barrel life from 290 to about 350 rounds. This was increased further by the introduction of a titanium dioxide and wax compound known as "Swedish Additive" on New Jersey for her tour in Vietnam, and later used on all four Iowas when they were reactivated in the 1980s. These measures were further augmented by the addition of polyurethane jackets, which were placed over the powder bags to reduce gaseous erosion during the firing of the guns. These measures greatly prolonged barrel life, and ultimately resulted in a shift from measuring barrel life in equivalent service rounds (ESR) to measuring barrel life in fatigue equivalent rounds (FER).After the guns were fired, each rifle barrel had to be cleaned. Unlike small caliber guns which can be field-stripped, the guns aboard an Iowa-class battleship could not be disassembled, so the gunners mates assigned the job of cleaning the rifles required a full day or more to ensure that the barrels were correctly and adequately cleaned. To clean the rifles, a bore brush was lifted by two sailors and inserted into the gun barrel, where it was pulled through the rifle with the same equipment used to load the shells. Within the turret, crewmen checked to ensure that the breech fittings were properly cleaned and lubricated, while sailors outside the turret scraped off soot, and painted over flash burns left from the explosive expulsion of the 16-inch shells from the gun barrels.
The early main battery fire control consisted of the Fire Control Tower, two Mark 38 Gun Fire Control Systems (GFCS),  and fire control equipment located in two of the three turrets. As modernized in the 1980s, each turret carried a DR-810 radar that measured the muzzle velocity of each gun, which made it easier to predict the velocity of succeeding shots. Together with the Mark 160 FCS and better propellant consistency, the improvements created the most accurate battleship-caliber guns ever made.
The Fire Control Tower is the tallest superstructure on the ship. It houses several interesting areas, including a second Captain's Sea Cabin (on the 08 level), the 08 Battle Bridge, and at the top, the Mk 38 Fire Control Director (Spot 1) for the main guns. The aft Mk 38 is Spot 2. (9)
The Captain's 08 Sea Cabin is smaller and less outfitted than his cabin on the 04 Bridge behind the Chart House.
The 08 Battle Bridge Is a fully equipped Helm, and is armored, although it is not as large as the Helm in the Armored Conning Tower on the 04 level Navigation Bridge, nor is the armor as thick. The Battle Bridge gave better visibility in those early days of Radar.
While the Mk 38 Director is on the 012 level, the Gunnery Officer's station is the top level of the Armored Conning Tower on the 05 level (Spot 3).It was equipped with periscopes poking through the armor, and control consoles showing the status of the ship's weapons (director bearings, turret bearings, gun's loaded status, Fire Control (FC) Radar displays, etc.). With the radar's displays, the Gunnery Officer could determine what aim corrections (Spots) were needed by watching the fall of shot around the target.
The major components of the Mk 38 Gun Fire Control System (GFCS) were the Director, Plotting Room, and interconnecting data transmission equipment. Two systems, forward and aft, were each complete and independent, though they could be cross-connected. Their plotting rooms were isolated to protect against battle damage propagating from one to the other.
The forward Mk 38 Director (pictured) was situated on top of the fire control tower. The director was equipped with optical sights, optical Mark 45 Rangefinder (the long thin boxes sticking out of each side), and a Mark 13 Fire Control Radar antenna (the rectangular shape sitting on top). The purpose of the director was to track the target's present bearing and range. This could be done optically by the men inside using the sights and Rangefinder, or electronically with the radar.  (The FC radar was the preferred method.)  The present position of the target was called the Line-Of-Sight (LOS), and it was continuously sent down to the Mk 8 Rangekeeper in the plotting room by Synchro transmitters. Also, when not using the radar's display to determine Spots, the director was the optical spotting station.
The forward main battery plotting room was located below the waterline and inside the armored belt. It housed the forward system's Mark 8 Rangekeeper, Mark 41 Stable Vertical, Mk13 FC Radar controls and displays, Parallax Correctors, Fire Control Switchboard, battle telephone switchboard, battery status indicators, assistant Gunnery Officers, and Fire Control Technicians (FTs).
The Mk 8 Rangekeeper was an electromechanical analog computer whose function was to continuously calculate the gun's bearing and elevation, Line-Of-Fire (LOF), to hit a future position of the target. It did this by automatically receiving information from the director (LOS), the FC Radar (range), the ship's gyrocompass (true ship's course), the ship's Pitometer log (ship's speed), the Stable Vertical (ship's roll and pitch), and the ship's anemometer (relative wind speed and direction). Also, before the surface action started, the FTs made manual inputs for the average initial velocity of the projectiles fired out of the battery's gun barrels, and air density. With all this information, the Rangekeeper calculated the relative motion between "OWN SHIP" and "TARGET". It then could calculate an offset angle and change of range between the target's present position (LOS) and future position at the end of the projectile's time of flight. To this bearing and range offset, it added corrections for gravity, wind, Magnus effect of the spinning projectile, earth's curvature, and coriolis effect. The result was the turret's bearing and elevation orders (LOF). During the surface action, range and deflection Spots and target altitude (not zero during Gun Fire Support) were manually entered.
The Mk 41 Stable Vertical (also called Gun Director) was a vertical seeking gyroscope. Its function was to establish and maintain a stable earth vertical with its associated horizontal plane. With the horizontal plane established, the Mk 41 continuously measured the angles between the deck and the horizontal plane. These deck angles were continuously transmitted to the Rangekeeper so that it could keep the guns correctly elevated as the ship rolled and pitched. Mounted waist high on its side were the battery's firing keys. (see picture) The left key was the Salvo Signal Key, and it sounded the Salvo Buzzer in each of the turrets to warn the gun crews that the guns were about to fire. The center key (with bumps on its handle for tactile identification) was the Automatic Firing Key. When this key was held closed, the Mk 41 was enabled to automatically fire the guns whenever the ship's deck was parallel the horizontal plane. Also, if the sea state was such that the turrets' elevation power drives could not keep up with the ship's motion, the guns could be held at a fixed elevation, and the MK 41 could again automatically fire the guns as described. The right key was the Hand Firing Key. It bypassed the Mk 41, and fired the guns directly.The Mk 13 FC Radar supplied present target range, and it showed the fall of shot around the target so the Gunnery Officer could correct the system's aim with range and deflection spots put into the Rangekeeper. It could also automatically track the target by controlling the director's bearing power drive. Because of radar, Fire Control systems are able to track and fire at targets at a greater range and with increased accuracy during the day, night, or inclement weather. This was demonstrated in November 1942 when the battleship USS Washington engaged the Imperial Japanese Navy battlecruiser Kirishima at a range of 8,500 yards (7,800 m) at night. The engagement left Kirishima in flames, and she was ultimately scuttled by her crew. This capability gave the United States Navy a major advantage in World War II, as the Japanese did not develop radar or automated fire control to the level of the US Navy and were at a significant disadvantage. See also The Battle of Surigao Strait (25 October 1944) during the WWII Leyte Gulf landings.
The Parallax Correctors were needed because the turrets were located hundreds of feet from the director. There was one for each turret, and each had the turret/director distance manually set in. They automatically received Relative Target Bearing (bearing from own ship's bow), and Target Range. They corrected the bearing order for each turret so that all rounds fired in a salvo converged on the same point.The Fire Control Switchboard configured the battery. With it, the Gunnery Officer could mix and match the three turrets to the two GFCSs. He could have the turrets all controlled by the forward system, all controlled by the aft system, or split the battery to shoot at two targets.The assistant Gunnery Officers and Fire Control Technicians operated the equipment, talked to the turrets and ship's command by sound-powered telephone, and watched the Rangekeeper's dials and system status indicators for problems. If a problem arose, they could correct the problem, or reconfigure the system to mitigate its effect.
Turrets 2 and 3 had optical rangefinders and ballistics computers.  (The rangefinders are the boxes on the turret's rear corners). If in a surface action the GFCSs were damaged, the Turret Officer could turn the Auto-Local rotary switch to Local and continue the action using the turret's fire control equipment.
The large caliber guns were designed to fire two different 16-inch shells: an armor-piercing round for anti-ship and anti-structure work and a high explosive round designed for use against unarmored targets and shore bombardment. A third type of ammunition for delivering tactical nuclear warheads was developed subsequently.
The Mk. 8 APC (Armor-Piercing, Capped) shell weighed 2,700 lb (1225 kg) and was designed to penetrate the hardened steel armor carried by foreign battleships. At 20,000 yards (18 km) the Mk. 8 could penetrate 20 inches (500 mm) of steel armor plate. At the same range, the Mk. 8 could penetrate 21 feet (6.4 m) of reinforced concrete.For unarmored targets and shore bombardment, the 1,900 lb (862 kg) Mk. 13 HC (High-Capacity â€“ referring to the large bursting charge) shell was available. The Mk. 13 shell would create a crater 50 feet (15 m) wide and 20 feet (6 m) deep upon impact and detonation, and could defoliate trees 400 yards (360 m) from the point of impact. Mk. 13 High Capacity shells that were made by manufacturers other than the Naval Gun Factory received the designation Mk. 14 HC, but were otherwise identical.The final type of ammunition developed for the Iowa class were "Katie" shells. These shells were born from the concept of nuclear deterrence that had begun to shape the United States armed forces as the Cold War began. To compete with the Air Force and the Army, which had developed nuclear bombs and nuclear shells for use on the battlefield, the US Navy began a top-secret program to develop Mk. 23 nuclear naval shells with an estimated yield of 15 to 20 kilotons. These shells were designed to be launched from the best seaborne artillery platform available, which at the time were the four ships of the Iowa class. The shells entered development around 1953, and were reportedly ready by 1956; it is not known whether they were ever deployed on the Iowa-class battleships because the US Navy does not confirm or deny the presence of nuclear weapons aboard its ships. In 1991 the US unilaterally withdrew its nuclear artillery shells from service, and Russia responded in kind in 1992. The US removed around 1,300 nuclear shells from Europe and reportedly dismantled its last shells by 2003.
The secondary battery was a dual-purpose weapon system; it was designed to defend the ship from either surface or airborne threats. The original secondary battery consisted of 10 Mark 28, Mod 2 twin gun mounts, and four Mark 37 Gun Fire Control Systems. At first, this battery's effectiveness against aircraft diminished as planes became faster, but this changed toward the end of World War II through a combination of an upgrade to the Mk37 System and the development of the VT (Variable Time) proximity fuze. In preparation for the reactivations in the 1960s and 1980s, the battery was updated to the latest gun and fire control system modifications. In the 1968 upgrade to the USS New Jersey for service off Vietnam, three Mark 56 Gun Fire Control Systems were installed, two on either side just forward of the aft stack, and one between the aft mast and the aft Mk 38 Director tower. This increased New Jersey's anti-aircraft capability, because the Mk 56 system could track and shoot at faster planes. In the 1980s modernization, the Mk 56 GFCSs and four mounts were removed to make room for missiles, leaving the Secondary battery with four Mk 37 GFCSs and six twin mounts on all the Iowa class. By the time of the Gulf War the secondary battery was largely relegated to shore bombardment and littoral defense.  Since each battleship carried a small detachment of Marines aboard, the Marines would man one of the 5-inch gun mounts.
Each Mk 28 Mod 2 Mount carried two Mark 12, 5in/38cal gun assemblies, electric-hydraulic drives for bearing and elevation, optical sights, automatic fuze setter, automatic sight setter, and an upper handling room. Each armored twin mount weighed 170,635 lb (77,399 kg). The mount had a crew of 13, not including the ammunition movers in the upper handling room and magazines, drawn from the sailors and Marines serving aboard the ship.
The Mk 12 Gun Assembly (pictured) was a semi-automatic, power rammed, vertical sliding-wedge breech block type gun. The Gun Assembly shown in the picture is the mount's right gun. The left gun is the mirror image of the right gun. Since this gun assembly fired semi-fixed ammunition, (pictured) each round was delivered to the guns in two pieces. Each gun, in this twin mount, had its own projectile hoist and powder case hoist from the upper handling room. The electric-hydraulic projectile hoist would deliver a projectile next to the projectile man with the nose down and waist high. The electric-hydraulic powder case hoist poked the case through a powder scuttle in the gun room's deck just next to the powder man's feet.  At the load command, the powder man would slip a primer protector off the end of the powder case, extract the case from the scuttle, and lift it into the gun's rammer tray. Meanwhile, the projectile man would pull a projectile out of the hoist, and place it in the rammer tray in front of the powder case. Then, as he turned to get the next projectile out of the hoist, the projectile man would pull down on the rammer lever. This caused the power rammer to ram the projectile and powder case into the chamber. As the powder case cleared the top of the breechblock, the block would rise to seal the chamber. The gun was ready to fire. The case combination primer in the base of the powder case could be fired either electrically or by percussion. Electrical firing was the preferred method because the firing circuit could be energized by firing keys down in the plotting room when firing salvos at surface targets, or up in the director when firing at air targets. Percussion firing could be executed by the Pointer (man controlling elevation) by pushing a foot treadle. When the gun fired, the recoil's rearward motion returned the rammer lever to the up position, and the rammer would drive back to the rear of the rammer tray. During counter-recoil, the breechblock was automatically lowered and the spent powder case was ejected from the chamber. When the gun returned to battery, a blast of compressed air was sent down the bore to clean it out. The gun was ready to be reloaded.
The electric-hydraulic drives powered the mount's motion. The three modes of drive operation were automatic, local, and manual. In automatic, the drives would follow the bearing and elevation orders of the fire control system. In local, the drives would follow the motion of the trainer's and pointer's hand wheels.  (This is similar to power steering on a car.)  Manual was direct gear linkage from the hand wheels to move the mount with no power assist.
The periscopic sights (the boxes on the side of the mount) allowed the trainer and pointer to see the target from inside the armored enclosure. Each sight had movable prisms that allowed its line of sight to be moved relative to the barrel's bore axis. These prisms could be controlled by the fire control system when the mount was in Automatic, or by the mount's sight setter operator when the mount was in Local.   Local control was not the preferred combat method, but it could be used if the fire control systems were damaged. The mount captain was trained in aiming and correcting the fall of shot.
The upper handling room was just below the visible part of the mount. It was armored and reinforced to support the weight of the mount. A person standing in the upper handling room could look up and see the bottom of the gun mount inside the training circle on which the mount rotated. Hanging from the mount, and rotating with it, was the equipment used to pass ammunition up to the mount. This included the lower ends of the projectile and powder case hoists. In the center of the room there was a vertical tube that also turned with the mount. This tube enclosed the electrical power and control cables going up to the mount. Around the perimeter of the upper handling room were the ready service ammunition racks welded to the bulkheads. Close by, either in a corner of the handling room or in an adjoining compartment was the upper end of an ammunition hoist from the magazine. The responsibility of the men stationed in the upper handling room was to shuttle 30 to 40 projectiles and 30 to 40 powder cases per minute from the ready service racks to the hoists while avoiding the equipment rotating with the mount. During quiet spells, they would replenish the ready service racks with ammunition from the magazines.
The Mark 37 Gun Fire Control System (GFCS) was the primary Fire Control System for the Secondary Battery. There were four Mk37 GFCSs on board; one forward above the navigation bridge, two amidships on either side of the forward stack, and one aft between the aft Mk38 Director and Turret three. The major components of the Mk 37 GFCS were the Mk 37 Director, and the equipment in the plotting room.
The function of the Mark 37 director (pictured) was to track the present position of the target in bearing, elevation, and range. To do this, it had optical sights (the rectangular windows on the front), an optical rangefinder (the tubes sticking out each side), and Fire Control Radar antennas. On the MK 37 Director pictured, the rectangular antenna is for the Mark 12 FC radar, and the parabolic antenna on the left is for the Mk 22 FC radar. They were part of an upgrade to improve tracking of aircraft. The Director Officer also had a Slew Sight that he could use to quickly point the director towards a new target.
The secondary battery plotting rooms were down below the waterline and inside the armor belt. They contained four complete sets of fire control equipment needed to aim and shoot at four targets. Each set included a Mark 1A computer, a Mark 6 Stable Element, FC Radar controls and displays, Parallax correctors, a switchboard, and crew to operate it all.
The Mark 1A Fire Control Computer (pictured) was an electro-mechanical analog ballistic computer. Its function was to automatically aim the guns so that a fired projectile would collide with the target. This was the same function as the main battery's Mk 8 Rangekeeper above except that some of the targets the Mark 1A had to deal with also moved in elevation â€“ and much faster. For a surface target, the Secondary Battery's Fire Control problem is the same as the Main Battery's with the same type inputs and outputs. The major difference between the two computers was their ballistics calculations. The amount of gun elevation needed to project a 5-inch (127 mm) shell 9 nmi (17 km) is different than the elevation needed to project a 16-inch shell the same distance. The ballistics calculations in these mechanical analog computers were performed by mechanisms like differential gears, levers, and small rods riding on the surface of three-dimensional cams. These mechanical adders, multipliers, and table lookup devices were handmade at the factory, and were buried deep in the workings of the computer. It was not possible to change a computer's ballistics at sea until the advent of fast digital computers. The anti-aircraft fire control problem was more complicated because it had the additional requirement of tracking the target in elevation and making target predictions in three dimensions. The outputs of the Mk 1A were the same (gun bearing and elevation), except fuze time was added. The fuze time was needed because the ideal of directly hitting the fast moving aircraft with the projectile was impractical. With fuze time set into the shell, it was hoped that it would explode near enough to the target to destroy it with the shock wave and shrapnel. Towards the end of World War II, the invention of the VT proximity fuze eliminated the need to use the fuze time calculation and its possible error. This greatly increased the odds of destroying an air target.
The function of the Mk 6 Stable Element (pictured) in this fire control system was the same as the function of the Mk 41 Stable Vertical in the main battery system above. It was a vertical seeking gyroscope that supplied the system with a stable up direction on a rolling and pitching ship. In surface mode, it replaced the director's elevation signal. It also had the surface mode firing keys.
The Fire-control radar used on the Mk 37 GFCS has evolved. In the 1930s, the Mk 37 Director did not have a radar antenna. Then in September 1941, the rectangular Mk 4 Fire-control radar antenna was mounted on top. Soon aircraft flew faster, and in c1944 to increase speed and accuracy the Mk 4 was replaced by a combination of the Mk 12 (rectangular antenna) and Mk 22 (parabolic antenna) radars. (pictured) Finally, the circular SPG 25 antenna was mounted on top as seen in the USS Wisconsin photo at the top of this article.  (Look at the Mk 37 Director just above the bridge.)
Since they were designed to escort the US fleet of fast attack aircraft carriers, the Iowa-class battleships were all intended to carry a fearsome array of anti-aircraft guns to protect US aircraft carriers from Japanese fighters and dive bombers. This array included up to 20 quad 40 mm mounts and 49 single 20 mm mounts. In the 1968 USS New Jersey re-activation for service off Vietnam, the 20 mm and 40 mm batteries were removed. In the 1980s re-activation, all the ships with 20 mm and 40 mm batteries had them removed, and four Phalanx CIWS mounts were added to all.
The Oerlikon 20 mm anti-aircraft gun was one of the most heavily produced anti-aircraft guns of the Second World War; the US alone manufactured a total of 124,735 of these guns. When activated in 1941 these guns replaced the 0.50"/90 (12.7 mm) M2 Browning MG on a one-for-one basis. The Oerlikon 20 mm AA gun remained the primary anti-aircraft weapon of the United States Navy until the introduction of the 40 mm Bofors AA gun in 1943.These guns were air-cooled and used a gas blowback recoil system. Unlike other automatic guns employed during World War II the barrel of the 20 mm Oerlikon gun did not recoil, the breechblock never locked against the breech and actually moved forward when the gun fired. This weapon lacked a counter-recoil brake, as the force of the counter-recoil was checked by the explosion of the next round of ammunition.
Between December 1941 and September 1944, 32% of all Japanese aircraft downed were credited to this weapon, with the high point being 48.3% for the second half of 1942. In 1943 the revolutionary Mark 14 Gun Sight was introduced which made these guns even more effective; however, the 20 mm guns were found to be ineffective against the Japanese Kamikaze attacks used during the latter half of World War II. They were subsequently phased out in favor of the heavier 40 mm Bofors AA guns.
Arguably the best light anti-aircraft weapon of World War II, the Bofors 40 mm anti-aircraft gun was used on almost every major warship in the US and UK fleet during World War II from about 1943 to 1945. Although a descendant of German and Swedish designs, the Bofors mounts used by the US Navy during World War II had been heavily "Americanized" to bring the guns up to the standards placed on them by the US Navy. This resulted in a guns system set to English standards (now known as the Standard System) with interchangeable ammunition, which simplified the logistics situation for World War II. When coupled with electric-hydraulic drives for greater speed and the Mark 51 Director (pictured) for improved accuracy, the Bofors 40 mm gun became a fearsome adversary, accounting for roughly half of all Japanese aircraft shot down between 1 October 1944 and 1 February 1945.When the Iowa-class battleships were launched in 1943 and 1944 they carried twenty quad Bofors 40 mm gun mounts, which they used for defense against enemy aircraft. These heavy guns were also employed in the protection of allied aircraft carriers operating in the Pacific Theater of World War II. These guns remained on the battleships Iowa, Missouri, and Wisconsin from the time they were commissioned until they were reactivated for service in the 1980s. As each battleship arrived for modernization during the early and mid-1980s the Bofors mounts that remained aboard were removed due in large part to the ineffectiveness of such manually aimed weapons against modern day jet fighters and enemy missiles. The replacement for the Bofors guns was the US Navy's Phalanx Close-in weapon system (CIWS).
During their modernization in the 1980s, each Iowa-class battleship was equipped with four of the US Navy's Phalanx CIWS mounts, two of which sat just behind the bridge and two which were forward and outboard of the after ship's funnel. Iowa, New Jersey, and Missouri were equipped with the Block 0 version of the Phalanx, while Wisconsin received the first operational Block 1 version in 1988.Developed as the final line of defense (terminal defense or point defense) against anti-ship missiles, the Phalanx Close in Weapon System (CIWS, pronounced "sea-whiz") is the anti-aircraft/anti-missile gun currently in use in the US Navy. Due to their distinctive shape, they have been nicknamed "R2D2s", in reference to the droid R2-D2 from the Star Wars universe. Designed in the early 1970s by General Dynamics, and currently produced by Raytheon, the Phalanx CIWS mount utilizes a 20 mm M61 Vulcan Gatling gun to destroy enemy missiles and aircraft that manage to escape anti-missile and anti-aircraft missiles fired from friendly ships.The Phalanx guns worked by using a search radar and a tracking radar to follow targets that approached within 1 to 1.5 nautical miles (2.8 km). When a target was within this range the CIWS mount moved to track the target while simultaneously evaluating the target against several preset criteria to determine the next course of action. Depending on whether the target criteria were met, the Phalanx mount automatically engaged the incoming target if it was judged to be hostile in nature, or the system recommended that the Phalanx operator engage the target.Phalanx CIWS mounts were used by Missouri and Wisconsin during the 1991 Gulf War; Wisconsin alone fired 5,200 20 mm Phalanx CIWS rounds. Missouri also received Phalanx fire during a "friendly fire" incident in which the Oliver Hazard Perry-class guided missile frigate USS Jarrett mistook chaff fired by Missouri for a legitimate target and shot at Missouri. Rounds from this attack struck the ship in the bulkhead above the famed "surrender deck" and bounced off the armor, one round penetrated the forward funnel and passed completely through it, and another round penetrated a bulkhead and embedded in an interior passageway of the ship.
During the modernization in the 1980s, three important weapons were added to the Iowa-class battleships. The first was the CIWS anti-aircraft/anti-missile system discussed above. The other two were missiles for use against both land and sea targets. At one point the NATO Sea Sparrow was to be installed on the reactivated battleships; however, it was determined that the system could not withstand the over-pressure effects when the main battery was fired.
The BGM-109 Tomahawk Land Attack Missile (TLAM) was first introduced in the 1970s, and entered service with the United States in 1983. Designed as a long-range, all-weather, subsonic cruise missile, the Tomahawk was capable of reaching targets at a much greater range than the 16-inch (406 mm) guns on the Iowa-class ships. When added to the battleships in the 1980s the Tomahawk became the longest-ranged weapon carried by the battleships.Owing to the original 1938 design of the battleships, the Tomahawk missiles could not be fitted to the Iowa class unless the battleships were physically rebuilt in such a way as to accommodate the missile mounts that would be needed to store and launch the Tomahawks. This realization prompted the removal of the anti-aircraft guns previously installed on the Iowas and the removal of four of each of the battleships' ten 5"/38 DP mounts. The mid and aft end of the battleships were then rebuilt to accommodate the missile magazines. This resulted in the construction of two separate platforms, one located between the first and second funnel and one located behind the second funnel, to which MK-143 Armored Box Launcher (ABL) canisters could be attached. Each Armored Box Launcher carried four missiles, and each of the battleships was outfitted with eight canisters, enabling the Iowa-class to carry and fire a total of 32 Tomahawk missiles.The type of Tomahawk carried by the battleships varied, as there were three basic configurations for the Tomahawk: the Anti-Ship Missile (TASM), the Land-Attack Missile-Conventional (TLAM-C), and the Land-Attack Missile-Nuclear (TLAM-N). Each version was similar in appearance and used the same airframe body and launcher. The conventional Tomahawk missile could carry a 1,000 lb (450 kg) explosive warhead or submunitions which used the missile body to reach their destination. The nuclear variant carried a 200 kt W80 nuclear warhead.The TLAM could be equipped with an inertial and terrain contour matching (TERCOM) radar guidance package to find and destroy its target. The TERCOM radar used a stored map reference to compare with the actual terrain to determine the missile's position. If necessary, a course correction was then made to place the missile on course to the target. Terminal guidance in the target area was provided by the optical Digital Scene Matching Area Correlation (DSMAC) system, which compared a stored image of target with the actual target image.The firing weight of the Tomahawk was 2,650 lb (1,200 kg) plus a 550 lb (250 kg) booster. It had a cruising speed of 0.5 Mach and an attack speed of 0.75 Mach. The anti-ship version of the Tomahawk had an operating range of 250 nmi (460 km) and a maximum range of 470 nmi (870 km), while the conventional land attack missile version had a maximum range of 675 nmi (1,250 km) and TLAM-N had maximum range of 1,500 nmi (2,800 km).During the 1991 Gulf War, USS Missouri and USS Wisconsin used ABL launchers to fire Tomahawk missiles at Iraqi targets during Operation Desert Storm. Wisconsin served as the Tomahawk Land Attack Missile (TLAM) strike commander for the Persian Gulf, directing the sequence of launches that marked the opening of Operation Desert Storm and fired a total of 24 of her own TLAMs during the first two days of the campaign.
For protection against enemy ships, the Iowa class was outfitted with the Harpoon Weapons System. The system consisted of four Mk 141 "shock-hardened" quad cell launchers designed to carry and fire the McDonnell Douglas RGM-84 Harpoon anti-ship missile. Each Harpoon was placed in one of four Mk 141 launchers located alongside the aft stack; eight per side, in two pods of four. The weight of the Harpoon at firing was 1,530 lb (690 kg), which included a booster weighing about 362 lb (164 kg). The cruising speed was 0.87 Mach and the maximum range was 64 nmi (119 km) in Range and Bearing Launch mode and 85 nmi (157 km) in Bearing Only Launch mode.When an Iowa-class battleship fired a Harpoon missile, a booster propelled the missile away from the ship; after approximately 5 miles (8 km), the booster dropped away. After the booster was discarded a turbojet engine ignited and propelled the missile to the target. The stabilizing and actuator fins, which helped to guide the missile to its target, were stored folded in the canister and sprang into position after launching. These fins directed the missile to the target through inputs from the AN/SWG-1 Harpoon Fire Control System.The battleships carried and used the RGM/UGM-84 variants of the Harpoon missile, which was designed to be fired by surface ships. The version used a solid-fueled rocket booster in an A/B44G-2 or -3 booster section, which was discarded after burn-out. The maximum range was around 140 kilometres (76 nmi).After launch, the missile was guided towards the target location as determined by the ship using a three-axis Attitude Reference Assembly (ATA) in an AN/DSQ-44 guidance section. The ATA was less accurate than a full-fledged inertial system, but good enough for Harpoon's range. For stabilization and control, the AGM-84A had four fixed cruciform wings (3x BSU-42/B, 1x BSU-43/B) and four movable BSU-44/B tail fins. The missile flew at a low cruise altitude and at a predetermined distance from the expected target position, its AN/DSQ-28 J-band active radar seeker in the nose was activated to acquire and lock on the target. The radar switch-on distance could be set to lower or higher values, the former requiring a more precisely-known target location but reducing the risk to be defeated by enemy Electronic Counter Measures (ECM).An alternative launch mode was called Bearing-Only Launch (BOL). In this mode, the missile was launched in the general direction of the target, and its radar activated from the beginning to scan for the target in a +/- 45Â° sector in front of the flight path. Once a target was located and the seeker locked the xGM-84A missile climbed rapidly to about 1800 m before diving on the target in what was known as a "pop-up maneuver". The 221 kg (488 lb) WDU-18/B penetrating blast-fragmentation warhead (in the WAU-3(V) /B warhead section) was triggered by a time-delayed impact fuze. When no target was acquired after radar activation, the Harpoon would self-destruct.

The Armed Forces Special Weapons Project (AFSWP) was a United States military agency responsible for those aspects of nuclear weapons remaining under military control after the Manhattan Project was succeeded by the Atomic Energy Commission on 1 January 1947. These responsibilities included the maintenance, storage, surveillance, security and handling of nuclear weapons, as well as supporting nuclear testing. The AFSWP was a joint organization, staffed by the United States Army, United States Navy and United States Air Force; its chief was supported by deputies from the other two services. Major General Leslie R. Groves, the former head of the Manhattan Project, was its first chief.
The early nuclear weapons were large, complex and cumbersome. They were stored as components rather than complete devices and required expert knowledge to assemble. The short life of their lead-acid batteries and modulated neutron initiators, and the heat generated by the fissile cores, precluded storing them assembled. The large quantity of conventional explosive in each weapon demanded special care be taken in handling. Groves hand-picked a team of regular Army officers, who were trained in the assembly and handling of the weapons. They in turn trained the enlisted soldiers, and the Army teams then trained teams from the Navy and Air Force.
As nuclear weapons development proceeded, the weapons became mass-produced, smaller, lighter, and easier to store, handle and maintain. They also required less effort to assemble. The AFSWP gradually shifted its emphasis away from training assembly teams, and became more involved in stockpile management and providing administrative, technical and logistical support. It supported nuclear weapons testing, although after Operation Sandstone in 1948, this was increasingly in a planning and training capacity rather than a field role. In 1958, the AFSWP became the Defense Atomic Support Agency (DASA), a field agency of the Department of Defense.
Nuclear weapons were developed during World War II by the Manhattan Project, a major research and development effort led by the United States, with participation from the United Kingdom and Canada. From 1942 to 1946, it was under the direction of Major General Leslie R. Groves, Jr., of the US Army Corps of Engineers. It created a network of production facilities, most notably for uranium enrichment at Oak Ridge, Tennessee,  plutonium production at Hanford, Washington and weapons research and design at the Los Alamos Laboratory in Los Alamos, New Mexico. The nuclear weapons that were developed were used in the atomic bombings of Hiroshima and Nagasaki in August 1945.After the war ended, the Manhattan Project supported the nuclear weapons testing at Bikini Atoll as part of Operation Crossroads in 1946. One of Secretary of the Navy James Forrestal's aides, Lewis Strauss proposed this series of tests to refute "loose talk to the effect that the fleet is obsolete in the face of this new weapon." The nuclear weapons were handmade devices, and a great deal of work remained to improve their ease of assembly, safety, reliability and storage before they were ready for production. There were also many improvements to their performance that had been suggested or recommended, but that had not been possible under the pressure of wartime development.Groves's biggest concern was about people. Soldiers and scientists wanted to return to their peacetime pursuits, and there was a danger that wartime knowledge would be lost, leaving no one who knew how to handle and maintain nuclear weapons, much less how to improve the weapons and processes. The military side of the Manhattan Project had relied heavily on reservists, as the policy of the Corps of Engineers was to assign regular officers to field commands. The reservists were now eligible for separation. To replace them, Groves asked for fifty West Point graduates from the top ten percent of their classes to man bomb assembly teams at Sandia Base, where the assembly staff and facilities had been moved from Los Alamos and Wendover Field in September and October 1945. He felt that only such high quality personnel would be able to work with the scientists who were currently doing the job. They were also urgently required for many other jobs in the postwar Army. When General Thomas T. Handy turned down his request, Groves raised the matter with the Chief of Staff of the Army, General of the Army Dwight D. Eisenhower, who similarly did not approve it. Groves then went over his head too, and took it to the Secretary of War, Robert P. Patterson, who agreed with Groves.  The personnel manned the 2761st Engineer Battalion (Special), which became a field unit under the Armed Forces Special Weapons Project (AFSWP).Groves hoped that a new, permanent agency would be created to take over the responsibilities of the wartime Manhattan Project in 1945, but passage of the Atomic Energy Act of 1946 through Congress took much longer than expected, and involved considerable debate about the proper role of the military with respect to the development, production and control of nuclear weapons. The act that was signed by President Harry S. Truman on 1 August 1946 created a civilian agency, the United States Atomic Energy Commission (AEC), to take over the functions and assets of the Manhattan Project, but the commissioners were not appointed until October, and AEC did not assume its role until 1 January 1947. In the meantime, the Military Appropriation Act of 1946 gave the Manhattan Project $72.4 million for research and development, and $19 million for housing and utilities at Los Alamos and Oak Ridge.The Atomic Energy Act provided for a Military Liaison Committee to advise the AEC on military matters, so Patterson appointed Lieutenant General Lewis H. Brereton, who became chairman, along with Major General Lunsford E. Oliver and Colonel John H. Hinds as Army members of the Military Liaison Committee; Forrestal appointed Rear Admirals Thorvald A. Solberg, Ralph A. Ofstie and William S. Parsons as its naval members.
Patterson asked Groves to create a new agency to take over responsibility for the aspects of nuclear weapons that still remained under the military. It was to be jointly staffed by the Army and Navy, and on 29 January 1947, Patterson and Forrestal issued a memorandum that formally established the AFSWP. Its chief would be  appointed jointly by the Chief of Staff of the Army and the Chief of Naval Operations, along with a deputy from the opposite service. Both would be members of the Military Liaison Committee, because the Atomic Energy Act stipulated that the Military Liaison Committee was the sole military body that dealt with the AEC. In February 1947, Eisenhower and Chief of Naval Operations Fleet Admiral Chester W. Nimitz appointed Groves as head of the AFSWP, with Parsons as his deputy. Accordingly, Groves was appointed to the Military Liaison Committee, although the newly appointed AEC chairman, David E. Lilienthal, told Patterson that he did not think that it was a good idea, because Groves had run the Manhattan Project by himself for four years, and was not used to having to compromise.Groves and Parsons drafted a proposed organization and charter for the AFSWP, which they sent to Eisenhower and Nimitz for approval in July 1947. Groves did not get everything that he asked for; he wanted a status equal to that of a deputy to the Chief of Staff and Chief of Naval Operations, but the most that Eisenhower and Nimitz would allow was a status equal to that of the heads of a technical service, although Groves still reported directly to them. They also characterized his role as a staff post rather than a command, although Groves was already exercising the functions of a commander at Sandia. After the National Security Act of 1947 created an independent Air Force, Groves reported to the Chief of Staff of the Air Force as well, and was given a second deputy chief from the Air Force, Major General Roscoe C. Wilson, who had worked on the Silverplate project during the war.Groves initially established the headquarters of the AFSWP in the old offices of the Manhattan Project on the fifth floor of the New War Department Building in Washington, DC, but on 15 April 1947 it moved to the Pentagon. As AFSWP headquarters expanded, it filled up its original accommodation, and began using office space in other parts of the building, which was not satisfactory from a security point of view. In August 1949, it moved to 18,000 square feet (1,700 m2) of new offices inside the Pentagon. This included space for a soundproof conference room, a darkroom, and vaults where its records and films were stored.
The 2761st Engineer Battalion (Special) at Sandia was commanded by Colonel Gilbert M. Dorland, and consisted of a headquarters company, a security company (Company A), a bomb assembly company (Company B) and a radiological monitoring company (Company C), although Company C was never fully formed. For training purposes, Company B was initially divided into command, electrical, mechanical and nuclear groups, but the intention was to create three integrated 36-man bomb assembly teams. To free the bomb assembly teams from having to train newcomers, a Technical Training Group (TTG) was created under Lieutenant Colonel John A. Ord, a Signal Corps officer with a Doctor of Science degree from Carnegie Institute of Technology who had directed the training of thousands of radar technicians at the Southern Signal Corps School during the war. The battalion was redesignated the 38th Engineer Battalion (Special) in April 1947, and in July it became part of the newly created AFSWP Field Command, under the command of Brigadier General Robert M. Montague. The TTG was soon reporting directly to Montague as well.The first bomb assembly team was formed in August 1947, followed by a second in December and a third in March 1948. Experience with assembling the bombs convincingly demonstrated the requirement, in Sandia if not in Washington, for a much larger unit. Groves reluctantly approved a 109-man special weapons unit, and Montague converted the three lettered companies of the 38th Engineer Battalion into special weapons units. In 1948, they began training a Navy special weapons unit, as the Navy foresaw delivery of nuclear weapons with its new North American AJ Savage bombers from its Midway-class aircraft carriers. This unit became the 471st Naval Special Weapons Unit on its certification in August 1948. Two Air Force units were created in September and December 1948, which became the 502d and 508th Aviation Squadrons. An additional Army special weapons unit was created in May 1948, and in December, the 38th Engineer Battalion (Special) became the 8460th Special Weapons Group, with all seven special weapons units under its command. The four Army units were then renamed the 111th, 122d, 133d and 144th Special Weapons Units. During the late 1940s the Air Force gradually became the major user of nuclear weapons, and by the end of 1949, it had twelve assembly units, and another three in training, while the Army had only four, and the Navy three, one for each of the three Midway-class carriers.In March 1948, the  Chief of Staff of the Air Force, General Carl Spaatz, proposed that the Air Force take over the AFSWP, on the grounds that the Key West Agreement had given it responsibility for strategic bombing. This would have simplified command of the AFSWP, as it would have been answerable to only one service chief instead of three The Army cautiously supported the proposal, but the Navy was strongly opposed, fearing that the Air Force's confusion of atomic bombing and strategic bombing would impede or even prevent the Navy from having access to nuclear weapons, which it felt was necessary to accomplish its primary maritime mission. Another series of talks was held at the Naval War College in Newport, Rhode Island, from 20 to 22 August 1948, which resulted in the Newport Agreement, under which the Navy agreed to drop its opposition to the AFSWP being placed under the Air Force temporarily, in return for the Air Force recognizing the Navy's requirement for nuclear weapons. When the Air Force moved to make the temporary arrangement permanent in September 1948, the Army and Navy objected, and the Military Liaison Committee directed that the AFSWP should remain a tri-service organization answerable to the three service chiefs.
Groves and the wartime director of the Los Alamos Laboratory, Robert Oppenheimer, had begun the move of ordnance functions to Sandia in late 1945. The laboratory's ordnance engineering division, known as Z Division, after its first director, Jerrold R. Zacharias, was split between Los Alamos and Sandia. Between March and July 1946, Z Division relocated to Sandia, except for its mechanical engineering (Z-4) section, which followed in February 1947. Z Division worked on improving the mechanical and electrical reliability of the Mark 3 Fat Man bomb, but this work was disrupted by the Crossroads tests.
The 1947 nuclear stockpile consisted of nuclear weapons components, not weapons. Meeting with Truman in April 1947, Lilienthal informed him that not only were there no assembled weapons, but there were only a few sets of components, and no fully trained bomb assembly teams. By August 1946, Sandia Base held electrical and mechanical assemblies for about 50 Fat Man bombs, but there were only nine fissile cores in storage. The stockpile of cores grew to 13 in 1947, and 53 in 1948. Oppenheimer noted that the bombs were "still largely the haywire contraptions that were slapped together in 1945." With a half-life of only 140 days, the polonium-beryllium modulated neutron initiators had to be periodically removed from the plutonium pits, tested, and, if necessary, replaced. The cores had to be stored separately from the high explosive blocks that would surround them in the bomb because they generated enough heat to melt the plastic explosive over time. The heat could also affect the cores themselves, provoking a phase transition to a different allotrope of plutonium. They had to be periodically inspected by technicians wearing gloves and respirators. The bomb's electrical power for its radar fuzes and detonators came from a pair of lead-acid batteries similar to those used in cars. These had to be charged 24 hours before use. After a few days, the bomb had to be partially disassembled so that they could be re-charged; and three days after that the batteries had to be replaced.
The 38th Engineer Battalion's electrical group studied the batteries, the electrical firing systems and the radar fuzes which detonated the bomb at the required altitude. The mechanical group dealt with the exploding-bridgewire detonators and the explosive lenses. The nuclear group moved to Los Alamos to study the cores and initiators. As part of their training, they attended lectures by Edward Teller, Hans Bethe, Lise Meitner and Enrico Fermi. The electrical and mechanical groups at Sandia, although not the nuclear group, completed their training around the end of October 1946 and spent the next month devising the best methods of assembling a Fat Man, drawing up detailed checklists so that later bomb assembly teams could be trained. They also drew up a proposed table of organization and equipment for an assembly team. It took two weeks for them to assemble their first bomb in December 1946.Most of 1947 was spent planning for a field exercise in which a bomb team would deploy to a base and assemble weapons under field conditions. A 20-foot (6.1 m) by 100-foot (30 m) portable building was acquired and outfitted as field workshops that could be loaded onto a C-54 or C-97 transport aircraft. In November 1947, the 38th Engineer Battalion carried out its first major field exercise, Operation Ajax. It drew bomb components, except for fissile cores, from the AEC, and deployed by air to Wendover Field, Utah. This was the home of the 509th Bombardment Group, which was the only unit operating Silverplate B-29 bombers, and therefore the only B-29 group capable of delivering nuclear weapons. To simulate operational conditions, they took a roundabout route via New England and Seattle. Over the following ten days, they assembled bombs and flew training missions with them, including a live drop at the Naval Ordnance Test Station at Inyokern, California.This was followed by other exercises. In one exercise in March 1948, the base personnel successfully fought off an "attack" by 250 paratroopers from Fort Hood, Texas. In another exercise in November 1948, the 471st Special Weapons Unit flew to Norfolk, Virginia, and practiced bomb assembly on board the Midway-class aircraft carriers.
In addition to assembly of weapons, the AFSWP supported nuclear weapons testing. For Operation Sandstone in 1948, Groves ordered Dorland to fill every possible job with his men. He did this so well that Strauss, now an AEC commissioner, became disturbed at the number of AFSWP personnel who were participating, and feared that the Soviet Union might launch a sneak attack on Enewetak to wipe out the nation's ability to assemble nuclear weapons. The successful testing in Operation Sandstone was a major leap forward. The new Mark 4 nuclear bomb that the AEC began delivering in 1949 was a production design that was much easier to assemble and maintain, and enabled a bomb assembly team to be reduced to just 46 men. Kenneth D. Nichols, the wartime commander of the Manhattan District, now "recommended that we should be thinking in terms of thousands of weapons rather than hundreds."After Operation Sandstone, only relatively small numbers of AFSWP personnel were involved in nuclear testing. The AFSWP was heavily involved in the planning, preparation and coordination of tests, but it had limited participation in the tests themselves, where the bomb assembly function was usually undertaken by scientists.  During Operation Buster-Jangle, AFSWP personnel showed films and gave lectures to 2,800 military personnel who had been selected to witness the test, explaining what would occur and the procedures to be followed. This was expanded to cater for the more than 7,000 personnel who were involved in Operation Upshotâ€“Knothole in 1953.
When the AEC was formed in 1947 it acquired custody of nuclear components from the Manhattan Project on the understanding that the matter would be reviewed. In November 1947, the Military Liaison Committee requested that custody of the nuclear stockpile be transferred to the military, but Lilienthal believed that AEC custody of the stockpile was an important aspect of civilian control of nuclear weapons. He was disturbed that the AFSWP had not informed the AEC in advance of Operation Ajax. For his part, Groves suspected that the AEC was not keeping bomb components in the condition in which the military wanted to receive them, and Operation Ajax only confirmed his suspicions. Reviewing the exercise, Montague reported that "under the existing law, with the AEC charged with procurement and custody of all atomic weapons, there was no adequate logistic support for the weapon." He recommended a larger role for the military, a recommendation with which Groves concurred, but was powerless to implement.
Groves retired at the end of February 1948, and Nichols was designated as his successor with the rank of major general. At the same time, Forrestal, now the Secretary of Defense, reorganized the Military Liaison Committee. A civilian, Donald F. Carpenter, replaced Brereton as chairman, and there were now two members from each of the three services. On 11 March, Truman summoned Lilienthal, Nichols and Secretary of the Army Kenneth C. Royall to his office, and told them that he expected the AFSWP and the AEC to cooperate.Nichols's position was the same as Groves's and Montague's: that nuclear weapons needed to be available in an emergency, and the men who had to use them in battle needed to have experience with their maintenance, storage and handling. Norris Bradbury, who had replaced Oppenheimer as the director of the Los Alamos Laboratory in December 1945, argued that rapid transfer could be accomplished by improved procedures and that the other difficulties could best be resolved by further development, mostly from the scientists. Forrestal and Carpenter took the matter up with Truman, who issued his decision on 21 July 1948: "I regard the continued control of all aspects of the atomic energy program, including research, development and the custody of atomic weapons as the proper functions of the civil authorities."With the outbreak of the Korean War in 1950, air transport resources were put under great strain, and it was decided to reduce the requirement for it by pre-positioning non-nuclear components at locations in Europe and the Pacific. That way, in an emergency, only the nuclear components would have to be flown out. In June, Truman ordered the transfer of 90 sets of non-nuclear Mark 4 components to the AFSWP for training purposes. In December, he authorized the carriage of non-nuclear components on board the Midway-class carriers. In April 1951, the AEC released nine Mark 4 weapons to the Air Force in case the Soviet Union intervened in the war in Korea. These were flown to Guam, where they were maintained by the Air Force special weapons unit there. Thus, at the end of 1951, there were 429 weapons in AEC custody and nine held by the Department of Defense.In the light of this, a new AEC-AFSWP agreement on "Responsibilities of Stockpile Operations" was drawn up in August 1951, but in December, the Joint Chiefs of Staff began a new push for weapons to be permanently assigned to the armed forces, so as to ensure a greater degree of flexibility and a higher state of readiness. On 20 June 1953, Eisenhower, now as president, approved the deployment of nuclear components in equal numbers to non-nuclear components, and the Atomic Energy Act of 1954 amended the sections of the old act that gave exclusive custody to the AEC. By 1959, the nuclear stockpile had grown to 12,305 weapons of which 3,968 were in AEC custody and the remaining 8,337 were held by the Department of Defense. The total yield of the stockpile was now in excess of 19,000 megatons of TNT (79,000 PJ).As Bradbury had promised, with research and development, nuclear weapons became smaller, simpler and lighter. They also became easier to store, assemble, test and maintain. Thus, while under Eisenhower's New Look policy the Armed Forces became more heavily involved with aspects of nuclear weapons than ever, the role of the AFSWP diminished. It began moving away from training assembly teams, which were increasingly not required, as its primary mission, and became more involved in the management of the rapidly growing nuclear stockpile, and providing technical advice and logistical support. In 1953, the AFSWP Field Command had 10,250 personnel. On 16 October 1953, the Secretary of Defense charged the AFSWP with responsibility for "a centralized system of reporting and accounting to ensure that the current status and location" of all nuclear weapons "will be known at all times". The Atomic Warfare Status Center was created within the AFSWP to handle this mission.
In April 1958, Eisenhower asked Congress for legislation to overhaul the Department of Defense. Over a decade had passed since the legislation which had established it, and he was concerned about the degree of inter-service rivalry, duplication and mismanagement that was evident in many programs. In ballistic missile development, the Soviet Sputnik program had demonstrated that country's technological lead over the United States. The Army and Air Force had rival programs, PGM-19 Jupiter and PGM-17 Thor respectively, and the additional cost to the taxpayers of developing two systems instead of one was estimated at $500 million.The Defense Reorganization Act of 1958 was signed by Eisenhower in August 1958. It increased the authority of the Secretary of Defense, who was authorized to establish such defense agencies as he thought necessary "to provide for more effective, efficient and economical administration and operation". The first field agency established under the act was the Defense Atomic Support Agency (DASA), which replaced the AFSWP on 1 May 1959. The new agency reported to the Secretary of Defense through the Joint Chiefs of Staff, and was given responsibility for the supervision of all Department of Defense nuclear testing, which had hitherto been handled by the individual services. Otherwise, its role and organization remained much the same, and its commander, Rear Admiral Edward N. Parker, remained as its first director. Eisenhower's proposed nuclear testing moratorium ultimately fundamentally changed DASA's mission, as nuclear testing was phased out, Cold War tensions eased, and nuclear disarmament became a prospect.

The Armero tragedy (Spanish: Tragedia de Armero [tÉ¾aËˆxeÃ°ja Ã°e aÉ¾ËˆmeÉ¾o]) was one of the major consequences of the eruption of the Nevado del Ruiz stratovolcano in Tolima, Colombia, on November 13, 1985. After 69 years of dormancy, the volcano's eruption caught nearby towns unaware, even though the government had received warnings from multiple volcanological organizations to evacuate the area after the detection of volcanic activity two months earlier.As pyroclastic flows erupted from the volcano's crater, they melted the mountain's glaciers, sending four enormous lahars (volcanically induced mudflows, landslides, and debris flows) down its slopes at 50 kilometers per hour (30 miles per hour). The lahars picked up speed in gullies and coursed into the six major rivers at the base of the volcano; they engulfed the town of Armero, killing more than 20,000 of its almost 29,000 inhabitants. Casualties in other towns, particularly ChinchinÃ¡, brought the overall death toll to 23,000. Footage and photographs of Omayra SÃ¡nchez, a young victim of the tragedy, were published around the world. Other photographs of the lahars and the impact of the disaster captured attention worldwide and led to controversy over the degree to which the Colombian government was responsible for the disaster. A banner at a mass funeral in IbaguÃ© read, "The volcano didn't kill 22,000 people. The government killed them."
The relief efforts were hindered by the composition of the mud, which made it nearly impossible to move through without becoming stuck. By the time relief workers reached Armero twelve hours after the eruption, many of the victims with serious injuries were dead. The relief workers were horrified by the landscape of fallen trees, disfigured human bodies, and piles of debris from entire houses. This was the second-deadliest volcanic disaster of the 20th century, surpassed only by the 1902 eruption of Mount PelÃ©e, and is the fourth-deadliest volcanic event recorded since 1500 AD. The event was a foreseeable catastrophe exacerbated by the populace's unawareness of the volcano's destructive history; geologists and other experts had warned authorities and media outlets about the danger over the weeks and days leading up to the eruption. Hazard maps for the vicinity were prepared, but poorly distributed. On the day of the eruption, several evacuation attempts were made, but a severe storm restricted communications. Many victims stayed in their houses as they had been instructed, believing that the eruption had ended. The noise from the storm may have prevented many from hearing the sounds of the eruption until it was too late.
Nevado del Ruiz has erupted several times since the disaster, and continues to threaten up to 500,000 people living along the Combeima, ChinchinÃ¡, Coello-Toche, and Guali river valleys. A lahar (or group of lahars) similar in size to the 1985 event might travel as far as 100 kilometres (60 mi) from the volcano, and could be triggered by a small eruption. To counter this threat, the Colombian government established a specialized office which promotes awareness of natural threats. The United States Geological Survey also created the Volcano Disaster Assistance Program and the Volcano Crisis Assistance Team, which evacuated roughly 75,000 people from the area around Mount Pinatubo before its 1991 eruption. In 1988, three years after the eruption, Dr. Stanley Williams of Louisiana State University stated that, "With the possible exception of Mount St. Helens in the state of Washington, no other volcano in the Western Hemisphere is being watched so elaborately" as Nevado del Ruiz. Additionally, many of Colombia's cities have programs to raise awareness of natural disaster planning programs which have helped save lives in natural disasters. Near Nevado del Ruiz in particular, locals have become wary of volcanic activity: when the volcano erupted in 1989, more than 2,300 people living around it were evacuated.
Armero, located 48 kilometers (30 mi) from the Nevado del Ruiz volcano and 169 kilometers (105 mi) from Colombia's capital of BogotÃ¡, was the third largest town in Tolima Department, after IbaguÃ© and Espinal. A prominent farming town before the eruption, it was responsible for roughly one-fifth of Colombia's rice production, and for a large share of the cotton, sorghum, and coffee crops. Much of this success can be attributed to Nevado del Ruiz, as the fertile volcanic soil had stimulated agricultural growth.Built on top of an alluvial fan that had been host to historic lahars, the town was previously destroyed by a volcanic eruption in 1595 and by mudflows in 1845. In the 1595 eruption, three distinct Plinian eruptions produced lahars that claimed the lives of 636 people. During the 1845 event, 1,000 people were killed by earthquake-generated mudflows near the Magdalena River.Nevado del Ruiz has undergone three distinct eruptive periods, the first beginning 1.8 million years ago. During the present period (beginning 11,000 years ago), it has erupted at least twelve times, producing ashfalls, pyroclastic flows, and lahars. The historically recorded eruptions have primarily involved a central vent eruption (in the caldera) followed by an explosive eruption, then the formation of lahars. Ruiz's earliest identified Holocene eruption was in about 6660 BC, and further eruptions occurred around 1245, 850, 200 BC and in about 350, 675, in 1350, 1541 (perhaps), 1570, 1595, 1623, 1805, 1826, 1828 (perhaps), 1829, 1831, 1833 (perhaps), 1845, 1916, December 1984 through March 1985, 1987 through July 1991, and possibly in April 1994. Many of these eruptions involved a central vent eruption, a flank vent eruption, and a phreatic (steam) explosion. Ruiz is the second-most active volcano in Colombia after Galeras.One week before the eruption, the Palace of Justice siege took place. The assailants (M-19 a Marxist, Terrorist Insurgency group) planned to hold a trial involving Colombian President Belisario Betancur. He refused to participate and sent the national army into the building. The attackers were holding several hundred hostages, including the 24 Supreme Court justices and 20 other judges. In the ensuing battle between the two forces, more than 75 hostages died (including 11 judges). This disaster, coupled with the Armero tragedy, spurred the Colombian government to predict and prepare for a broad range of threats.
In late 1984, geologists noticed that seismic activity in the area had begun to increase. Increased fumarole activity, deposition of sulfur on the summit of the volcano, and phreatic eruptions also alerted geologists to the possibility of an eruption. Phreatic events, when rising magma encounters water, continued well into September 1985 (one major event took place on September 11, 1985), shooting steam high into the air. Activity began to decline in October, probably because the new magma had finished ascending into Nevado del Ruiz's volcanic edifice.An Italian volcanological mission analyzed gas samples from fumaroles along the Arenas crater floor and found them to be a mixture of carbon dioxide and sulfur dioxide, indicating a direct release of magma into the surface environment. Publishing a report for officials on October 22, 1985, the scientists determined that the risk of lahars was unusually high. To prepare for the eruption, the report gave several simple preparedness techniques to local authorities. Another team gave the local officials seismographs, but no instructions on how to operate them.Volcanic activity increased again in November 1985 as magma neared the surface. Increasing quantities of gases rich in sulfur dioxide and elemental sulfur began to appear in the volcano. The water content of the fumaroles' gases decreased, and water springs in the vicinity of Nevado del Ruiz became enriched with magnesium, calcium and potassium, leached from the magma.The thermodynamic equilibration temperatures, corresponding to the chemical composition of the discharged gases, ranged from 200 to 600 Â°C (400 to 1,100 Â°F); this is a measure of the temperature at which the gases equilibrated within the volcano. The extensive degassing of the magma caused pressure to build up inside the volcano in the space above the magma, which eventually resulted in the explosive eruption.
In September 1985, as earthquakes and phreatic eruptions rocked the area, local officials began planning for an evacuation. In October, a hazard map was finalized for the area around Nevado del Ruiz. This map highlighted the danger from falling materialâ€”including ash and rockâ€”near Murillo, Santa Isabel, and Libano, as well as the threat of lahars in Mariquita, Guayabal, ChinchinÃ¡ and Armero.The map was poorly distributed to the people at high risk from Ruiz: many survivors had never heard of it, even though several of the country's major newspapers featured versions of the map. Henry Villegas of INGEOMINAS (Colombian Institute of Mining and Geology) stated that the hazard maps clearly demonstrated that Armero would be affected by the lahars, but that the map "met with strong opposition from economic interests." He added that because the map was not prepared long before the eruption, mass production and distribution of it in time was difficult.At least one of the hazard maps published in the prominent El Espectador newspaper in BogotÃ¡ included glaring errors. Without proper graphic scaling, it was unclear how big the map's hazard zones really were. The lahars on the map did not have a distinct ending point, and the main threat seemed to be from pyroclastic flows, not from mudflows. Though the map was colored blue, green, red, and yellow, there was no key to indicate what each color represented, and Armero was located in the green zone (believed to indicate the safest area.Another map published by the El Tiempo newspaper featured illustrations which "gave a perception of topography to the public unfamiliar with maps, allowing them to relate hazard zones to the landscape." In spite of this presentation that was keyed to the audience, the map ended up a more artistic representation of the risk than a purely scientific one.The day of the eruption, black ash columns erupted from the volcano at approximately 3:00 pm local time. The local Civil Defense director was promptly alerted to the situation. He contacted INGEOMINAS, which ruled that the area should be evacuated; he was then told to contact the Civil Defense directors in BogotÃ¡ and Tolima. Between 5:00 and 7:00 pm, the ash stopped falling, and local officials instructed people to "stay calm" and go inside. Around 5:00 pm an emergency committee meeting was called, and when it ended at 7:00 pm, several members contacted the regional Red Cross over the intended evacuation efforts at Armero, Mariquita, and Honda.The IbaguÃ© Red Cross contacted Armero's officials and ordered an evacuation, which was not carried out because of electrical problems caused by a storm. The storm's heavy rain and constant thunder may have overpowered the noise of the volcano, and with no systematic warning efforts, the residents of Armero were completely unaware of the continuing activity at Ruiz. At 9:45 pm, after the volcano had erupted, Civil Defense officials from IbaguÃ© and Murillo tried to warn Armero's officials, but could not make contact. Later they overheard conversations between individual officials of Armero and others; famously, a few heard the Mayor of Armero speaking on a ham radio, saying "that he did not think there was much danger", when he was overtaken by the lahar.
At 9:09 p.m., on November 13, 1985, Nevado del Ruiz ejected dacitic tephra more than 30 kilometres (20 mi) into the atmosphere. The total mass of the erupted material (including magma) was 35 million metric tons, only three percent of the amount that erupted from Mount St. Helens in 1980.  The eruption reached 3 on the Volcanic Explosivity Index. The mass of the ejected sulfur dioxide was about 700,000 metric tons, or about two percent of the mass of the erupted solid material, making the eruption unusually sulfur rich.The eruption produced pyroclastic flows that melted summit glaciers and snow, generating four thick lahars that raced down river valleys on the volcano's flanks, destroying a small lake that was observed in Arenas' crater several months before the eruption. Water in such volcanic lakes tends to be extremely salty, and may contain dissolved volcanic gases. The lake's hot, acidic water significantly accelerated the melting of the ice, an effect confirmed by the large amounts of sulfates and chlorides found in the lahar flow.The lahars, formed of water, ice, pumice, and other rocks, incorporated clay from eroding soil as they traveled down the volcano's flanks. They ran down the volcano's sides at an average speed of 60 kilometres per hour (40 mph), dislodging rock and destroying vegetation. After descending thousands of meters down the side of the volcano, the lahars followed the six river valleys leading from the volcano, where they grew to almost four times their original volume. In the GualÃ­ River, a lahar reached a maximum width of 50 metres (160 ft).Survivors in Armero described the night as "quiet". Volcanic ash had been falling throughout the day, but residents were informed it was nothing to worry about. Later in the afternoon, ash began falling again after a long period of quiet. Local radio stations reported that residents should remain calm and ignore the material. One survivor reported going to the fire department to be informed that the ash was "nothing".During the night, the electrical power suddenly turned off and the radios went silent. Just before 11:30 p.m., a huge stream of water swept through Armero; it was powerful enough to flip cars and pick up people. A loud roar could be heard from the mountain, but the residents were panicked over what they believed to be a flood.
At 11:30 p.m., the first lahar hit, followed shortly by the others. One of the lahars virtually erased Armero; three-quarters of its 28,700 inhabitants were killed. Proceeding in three major waves, this lahar was 30 metres (100 ft) deep, moved at 12 metres per second (39 ft/s; 27 mph), and lasted ten to twenty minutes. Traveling at about six metres per second (20 ft/s; 13 mph), the second lahar lasted thirty minutes and was followed by smaller pulses.A third major pulse brought the lahar's duration to roughly two hours. By that point, 85 percent of Armero was enveloped in mud. Survivors described people holding on to debris from their homes in attempts to stay above the mud. Buildings collapsed, crushing people and raining down debris.The front of the lahar contained boulders and cobbles that would have crushed anyone in their path, while the slower parts were dotted by fine, sharp stones which caused lacerations. Mud moved into open wounds and other open body parts â€” the eyes, ears, and mouth â€” and placed pressure capable of inducing traumatic asphyxia in one or two minutes upon people buried in it. MartÃ­ and Ernst state in their work Volcanoes and the Environment that they believe that many who survived the lahars succumbed to their injuries as they were trapped, or contracted hypothermia, though the latter is unlikely, given that survivors described the water as warm.Another lahar, which descended through the valley of the ChinchinÃ¡  River, killed about 1,800 people and destroyed 400 homes in ChinchinÃ¡. In total, more than 23,000 people were killed, approximately 5,000 were injured, and 5,000 homes throughout thirteen villages were destroyed. Some 230,000 people were affected, 27,000 acres (11,000 ha) were disrupted, and there were nearly 20,000 survivor-refugees. The Armero tragedy, as the event came to be known, was the second-deadliest volcanic disaster of the 20th century, surpassed only by the 1902 eruption of Mount PelÃ©e, and is the fourth-deadliest volcanic eruption recorded since 1500 AD. It is also the deadliest lahar, and Colombia's worst natural disaster.
The loss of life was exacerbated by the lack of an accurate timeframe for the eruption and the unwillingness of local authorities to take costly preventative measures without clear signs of imminent danger. Because its last substantial eruption had occurred 140 years earlier, in 1845, it was difficult for many to accept the danger presented by the volcano; locals even called it the "Sleeping Lion."Hazard maps showing that Armero would be completely flooded after an eruption were distributed more than a month before the eruption, but the Colombian Congress criticized the scientific and civil defense agencies for scaremongering. The eruption occurred at the height of guerrilla warfare in BogotÃ¡, Colombia's capital, and so the government and army were preoccupied at the time of the eruption.
The day after the eruption, relief workers were appalled at its impact. The lahars had left behind a gray mass which covered the entire town. Armero was dotted with broken trees and horribly disfigured human bodies. Debris from huts and homes protruded from beneath the gray mud. A few bags filled with crops were discovered in the mud. Workers described an acrid smell of "rotting bodies, [...] wood smoke and decaying vegetables." To the horror of these workers, who were scrambling to begin relief efforts, survivors let out moans of pain and agony. The damages were assessed at six billion dollars, an amount approximately one-fifth of Colombia's 1985 Gross National Product.As news of the catastrophe spread around the world, the ongoing Colombian presidential election stopped, and the guerrilla fighters stopped their campaign "in view of the painful tragedy that has befallen our [the Colombian fighters] nation." Tickets for Colombian national championship soccer games added a surcharge of five cents to go to relief efforts.Scientists who later analyzed the seismograph data noticed that several long-period earthquakes (which begin strongly and then slowly die out) had occurred in the final hours before the eruption. Volcanologist Bernard Chouet said that, "the volcano was screaming 'I'm about to explode'", but the scientists who were studying the volcano at the time of the eruption were not able to read the signal.
The eruption occurred two months after the 1985 Mexico City earthquake, limiting the amount of supplies that could be sent to each of the disasters. Efforts were organized in IbaguÃ© and BogotÃ¡ for Armero and in Cali for Chinchina, where medical teams gathered. Makeshift triage stations were established in Lerida, Guayabal, and Mariquita, and soon were overwhelmed with the sheer number of victims. The remaining victims were directed to IbaguÃ©'s hospitals, as local institutions had already been destroyed or were at risk from further lahars.
The US government spent over $1 million in aid (equivalent to $2.3 million today), and US Ambassador to Colombia Charles S. Gillespie, Jr. donated an initial $25,000 to Colombian disaster assistance institutions ($58,000 today). The Office of Foreign Disaster Assistance of the US Agency for International Development (AID) sent one member of the United States Geological Survey (USGS), along with an AID disaster-relief expert and 12 helicopters with support and medical personnel from Panama.The US subsequently sent additional aircraft and supplies, including 500 tents, 2,250 blankets, and several tent repair kits. Twenty-four other nations contributed to the rescue and assistance of survivors. Ecuador supplied a mobile hospital, and Iceland's Red Cross sent $4,650 ($10,800 today). The French government sent their own medical supplies with 1,300 tents. Japan sent $1.25 million ($2.91 million today), along with eight doctors, nurses, and engineers, plus $50,000 ($116,500 today) to the United Nations for relief efforts. Another $50,000 ($116,500 today) was donated by the Lions Clubs International Foundation.Rescue efforts were hindered by the soft mud that was up to 4.6 meters (15 ft) deep in some places, making it virtually impossible for anyone to traverse it without sinking in. To make the situation worse, the highway connected to Armero and several bridges to it had been demolished by the lahars. It took twelve hours for the first survivors to be rescued, so those with serious but treatable injuries probably died before the rescuers arrived.Because Armero's hospital was destroyed in the eruption, helicopters moved survivors to nearby hospitals. Six local towns set up makeshift emergency relief clinics, consisting of treatment areas and shelters for the homeless. To help with the treatment, physicians and rescue teams came from all over the country. Of the 1,244 patients spread over the clinics, 150 died from infection or associated complications. Had antibiotics been readily available and all of their lacerations been thoroughly cleaned, many of these people could have been saved.On November 20, 1985, one week later, rescue efforts began to cease. Nearly 4,000 relief workers and rescue team members were still searching for survivors, with little hope of finding any. By then, the official death toll was registered at 22,540 people; additional counts showed that 3,300 were missing, 20,000 homeless, and 4,000 injured. Looters raided the ruins and survivors faced concerns of typhus and yellow fever. For most of the relief workers, their job was over.The eruption was used as an example for psychiatric recuperation after natural disasters by Robert Desjarlais and Leon Eisenberg in their work World Mental Health: Problems and Priorities in Low-Income Countries. The authors were concerned that only initial treatment for the survivors' psychological trauma was conducted. One study showed that the victims of the eruption suffered from anxiety and depression, which can lead to alcohol abuse, marital problems and other social issues.Rafael Ruiz, an Army Major who briefly served as Armero's provisional mayor after the disaster, stated that there were survivors who, due to the trauma of the event, were "jittery", experienced "nightmares", and suffered from "emotional problems." He added that the progress made by Christmas of 1985 was considerable, but that there was "still a long way to go."
A lack of preparation for the disaster contributed to the high death toll. Armero had been built on an alluvial fan that had been overrun by historic mudflows; authorities had ignored a hazard-zone map that showed the potential damage to the town from lahars. Residents stayed inside their dwellings to avoid the falling ash, as local officials had instructed them to do, not thinking that they might be buried by the mudflows.The disaster gained international notoriety due in part to a photograph taken by photographer Frank Fournier of a young girl named Omayra SÃ¡nchez, who was trapped beneath rubble for three days before she died. Following the eruption, relief workers gathered around the girl, speaking with her and listening to her responses. She attracted the attention of the reporters at the site because of her sense of dignity and courage, and caused controversy when people wondered why the media workers had not saved her (which was impossible without equipment).An appeal to the government for a pump to lower the water around her was left unanswered, and she succumbed to gangrene and hypothermia after 60 hours of being trapped. Her death epitomized the tragic nature of the Armero disaster â€“ she could have been saved had the government responded promptly and addressed the concerns over the volcano's potency. The photograph earned the World Press Photo of the Year for "capturing the event of greatest journalistic importance".Two photographers from the Miami Herald won a Pulitzer Prize for photographing the effects of the lahar. Dr. Stanley Williams of Louisiana State University said that following the eruption, "With the possible exception of Mount St. Helens in the state of Washington, no other volcano in the Western Hemisphere is being watched so elaborately." In response to the eruption, the USGS Volcano Crisis Assistance Team was formed in 1986, and the Volcano Disaster Assistance Program.
Concerns over the alleged negligence of local officials to alert locals of the volcano's threat led to controversy. The mayor of Armero, Ramon Rodriguez and other local officials had tried to bring the volcano's potential eruption to the attention of the Colombian government, but to no avail. For months, Rodriguez appealed to various officials, including congressmen and the Governor of Tolima Department. Rodriguez once referred to the volcano as a "time bomb" and told reporters that he believed an eruption would disrupt the natural dam above Armero, resulting in floods.Despite his persistence, only one congressman managed to inquire about the reality of the situation. Reports from the Colombian Minister of Mines, Minister of Defence, and Minister of Public Works "all asserted that the government was aware of the risk from the volcano and was acting to protect the population". The lack of responsibility for the disaster prompted lawmakers to campaign for Tolima's governor (Eduardo Alzate Garcia) to resign. In the media, similar thoughts and questions were hotly debated. One of the most aggressive campaigns came from a mass funeral in IbaguÃ© for the victims, claiming that "The volcano didn't kill 22,000 people. The government killed them."
The volcano continues to pose a serious threat to nearby towns and villages. Of the threats, the one with the most potential for danger is that of small-volume eruptions, which can destabilize glaciers and trigger lahars. Although much of the volcano's glacier mass has retreated, a significant volume of ice still sits atop Nevado del Ruiz and other volcanoes in the Ruizâ€“Tolima massif. Melting just 10 percent of the ice would produce lahars with a volume of up to 200 million cubic metres (7.1 billion cubic feet) â€“ similar to the lahar that destroyed Armero in 1985. In just hours, these lahars can travel up to 100 km (62 mi) along river valleys.Estimates show that up to 500,000 people living in the Combeima, Chinchina, Coello-Toche, and Guali valleys are at risk, with 100,000 individuals being considered to be at high risk. Lahars pose a threat to the nearby towns of Honda, Mariquita, Ambalema, Chinchina, Herveo, Villa Hermosa, Salgar and La Dorada. Although small eruptions are more likely, the two-million-year eruptive history of the Ruizâ€“Tolima massif includes numerous large eruptions, indicating that the threat of a large eruption cannot be ignored. A large eruption would have more widespread effects, including the potential closure of BogotÃ¡'s airport due to ashfall.As the Armero tragedy was exacerbated by the lack of early warnings, unwise land use, and the unpreparedness of nearby communities, the government of Colombia created a special program, the Oficina Nacional para la AtenciÃ³n de Desastres (National Office for Disaster Preparedness), now known as the DirecciÃ³n de PrevenciÃ³n y AtenciÃ³n de Desastres (Directorate for Disaster Prevention and Preparedness) â€“ to prevent such incidents in the future.
All Colombian cities were directed to promote prevention planning to mitigate the consequences of natural disasters, and evacuations due to volcanic hazards have been carried out. About 2,300 people living along five nearby rivers were evacuated when Nevado del Ruiz erupted again in 1989. When another Colombian volcano, Nevado del Huila, erupted in April 2008, thousands of people were evacuated because volcanologists worried that the eruption could be another "Nevado del Ruiz".The lessons from the Armero tragedy have inspired a lahar warning system for Mt. Rainier, which has a similar potential for lahars.Armero was never rebuilt after the tragedy. Instead, the survivors were relocated to the towns of Guayabal and LÃ©rida, rendering Armero a ghost town.
A little less than one year later, Pope John Paul II flew over Armero and then visited LÃ©rida's refugee camps with Colombian President Belisario Betancur. He spoke about the disaster and declared the site of Armero "holy land". Although many victims of the disaster were commemorated, Omayra SÃ¡nchez in particular was immortalized by poems, novels, and music pieces. One work (Adios, Omayra) by Eduardo Santa illustrated the girl's last days of life and her symbolism of the catastrophe. Survivors were also recognized in GermÃ¡n Santa MarÃ­a BarragÃ¡n's dramatized television special titled "No MorirÃ¡s" (You Will Not Die). Much of the cast was composed of victims of the tragedy who appeared at the cast calls to be extras.
At the end of 2015, it was announced that Armero, a film about the tragedy, would be released sometime in 2016. Directed by Christian Mantilla, the movie tells the story of the events that took place in November 1985. The movie was released on September 21, 2017.
Vargas tragedy â€“ a similarly catastrophic debris flow event caused by torrential rains in Venezuela in 1999
Desjarlais, Robert & Eisenberg, Leon (1996). World Mental Health: Problems and Priorities in Low-Income Countries. Oxford University Press US. ISBN 978-0-19-509540-1.
MartÃ­, Joan & Ernst, Gerald (2005). Volcanoes and the Environment. Cambridge University Press. ISBN 978-0-521-59254-3.
Mileti, Dennis S., Bolton, Patricia A., Fernandez, Gabriel, and Updike, Randall G. (1991). The Eruption of Nevado Del Ruiz Volcano Colombia, South America, November 13, 1985. Washington, D.C.: Commission on Engineering and Technical Systems (National Academy Press). ISBN 978-0-309-04477-6.CS1 maint: Uses authors parameter (link)
Villegas, Henry (September 2003). "Display of the Nevado del Ruiz Volcanic Hazard Map Using GIS" (PDF). Geocarto International. Geocarto International Centre. 18 (3): 5â€“13. doi:10.1080/10106040308542276. Retrieved July 20, 2010.
Video about emergency response to the tragedy (15 minutes), Pan American Health Organization (hosted on YouTube)
(in Spanish) Text of the prayer made by Pope John Paul II in July 1986 at the memorial for the victims (Vatican website)

Armillaria gallica (synonymous with A. bulbosa and A. lutea) is a species of honey mushroom in the family Physalacriaceae of the order Agaricales. The species is a common and ecologically important wood-decay fungus that can live as a saprobe, or as an opportunistic parasite in weakened tree hosts to cause root or butt rot. It is found in temperate regions of Asia, North America, and Europe. The species forms fruit bodies singly or in groups in soil or rotting wood. The fungus has been inadvertently introduced to South Africa. Armillaria gallica has had a confusing taxonomy, due in part to historical difficulties encountered in distinguishing between similar Armillaria species. The fungus received international attention in the early 1990s when an individual colony living in a Michigan forest was reported to cover an area of 15 hectares (37 acres), weigh at least 9,500 kilograms (21,000 lb), and be 1,500 years old. This individual is popularly known as the "humungous fungus", and is a tourist attraction and inspiration for an annual mushroom-themed festival in Crystal Falls. Recent studies have revised the fungus's age to 2,500 years and its size to about 440 tons, four times the original estimate.Armillaria gallica is a largely subterranean fungus, and it produces fruit bodies that are up to about 10 cm (3.9 in) in diameter, yellow-brown, and covered with small scales. On the underside of the caps are gills that are white to creamy or pale orange. The stem may be up to 10 cm (3.9 in) long, with a white cobwebby ring that divides the color of the stem into pale orange to brown above, and lighter-colored below. The fungus can develop an extensive system of underground root-like structures, called rhizomorphs, that help it to efficiently decompose dead wood in temperate broadleaf and mixed forests. It has been the subject of considerable scientific research due to its importance as a plant pathogen, its ability to bioluminesce, its unusual life cycle, and its ability to form large and long-lived colonies.
Confusion has surrounded the nomenclature and taxonomy of the species now known as Armillaria gallica, paralleling that surrounding the genus Armillaria. The type species, Armillaria mellea, was until the 1970s believed to be a pleiomorphic species with a wide distribution, variable pathogenicity, and one of the broadest host ranges known for the fungi. In 1973, Veikko Hintikka reported a technique to distinguish between Armillaria species by growing them together as single spore isolates on petri dishes and observing changes in the morphology of the cultures. Using a similar technique, Kari Korhonen showed in 1978 that the European Armillaria mellea species complex could be separated into five reproductively isolated species, which he named "European Biological Species" (EBS) A through E. About the same time, the North American A. mellea was shown to be ten different species (North American Biological Species, or NABS I through X); NABS VII was demonstrated shortly after to be the same species as EBS E. Because several research groups had worked with this widely distributed species, it was assigned several different names.
The species that Korhonen called EBS B was named A. bulbosa by Helga MarxmÃ¼ller in 1982, as it was thought to be equivalent to Armillaria mellea var. bulbosa, first described by Jean Baptiste Barla (Joseph Barla) in 1887, and later raised to species status by Josef VelenovskÃ½ in 1927. In 1973, the French mycologist Henri Romagnesi, unaware of VelenovskÃ½'s publication, published a description of the species he called Armillariella bulbosa, based on specimens he had found near CompiÃ¨gne and Saint-Sauveur-le-Vicomte in France. These specimens were later demonstrated to be the same species as the EBS E of Korhonen; EBS B was later determined to be A. cepistipes. Therefore, the name A. bulbosa was a misapplied name for EBS E. In 1987 Romagnesi and MarxmÃ¼ller renamed EBS E to Armillaria gallica. Another synonym, A. lutea, had originally been described by Claude Casimir Gillet in 1874, and proposed as a name for EBS E. Although the name had priority due to its early publication date, it was rejected as a nomen ambiguum because of a lack of supporting evidence to identify the fungus, including a specimen, type locality, and incomplete collection notes. A. inflata (VelenovskÃ½, 1920) may represent another synonym, but the type specimens were not preserved, so it is considered a dubious name (nomen dubium). As of 2010, both the Index Fungorum and MycoBank consider Armillaria gallica Marxm. & Romagn. to be the current name, with A. bulbosa and A. lutea as synonyms.Phylogenetic analysis of North American Armillaria species based on analysis of amplified fragment length polymorphism data suggests that A. gallica is most closely related to A. sinapina, A. cepistipes, and A. calvescens. These results are similar to those reported in 1992 that compared sequences of nuclear ribosomal DNA.The specific epithet gallica is botanical Latin for "French" (from Gallia, "Gaul"), and refers to the type locality. The prior name bulbosa is Latin for "bulb-bearing, bulbous" (from bulbus and the suffix -osa). Armillaria is derived from the Latin armilla, or "bracelet".
The fruit bodies of Armillaria gallica have caps that are 2.5â€“9.5 cm (1.0â€“3.7 in) broad, and depending on their age, may range in shape from conical to convex to flattened. The caps are brownish-yellow to brown when moist, often with a darker-colored center; the color tends to fade upon drying. The cap surface is covered with slender fibers (same color as the cap) that are erect, or sloping upwards.
When the fruit bodies are young, the underside of the caps have a cottony layer of tissue stretching from the edge of the cap to the stemâ€”a partial veilâ€”which serves to protect the developing gills. As the cap grows in size the membrane is eventually pulled away from the cap to expose the gills. The gills have an adnate (squarely attached) to somewhat decurrent (extending down the length of the stem) attachment to the stem. They are initially white, but age to a creamy or pale orange covered with rust-colored spots. The stem is 4â€“10 cm (1.6â€“3.9 in) long and 0.6â€“1.8 cm (0.24â€“0.71 in) thick, and almost club-shaped with the base up to 1.3â€“2.7 cm (0.5â€“1.1 in) thick. Above the level of the ring, the stem is pale orange to brown, while below it is whitish or pale pink, becoming grayish-brown at the base. The ring is positioned about 0.4â€“0.9 cm (0.16â€“0.35 in) below the level of the cap, and may be covered with yellowish to pale-brownish woolly cottony mycelia. The base of the stem is attached to rhizomorphs, black root-like structures 1â€“3 mm in diameter. While the primary function of the below-ground mycelia is to absorb nutrients from the soil, the rhizomorphs serve a more exploratory function, to locate new food bases.
When the spores are seen in deposit, such as with a spore print, they appear whitish. They have an ellipsoid or oblong shape, usually contain an oil droplet, and have dimensions of 7â€“8.5 by 5â€“6 Âµm. The spore-bearing cells, the basidia, are club-shaped, four-spored (rarely two-spored), and measure 32â€“43 by 7â€“8.7 Âµm. Other cells present in the fertile hymenium include the cheilocystidia (cystidia present on the edge of a gill), which are club-shaped, roughly cylindrical and 15â€“25 by 5.0â€“12 Âµm. Cystidia are also present on the stem (called caulocystidia), and are broadly club-shaped, measuring 20â€“55 by 11â€“23 Âµm. The cap cuticle is made of hyphae that are irregularly interwoven and project upward to form the scales seen on the surface. The hyphae that make up the surface scales typically measure 26â€“88 Âµm long by 11â€“27 Âµm thick and can be covered with a crust of pigment. Clamp connections are present in the hyphae of most tissues.
Like all Armillaria species, A. gallica is considered edible. Thorough cooking is usually recommended, as the raw mushroom tastes acrid when fresh or undercooked. One author advises to consume only a small portion initially, as some people may experience an upset stomach. The taste is described as "mild to bitter", and the odor "sweet", or reminiscent of camembert cheese.
Armillaria calvescens is rather similar in appearance, and can only be reliably distinguished from A. gallica by observing microscopic characteristics. A. calvescens has a more northern distribution, and in North America, is rarely found south of the Great Lakes. A. mellea has a thinner stem than A. gallica, but can be more definitively distinguished by the absence of clamps at the base of the basidia. Similarly, A. cepistipes and A. gallica are virtually identical in appearance (especially older fruit bodies), and are identified by differences in geographical distribution, host range, and microscopic characteristics. Molecular methods have been developed to discriminate between the two species by comparing DNA sequences in the gene coding translation elongation factor 1-alpha.
Armillaria gallica can produce cyclobutane-containing metabolites such as arnamiol, a natural product that is classified as a sesquiterpenoid aryl ester. Although the specific function of arnamiol is not definitively known, similar chemicals present in other Armillaria species are thought to play a role in inhibiting the growth of antagonistic bacteria or fungi, or in killing cells of the host plant prior to infection.
The mycelia (but not the fruit bodies) of Armillaria gallica are known to be bioluminescent. Experiments have shown that the intensity of the luminescence is enhanced when the mycelia are disturbed during growth or when they are exposed to fluorescent light. Bioluminescence is caused by the action of luciferases, enzymes that produce light by the oxidation of a luciferin (a pigment). The biological purpose of bioluminescence in fungi is not definitively known, although several hypotheses have been suggested: it may help attract insects to help with spore dispersal, it may be a by-product of other biochemical functions, or it may help deter heterotrophs that might consume the fungus.
Researchers reported finding Armillaria gallica in the Upper Peninsula of Michigan in the early 1990s, during an unrelated research project to study the possible biological effects of extremely low frequency radio stations, which were being investigated as a means to communicate with submerged submarines. In one particular forest stand, Armillaria-infected oak trees had been harvested, and their stumps were left to rot in the field. Later, when red pines were planted in the same location, the seedlings were killed by the fungus, identified as A. gallica (then known as A. bulbosa). Using molecular genetics, they determined that the underground mycelia of one individual fungal colony covered 15 ha (37 acres), weighing over 9,500 kilograms (21,000 lb), with an estimated age of 1,500 years. The analysis used restriction fragment length polymorphism (RFLP) and random amplification of polymorphic DNA (RAPD) to examine isolates collected from fruit bodies and rhizomorphs (underground aggregations of fungal cells that resemble plant roots) along 1-kilometer (0.6 mi) transects in the forest. The 15-hectare area yielded isolates that had identical mating type alleles and mitochondrial DNA restriction fragment patterns; this degree of genetic similarity indicated that the samples were all derived from a single genetic individual, or clone, that had reached its size through vegetative growth. In their conclusion, the authors noted: "This is the first report estimating the minimum size, mass, and age of an unambiguously defined fungal individual. Although the number of observations for plants and animals is much greater, members of the fungal kingdom should now be recognized as among the oldest and largest organisms on earth." After the Nature paper was published, major media outlets from around the world visited the site where the specimens were found; as a result of this publicity, the individual acquired the common name "humongous fungus". There was afterward some scholarly debate as to whether the fungus qualified to be considered in the same category as other large organisms such as the blue whale or the giant redwood.The fungus has since become a popular tourist attraction in Michigan, and has inspired a "Humongous Fungus Fest" held annually in August in Crystal Falls. The organism was the subject of a Late Show Top Ten List on Late Night with David Letterman, and an advertising campaign by the rental company U-Haul.
The life cycle of A. gallica includes two diploidizationâ€“haploidization events. The first of these is the usual process of cell fusion (forming a diploid) followed by meiosis during the formation of haploid basidiospores. The second event is more cryptic and occurs before fruit body formation. In most basidiomycetous fungi, the hyphae of compatible mating types will fuse to form a two-nucleate, or dikaryotic stage; this stage is not observed in Armillaria species, which have cells that are mostly monokaryotic and diploid. Genetic analyses suggest that the dikaryotic mycelia undergo an extra haploidization event prior to fruit body formation to create a genetic mosaic. These regular and repeating haploidization events result in increased genetic diversity, which helps the fungus to adapt to unfavorable changes in environmental conditions, such as drought.The growth rate of A. gallica rhizomorphs is between 0.3 and 0.6 m (1.0 and 2.0 ft) per year. Population genetic studies of the fungus conducted in the 1990s demonstrated that genetic individuals grow mitotically from a single point of origin to eventually occupy territories that may include many adjacent root systems over large areas (several hectares) of forest floor. Based on the low mutation rates observed in large, long-lived individuals, A. gallica appears to have an especially stable genome. It has also been hypothesized that genetic stability may result from self-renewing mycelial repositories of nuclei with stem cell-like properties.
Armillaria gallica can normally be found on the ground, but sometimes on stumps and logs. Mushrooms that appear to be terrestrial are attached to plant roots underneath the surface. It is widely distributed and has been collected in North America, Europe, and Asia (China, Iran, and Japan). The species has also been found in the Western Cape Province of South Africa, where it is thought to have been introduced from potted plants imported from Europe during the early colonization of Cape Town. In Scandinavia, it is absent in areas with very cold climates, like Finland or Norway, but it is found in southern Sweden. It is thought to be the most prevalent low altitude species of Armillaria in Great Britain and France. The upper limits of its altitude vary by region. In the French Massif Central, it is found up to 1,100 m (3,600 ft), while in Bavaria, which has a more continental climate, the upper limit of distribution reaches 600 m (2,000 ft). In Serbian forests, it is the most common Armillaria between elevations of 70 to 1,450 m (230 to 4,760 ft). Field studies suggest that A. gallica prefers sites that are low in organic matter and have high soil pHs.In North America, it is common east of the Rocky Mountains, but rare in the Pacific Northwest. In California, where it is widely distributed, the fungus is found in a variety of plant communities, including aspen, coastal oak woodland, Douglas Fir, Klamath mixed conifer, montane hardwood, montane hardwood-conifer, montane riparian, Redwood, Sierran mixed conifer, valley oak woodland, valley-foothill riparian, and White Fir. It was found to be the most common Armillaria species in hardwood and mixed oak forests in western Massachusetts.A Chinese study published in 2001 used the molecular biological technique restriction fragment length polymorphism to analyze the differences in DNA sequence between 23 A. gallica specimens collected from the Northern Hemisphere. The results suggest that based on the restriction fragment length polymorphism patterns observed, there are four global A. gallica subpopulations: the Chinese, European, North Americanâ€“Chinese, and North Americanâ€“European geographical lineages. A 2007 study on the northeastern and southwestern Chinese distribution of Armillaria, using fruit body and pure culture morphology, concluded that there are several unnamed species (Chinese biological species C, F, H, J and L) that are similar to the common A. gallica.
Armillaria gallica is a weaker pathogen than the related A. mellea or A. solidipes, and is considered a secondary parasiteâ€”typically initiating infection only after the host's defenses have been weakened by insect defoliation, drought, or infection by another fungus. Fungal infection can lead to root rot or butt rot. As the diseased trees die, the wood dries, increasing the chance of catching fire after being struck by lightning. The resulting forest fire may, in turn, kill the species that killed the trees. Plants that are under water stress caused by dry soils or waterlogging are more susceptible to infection by A. gallica. It has been shown to be one of several Armillaria species responsible for widespread mortality of oak trees in the Arkansas Ozarks. The fungus has also been shown to infect Daylily in South Carolina, Northern highbush blueberry (Vaccinium corymbosum) in Italy and vineyards (Vitis species) of RÃ­as Baixas in northwestern Spain. The latter infestation "may be related to the fact that the vineyards from which they were isolated were located on cleared forestry sites". When A. solidipes and A. gallica co-occur in the same forest, infection of root systems by A. gallica may reduce damage or prevent infection from A. solidipes.
Armillaria gallica can develop an extensive subterranean system of rhizomorphs, which helps it to compete with other fungi for resources or to attack trees weakened by other fungi. A field study in an ancient broadleaved woodland in England showed that of five Armillaria species present in the woods, A. gallica was consistently the first to colonize tree stumps that had been coppiced the previous year. Fractal geometry has been used to model the branching patterns of the hyphae of various Armillaria species. Compared to a strongly pathogenic species like A. solidipes, A. gallica has a relatively sparse branching pattern that is thought to be "consistent with a foraging strategy in which acceptable food bases may be encountered at any distance, and which favours broad and divisive distribution of potential inoculum." Because the rhizomorphs form regular networks, mathematical concepts of graph theory have been employed to describe fungal growth and interpret ecological strategies, suggesting that the specific patterns of network attachments allow the fungus "to respond opportunistically to spatially and temporally changing environments".Armillaria gallica may itself be parasitized by other soil flora. Several species of the fungus Trichoderma, including Trichoderma polysporum, T. harzianum and T. viride, are able to attack and penetrate the outer tissue of A. gallica rhizomorphs and parasitize the internal hyphae. The infected rhizomorphs become devoid of living hyphae about one week after the initial infection. Entoloma abortivum is another fungus that can live parasitically upon A. gallica. The whitish-gray malformed fruit bodies that may result are due to the E. abortivum hyphae penetrating the mushroom and disrupting its normal development.

Armillaria luteobubalina, commonly known as the Australian honey fungus, is a species of mushroom in the family Physalacriaceae.  Widely distributed in southern Australia, the fungus is responsible for a disease known as Armillaria root rot, a primary cause of Eucalyptus tree death and forest dieback. It is the most pathogenic and widespread of the six Armillaria species found in Australia. The fungus has also been collected in Argentina and Chile. Fruit bodies have cream- to tan-coloured caps that grow up to 10 cm (4 in) in diameter and stems that measure up to 20 cm (8 in) long by 1.5 cm (1 in) thick. The fruit bodies, which appear at the base of infected trees and other woody plants in autumn (Marchâ€“April), are edible, but require cooking to remove the bitter taste. The fungus is dispersed through spores produced on gills on the underside of the caps, and also by growing vegetatively through the root systems of host trees. The ability of the fungus to spread vegetatively is facilitated by an aerating system that allows it to efficiently diffuse oxygen through rhizomorphsâ€”rootlike structures made of dense masses of hyphae.
Armillaria luteobubalina was first described in 1978, after having been discovered several years earlier growing in a Eucalyptus plantation in southeastern Australia. It distinguished itself from other known Australian Armillaria species by its aggressive pathogenicity. It may take years for infected trees to show signs of disease, leading to an underestimation of disease prevalence. Studies show that the spread of disease in eucalypt forests is associated with infected stumps left following logging operations. Although several methods have been suggested to control the spread of disease, they are largely economically or environmentally unfeasible. Phylogenetic analyses have determined that A. luteobubalina is closely related to A. montagnei and that both of these species are in turn closely related to the Brazilian species A. paulensis. The distribution of A. luteobubalina suggests that it is an ancient species that originated before the separation of the precursor supercontinent Gondwana.
Armillaria luteobubalina was first described in 1978 by mycologists Roy Watling and Glen Kile, who studied its effects on a fast-growing plantation of Eucalyptus regnans near Traralgon, Victoria. The plantation, established in 1963, consisted largely of trees with a mean height of about 25 m (80 ft). A cluster of dead and dying trees discovered in 1973 suggested attack by a virulent primary pathogen, that is, one capable of infecting a host before invasion by other, secondary pathogens. This finding was inconsistent with the pathogenic behaviour of the known Armillaria species in Australia at the time, A. mellea and A. elegans. Further study over the next few years showed that the fungus spread by the growth of underground mycelia in root systems, expanding outward from the initial infected stump at an average of 2.5 m (8.2 ft) per year. Most Australian records of Armillaria infections referred to A. mellea, based on the presence of black rhizomorphs. For over one hundred years, A. mellea was thought to be a pleiomorphic (occurring in various distinct forms) species with a widespread distribution and host range, and variable pathogenicity. which led to great confusion among taxonomists and plant pathologists alike. In 1973, Veikko Hintikka reported a technique to distinguish between Armillaria species by growing them together as single spore isolates on petri dishes and observing changes in the morphology of the cultures. Using similar techniques, mycologists eventually determined that the Armillaria mellea species complex in Europe and North America in fact consisted of five and ten distinct "biological species", respectively.Watling and Kile compared the macroscopic and microscopic characters of the pathogenic Armillaria with A. polymyces (now known as A. obscura), A. mellea, A. limonea and A. novae-zelandiae and found sufficient differences between them to warrant designating the species as new. Its specific epithet is derived from the Latin lutea "yellow", and was chosen to highlight an important distinguishing characteristic: the strong yellow colour of the cap and lack of reddish or brown tones in the stem typical of other resident Armillaria.A phylogenetic study of South American Armillaria species concluded that A. luteobubalina is in a lineage that includes A. montagnei, and these are sister to a lineage containing A. paulensis, a species known from a single specimen collected in SÃ£o Paulo, Brazil. Although they are very similar, specimens of A. luteobubalina have smaller spores than Argentinian specimens of A. montagnei, and their distinctness is well-supported with phylogenetic analysis. Based on analysis of pectic enzymes, A. luteobubalina is closely related to A. limonea, a species found in New Zealand; this result corroborates phylogenetic analyses reported in 2003 and 2006. Molecular analysis of 27 collections of A. luteobubalina from southwest Western Australia and one from Traralgon revealed four distinct polymorphic groups. The genetic variety suggests it is native to Australia.
Up to 10 cm (4 in) in diameter, the cap is convex to flattened in shape with a central umbo (a rounded elevation) and is various shades of cream, yellow and tan. The cap surface is covered with darker scales and feels rough to the touch. The cap edge, or margin, is rolled inward in young specimens. The crowded gills are sinuate and white to cream in colour initially, brownish-cream or pinkish brown in maturity, and sometimes with yellow or rust-coloured marks close to the margins. The stem is central (that is, it joins the cap in the centre) and is up to 20 cm (8 in) long by 1.5 cm (1 in) thick. It is slightly thicker at its base than its apex, sometimes almost bulb-like. The stem surface is streaked with fibrils that run up and down its length. It has a floppy yellow wool-like ring which may develop irregular, jagged edges with time. The flesh is white, and in the stem has a woolly or stringy consistency. Although it has a hot-bitter taste, Armillaria luteobubalina is edible, and cooking removes the bitterness.
The spore print is white when fresh, but becomes more cream-coloured when dry. The smooth spores are oval to ellipsoid, hyaline (translucent), non-amyloid (meaning they do not absorb iodine from Melzer's reagent), and typically measure 6.5â€“7.5 by 4.5â€“5.5 Î¼m. The basidia (spore-bearing cells) are thin-walled, hyaline, and lack clamp connections at their bases. They are usually four-spored but occasionally two-spored, with sterigmata (projections that attach to the spores) up to 4 Î¼m long. The cheilocystidia (cystidia that occur on the edge of a gill) are mostly club-shaped, thin-walled, hyaline, and measure 15â€“30 by 6â€“10 Î¼m.
Five other Armillaria species are found in Australia. Within the range of A. luteobubalina, A. hinnulea is restricted to gully habitats. A. fumosa is a rarer species found only in poorly drained or seasonally wet locations. A. luteobubalina and A. montagnei  share cap features and a similar unpleasant flavour, but the latter species has an olive-tinged cap, larger spores (9.5â€“11 by 5.5â€“7 Âµm compared to 6.5â€“7.5 by 4.5â€“5.5 Âµm) and a more conspicuous annulus than those found in A. luteobubalina. The morphology of the vegetative structures of A. limonea is distinctly different than A. luteobubalina, and can be used to distinguish the two species.  A. novae-zelandiae has a sticky more flattened cap and stem below the ring and is found in wet forests, and A. pallidula is a species with cream gills maturing to pale pink found in tropical Australia arising from dead tree stumps or the roots of dead or living trees. A. luteobubalina is the only Armillaria species which occurs in Western Australia. Distinguishing Australian species is economically important, because A. luteobubalina is more pathogenic than the other members of the genus. A molecular diagnostic test, developed in 2002, can accurately identify each species using DNA extracted from its mycelia. Before this, species identification was limited to times when fruit bodies were in season. This technology also revealed a variation in the molecular material of A. luteobubalina that suggested sexual reproduction.
Armillaria luteobubalina has been recorded in southeastern Australia, from the southeastern corner of Queensland through eastern New South Wales and across Victoria into southeastern South Australia. It also occurs in Tasmania and southwestern Western Australia. Those of the karri forests (consisting largely of the species E. diversicolor) of the southwest have paler and yellower caps than those in the jarrah forests (which contain predominantly Eucalyptus marginata) further north. The fruit bodies arise on wood, especially on stumps or around the base of trees, and often in huge numbers. They usually appear between April and July, although most production occurs in the second half of May. Abundant in woodlands, it can invade gardens and orchards, where it can attack many woody plants. The honey fungus infected and killed many plants near tuart trees (Eucalyptus gomphocephala) which had been cut down near Kings Park in suburban Perth. Armillaria luteobubalina is commonly found in eucalyptus forests in Australia, and is thought to be the most pathogenic and most widespread Armillaria species in the major western Australian forest types. The mushroom has also been reported from southern South America, in Argentina and Chile. A 2003 study of the molecular phylogenetics and pattern of its distribution in South America and Australia indicate that A. luteobubalina is an ancient species, originating before the separation of the precursor supercontinent Gondwana. Genetic differences between isolates in the South American and Australian populations indicate a long period of geographical separation, and the authors suggest that they "later might be regarded as independent taxa".
Trees that are infected by A. luteobubalina show characteristic symptoms both above and below ground. Above the ground, the base of the tree develops inverted V-shaped lesions, and the infected wood undergoes white rot, a fungal wood decay process where the cellulose and lignin of the sapwood are both broken down, leaving the wood stringy. The bark of the stem dies and becomes discoloured up to 3 m (10 ft) above the ground. Clusters of fruit bodies appear at the base of the tree in autumn. Crowns may show gradual deterioration, or tree death may occur suddenly. Below the ground, characteristic symptoms of infections include rotting the ends of tree roots, white-rotted sapwood, and the presence of fan-shaped areas of white mycelium below dead or infected bark.
In selectively logged eucalypt forests in the central highlands of Victoria, it has been estimated that about 3â€“5% of the forest area is "moderately to severely affected" by Armillaria root rot caused by A. luteobubalina. A review of eucalypt plantations planted in New South Wales from 1994 to 2005 found that infection by A. luteobubalina was rare, and only accounted for 1% of mortality in total. In this instance, the cases had been restricted to Eucalyptus nitens on the Dorrigo Plateau. Unlike other Armillaria species found in Australia's native forests, which require a host tree to become weakened by prior infection by a different species, A. luteobubalina is a primary pathogen, and can infect healthy trees. Tree roots may be infected for years before showing above-ground symptoms, making it difficult to accurately assess the true extent of disease in a forest stand. Surveys are usually conducted in autumn, to coincide with the appearance of fruit bodies; infection is assessed by the presence of basal scars on the trees, and the appearance of fruit bodies. Several factors, howeverâ€”such as cost, variable on-site conditions, and non-symptomatic diseased treesâ€”make it difficult for such surveys to reliably detect all infections. One study showed that above-ground examinations detected only 50% of the trees actually infected, leading to underestimation of the incidence of true infection by 20â€“40%. The study used more intensive surveying methods to determine that 25- to 30-year-old karri regrowth forests in western Australia showed an average of 40â€“45% incidence of infection.
Several studies have shown that the spread of Armillaria root rot in eucalypt forests is associated with infected stumps that remain after an area has been logged. Armillaria luteobubalina can persist on these stumps, using them as a source of food for up to 25 or more years. In one case reported in Ovens, Victoria, the disease was spread to blueberry plants (Vaccinium species) via buried fragments of infected Eucalyptus that remained following preparation of the previously forested site for planting. In individual forest stands, fungal infection is usually found in discrete disease patches separated by stands of healthy treesâ€”a discontinuous distribution. Large-scale aerial photography can be used to identify regions of forest infected by the species. The species also causes damage to trees and bushes in coastal dune woodlands, shrubland, and heath communities. It can be found on a wide range of hosts, but is most commonly associated with (in order of decreasing frequency) jarrah (Eucalyptus marginata), bull banksia (Banksia grandis), marri (E. calophylla), Lasiopetalum floribundum, and Acacia saligna. It has also infected scattered populations of wandoo (E. wandoo). The fungus has also been reported to infect Nothofagus species in Argentina, and Pinus radiata in Chile.Armillaria luteobubalina uses "an elaborate, sophisticated aeration system" that enables it to efficiently deliver oxygen into the rhizomorphs, helping it thrive in low-oxygen environments. When grown in culture, the mycelium develops into a continuous region of tissue with a perforated crust. This tissue is hydrophobic and resistant to becoming waterlogged. Rhizomorphs develop beneath clusters of so-called "air-pores" near the perforations. These gas spaces connect the atmosphere with the central canal of the rhizomorph, to facilitate diffusion of oxygen and satiate the organism's high oxygen requirement during growth. This aeration system is thought to be an important factor in the organism's pathogenicity, allowing it to grow on wet or waterlogged root surfaces and send hyphae or rhizomorphs into live roots or cut stumps, where conditions may be hypoxic. The rhizomorphs have a dichotomous branching pattern, so that they split or bifurcate at various intervals. Experiments and field observations have shown that this allows the fungus to be a more aggressive and virulent pathogen than Armillaria species whose rhizomorphs branch monopodially (where lateral branches grow from a main stem). Although the structure of A. luteobubalina rhizomorphs is specialised for spread in potentially anaerobic conditions, the soil mycelium is adaptive and can amplify the absorptive surface of peripheral hyphae in response to the presence of nutrient-rich soil.
Methods for controlling the spread of Armillaria root rot include physical removal of infected trees, stumps and large roots; fumigation of soil around infected hosts; and injection of fumigants directly into infected hosts. These methods are often not practical due to high cost, introduction of toxic chemicals that affect other organisms, or health and safety issues for the operator. Biological control is another method that has been investigated to control root rot caused by A. luteobubalina. In one study, thinning stumps of Eucalyptus diversicolor were simultaneously inoculated with A. luteobubalina and one of the saprobic wood decay fungi Coriolus versicolor, Stereum hirsutum and Xylaria hypoxylon; all three fungi significantly reduced infection by A. luteobubalinea. These results were echoed in another study of stumps in karri regrowth forests, where it was shown that the presence of other wood decay fungi suppressed the growth of A. luteobubalina on the stump base.

The Army of Sambre and Meuse (French: ArmÃ©e de Sambre-et-Meuse) was one of the armies of the French Revolution. It was formed on 29 June 1794 by combining the Army of the Ardennes, the left wing of the Army of the Moselle and the right wing of the Army of the North.  Its maximum paper strength was approximately 83,000.
After an inconclusive campaign in 1795, the French planned a co-ordinated offensive in 1796 using Jean-Baptiste Jourdan's Army of the Sambre et Meuse and the Army of the Rhine and Moselle commanded by his superior, Jean Victor Moreau. The first part of the operation called for Jourdan to cross the Rhine north of Mannheim and divert the Austrians while the Army of the Moselle crossed the southern Rhine at Kehl and Huningen. This was successful and, by July 1796, a series of victories forced the Austrians, commanded by Archduke Charles to retreat into the German states. By late July, most of the southern German states had been coerced into an armistice. The Army of Sambre and Meuse maneuvered around northern Bavaria and Franconia, and the Army of the Rhine and Moselle operated in Bavaria.
Internal disputes between Moreau and Jourdan and with Jourdan's subordinate commanders within the Army of the Sambre and Meuse prevented the two armies from uniting. This gave the Austrian commander time to reform his own forces, driving Jourdan to the northwest. By the end of September 1796, Charles had permanently separated the two French armies, forcing Jourdan's command further northwest and eventually across the Rhine. On 29 September 1797, the Army of Sambre and Meuse merged with the Army of the Rhine and Moselle to become the Army of Germany.
Initially, the rulers of Europe viewed the 1789 revolution in France as an internal matter between the French king and his subjects. In 1790, Leopold succeeded his brother Joseph as emperor of the Holy Roman Empire; by 1791, the danger to his sister, Marie Antoinette and her children,  alarmed him. In August 1791, in consultation with French Ã©migrÃ© nobles and Frederick William II of Prussia, Leopold's Declaration of Pillnitz articulated that the interests of the monarchs of Europe were as one with the interests of Louis and his family. He and his fellow monarchs threatened unspecified consequences if anything should happen to the royal family. French Ã©migrÃ©s continued to agitate for support of a counter-revolution, and on 20 April 1792 the French National Convention declared war on Austria. In this War of the First Coalition (1792â€“1798), France ranged itself against most of the European states sharing its land or water borders, plus Portugal and the Ottoman Empire.Although initially successful in the campaigns of 1792 and 1793, the French army lost some effectiveness during the Reign of Terror, during which its generals were intimidated or executed and many of the army's experienced officers left France for safer havens. Elements of the armies that were later formed into the Army of Sambre and Meuse participated in the conquest of the Netherlands and the Siege of Luxembourg. The various elements of the army won a victory at the Battle of Fleurus on 16 June 1794. The merging of the forces into the Army of Sambre and Meuse was made official soon afterwards. Shortly after Fleurus, the position of the First Coalition in Flanders collapsed and the French armies overran the Austrian Netherlands and the Dutch Republic in the winter of 1794â€“1795. French and Coalition military strategy subsequently focused on the Rhine river as the principle line of defense: for each side, control of the opposite bank or at least, the river's principal crossings, was the basis of defensive strategy.
The Rhine River flows west along the border between the German states and the Swiss Cantons. The 80 mi (130 km) stretch between Rheinfall, by Schaffhausen and Basel, is the High Rhine (Hochrhein); it cuts through steep hillsides over a gravel bed, and moves in torrents in such paces as the former rapids at Laufenburg. A few miles north and east of Basel, the terrain flattens. The Rhine makes a wide, northerly turn, in what is called the Rhine knee, and enters the so-called Rhine ditch (Rheingraben), part of a rift valley bordered by the Black Forest on the east and Vosges mountains on the west.The Rhine looked different in the 1790s than it does in the twenty-first century; the passage from Basel to Iffezheim was "corrected" (straightened) between 1817 and 1875. Construction of a canal to control the water level occurred from 1927 to 1974. In 1790, the river was wild and unpredictable, in some places more than four times wider than in the twenty-first century, even under normal conditions. Its channels wound through marsh and meadow and created islands of trees and vegetation that were periodically submerged by floods. Systems of viaducts and causeways made access reliable at Kehl, by Strasbourg, and at HÃ¼ningen, by Basel. In 1796, the plain on both sides of the river, some 19 mi (31 km) wide, was dotted with villages and farms. At the furthest edges of the flood plain, especially on the eastern side, the old mountains created dark shadows on the horizon. Tributaries cut through the hilly terrain of the Black Forest, creating deep defiles in the mountains, and became rivulets through the flood plain to the river.
The German-speaking states on the east bank of the Rhine were part of the vast complex of territories in central Europe called the Holy Roman Empire. The number of territories in the Empire included more than 1,000 entities. Their size and influence varied, from the Kleinstaaten (little states) that covered no more than a few square miles to large and powerful states. The states and territories involved in late 1796 included the Breisgau (Habsburg), Offenburg and Rottweil (imperial cities), the princely states of FÃ¼rstenberg, Neuenburg and Hohenzollern, the Margraviate of Baden, the Duchy of WÃ¼rttemberg, and several dozen ecclesiastic polities. Rule varied: they included free imperial cities of different sizes, such as the powerful Augsburg and the minuscule Weil der Stadt; ecclesiastical territories, also of varying sizes and influence, such as the wealthy Abbey of Reichenau and the powerful Archbishopric of Cologne; and such dynastic states as WÃ¼rttemberg. When viewed on a map, the Empire resembled a Flickenteppich (patchwork carpet).  Some states included non-contiguous pieces, the Habsburg domains and Hohenzollern Prussia also governed territories outside the Empire, such as the Habsburg territories in eastern Europe and northern Italy; for others, a village could belong predominantly to one polity but have a farmstead, a house or even one or two strips of land that belonged to another polity. There were also territories surrounded by France that belonged to WÃ¼rttemberg, such as the county of Solm, the archbishopric of Trier and Hesse-Darmstadt. Among the German-speaking states, the Holy Roman Empire's administrative and legal mechanisms provided a venue to resolve disputes between peasants and landlords, between and within jurisdictions. Through the organization of Imperial Circles (Reichskreise), groups of states consolidated resources and promoted regional and organizational interests, including economic cooperation and military protection.
By 1792 the armies of the French Republic were in a state of disruption; experienced soldiers of the Ancien RÃ©gime fought side by side with volunteers. Recruits, urged on by revolutionary fervor from the special representativesâ€”agents of the legislature, sent to ensure cooperation among the militaryâ€”lacked the discipline and training to function efficiently; frequently insubordinate, they often refused orders and undermined unit cohesion. After a defeat, they were capable of mutiny, as ThÃ©obald Dillon learned when his troops lynched him in 1792.The problems of command became more acute following the 1793 introduction of mass conscription (levÃ©e en masse). French commanders walked a fine line between the security of the frontier and the Parisian clamor for victory. Add to this the desperate condition of the Armyâ€”in training, supplies and leadershipâ€”and the military leadership faced a crisis. They were constantly under suspicion from the representatives of the new regime and sometimes from their own soldiers. Failure to achieve unrealistic expectations implied disloyalty and the price of disloyalty was an appointment with Madame guillotine:  several of the highest ranking generals, including the aged Nicolas Luckner, Jean Nicolas Houchard, Adam Philippe Custine, Arthur Dillon and Antoine Nicolas Collier, were killed. Francisco de Miranda's failure to take Maastricht landed him in La Force Prison for several years. Many of the old officer class had emigrated, forming Ã©migrÃ© armies; the cavalry in particular suffered from their departure and the Hussards du Saxe and the 15Ã©me Cavalerie (Royal Allemande) regiments defected en masse to the Austrians. The artillery arm, considered by the old nobility to be an inferior assignment, was less affected by emigration and survived intact.
Military planners in Paris understood that the upper Rhine Valley, the south-western German territories and Danube river basin held strategic importance for the defense of the Republic. The Rhine offered a formidable barrier to what the French perceived as Austrian aggression and the state that controlled its crossings controlled the river and access into the territories on either side. Ready access across the Rhine and along the Rhine bank between the German states and Switzerland or through the Black Forest, gave access to the upper Danube river valley. For the French, control of the Upper Danube or any point in between, was of immense strategic value and would give the French a reliable approach to Vienna.
The basic unit of the army, the demi-brigade, mixed the men of the old army with the recruits from the levee en masse.  Ideally, it was designed to include the regular infantry inherited from the old Royal regiments of the King, who were relatively well trained and equipped, dressed in white uniforms and wearing tarleton helmets, with the national guard units, who were less well-trained or equipped, with blue uniforms, and the  fÃ©dÃ©rÃ© volunteer battalions, who were poorly trained and equipped, with no uniform other than a red phrygian cap and a tricolour cockade. In 1794, the right flank of the Armies of the Center, later called the Army of the Moselle, the entirety of the Armies of the North and the Ardennes formed the Army of the Sambre and Meuse, on 29 June 1794.  The remaining units of the former Army of the Center and the Army of the Rhine united initially on 29 November 1794 and formally on 20 April 1795, under command of General Jean-Charles Pichegru as the Army of the Rhine and Moselle. These were the French armies involved in the successes at Fleurus and the Lowlands, but the strength of the units had been enhanced by untrained conscripts.Pressures exerted by the Coalition forces on the French front at the Rhine required the movement of the Army of Sambre and Meuse troops from the Fortress of Luxembourg, Belgium and the Netherlands into a unit on the middle Rhine. These units were reorganized into task forces that wcould engage the Austrian and Coalition forces directly in the Rhineland. Its paper strength equaled close to 83,000 men, although its actual strength was considerably less. By 1 October 1795, some of the troops had been assembled in five locations to form an advanced guard of 63,615, men commanded by the veteran General of Division FranÃ§ois Joseph Lefebvre.  General Louis Friant's division of 3,296 men remained at the Luxembourg fortress and General Antoine Morlot's division of 3,471 remained in Aachen.
Divisional position unnamedGenerals of Brigade Jean FranÃ§ois Leval, Jean-Baptiste Jacopin and Jean-Joseph Ange d'Hautpoul
General of Division Jacques Louis FranÃ§ois Delaistre de TillyGeneral of Brigade Bernard Ã‰tienne Marie Duvignau  and Jean Thomas Guillaume Lorge
General of Division Paul GrenierGenerals of Brigade Henri Simon, Jean-Baptiste OliviÃ©,  and Christophe Ossvald
General of Division AndrÃ© PoncetGenerals of Brigade Jean-Baptiste Schlachter and Jean-de-Dieu Soult
General of Division Jean Ã‰tienne ChampionnetGenerals of Brigade Claude Juste Alexandre Louis Legrand and Louis Klein
General of Division Louis-Auguste JuvÃ©nal des Ursins d'Harville6th, 8th, 10, and 13th Cavalry Regiments (four squadrons each)Total 1,593 men
General of Division FranÃ§ois SÃ©verin Marceau-DesgraviersGenerals of Brigade Gilbert Bandy de NalÃ¨che and Jean Hardy
General of Division Claude-Sylvestre ColaudGenerals of Brigade Louis Bastoul and Charles Jean Theodore Schoenmezel
In 1795 the French sent the Army of the Sambre and Meuse, also called the northern army, and the Army of the Rhine and Moselle, sometimes called the southern army, in thrusts across the Rhine. After winning a bridgehead on the east bank, the northern French army under Jourdan advanced south to the Main River. On 8 September 1795, Jourdan's northern army crossed the Rhine north of DÃ¼sseldorf. Besieging the Bavarian garrison in DÃ¼sseldorf, the rest of the Army of Sambre and Meuse swept south as far as the Lahn River, by 20 September. Hemmed in by Lefebvre and 12,600 French troops, Count Hompesch surrendered the Bavarian garrison at DÃ¼sseldorf on 21 September.Threatened by Jourdan's incursion, the Habsburg commander, FranÃ§ois SÃ©bastien Charles Joseph de Croix, Count of Clerfayt, shifted his army north to oppose him. This movement gave Pichegru the opportunity to move his army against the weakened rear guard of Clerfayt's force. Despite having a sizable garrison force, Baron von Belderbusch turned over Mannheim and its 471 guns to the Army of Rhine and Moselle after negotiations. The Austrians were furious at their ally but could do nothing to prevent the French from gaining this valuable bridgehead. Pichegru, the commander of the southern French army, proved uncooperative, which allowed Clerfayt to maneuver the bulk of the Austrian forces against Jourdan. Clerfayt crossed the Main to the east, gaining a dangerously exposed position on the French left flank. After being repulsed at HÃ¶chst, the French withdrew northwards, eventually abandoning the east bank of the Rhine.
The campaign of 1796 was part of the French Revolutionary Wars in which republican France pitted itself against a fluid coalition of Prussians and Austrians and several other states of the Holy Roman Empire, the British, Sardinians, Dutch and royalist French emigres.  The French had won several victories but the campaigns of 1793 through 1795 had been less successful. The Coalition partners had difficulty coordinating their war aims and their efforts faltered. In 1794 and 1795, French victories in northern Italy salvaged French enthusiasm for the war and forced the Coalition to withdraw further into Central Europe.  At the end of the Rhine Campaign of 1795, the Habsburg Austrian Coalition and the French Republicans called a truce between their forces that had been fighting in Germany. The agreement lasted until 20 May 1796, when the Austrians announced that the truce would end on 31 May.The Austrian Army of the Lower Rhine included 90,000 Habsburg and Imperial troops. The 20,000-man right wing, first under Duke Ferdinand Frederick Augustus of WÃ¼rttemberg, then later under Wilhelm von Wartensleben, stood on the east bank of the Rhine behind the Sieg River, observing the French bridgehead at DÃ¼sseldorf. The garrisons of Mainz Fortress and Ehrenbreitstein Fortress included 10,000 more. The remainder of the Imperial and Coalition army, the 80,000-strong Army of the Upper Rhine, secured the west bank behind the Nahe River. Commanded by Dagobert Sigmund von Wurmser, this force anchored its right wing in Kaiserslautern on the west bank, while the left wing under Anton SztÃ¡ray, Michael von FrÃ¶hlich and Louis Joseph, Prince of CondÃ© guarded the Rhine from Mannheim to Switzerland. The original Austrian strategy was to capture Trier and to use their position on the west bank to strike at each of the French armies in turn. After news arrived in Vienna of Napoleon Bonaparte's successes in northern Italy, Wurmser was sent to there with 25,000 reinforcements and the Aulic Council gave Archduke Charles command over both Austrian armies in the Rhineland and ordered him to hold his ground.Two French armies opposed the Imperial and Coalition troops. Jean Victor Moreau's commanded both armies, but the northern army, Sambre and Moselle, was large enough for a sub command: Jourdan. The 80,000-man Army of Sambre and Meuse held the west bank of the Rhine down to the Nahe and then southwest to Sankt Wendel. On the army's left flank, Jean Baptiste KlÃ©ber had 22,000 troops in an entrenched camp at DÃ¼sseldorf. The Army of the Rhine and Moselle, directly commanded by Moreau, was positioned behind (west of) the Rhine from HÃ¼ningen, where Pierre Marie BarthÃ©lemy Ferino commanded the furthest right wing, northward, along the Queich River near Landau, and with its left wing extended west toward SaarbrÃ¼cken. The far right wing under.The French plan called for a spring (Aprilâ€“Mayâ€“June) offensive, during which two French armies would press against the flanks of the Coalition's northern armies in the German states and a third army approached Vienna through Italy. Jean-Baptiste Jourdan's army would push south from DÃ¼sseldorf, hopefully drawing troops toward themselves, while Moreau's army massed on the east side of the Rhine by Mannheim; a deft feint toward Mannheim caused Charles to reposition his troops. Once this occurred, Moreau's army executed a forced march south and, on 23 June, overwhelmed the bridgehead at Kehl. The Imperial troops there included only 7,000 troops recruited that spring from the Swabian Circle polities; despite their lack of experience and training, they held the bridgehead for several hours before retreating toward Rastatt. Moreau reinforced the bridgehead with his forward guard and his troops poured into Baden unhindered. In the south, by the Swiss city of Basel, Ferino's column moved quickly across the river and advanced (eastward) up the Rhine along the Swiss and German shoreline toward Lake Constance, spreading into the southern end of the Black Forest. Worried that his supply lines would be overextended or his army would be flanked, Charles retreated to the east. By the end of July, the entirety of the Swabian Circle, most of Bavaria, Franconia, Baden and Wuerttemberg had reached a separate peace with the French. which disarmed the Imperial army, and gave French free rein to demand supplies from the southern polities.With Charles absent from the north, Jourdan recrossed the Rhine and drove Wartensleben behind the Lahn river. The Army of Sambre and Meuse defeated its opponents in the Battle of Friedberg (also called the First Battle of Limburg) on 10 July, while Charles was busy at Ettlingen. Jourdan captured Frankfurt am Main on 16 July. Leaving behind FranÃ§ois SÃ©verin Marceau-Desgraviers with 28,000 troops to blockade Mainz and Ehrenbreitstein, Jourdan pressed up the Main River. Following Carnot's strategy, the French commander continually operated against Wartensleben's north flank, causing the Austrian general to fall back. Jourdan's army numbered over 46,000 men, while Wartensleben counted 36,000 troops; Wartensleben refused to attack the larger French force. Buoyed up by their forward movement and by the capture of Austrian supplies, the French captured WÃ¼rzburg on 4 August. Three days later, the Army of Sambre and Meuse, under the temporary direction of KlÃ©ber, won another clash with Wartensleben at Forchheim on 7 August. Despite this success, though, the two French armies remained separated.
Archduke Charles saw that if he could unite with Wartenbsleben, he could pick off the French armies in succession. Having sufficient reinforcements and having transferred his supply line from Vienna to Bohemia, he moved north to unite with Wartensleben.  With 25,000 of his best troops, Charles crossed to the north bank of the Danube at Regensburg.  On 22 August 1796, Charles and Friedrich Joseph, Count of Nauendorf, encountered Bernadotte's division at Neumarkt. The outnumbered French were driven north west through Altdorf bei NÃ¼rnberg to the Pegnitz River. Leaving Friedrich Freiherr von Hotze with a division to pursue Bernadotte, the Archduke thrust north at Jourdan's right flank. The French fell back to Amberg as Charles and Wartensleben's forces converged on the Army of Sambre and Meuse. On 20 August, Moreau sent Jourdan a message vowing to closely follow Charles, which he did not do. In the Battle of Amberg on 24 August, Charles defeated the French and destroyed two battalions of their rear guard. The Austrians lost 400 killed and wounded out of 40,000 troops. Of a total of 34,000 soldiers, the French suffered greater losses of 1,200 killed and wounded plus 800 men and two colors captured. Jourdan retreated first to Sulzbach and then behind the Regnitz river where Bernadotte joined him on 28 August. Hotze and his Habsburg troops reoccupied NÃ¼rnberg and Jourdan, who had expected Moreau to keep Charles occupied in the south, found himself outnumbered.
As Jourdan fell back to Schweinfurt, he saw a chance to retrieve his campaign by offering battle at WÃ¼rzburg, an important stronghold on the Main River.  At this point, the petty jealousies and rivalries that had fostered in the Army over the summer came to a head. Jourdan had a spat with his wing commander KlÃ©ber and that officer suddenly resigned his command. Two generals from KlÃ©ber's clique, Bernadotte and Colaud, also made excuses to leave the army immediately. Faced with this mutiny, Jourdan replaced Bernadotte with General Henri Simon and divided Colaud's rebellious units among the other divisions. Jourdan marched south with 30,000 men of the infantry divisions of Simon, Jean Ã‰tienne Championnet, Paul Grenier and with Jacques Philippe Bonnaud's reserve cavalry. Lefebvre's division, 10,000-strong, remained at Schweinfurt to cover a possible retreat.Anticipating Jourdan's move, Charles had already rushed his army toward WÃ¼rzburg, where they engaged on 1 September. Marshaling the divisions of Hotze, SztÃ¡ray, Kray, Johann Sigismund Riesch, Johann I Joseph, Prince of Liechtenstein and Wartensleben, the Austrians won the Battle of WÃ¼rzburg on 3 September, forcing the French to retreat to the Lahn river. Charles lost 1,500 casualties out of 44,000 troops against 2,000 French casualties. The losses at WÃ¼rzburg compelled the French to lift the siege of Mainz on 7 September and to move those troops to reinforce their lines further east. On 10 September, Marceau reinforced the Army of Sambre and Meuse with 12,000 troops that had been blockading the east side of Mainz. Jean Hardy's division from the west side of Mainz retreated to the Nahe river and dug in. The French government belatedly recognized the difficulties in which the Army of the Sambre and Meuse struggled and transferred two divisions commanded by Jacques MacDonald and Jean Castelbert de Castelverd from the idle Army of the North. MacDonald's division stopped at DÃ¼sseldorf while Castelverd's was placed in the French line on the lower Lahn. These reinforcements brought Jourdan's strength back to 50,000 but the French abandonment of the sieges at Mainz and later Mannheim and Philippsburg, released about 27,000 Habsburg troops to reinforce Charles' now overwhelming numbers. Moreau continued in the south to press toward Vienna, seemingly oblivious to Jourdan's situation.Over the next few days, most of the Army of Sambre and Meuse returned to the west bank of the Rhine, except for a small rear guard. After his disastrous panic at Diez in which he prematurely abandoned a critical bridge position, Jean Castelbert de Castelverd held east bank entrenchments at Neuwied, Poncet crossed at Bonn while the other divisions retired behind the Sieg river. Jourdan handed over command to Pierre de Ruel, marquis de Beurnonville, on 22 September. Charles left 32,000 to 36,000 troops commanded by Franz von Werneck in the north, 9,000 more in Mainz and Mannheim to insure the Army did not recross the Rhine, and moved south with 16,000 men to intercept Moreau.
Archduke Charles ruined the French strategy in the north; the Army of Sambre and Meuse withdrew across the river and remained inactive for the rest of the year. On 18 April 1797, with Napoleon's army threatening Vienna, Austria and France agreed to terms of an armistice, which was followed by five months of negotiation, leading to the Peace of Campo Formio which concluded the War of the First Coalition on 18 October 1797. The peace treaty was to be followed up by the Congress of Rastatt. Campo Formio's terms held until 1798, when both groups recovered their military strength and began the War of the Second Coalition. Despite the renewal of military action, the Congress continued its meetings in Rastatt until the assassination of the French delegation in April 1799. The Army of Sambre and Meuse remained in cantonment until 29 September 1797, when it was united with other units, to form the Army of Germany.

Sir Arnold Edward Trevor Bax  (8 November 1883 â€“ 3 October 1953) was an English composer, poet, and author. His prolific output includes songs, choral music, chamber pieces, and solo piano works, but he is best known for his orchestral music. In addition to a series of symphonic poems he wrote seven symphonies and was for a time widely regarded as the leading British symphonist.
Bax was born in the London suburb of Streatham to a prosperous family. He was encouraged by his parents to pursue a career in music, and his private income enabled him to follow his own path as a composer without regard for fashion or orthodoxy. Consequently, he came to be regarded in musical circles as an important but isolated figure. While still a student at the Royal Academy of Music Bax became fascinated with Ireland and Celtic culture, which became a strong influence on his early development. In the years before the First World War he lived in Ireland and became a member of Dublin literary circles, writing fiction and verse under the pseudonym Dermot O'Byrne. Later, he developed an affinity with Nordic culture, which for a time superseded his Celtic influences in the years after the First World War.
Between 1910 and 1920 Bax wrote a large amount of music, including the symphonic poem Tintagel, his best-known work. During this period he formed a lifelong association with the pianist Harriet Cohen â€“ at first an affair, then a friendship, and always a close professional relationship. In the 1920s he began the series of seven symphonies which form the heart of his orchestral output. In 1942 Bax was appointed Master of the King's Music, but composed little in that capacity. In his last years he found his music regarded as old-fashioned, and after his death it was generally neglected. From the 1960s onwards, mainly through a growing number of commercial recordings,  his music was gradually rediscovered, although little of it is heard with any frequency in the concert hall. In more recent years, Bax's music has been (re-)discovered enthusiastically by a new generation via online distribution services such as YouTube.
Bax was born in the London suburb of Streatham, Surrey, to a prosperous Victorian family. He was the eldest son of Alfred Ridley Bax (1844â€“1918) and his wife, Charlotte Ellen, nÃ©e Lea (1860â€“1940). The couple's youngest son, Clifford Lea Bax, became a playwright and essayist. Alfred Bax was a barrister of the Middle Temple, but having a private income he did not practise. In 1896 the family moved to a mansion in Fellows Road, Hampstead. Bax later wrote that although it would have been good to be raised in the country, the large gardens of the family house were the next best thing. He was a musical child: "I cannot remember the long-lost day when I was unable to play the piano â€“ inaccurately".After a preparatory school in Balham, Bax attended the Hampstead Conservatoire during the 1890s. The establishment was run â€“ "with considerable personal pomp", according to Bax â€“ by Cecil Sharp, whose passion for English folk-song and folk-dance excited no response in his pupil. An enthusiasm for folk music was widespread among British composers of the late 19th and early 20th centuries, including Parry, Stanford, Vaughan Williams and Holst; Sullivan and Elgar stood aloof, as did Bax, who later put into general circulation the saying, "You should make a point of trying every experience once, excepting incest and folk-dancing."
In 1900 Bax moved on to the Royal Academy of Music, where he remained until 1905, studying composition with Frederick Corder and piano with Tobias Matthay. Corder was a devotee of the works of Wagner, whose music was Bax's principal inspiration in his early years. He later observed, "For a dozen years of my youth I wallowed in Wagner's music to the almost total exclusion â€“ until I became aware of Richard Strauss â€“ of any other". Bax also discovered and privately studied the works of Debussy, whose music, like that of Strauss, was frowned on by the largely conservative faculty of the Academy.Although Bax won a Macfarren Scholarship for composition and other important prizes, and was known for his exceptional ability to read complex modern scores on sight, he attracted less recognition than his contemporaries Benjamin Dale and York Bowen. His keyboard technique was formidable, but he had no desire for a career as a soloist. Unlike most of his contemporaries, he had private means that made him free to pursue his musical career as he chose, without the necessity of earning an income. The Times considered that Bax's independence and disinclination to heed his teachers ultimately damaged his art, because he did not develop the discipline to express his imagination to the greatest effect.After leaving the Academy Bax visited Dresden, where he saw the original production of Strauss's Salome, and first heard the music of Mahler, which he found "eccentric, long-winded, muddle-headed, and yet always interesting". Among the influences on the young Bax was the Irish poet W. B. Yeats; Bax's brother Clifford introduced him to Yeats's poetry and to Ireland. Influenced by Yeats's The Wanderings of Oisin, Bax visited the west coast of Ireland in 1902, and found that "in a moment the Celt within me stood revealed". His first composition to be performed â€“ at an Academy concert in 1902 â€“ was an Irish dialect song called "The Grand Match".
Musically, Bax veered away from the influence of Wagner and Strauss, and deliberately adopted what he conceived of as a Celtic idiom. In 1908 he began a trilogy of tone poems called Eire (I. Into the Twilight / II. In the FaÃ«ry Hills / III. Roscatha), described by his biographer Lewis Foreman as the beginning of the composer's truly mature style. The first of these pieces, Into the Twilight, was premiered by Thomas Beecham and the New Symphony Orchestra in April 1909, and the following year, at Elgar's instigation, Henry Wood commissioned the second in the cycle, In the FaÃ«ry Hills.  The work received mixed notices. The Manchester Guardian's reviewer wrote, "Mr Bax has happily suggested the appropriate atmosphere of mystery"; The Observer found the piece "very undeterminate and unsatisfying, but not difficult to follow". The Times commented on the "rather second-hand language" at some points, derivative of Wagner and Debussy, although "there is still a great deal which is wholly individual". The Musical Times praised "a mystic glamour that could not fail to be felt by the listener" although the coherence of the piece "was not instantly discernible". A third work in the cycle, Roscatha, was not performed in the composer's lifetime.Bax's private means enabled him to travel to the Russian Empire in 1910. He was in pursuit of Natalia Skarginska, a young Ukrainian whom he had met in London â€“ one of several women with whom he fell in love over the years. The visit eventually proved a failure from the romantic point of view but musically enriched him. In Saint Petersburg he discovered and immediately loved ballet; he absorbed Russian musical influences that inspired material for the First Piano Sonata, the piano pieces, "May Night in the Ukraine" and "Gopak", and the First Violin Sonata, dedicated to Skarginska. Foreman describes him in this period as "a musical magpie, celebrating his latest discoveries in new compositions"; Foreman adds that Bax's own musical personality was strong enough for him to assimilate his influences and make them into his own. Russian music continued to influence him until the First World War. An unfinished ballet Tamara, "a little-Russian fairy tale in action and dance", provided material the composer reused in post-war works.Having given up his pursuit of Skarginska, Bax returned to England; in January 1911 he married the pianist Elsita Luisa Sobrino (b. 1885 or 1886), daughter of the teacher and pianist, Carlos Sobrino, and his wife, Luise, nÃ©e Schmitz, a singer. Bax and his wife lived first in Chester Terrace, Regent's Park, London, and then moved to Ireland, taking a house in Rathgar, a well-to-do suburb of Dublin. They had two children, Dermot (1912â€“1976) and Maeve Astrid (1913â€“1987).  Bax became known in Dublin literary circles under the pseudonym "Dermot O'Byrne"; he mixed with the writer George William Russell and his associates, and published stories, verses and a play. Reviewing a selection of the prose and poetry reissued in 1980, Stephen Banfield found most of Bax's earlier poems "like his early music, over-written, cluttered with the secondhand lumber of early Yeats, though the weakness is one of loosely chosen language rather than complexity." Banfield had better things to say of the later poems, where Bax "focuses matters, whether laconically and colloquially upon the grim futility of the 1916 Easter rising ... or pungently upon his recurrent disillusionment about love."  Some of Bax's writings as O'Byrne were regarded as subversively sympathetic to the Irish republican cause, and the government censor prohibited their publication.
At the beginning of the war Bax returned to England. A heart complaint, from which he suffered intermittently throughout his life, made him unfit for military service; he acted as a special constable for a period. At a time when fellow composers including Vaughan Williams, Arthur Bliss, George Butterworth and Ivor Gurney were serving overseas, Bax was able to produce a large body of music, finding, in Foreman's phrase, "his technical and artistic maturity" in his early thirties.  Among his better-known works from the period are the orchestral tone poems November Woods (1916) and  Tintagel (1917â€“19).
During his time in Dublin Bax had made many republican friends. The Easter rising in April 1916 and the subsequent execution of the ringleaders shocked him deeply. He expressed his feelings in some of his music such as the orchestral In Memoriam and the "Elegiac Trio" for flute, viola, and harp (1916), as well as in his poetry.In addition to his Irish influences, Bax also drew on a Nordic tradition, being inspired by the Norwegian poet BjÃ¸rnstjerne BjÃ¸rnson and Icelandic sagas. Bax's Symphonic Variations for Piano and Orchestra (1917) is seen by the musicologist Julian Herbage as the turning-point from the Celtic to the Nordic in Bax's oeuvre; Herbage views it as a further indication of the shift that Winter Legends, composed thirteen years later, has a Nordic rather than a Celtic setting.During the war Bax began an affair with the pianist Harriet Cohen, for whom he left his wife and children. Musically, she was his muse for the rest of his life; he wrote numerous pieces for her, and she was the dedicatee of eighteen of his works.  He took a flat in Swiss Cottage, London, where he lived until the start of the Second World War. He sketched many of his mature works there, often taking them in short score to his favoured rural retreats, Glencolmcille in Ireland and then from 1928 onwards Morar in Scotland, to work on the full score at leisure.
In a study of Bax in 1919 his friend and confidante, the critic Edwin Evans, commented on the waning of the Celtic influence in the composer's music and the emergence of "a more austere, abstract art". From the 1920s onwards Bax seldom turned to poetic legend for inspiration. In Foreman's view, in the post-war years Bax was recognised for the first time as an important, though isolated, figure in British music. The many substantial works he wrote during the war years were heard in public, and he started writing symphonies. Few English composers had so far written symphonies that occupied a secure place in the repertoire, the best known being Elgar (Aâ™­ and Eâ™­ symphonies) and Vaughan Williams (Sea, London and Pastoral symphonies). During the 1920s and into the 1930s Bax was seen by many as the leading British symphonist.
Bax's First Symphony was written in 1921â€“22, and when first given it was a great success, despite its ferocity of tone. The critics found the work dark and severe. The Daily News commented, "It is full of arrogant, almost blatant, virility. Its prevailing tone colour is dark, very dark â€“ thick clouds with only here and there a ray of sunlight." The Daily Telegraph suggested that if there was any humour in the piece, it was sardonic. The Manchester Guardian noted the severity of the work, but declared it "a truly great English symphony". The work was a box-office attraction at the Proms for several years after the premiere. In Foreman's view, Bax was at his musical peak for a fairly short time, and his reputation was overtaken by those of Vaughan Williams and William Walton. The Third Symphony was completed in 1929 and, championed by Wood, remained for some time among the composer's most popular works.In the mid-1920s, while his affair with Cohen continued, Bax met the twenty-three-year-old Mary Gleaves, and for more than two decades he maintained relationships with both women. His affair with Cohen ripened into warm friendship and continuing musical partnership. Gleaves became his companion from the later 1920s until his death.In the 1930s, Bax composed the last four of his seven symphonies. Other works from the decade include the popular Overture to a Picaresque Comedy (1930), several works for chamber groups, including a nonet (1930), a string quintet (1933), an octet for horn, piano, and strings (1934) and his third and last string quartet (1936). The Cello Concerto (1932) was commissioned by and dedicated to Gaspar CassadÃ³, who quickly dropped the work from his repertoire. Although Beatrice Harrison championed the concerto in the 1930s and 1940s, Bax said, "The fact that nobody has ever taken up this work has been one of the major disappointments of my musical life".Bax was knighted in 1937; he had neither expected nor sought the honour, and was more surprised than delighted to receive it. As the decade progressed, he became less prolific; he commented that he wanted to "retire, like a grocer".  Among his compositions from the period was the Violin Concerto (1938). Although not written to commission, he had composed it with the violin virtuoso Jascha Heifetz in mind. Heifetz never played it, and it was premiered in 1942 by Eda Kersey with the BBC Symphony Orchestra and Wood.
After the death of the Master of the King's Music, Sir Walford Davies, in 1941, Bax was appointed to succeed him. The choice surprised many. Bax, despite his knighthood, was not an Establishment figure; he himself had expressed a disinclination to "shuffle around in knee-breeches". In the opinion of The Times the appointment was not a good one: "Bax was not cut out for official duties and found their performance irksome". Nonetheless, Bax wrote a handful of occasional pieces for royal events, including a march for the Coronation in 1953.
After the Second World War began, Bax moved to Sussex, taking up residence at the White Horse Hotel, Storrington, where he lived for the rest of his life. He abandoned composition and completed a book of memoirs about his early years, Farewell, My Youth. The Times found it at times waspish, at times reticent, surprising in parts, and regrettably short. Later in the war Bax was persuaded to contribute incidental music for a short film, Malta G. C.; he subsequently wrote music for David Lean's Oliver Twist (1948) and a second short film, Journey into History (1952). His other works from the period include the short Morning Song for piano and orchestra, and the Left-Hand Concertante (1949), both written for Cohen. Bax and the Poet Laureate, John Masefield, worked on a pageant, The Play of Saint George in 1947, but the project was not completed.In his last years, Bax maintained a contented retirement for much of the time. Walton commented, "an important cricket match at Lord's would bring him hurrying up to town from his pub at Storrington with much greater excitement than a performance of one of his works". In 1950, after hearing his Third Symphony played at Bournemouth, he said, "I ought perhaps to be thinking of an eighth", but by this time he had begun to drink quite heavily, which aged him rapidly and impaired his ability to concentrate on a large-scale composition.  He wrote in 1952, "I doubt whether I shall write anything else â€¦ I have said all I have to say and it is of no use to repeat myself." Celebrations were planned by the HallÃ© Orchestra and others to celebrate Bax's seventieth birthday in November 1953. The celebrations became memorials: while visiting Cork in October 1953 Bax died suddenly of heart failure. He was interred in St. Finbarr's Cemetery, Cork.
Bax's fellow composer Arthur Benjamin wrote that Bax was "a fount of music", whose "spontaneous and inexhaustible outpourings", unique among his contemporaries, were comparable to those of Schubert and DvoÅ™Ã¡k. Evans has suggested that Bax's music paradoxically combines robustness and wistfulness, a view that later commentators including Herbage have endorsed. The early music is often instrumentally difficult or orchestrally and harmonically complex; from about 1913 onwards he moved towards a simpler, sparer style. The composer and musicologist Anthony Payne considers that Bax's best works date from the period between 1910 and 1925: he instances The Garden of Fand, Tintagel, November Woods, the Second Piano Sonata, Viola Sonata, and first two symphonies. By the 1930s Bax's music ceased to be regarded as new and difficult, and towards the end of that decade it was attracting less attention than before.The conductor Vernon Handley, long associated with Bax's music, commented that the composer's influences include Rachmaninoff and Sibelius as well as Richard Strauss and Wagner: "He was aware of jazz and many more composers on the European scene than we are now. That finds its way into a person's psyche and personality and into his technique as a musician."The critic Neville Cardus wrote of Bax's music:
The paradox is that Bax's methods, his idiom and tonal atmosphere are impersonal: that is to say, there is no direct unfolding of an individual state of mind or soul as we find in Elgar or Gustav Mahler. Yet there is no mistaking the Bax physiognomy or psychology: always through the gloom and thickets of the symphonies the warm rays of an approachable, lovable man and nature may be felt.
York Bowen thought it regrettable that Bax's orchestral works frequently call for exceptionally large forces: "When the score demands such luxuries as triple or quadruple woodwind, six horns, three or four trumpets, extra percussion and perhaps organ, it is undoubtedly throwing extra difficulties in the way of performance." The composer Eric Coates commented that Bax's music appealed greatly to orchestral players: "whichever instrument he wrote for, it was as if he played that instrument himself, so well did he seem to write for it".
While in Dresden in 1907 Bax began work on what he later called "a colossal symphony which would have occupied quite an hour in performance, were such a cloud-cuckoo dream to become an actuality". He added "Happily, it never has!", but he left a complete piano sketch, which was orchestrated in 2012â€“13 by Martin Yates, and recorded for the Dutton Vocalion label; it lasts for 77 minutes. The four-movement work, more conventional in structure than his completed symphonies, shows a strong Russian influence in its material.Bax wrote his seven completed symphonies between 1921 and 1939. In a study of the seven, David Cox wrote in 1967 that they were "often dismissed as amorphous by those who imagine that Bax consists only of Celtic mistiness and 'atmosphere'. In fact they have considerable strength and frequent astringence; and formally the thematic material is presented with consistency and purpose." In Herbage's view, the cycle can be seen to fall into two groups â€“ the first three and the last three â€“ with the Fourth Symphony as "an extrovert interlude between these largely introspective works". Handley agreed that the first three could be grouped together; Foreman sees a Celtic influence in all three, with Bax's emotions about the Easter rising and its aftermath discernible. The Fourth is generally regarded as a more optimistic work than its predecessors and successors. Handley calls it "festive", but comments that its ideas developed into darker mood in the Fifth and Sixth. The Fifth is, for Herbage, "the greatest tour-de-force"; the Sixth stands out for its "magnificent final movement", which the critic Peter Pirie said "tears the earth up by its roots"; and the Seventh has an elegiac tone, its simplicity far removed from the discursive and complex music of Bax's earlier years.
Bax's first work for solo instrument and orchestra was the 50-minute Symphonic Variations in Eâ™­ (1919), written for Harriet Cohen. The Times considered it "like one of those deeds of recklessness which in the Army may be followed either by a Court-martial or a V.C. We incline to favour the Court-martial, and to award the V.C. to Miss Harriet Cohen for her part in the enterprise."The Cello Concerto (1932) was Bax's first attempt at a full-scale conventional concerto. It calls for a smaller orchestra than he customarily employed, with no trombones or tuba, and no percussion apart from timpani. Foreman points to many subtleties of scoring, but notes that it has never ranked high among the composer's mature works. The Violin Concerto (1937â€“38) is, like the last symphony, in a more relaxed vein than most of Bax's earlier music. Cardus singled it out as "unusually fine", although Heifetz may have felt it not virtuosic enough. The composer described it as in the romantic tradition of Joachim Raff.Among the minor concertante works is Variations on the Name Gabriel FaurÃ© (1949) for harp and strings, in a style more neoclassical than most of Bax's music.  Bax's last concertante piece was a short work for piano and orchestra (1947) written in his capacity as Master of the King's Music, marking Princess Elizabeth's twenty-first birthday.
Bax's tone poems are in a variety of styles and have varied sharply in their popularity. His impressionistic tone poem In the FaÃ«ry Hills is described by Grove as "a succinct and attractive piece". It was modestly successful, but Spring Fire (1913) is instanced by Foreman as a difficult work; it was not performed in Bax's lifetime. During the First World War Bax wrote three tone poems, two of which â€“ The Garden of Fand (1913â€“16) and November Woods (1917) â€“ have remained on the fringes of the modern repertoire, and a third â€“ Tintagel (1917â€“19) â€“ which in the decade after his death was the only work by which Bax was known to the public. Grove characterises all three as musical evocations of nature, with little expression of subjective personal response. The orchestral piece that was neglected longest was In memoriam (1917), a lament for Patrick Pearse, who was shot for his part in the Easter rising; the work was not played until 1998. Bax reused the main melody for his incidental music to Oliver Twist (1948).Oliver Twist was the second of Bax's film scores. The first was for a short wartime propaganda film, Malta, G. C.. A four-movement suite was published after the release of the latter,  containing what The Penguin Guide to Recorded Classical Music calls "a notable March with a genuine nobilmente theme in the best Elgarian tradition". Bax's third and last cinema score was for a ten-minute short film Journey into History in 1952.Other orchestral works include Overture, Elegy and Rondo (1927) â€“ a lightweight piece, according to Grove. The Overture to a Picaresque Comedy (1930), was for a time one of his most popular works. It was described by the composer as "Straussian pastiche" and by The Times as "gay and impudent, and with that tendency to vulgarity which so easily besets the instinctively refined composer determined to let himself go", Cardus thought the work so appealing that to live up to the overture the putative comedy would have to be "written by Hofmannsthal and Shaw in collaboration. Not often is English music so free and audacious as this, so gay and winning."
The critic Peter Latham remarked that he was surprised that Bax had never set any of Yeats's poems to music. Bax replied, "What, I? I should never dare!". Latham added that Bax's sensitiveness to poetic values made him "painfully aware of the violence that even the best musical setting must do to a poem". Eventually this feeling caused him to give up song-writing completely.
At the start of his composing career, songs, together with piano music, formed the core of Bax's work. Some of the songs, mainly the early ones, are conspicuous for the virtuosity of their piano parts, which tend to overwhelm the voice. Grove contrasts the virtuoso accompaniment of "The Fairies" (1905) with the simpler "The White Peace" (1907), one of his most popular songs. The musical analyst Trevor Hold writes that the piano "goes berserk" in "Glamour" (1920). Among the poets whose verses Bax set were his brother Clifford, Burns, Chaucer, Hardy, Housman, Joyce, Synge and Tennyson. The composer himself singled out for mention in his Who's Who article "A Celtic Song-Cycle" (1904) to words by "Fiona Macleod" (a pen name of the poet William Sharp). Among the post-war songs, Hold considers Bax's "In the Morning" (1926) to be one of the best of all settings of Housman's works, "and it makes you wish that Bax had made further explorations into the Shropshire landscape." Hold classes that song, together with "Across the Door" (1921), "Rann of Exile" (1922) and "Watching the Needleboats" (1932), as "truly modern, 20th-century masterpieces of song".Bax wrote a substantial number of choral works, mostly secular but some religious. He was a nominal member of the Church of England, but in the view of the critic Paul Spicer, "None of Bax's choral music can be described as devotional or even suitable for church use â€¦ Here is a secular composer writing voluptuous music." The choral works with religious texts include his largest-scale unaccompanied vocal piece, Mater ora Filium (1921), inspired by William Byrd's Five Part Mass; it is a setting of a medieval carol from a manuscript held by Balliol College, Oxford. The composer Patrick Hadley considered it "an unsurpassed example of modern unaccompanied vocal writing".  Bax's other choral works include settings of words by Shelley (Enchanted Summer, 1910), Henry Vaughan (The Morning Watch, 1935), Masefield (To Russia, 1944), and Spenser (Epithalamium, 1947).
In his overview of Bax's earlier chamber works, Evans identifies as among the most successful the Phantasy for viola, the Trio for piano, violin, and viola and "a String Quintet of such difficulty that an adequate performance has seldom if ever been possible". He rates the Second Violin Sonata (1915) as the composer's most individual work to that date. For Evans, the culminating point of Bax's early chamber music was the Piano Quintet, a work "of such richness of invention that it would be an ornament to the musical literature of any country or period".  Foreman makes particular mention of the First String Quartet (1918 â€“ "a classical clarity of texture and form to its Celtic inspiration", and the "grittier" Second Quartet (1925), the Viola Sonata (1922), the Phantasy Sonata for viola and harp (1927) and the Sonata for Flute and Harp (1928).The composer and musical scholar Christopher Palmer writes that Bax was unusual among British composers in composing a substantial oeuvre for solo piano. Bax published four piano sonatas (1910â€“32), which are, in Palmer's view, as central to the composer's piano music as the symphonies are to the orchestral output. The first two sonatas are each in a single movement, of about twenty minutes; the third and fourth are in conventional three-movement form. The First Symphony was originally planned as a large-scale piano sonata in Eâ™­ (1921); the manuscript score of the latter came to light in the early 1980s and was performed for the first time in 1983.        Bax's own virtuosity as a pianist is reflected in the demands of many of his piano pieces. Palmer cites Chopin and Liszt as major influences on Bax's piano style as well as Balakirev and the other Russians whose influence is seen throughout the composer's work. For piano duo Bax composed two tone poems, Moy Mell (1917) and Red Autumn (1931). His shorter piano pieces include picturesque miniatures such as In a Vodka Shop (1915), A Hill Tune (1920) and Water Music (1929).
In his later years Bax's music fell into neglect. Sir John Barbirolli wrote, "I think he felt keenly that his richly wrought and masterly scores were no longer 'fashionable' to-day, but nothing could deter him from the path of complete honesty and sincerity in his musical thought." The neglect became more complete after the composer's death. He had always sustained a Romantic outlook, distancing himself from musical modernism and especially Arnold Schoenberg's serialism, of which Bax wrote in 1951:
I believe that there is little probability that the twelve-note scale will ever produce anything more than morbid or entirely cerebral growths. It might deal successfully with neuroses of various kinds, but I cannot imagine it associated with any healthy and happy concept such as young love or the coming of spring.
Neither Bax's views nor his works were fashionable in the two decades after his death. The critic Michael Kennedy writes that the mid-1950s were a time of "immense change and transition in influential musical circles." The music favoured by the cultural establishment until then was regarded as having made Britain musically parochial and indifferent to the developments of the past half-century. In Kennedy's words, "Rubbra, Bax and Ireland found themselves out in the cold".Foreman comments that in the years after Bax's death his reputation was kept alive by a single work â€“ Tintagel. Kennedy estimates that it took "twenty painful years" before the music of the British romantics including Bax made headway against the dominance of modernism. Foreman dates the revival of Bax's music to Handley's performances of the Fourth Symphony and other works with the Guildford Philharmonic Orchestra in the 1960s, and the pioneering recordings by Lyrita Recorded Edition of five of the symphonies. Scholarly consideration of Bax's life and music came with studies by Colin Scott-Sutherland (1973) and Foreman (1983). Bax's centenary in 1983 was marked by twenty programmes on BBC Radio 3, covering a wide range of the composer's music. In 1985 the Sir Arnold Bax Trust was established to promote the composer's work including the sponsoring of live performances and recording and publication of his music and writings. Since then a large number of Bax's works, major and minor, have been recorded (see below). The proliferation of Bax recordings has not been matched by a revival in his fortunes in the concert hall; the critic Stephen Moss observed in The Guardian in 2007, "Bax is considered the promotional kiss of death." In 1999 the Oxford University Press published a complete catalogue of Bax's works compiled and annotated by Graham Parlett; Lionel Pike, writing in Music & Letters, called it "a benchmark for any future researchers seeking to compile a catalogue of a composer's works".
Two recordings of Bax as a pianist were made in 1929. With Lionel Tertis he recorded his own Viola Sonata for Columbia, and with May Harrison he recorded Delius's Violin Sonata No 1 for the rival HMV label. Of the symphonies, only the Third was recorded in the composer's lifetime; it was played by the HallÃ© under Barbirolli and released in 1944. The Viola Sonata, Nonet and Mater ora Filium were recorded under the auspices of the English Music Society in 1937 and 1938. The Phantasy Sonata for Viola and Harp, the Sonata for Two Pianos and a handful of the songs were recorded on 78 rpm discs. Of the tone poems, Eugene Goossens conducted the first recording of Tintagel, in 1928; twenty years later a set of The Garden of Fand with Beecham and the Royal Philharmonic Orchestra was released by HMV. By 1955 Bax on record was so scarce that The Record Guide listed only Tintagel, the Coronation March, the unaccompanied choral work What is it Like to be Young and Fair? and the solo piano piece Paean.Parlett included an extensive discography in his 1999 A Catalogue of the Works of Sir Arnold Bax, later expanded and updated in a website. At 2015 the latter lists more than 250 works by Bax that have been recorded and published. The discography includes three complete cycles of Bax's symphonies released on CD, two by Chandos Records, the first conducted by Bryden Thomson (recorded 1983â€“88) and the second by Handley (2003); between them was a cycle issued by Naxos Records conducted by David Lloyd-Jones (recorded 1997â€“2001). The major tone poems and other orchestral works have been recorded, many of them in several different versions. Bax's chamber music is well represented on disc, with recordings of most of the works, and multiple versions of many, including the Elegiac Trio, the Clarinet Sonata and the Fantasy Sonata. Much of the piano music has been recorded by pianists including Iris Loveridge, John McCabe, Ashley Wass and Michael Endres, though by 2015 no integral survey had yet been recorded. Of the vocal works, by far the most often recorded is Mater ora Filium, but other choral works, and a representative selection of the songs are on disc.
Bax received the gold medals of the Royal Philharmonic Society (1931) and the Worshipful Company of Musicians (1931), and the Cobbett Medal for chamber music (1931). He was awarded honorary doctorates by the universities of Oxford (1934) and Durham (1935) and the National University of Ireland (1947). A Bax Memorial Room at University College Cork, was opened by Vaughan Williams in 1955. He was knighted in the 1937 Coronation Honours and was advanced to KCVO in 1953. An English Heritage blue plaque, unveiled in 1993, commemorates Bax at his birthplace, 13 Pendennis Road in Streatham.In 1992 Ken Russell made a television film dramatising Bax's later years, The Secret Life of Arnold Bax. Russell himself portrayed Bax and Glenda Jackson appeared as Harriet Cohen.
