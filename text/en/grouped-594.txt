
The Smyth Report is the common name of an administrative history written by American physicist Henry DeWolf Smyth about the Manhattan Project, the Allied effort to develop atomic bombs during World War II. The full title of the report is A General Account of the Development of Methods of Using Atomic Energy for Military Purposes. It was released to the public on August 12, 1945, just days after the atomic bombings of Hiroshima and Nagasaki on August 6 and 9.
Smyth was commissioned to write the report by Major General Leslie R. Groves, Jr., the director of the Manhattan Project. The Smyth Report was the first official account of the development of the atomic bombs and the basic physical processes behind them. It also served as an indication as to what information was declassified; anything in the Smyth Report could be discussed openly. For this reason, the Smyth Report focused heavily on information, such as basic nuclear physics, which was either already widely known in the scientific community or easily deducible by a competent scientist, and omitted details about chemistry, metallurgy, and ordnance. This would ultimately give a false impression that the Manhattan Project was all about physics.
The Smyth Report sold almost 127,000 copies in its first eight printings, and was on The New York Times best-seller list from mid-October 1945 until late January 1946. It has been translated into over 40 languages.
Henry D. Smyth was a professor of physics and chairman of the physics department of Princeton University from 1935 to 1949. During World War II, he was involved in the Manhattan Project from early 1941, initially as a member of the National Defense Research Committee’s Committee on Uranium, and later as an associate director of the Metallurgical Laboratory in Chicago. In late 1943, the President of Princeton University, Harold W. Dodds, began insisting that Smyth work part-time at Princeton, where there was a shortage of physicists because so many of them were engaged in war work. Princeton had commitments to teach army and navy personnel, and he needed physicists like Smyth to meet those commitments. Smyth therefore became a consultant at Chicago, where he was in charge of designing a nuclear reactor that used heavy water as a neutron moderator, and commuted from Princeton, working in Chicago on alternate weeks.In early 1944, Smyth raised the possibility of producing an unclassified report for the general public on the achievements of the Manhattan Project. The director of the Metallurgical Laboratory, Arthur Compton, supported the idea. He arranged a meeting with James B. Conant, the President of Harvard University and one of the senior administrators of the Manhattan Project, who had similar thoughts. Conant took up the matter with the Manhattan Project's director, Major General Leslie R. Groves, Jr.. In April, Smyth received a formal letter from Groves asking him to write such a report. Both the report and the choice of Smyth as its author were approved by the Manhattan Project’s governing body, the Military Policy Committee, in May 1944.The Report was to serve two functions. First, it was to be the public and official U.S. government account of the development of the atomic bombs, outlining the development of the then-secret laboratories and production sites at Los Alamos, New Mexico, Oak Ridge, Tennessee, and Hanford, Washington, and the basic physical processes responsible for the functioning of nuclear weapons, in particular nuclear fission and the nuclear chain reaction. Second, it served as a reference for other scientists as to what information was declassified—anything said in the Smyth Report could be said freely in open literature. For this reason, the Smyth Report focused heavily on information already available in declassified literature, such as much of the basic nuclear physics used in weapons, which was either already widely known in the scientific community or could have been easily deduced by a competent scientist.Smyth stated the purpose of the Smyth Report in the Preface:
The ultimate responsibility for our nation's policy rests on its citizens and they can discharge such responsibilities wisely only if they are informed. The average citizen cannot be expected to understand clearly how an atomic bomb is constructed or how it works but there is in this country a substantial group of engineers and scientists who can understand such things and who can explain the potentialities of atomic bombs to their fellow citizens. The present report is written for this professional group and is a matter-of-fact, general account of work in the USA since 1939 aimed at the production of such bombs. It is neither a documented official history nor a technical treatise for experts. Secrecy requirements have affected both the detailed content and general emphasis so that many interesting developments have been omitted.
This contrasted somewhat with what Groves wrote in the foreword:All pertinent scientific information which can be released to the public at this time without violating the needs of national security is contained in this volume.  No requests for additional information should be made to private persons or organizations associated directly or indirectly with the project. Persons disclosing or securing additional information by any means whatsoever without authorization are subject to severe penalties under the Espionage Act.
Smyth possessed security clearances necessary to visit project sites, access documents and to discuss the work with the research personnel.  Groves approved Smyth's request to hire another Princeton physicist, Lincoln G. Smith, as a research assistant.  A letter to the Manhattan Project's senior managers, Kenneth Nichols, Robert Oppenheimer, Ernest Lawrence, Harold Urey, and Franklin Matthias, explained:The purpose is to give clearly and promptly recognition to those who have worked so long and necessarily so anonymously ... To accomplish his purpose, Dr. Smyth must have rather complete information concerning your phase of the project including access to necessary documents ... [and] information and advice from you and your principal assistants.
Since Smyth still had his commitments at Princeton and Chicago, he could only work on the report part-time. He wrote the report in his office in Princeton's Palmer Laboratory. Bars were installed on the windows of Smyth's office and the one adjacent to it. The hallway door to his office was locked and blocked by a large safe so that the only access was through the adjacent office, where there was an armed guard. The guards worked in eight-hour shifts, and one was present around the clock. When Smyth sent papers to Groves in Washington, D.C., they went by military courier.Smyth sent an outline and rough draft of the report to Groves for approval in August 1944, followed in February 1945 by drafts of the first twelve chapters, leaving only the final chapter to be completed. Groves and Conant reviewed the drafts, and made several criticisms. They felt that it was too technical for general readers, did not mention the names of enough participants, and dwelt too much on the activities at the Los Alamos Laboratory. Groves was particularly anxious that deserving people be mentioned, as he felt that this would lessen the danger of security breaches. After Smyth made a series of changes in response to this, Groves sent the manuscript to his scientific adviser, Richard Tolman. Tolman was assisted by two physicists who were working in his office at the National Defense Research Committee as technical aides, Paul C. Fine from the University of Texas, and William Shurcliff from Harvard University. They had the dual task of editing and censoring the manuscript.
Smyth and Tolman accepted a set of criteria, agreeing that information could be released under the conditions: I. (A) That it is important to a reasonable understanding of what had been done on the project as a whole or (B) That it is of true scientific interest and likely to be truly helpful to scientific workers in this country and
II. (A) That it is already generally known by competent scientists or (B) that it can be deduced or guessed by competent scientists from what is already known, combined with the knowledge that the project was in the overall successful or
III. (A) That it has no real bearing on the production of atomic bombs or (B) That it could be discovered by a small group (15 of whom not over 5 would be senior men) of competent scientists working in a well-equipped college lab in a year's time or less.
Writing to Oppenheimer in April 1945, Smyth noted that All discussion of ordnance work is also to be removed. There is no objection to including the general statement of the ordnance problem and all the other parts of the problem, but the approaches to solution that have been made will be omitted. On the other hand, the feeling is that there is no objection to including the nuclear physics. The General believes that the metallurgical work and a considerable amount of the chemistry work should be excluded on the ground that it would be extremely difficult for the average scientist to carry out any of this work without supplies and material which would not be available to him. I am not entirely clear how this criterion should be applied, but it probably means the elimination of the metallurgical work on plutonium and at least of some of the chemistry.
Tolman and his assistants finished making their changes in July 1945, and Groves had copies sent out by courier to selected personnel. Each submitted a written report, which was returned with the courier and the manuscript. These were busy people who sometimes only had a few days or even hours to look at the manuscript. Many, but not all, merely signed a statement saying that they were happy with it. Nichols, the commander of the Manhattan District, sent back a detailed review. He had concerns about the amount of credit being given to different people and organizations, and recommended that "full credit be given to H. D. Smyth for preparing it and that the statement be made that the Army has no responsibility for the report except for asking him to do it." Smyth was given credit, but no such statement was issued. To prepare the final draft for the printer, Groves brought typists with the required security clearances to Washington, D.C., from the Manhattan District's headquarters in Oak Ridge.Because the Manhattan Project was an Allied endeavor, Groves had to obtain permission from the British and American governments to publish the Smyth Report. A meeting was held on August 2, 1945 in the office of the Secretary of War, Henry Stimson. Accompanying Stimson were his two assistants, Harvey Bundy and George L. Harrison, and his military aide, Colonel William H. Kyle. Groves, Conant, and Tolman represented the Manhattan Project. James Chadwick, the head of the British scientific mission to the Manhattan Project, and Roger Makins from the British Embassy represented Britain. The meeting went on for two hours, as Groves and Conant sought to reassure Stimson that the report would not give vital secrets away to the Soviet Union.For his part, Chadwick, who had not yet read the manuscript, could not fathom why the Americans wanted to publish such a document. When he did read it, he became quite alarmed. His concerns were addressed in a meeting with Groves and Conant, and he accepted their point of view. "I am now convinced," he wrote, "that the very special circumstances arising from the nature of the project, and of its organization, demand special treatment, and a report of this kind may well be necessary to maintain security of the really essential facts of the project."
A thousand copies of the report were printed by lithography at the Pentagon, and deposited in Groves's office in the New War Department Building in Washington, DC, where they were kept securely locked away. Final approval was sought from the President, Harry S. Truman, in a meeting at the White House on August 9, 1945, three days after the bombing of Hiroshima. Stimson, Harrison, Groves, Conant, Vannevar Bush, and Fleet Admiral William D. Leahy presented their views, and Truman authorized the immediate release of the report. The War Department released the thousand copies of the report that had been kept in Groves's office to the media for use by the radio broadcasters with an embargo time of 9:00 pm on August 11, 1945, and for the newspapers of August 12.
The original title of the report, before it was published in book form, was Nuclear Bombs: A General Account of the Development of Methods of Using Nuclear Energy for Military Purposes Under the Auspices of the United States Government, 1940–1945. The word "nuclear" was changed to "atomic" because while the former was favoured by physicists, it was not in common use by the general public at that time. This was the title used on the copyright certificate. The book was copyrighted to Smyth but issued with the statement that "reproduction in whole or in part is authorized and permitted". Groves had the report copyrighted by Smyth in order to prevent someone else from copyrighting it.Groves was concerned about the security implications of the title, so instead of having "Atomic Bombs" on the cover, it was left blank, and a rubber stamp was made. The intention was for this to be used on each copy before it was distributed. This was done for the copyright deposit copies, but not those given to the press or the public. The lumbering subtitle therefore became the title. A side effect of this was that it became generally known as the "Smyth Report". Over the years, the term "nuclear" gradually gained traction, and by 1960 it had become more common than "atomic".In mid-1945, Smyth approached Datus C. Smith, the director of Princeton University Press, about the possibility of renting his printing plant to the government during a two-week summer shutdown so that Smyth could produce 5,000 copies of a top secret report. Smith’s response was that he found it hard to imagine anyone needing to print 5,000 copies of a top secret report. He found it much easier to imagine delays due to unexpected printing problems, and his workers returning from summer vacation to find themselves locked out of a plant filled with top secret material. Under the circumstances, he felt that he could not risk this.After the Smyth Report was officially released, Smith immediately offered to publish it. Smyth patiently explained that anyone was free to publish it, but Princeton University Press was only willing to do so on the understanding that this would be "Smyth's edition". Meanwhile, Smyth approached McGraw-Hill about publishing it. The editors at McGraw-Hill found the manuscript dull and somewhat technical for a general audience and suggested a rewrite. Smyth balked at this, as it would have meant going through the censorship process again. James S. Thompson, the president of McGraw-Hill, pointed out the U.S. Government Printing Office would be putting out an edition, probably more cheaply than he could, and there would likely be little profit in a McGraw-Hill edition. Smyth then turned back to Princeton University Press. He had only one condition: that he receive no royalties. Princeton University Press agreed, but added a stipulation of its own: that Groves's approval be secured. Smyth obtained this in a letter dated August 25, 1945.Princeton University Press received a copy of the typescript lithograph edition with hand corrections from Smyth on August 17, 1945. The typographers had already started work from another copy. Maple Press of York, Pennsylvania, was lined up to do the printing. Because of wartime shortages, one of a publisher’s biggest worries was finding adequate supplies of paper. Smith approached Manny and Leonard Relles from Central Paper, told them about the Smyth Report and its significance, and asked them if they could deliver 30 short tons (27 t) of paper to Maple Press in twelve days. They found a carload of paper on a siding in New England and sent it to York, providing enough paper for 30,000 copies, only half what Princeton University Press wanted.  The first edition of 30,000 copies was printing when word was received that paper had been found for another 30,000 copies. The presses were held for three hours while the train made its way to a siding in York, where the paper was unloaded and brought to the printing plant by trucks.There were minor differences between the original text and the version published by Princeton. In the Princeton publication, first and middle names were added instead of the previous use of abbreviations. In response to public concerns about radioactivity, Groves had text added to paragraph 12.18 explaining how the height of the explosions over Hiroshima and Nagasaki reduced fallout and allowed fission products to be drawn up into the upper atmosphere. He also had a one-sentence allusion to a poisoning effect of fission products in the production reactors redacted. This deletion was soon noticed by the Russian translators, and only served to highlight its importance to the Soviet atomic bomb project.Later editions also incorporated changes. Four typographical errors were found, and the word "photon" in paragraph 1.44 aroused so much correspondence from readers who mistakenly believed that it should be "proton" that it was decided to re-word the paragraph.  The British government became concerned that the Smyth report did not cover the British part in the project, and issued its own 40-page report, which was incorporated into the fifth printing in November 1945 as Appendix 7. A two-page report by the Canadian government was added as Appendix 8.The Smyth Report was translated into over 40 different languages. In addition to Princeton University Press, it was also published by the Government Printing Office, the Infantry Journal, and His Majesty's Stationery Office, and was reprinted in the October 1945 issue of Reviews of Modern Physics.
The first copies were delivered to bookstores on September 10. Many were wary of it, due to its technical nature, and feared that sales would be low. An exception was Scribner's Bookstores, which placed large early orders. At Oak Ridge, the Manhattan Project's major production site, 8,000 copies were sold through the employee welfare organization. Similar arrangements were made for Los Alamos and Richland, which were located in areas where bookstores were scarce.The Smyth Report was on The New York Times bestseller list from October 14, 1945, until January 20, 1946. Between 1946 and when the Smyth Report went out of print in 1973, it went through eight printings, and Princeton University Press sold 62,612 paperback and 64,129 hardback copies.Groves did not intend the Smyth Report to be the last word on the project. It formed an addendum to the Manhattan District History, the official history of the project. This eventually consisted of 35 volumes with 39 appendices or supplements. It was written in the immediate postwar years by the chemists, metallurgists, physicists, and administrators who had worked on the project. Since there were no security restrictions, it covered every aspect of the Manhattan Project, but was itself classified. Most of it was declassified in the 1960s and 1970s and became available to scholars, except for some technical details on the construction of the bombs.In her 2008 PhD dissertation, Rebecca Schwartz argued that Smyth's academic background and the Smyth Report's security-driven focus on physics at the expense of chemistry, metallurgy, and ordnance promoted a public perception of the Manhattan Project as primarily the achievement of physics and physicists. According to Schwartz, postwar histories and popular writing tended to follow the Smyth report in this regard, creating a lasting historiographical legacy. "Ever since", wrote Jon Agar, "the atomic bomb has been seen as an achievement of physics." In particular, the prominence given to Einstein's mass–energy equivalence equation indelibly associated it with the Manhattan Project. The Smyth Report, wrote Robert P. Crease, "more than any other single document made E = mc2 an emblem of atomic energy and weaponry."Groves felt that:
on the whole, and considering the rather difficult conditions under which it was prepared, the Smyth Report was extraordinarily successful in its efforts to distribute credit fairly and accurately. It would have been impossible to have prepared any document for publication covering the work of the Manhattan District that every reader would have found to his liking. But the fact is that all those who had the greatest knowledge of the subject were nearly unanimous in approving its publication as it was finally written. And there can be no question that it excellently served its purpose as an essential source of accurate information, particularly for a news-hungry America in the early days after Nagasaki.

Smythe's Megalith, also known as the Warren Farm Chamber, was a chambered long barrow located near the village of Aylesford in the south-eastern English county of Kent. Probably constructed in the fourth millennium BCE, during Britain's Early Neolithic period, it was discovered in 1822, at which point it was dismantled. Built out of earth and at least five local sarsen megaliths, the long barrow consisted of a roughly rectangular earthen tumulus with a stone chamber in its eastern end. Human remains were deposited into this chamber. 
Archaeologists have established that the monument was built by pastoralist communities shortly after the introduction of agriculture to Britain from continental Europe. Although representing part of an architectural tradition of long barrow building that was widespread across Neolithic Europe, Smythe's Megalith belonged to a localised regional variant of barrows produced in the vicinity of the River Medway, now known as the Medway Megaliths. Several of these still survive: Coldrum Long Barrow, Addington Long Barrow, and Chestnuts Long Barrow are on the river's western side, while Kit's Coty House, the Little Kit's Coty House, and the Coffin Stone are on the eastern side nearer to Smythe's Megalith. Close to the site of the lost monument is the White Horse Stone, a standing stone that may have once been part of another chambered long barrow.
The site may have been ransacked during the Middle Ages, as other Medway Megaliths were; by the early 19th century it was buried beneath soil, largely due to millennia of hillwash coming down from the adjacent Blue Bell Hill. In 1822, it was discovered by farm labourers ploughing the land; the local antiquarians Clement Smythe and Thomas Charles were called in to examine it. Shortly after, the labourers pulled away the stones and dispersed most of the human remains, destroying the monument. Smythe and Charles produced, but did not publish, reports on their findings, and these have been discussed by archaeologists since the mid-20th century.
Smythe's Megalith was located on the south-facing combe of Blue Bell Hill, within the vicinity of Warren Farm, near the village of Aylesford in the south-eastern English county of Kent. The location where it was found lies in a large field now to the east of the A229 dual carriageway. Nothing of the monument can now be seen and the specific location cannot be publicly accessed.
The Early Neolithic was a revolutionary period of British history. Between 4500 and 3800 BCE, it saw a widespread change in lifestyle as the communities living in the British Isles adopted agriculture as their primary form of subsistence, abandoning the hunter-gatherer lifestyle that had characterised the preceding Mesolithic period. This came about through contact with continental societies, although it is unclear to what extent this can be attributed to an influx of migrants or to indigenous Mesolithic Britons adopting agricultural technologies from the continent. The modern Kent region would have been key for the arrival of continental European settlers and visitors, because of its position on the estuary of the River Thames and its proximity to the continent.Britain was then largely forested; widespread forest clearance did not occur in Kent until the Late Bronze Age (c.1000 to 700 BCE). Environmental data from the vicinity of the White Horse Stone, a putatively prehistoric monolith near the River Medway, supports the idea that the area was still largely forested in the Early Neolithic, covered by a woodland of oak, ash, hazel/alder and amygdaloideae. Throughout most of Britain, there is little evidence of cereal or permanent dwellings from this period, leading archaeologists to believe that the Early Neolithic economy on the island was largely pastoral, relying on herding cattle, with people living a nomadic or semi-nomadic life.
Across Western Europe, the Early Neolithic marks the first period in which humans built monumental structures in the landscape. These constructs include chambered long barrows, rectangular or oval earthen tumuli which had a chamber built into one end. Some of these chambers were constructed from timber, although others were built using large stones, now known as "megaliths". The long barrows often served as tombs, housing the physical remains of the dead within their chamber. Individuals were rarely buried alone in the Early Neolithic, instead being interred in collective burials with other members of their community. These chambered tombs were built all along the Western European seaboard during the Early Neolithic, from southeastern Spain up to southern Sweden, taking in most of the British Isles; the architectural tradition was introduced to Britain from continental Europe in the first half of the fourth millennium BCE. Although there are stone buildings — like Göbekli Tepe in modern Turkey — which predate them, the chambered long barrows constitute humanity's first widespread tradition of construction using stone.Although now all ruined and not retaining their original appearance, at the time of construction the megaliths would have been some of the largest and most visually imposing Early Neolithic funerary monuments in Britain. Grouped along the River Medway as it cuts through the North Downs, they constitute the most southeasterly group of megalithic monuments in the British Isles, and the only megalithic group in eastern England. The archaeologists Brian Philp and Mike Dutto deemed the Medway Megaliths to be "some of the most interesting and well known" archaeological sites in Kent, while the archaeologist Paul Ashbee described them as "the most grandiose and impressive structures of their kind in southern England".The megaliths can be divided into two separate clusters: one to the west of the River Medway and the other on Blue Bell Hill to the east, with a distance between the two clusters of between 8 and 10 kilometres (5 and 6 miles). The western group includes Coldrum Long Barrow, Addington Long Barrow, and the Chestnuts Long Barrow. The eastern group consists of Smythe's Megalith, Kit's Coty House, Little Kit's Coty House, the Coffin Stone, and several other stones which might have once been parts of chambered tombs, most notably the White Horse Stone. It is not known if they were all built at the same time, or whether they were constructed in succession, while similarly it is not known if they each served the same function or whether there was a hierarchy in their usage.
The Medway long barrows all conformed to the same general design plan, and all aligned on an east to west axis. Each had a stone chamber at the eastern end of the mound, and they each probably had a stone facade flanking the entrance. The chambers were constructed from sarsen, a dense, hard, and durable stone that occurs naturally throughout Kent, having formed out of silicified sand from the Eocene epoch. Early Neolithic builders would have selected blocks from the local area, and then transported them to the site of the monument to be erected.These common architectural features among the Medway Megaliths indicate a strong regional cohesion with no direct parallels elsewhere in the British Isles. For instance, they would have been taller than most other chambered long barrows in Britain, with internal heights of up to 3.8 metres (10 feet). Nevertheless, as with other regional groupings of Early Neolithic long barrows — like the Cotswold-Severn group in south-western Britain — there are also various idiosyncrasies in the different monuments, such as Coldrum's rectilinear shape, the Chestnut Long Barrow's facade, and the long, thin mounds at Addington and Kit's Coty. These variations might have been caused by the monuments being altered over the course of their use.The builders were probably influenced by pre-existing tomb-shrines. Whether those people had grown up locally, or moved into the Medway area from elsewhere is not known. Based on a stylistic analysis of their architectural designs, the archaeologist Stuart Piggott thought that the plan behind the Medway Megaliths had originated in the area around the Low Countries; conversely, Glyn Daniel thought their design derived from Scandinavia, John H. Evans thought Germany, and Ronald F. Jessup suggested an influence from the Cotswold-Severn group. Ashbee noted that their close clustering in the same area was reminiscent of the megalithic tomb-shrine traditions of continental Northern Europe, and emphasised that the megaliths were a regional manifestation of a tradition widespread across Early Neolithic Europe. He nevertheless stressed that a precise place of origin was "impossible to indicate" with the available evidence.
The part of the chambered long barrow that was discovered was a stone chamber composed of four large stones. The stones used were sarsens. The northern stone measured 2.3 metres (7 ft 6 in) by 1.4 metres (4 ft 9 in) by 0.36 metres (1 ft 2 in). The southern stone measured 2.1 metres (7 ft) by 1.8 metres (5 ft 9 in) by 0.69 metres (2 ft 3 in). The third stone, on the western side, measured 0.91 metres (3 ft) by 1.2 metres (4 ft) by 0.46 metres (1 ft 6 in). A fourth, smaller stone, measuring 0.91 metres (3 ft) by 0.61 metres (2 ft) by 0.30 metres (1 ft), was placed to prevent the north stone falling onto its southern counterpart. This may have once been used to divide the chamber in two. Given the recorded dimensions of the stones, Ashbee suggested that the chamber may have once measured 6.1 metres (20 ft) in length and could have included as many as ten sarsen stones in its original construction. He also suggested that it would have had a height of around 1.2 metres (4 ft), making it one of the smaller chambers in the Medway region; the chamber at Kits Cot House, for instance, reached over 1.8 metres (6 ft) in height, and that at Chestnuts Long Barrow reached a height of about 2.7 metres (9 ft).Below these megaliths was a flat stone, measuring 1.2 metres (4 ft) in length and 0.91 metres (3 ft) in width. Lying atop this stone were human remains, reportedly aligned in an east to west orientation. Ashbee noted that such paving stones are rare in recorded chambered tombs, and suggested that it might instead have once been a cover stone that sat atop the chamber, but which had been knocked down at some point in the monument's history. In this scenario, the bones found atop it would have to have been disturbed from their original position. Also on the flat stone, near to the human remains, was the skull of a mole. A small sherd of unglazed pottery was also found with the bones. This need not have dated from the original period of the site's construction; as found at other, better-recorded sites, chambered long barrows could remain open for centuries or millennia after they were built, during which time other material was placed inside. For instance, small sherds of Beaker pottery, dating from the Late Neolithic, were found at Kit's Coty House, and the sherd found at Smythe's Megalith might also date from this period.
At the time of the site's discovery, there was no was apparent barrow, in part because the ground level of the area had been raised by millennia of hillwash coming down from further up Blue Bell Hill. However, as a result of what is known of this architectural style from better-recorded sites, it is apparent that this stone chamber would have been located at the eastern end of a long earthen barrow. Ashbee noted that this could have reached a length of 55 metres (180 feet). It may be that kerbstones also lined the sides of this barrow, as is evident at several other of the Medway Megaliths; Ashbee suggested that this could have contained as many as 110 or 120 sarsen stones. The monument may have had ditches flanking its sides, and chalk rubble collected in digging these ditches may have been piled up to help form the barrow.During the Early Neolithic, the site may have been close to other chambered long barrows; the White Horse Stone, for instance, is nearby and may have once been part of the chamber of these monuments. Various sarsen stones have been found in the vicinity of both, again perhaps reflecting the remnants of since-destroyed long barrows. To the south of the White Horse Stone was a building — termed "Structure 4806" by its excavators in the 2000s — that was constructed in the Early Neolithic period. Radiocarbon dating from the site suggests a usage date of between 4110-3820 and 3780-3530 calibrated BCE. 18 metres (59 ft) long and 8 metres (26 ft) wide, it was a longhouse of a type known from across various parts of Europe. If it had been a domestic residence, its size would mean that it was only "occupied by a small number of occupants, probably no more than a small family group". A smaller, circular building approximately 3.75 metres (12 ft) in diameter was present just to the south-east of the longhouse; there was little dating evidence for this, but what existed suggested a Late Neolithic origin. The archaeologists who excavated these buildings suggested that they might have been "houses of the living" that were intervisible with the "houses of the dead", including Smythe's Megalith. Alternately, they suggested that the longhouse was "part of the funerary tradition", used in preparing "the remains of the dead or for communal activities such as feasting".
Analysis of the bones found in the chamber took place in the 1820s. At the time, it was noted that most of the bones were broken into small pieces — something the examiner believed had been caused by the workmen who recovered them — but that they included pieces of skull, ribs, thigh, leg, and arm bones. There were two right sides of mandibles and two portions of ulnae including the olecranon, indicating that the remains of at least two individuals were present in the chamber. Analysis of the recovered teeth showed that the molars were worn down and flattened, indicating that the deceased had been of middle age.
Around 200 metres (660 ft) away from the Neolithic houses, a settlement was established on a spur of higher ground during the Late Bronze Age and Iron Age. This included several round houses and deep pits cut into the underlying chalk. These pits were perhaps originally used for corn storage, although were later infilled with ceramics, iron objects, animal bone, and two human burials. Archaeologists believed that this was not just domestic refuse but had been deposited with greater meaning as part of a ritualistic act.The archaeologist Paul Ashbee suggested that the chambered long barrow may have remained visible into the Middle Ages, and at this point may have been damaged by individuals digging into it. To support this idea, he noted the evidence for such deliberate medieval damage revealed through the archaeological excavation of Chestnuts Long Barrow. Similar claims of medieval destruction have also been made for Lower Kit's Coty House, Kit's Coty House, Coldrum Long Barrow, and Addington Long Barrow. Ashbee suggested that iconoclasm was likely, believing that the burial of the stones likely indicated that Christian zealots were trying to deliberately destroy and defame the pre-Christian monument.Conversely, the archaeologist John Alexander believed that this damage resulted from a robbery by medieval treasure hunters. Supporting this idea is comparative evidence, with the Close Roll of 1237 ordering the opening of barrows on the Isle of Wight in search for treasure, a practice that may have spread to Kent around the same time. Alexander believed that the destruction may have been brought about by a special commissioner, highlighting that the "expertness and thoroughness of the robbery" — as evidenced at Chestnuts — would have necessitated resources beyond that which a local community could likely produce.
In 1822, workmen were ploughing in a field that was at the time part of Warren Farm when they found that their ploughs were repeatedly striking stones beneath the surface. Removing the soil, they discovered three large stones several inches below. The farm's owner, George Fowle of Cobtree Manor, called in two men from Maidstone to inspect the monument: the antiquarian and historian Clement Taylor Smythe, and Thomas Charles, a doctor who lived in Maidstone and who had founded a museum at Chillington House. With Smythe present, the workmen removed the soil around the three stones, also revealing a smaller stone as part of the construct; he was aware of its similarity to the nearby Kit's Coty House. The stones were then removed, likely with the assistance of horses, destroying what remained of the monument.The following day, the workmen returned to the site, where they dug deeper and revealed a flat stone on which the human remains were found; Smythe was not present on this occasion. The workmen threw most of the human remains to the side, but some were collected by Smythe and analysed by Charles.
A brief article mentioning the discovery appeared in the Maidstone Journal on 4 July 1822; the information in it was then largely repeated in a volume of the Gentleman's Magazine that year. The latter also features some brief discussion as to who the deceased individuals in the chamber had been, speculating that it was "some chief slain in the battle fought here between Vortimer, King of Britain, and the Saxons". A second description of the site appeared in Gentleman's Magazine in 1834, written by S. C. Lampreys.About a year after the discovery, Smythe wrote an account in which he included both a sketch and plan of the chamber. Smythe's original report was not published at the time, but deposited in the archive of Maidstone Museum. In this unpublished document, he referred to the monument as a "British Tomb" or a "Druidical Monument". The document was only published in 1948, in an article written for the Archaeologia Cantiana journal by the archaeologist John H. Evans. Evans noted that "meagre and incomplete as it is", "we must be grateful" for this document "when we remember the unrecorded destruction wrought throughout the centuries upon this interesting and isolated megalithic necropolis".Alongside Smythe's report, another brief account was also produced and placed in the museum, likely written by Charles and again published in Evans' 1948 article. Ashbee later related that both of the reports written in the 1820s were "brief but valuable" and "in many ways in advance of their age". He noted that the destruction of prehistoric monuments during this "age of agricultural development" would have been quite commonplace and thus these antiquarians' records — written "almost half a century before the emergence of the outlines of present-day prehistory" as a field of scholarly study — were particularly important.In the 1920s, the archaeologist O. G. S. Crawford accessed the Maidstone Museum archives to determine the probable location of Smythe's Megalith. He then included it in his 1924 Ordnance Survey guide to archaeological sites in southeastern England. In 1955, several substantial stones were also found in the area. In 2000, Ashbee stated that some of the kerbstones had "recently come to light, buried in the ditches" of the monument.

The snoring rail (Aramidopsis plateni), also known as the Celebes rail or Platen's rail, is a large flightless rail and the only member of the genus Aramidopsis.  The species is endemic to Indonesia, and it is found exclusively in dense vegetation in wet areas of Sulawesi and nearby Buton. The rail has grey underparts, a white chin, brown wings and a rufous patch on the hind-neck. The sexes are similar, but the female has a brighter neck patch and a differently coloured bill and iris. The typical call is the snoring: ee-orrrr sound that gives the bird its English name.
Its inaccessible habitat and retiring nature mean that the snoring rail is rarely seen and as a result, little is known of its behaviour. Only the adult plumage has been described, and the breeding behaviour is unrecorded. It feeds on small crabs and probably other small prey such as lizards. Although protected under Indonesian law since 1972, the rail is threatened by habitat loss (even within nature reserves), hunting for food and predation by introduced species; it is therefore evaluated as vulnerable on the IUCN Red List.
The rails are a large and very widespread family, with nearly 150 species. They are small to medium-sized, terrestrial or wetland birds, and their short bodies are often flattened laterally to help them move through dense vegetation. Island species readily become flightless; of 53 extant or recently extinct taxa restricted to islands, 32 have lost the ability to fly.The snoring rail was first classified as Rallus plateni by German ornithologist August Wilhelm Heinrich Blasius in 1886, but was moved to its current monotypic genus Aramidopsis by English zoologist Richard Bowdler Sharpe in 1893. Following Taylor (1998), it was considered to be more similar to the Inaccessible Island and white-throated rails than to members of the genus Rallus, but a 2012 mitochondrial gene study suggests that it should actually be placed in Gallirallus, with Lewin's rail and the slaty-breasted rail as its closest relatives. Aramidopsis  derives from the genus name of the limpkin, Aramus and the Greek suffix opsis, "resembling". Although the rail shares the origin of its name with the South American Aramides species, its distinctive bill, thick legs and barred lower belly distinguish it from that group. The species name  plateni commemorates Carl Constantin Platen, a German doctor who collected birds and butterflies in the Malay Archipelago and gave Blasius his specimen of the rail. The common name refers to the rail's distinctive call, and was given to the bird as der Vogel Schnarch (the snoring bird) by German entomologist Gerd Heinrich when he rediscovered the species in 1932.
The snoring rail is 30 cm (12 in) long and weighs 143–160 g (5.0–5.6 oz). It is flightless, with short wings, a very short tail and strong legs and feet. The back and the underparts from the forecrown to the breast are grey, apart from a white chin, and the sides and rear of the neck are deep orange-red. Most of the rest of the upperparts are brown, and the belly, flanks, and undertail have white barring. The male has black legs, a yellow iris and a brown and greenish down-curved bill. The female is similar but has a brighter hindneck colour, less white on the chin, a red iris, a cream and reddish bill and blue-grey legs. Immature and juvenile plumages are undescribed. Visual confusion with sympatric rails is unlikely. The blue-faced rail is similar in size, but is chestnut above and black below, and the buff-banded rail has strongly marked upperparts, breast, and head. The slaty-breasted rail is smaller and has barred upperparts.The call, given frequently, is a short wheez followed by a distinctive snoring ee-orrrr. A deep hmmmm sound has also been recorded.
The species is an uncommon Indonesian endemic of lowland and hill forests in northern, north central and southeastern Sulawesi. Another population was found on Buton island in 1995.The typical habitat of this species is dense vegetation in wet areas. This may include impenetrable bamboo and liana in forests, rattan in regrown forests, or elephant grass and bushes on the hillsides of Minahassa Peninsula. Claims of the species occurring in rice fields are believed to be due to confusion with the buff-banded rail. The snoring rail occurs from sea level to 1,300 m (4,300 ft).
Its inaccessible habitat and sparse distribution means that little is known about this species. A few birds were shot by Platen and another expedition led by Paul Sarasin and his second cousin, Fritz, between 1893 and 1898, but the rail was then not seen for more than thirty years until Heinrich found it almost at the end of a two-year survey of Sulawesi, then known as Celebes. He described it as "the most priceless catch that I have ever hunted or will hunt". More than a decade later, Dutch ornithologist Louis Coomans de Ruiter also took a year to find the rail, despite concentrating on known suitable habitat. There were then no documented sightings until birds were observed in 1983 and 1989. Sight records remain infrequent, and only about ten specimen corpses have been studied.The snoring rail catches crabs in highland streams, and these crustaceans may be a major dietary item. It also forages in muddy areas, and has been recorded as consuming lizards. Nothing is known of its breeding behaviour other than a report of an adult seen feeding with two chicks in August 1983, but the original report gives no details of the claimed sighting.
The snoring rail is restricted to Sulawesi and Buton and has an estimated population of 3,500–15,000 individuals. Its numbers are thought to be decreasing, and its restricted range and small population mean that the species is classified as Vulnerable by the International Union for Conservation of Nature (IUCN).It may always have been thinly spread, but there has been widespread deforestation within its range resulting in loss and fragmentation of suitable habitat. The rail has been protected under Indonesian law since 1972, and the large Lore Lindu and Bogani Nani Wartabone National Parks are within its range, but logging and rattan cutting occurs even in these protected areas, and human encroachment is also a problem at Lore Lindu. The rail has been trapped for food in the past, and is sometimes killed by dogs, cats and other introduced predators. A 2007 survey of protected areas of Sulawesi failed to find the rail, suggesting that it is genuinely rare even in reserves.
Heinrich, Bernd (2007). The snoring bird: my family's journey through a century of biology. New York: Ecco (Harper Collins). ISBN 978-0-06-074215-7.
Jobling, James A (2010). The Helm Dictionary of Scientific Bird Names. London: Christopher Helm. p. 52. ISBN 978-1-4081-2501-4.
Meyer, Adolf Bernhard; Wiglesworth, Lionel W (1898). The Birds of Celebes and the neighbouring islands. 1. Berlin: R Friedlander & Sohn.
Meyer, Adolf Bernhard; Wiglesworth, Lionel W (1898). The Birds of Celebes and the neighbouring islands. 2. Berlin: R Friedlander & Sohn.
Roots, Clive (2006). Flightless Birds. Westport, Connecticut: Greenwood Publishing. ISBN 978-0-313-33545-7.
Taylor, Barry; van Perlo, Ber (1998). Rails. Robertsbridge, East Sussex: Pica / Christopher Helm. ISBN 1-873403-59-3.

The social history of viruses describes the influence of viruses and viral infections on human history. Epidemics caused by viruses began when human behaviour changed during the Neolithic period, around 12,000 years ago, when humans developed more densely populated agricultural communities. This allowed viruses to spread rapidly and subsequently to become endemic. Viruses of plants and livestock also increased, and as humans became dependent on agriculture and farming, diseases such as potyviruses of potatoes and rinderpest of cattle had devastating consequences.
Smallpox and measles viruses are among the oldest that infect humans. Having evolved from viruses that infected other animals, they first appeared in humans in  Europe and  North Africa thousands of years ago. The viruses were later carried to the New World by Europeans during the time of the Spanish Conquests, but the indigenous people had no natural resistance to the viruses and millions of them died during epidemics. Influenza pandemics have been recorded since 1580, and they have occurred with increasing frequency in subsequent centuries. The pandemic of 1918–19, in which 40–50 million died in less than a year, was one of the most devastating in history.
Louis Pasteur and Edward Jenner were the first to develop vaccines to protect against viral infections. The nature of viruses remained unknown until the invention of the electron microscope in the 1930s, when the science of virology gained momentum. In the 20th century many diseases both old and new were found to be caused by viruses. There were epidemics of poliomyelitis that were only controlled following the development of a vaccine in the 1950s. HIV is one of the most pathogenic new viruses to have emerged in centuries. Although scientific interest in them arose because of the diseases they cause, most viruses are beneficial. They drive evolution by transferring genes across species, play important roles in ecosystems and are essential to life.
Over the past 50,000–100,000 years, as modern humans increased in numbers and dispersed throughout the world, new infectious diseases emerged, including those caused by viruses. Earlier, humans lived in small, isolated communities, and most epidemic diseases did not exist. Smallpox, which is the most lethal and devastating viral infection in history, first emerged among agricultural communities in India about 11,000 years ago. The virus, which only infected humans, probably descended from the poxviruses of rodents.  Humans probably came into contact with these rodents, and some people became infected by the viruses they carried. When viruses cross this so-called "species barrier", their effects can be severe, and humans may have had little natural resistance. Contemporary humans lived in small communities, and those who succumbed to infection either died or developed immunity. This acquired immunity is only passed down to offspring temporarily, by antibodies in breast milk and other antibodies that cross the  placenta from the mother's blood to the unborn child's. Therefore, sporadic outbreaks probably occurred in each generation. In about 9000 BC, when many people began to settle on the fertile flood plains of the River Nile, the population became dense enough for the virus to maintain a constant presence because of the high concentration of susceptible people. Other epidemics of viral diseases that depend on large concentrations of people, such as mumps, rubella and polio, also first occurred at this time.The Neolithic age, which began in the Middle East in about 9500 BC, was a time when humans became farmers. This agricultural revolution embraced the development of monoculture and presented an opportunity for the rapid spread of several species of plant viruses. The divergence and spread of sobemoviruses – southern bean mosaic virus – date from this time. The spread of the potyviruses of potatoes, and other fruits and vegetables, began about 6,600 years ago.About 10,000 years ago the humans who inhabited the lands around the Mediterranean basin began to domesticate wild animals. Pigs, cattle, goats, sheep, horses, camels, cats and dogs were all kept and bred in captivity. These animals would have brought their viruses with them. The transmission of viruses from animals to humans can occur, but such zoonotic infections are rare and subsequent human-to-human transmission of animal viruses is even rarer, although there are notable exceptions such as influenza. Most viruses are species-specific and would have posed no threat to humans. The rare epidemics of viral diseases originating in animals would have been short-lived because the viruses were not fully adapted to humans and the human populations were too small to maintain the chains of infection.Other, more ancient, viruses have been less of a threat. Herpes viruses first infected the ancestors of modern humans over 80 million years ago. Humans have developed a tolerance to these viruses, and most are infected with at least one species. Records of these milder virus infections are  rare, but it is likely that early hominids suffered from colds, influenza and diarrhoea caused by viruses just as humans do today. More recently evolved viruses cause epidemics and pandemics – and it is these that history records.  The influenza virus is one that seems to have crossed the species barrier from pigs to ducks and water fowl and hence to humans. It is possible that a fatal plague in the Middle East at the time of the late 18th Dynasty was associated with this transmission at Amarna.
Among the earliest records of a viral infection is an Egyptian stele thought to depict an Egyptian priest from the 18th Dynasty (1580–1350 BC) with a foot drop deformity characteristic of a poliovirus infection. The mummy of  Siptah – a ruler during the 19th Dynasty – shows signs of poliomyelitis, and that of Ramesses V and some other Egyptian mummies buried over 3000 years ago show evidence of smallpox. There was an epidemic of smallpox in Athens in 430 BC, in which a quarter of the Athenian army and many of the city's civilians died from the infection.Measles is an old disease, but it was not until the 10th century that the Persian physician Muhammad ibn Zakariya al-Razi (865–925) – known as "Rhazes" – first identified it. Rhazes used the Arabic name hasbah for measles. It has had many other names including rubeola from the Latin word rubeus, "red", and morbilli, "small plague". The close similarities between measles virus, canine distemper virus and  rinderpest virus have given rise to speculation that measles was first transmitted to humans from domesticated dogs or cattle. The measles virus appears to have fully diverged from the then-widespread rinderpest virus by the 12th century.A measles infection confers lifelong immunity. Therefore, the virus requires a high population density to become endemic, and this probably did not occur in the Neolithic age.  Following the emergence of the virus in the Middle East, it reached India by 2500 BC. Measles was so common in children at the time that it was not recognised as a disease. In Egyptian hieroglyphs it was described as a normal stage of human development.
One of the earliest descriptions of a virus-infected plant can be found in a poem written by the Japanese Empress Kōken (718–770), in which she describes a plant in summer with yellowing leaves. The plant, later identified as Eupatorium lindleyanum, is often infected with tomato yellow leaf curl virus.
The rapidly growing population of Europe and the rising concentrations of people in its towns and cities became a fertile ground for many infectious and contagious diseases, of which the Black Death – a bacterial infection – is probably the most notorious. Except for smallpox and influenza, documented outbreaks of infections now known to be caused by viruses were rare. Rabies, a disease that had been recognised for over 4000 years, was rife in Europe, and continued to be so until the development of a vaccine by Louis Pasteur in 1886. The average life expectancy in Europe during the Middle Ages was 35 years;  60% of children died before the age of 16, many of them during their first 6 years of life. Physicians – what few there were – relied as much on astrology as they did on their limited medical knowledge. Some treatments for infections consisted of ointments prepared from cats that had been roasted in hedgehog fat. Among the plethora of diseases that caused childhood death were measles, influenza and smallpox. The Crusades and the Muslim conquests aided the spread of smallpox, which was the cause of frequent epidemics in Europe following its introduction to the continent between the fifth and seventh centuries.Measles was endemic throughout the highly populated countries of Europe, North Africa and the Middle East. In England the disease, then called "mezils", was first described in the 13th century, and it was probably one of the 49 plagues that occurred between 526 and 1087.
Rinderpest, which is caused by a virus closely related to measles virus, is a disease of cattle known since Roman times. The disease, which originated in Asia, was first brought to Europe by the invading Huns in 370. Later invasions of Mongols, led by Genghis Khan and his army, started pandemics in Europe in 1222, 1233 and 1238. The infection subsequently reached England following the importation of cattle from the continent. At the time rinderpest was a devastating disease with a mortality rate of 80–90%. The resulting loss of cattle caused famine.
A short time after Henry Tudor's victory at the Battle of Bosworth on 22 August 1485, his army suddenly went down with "the English sweat", which contemporary observers described as a new disease. The disease, which was unusual in that it mainly affected the affluent, might have originated in France where Henry VII had recruited soldiers for his army. An epidemic hit London in the hot summer of 1508. Victims died within a day, and there were deaths throughout the city. The streets were deserted apart from carts transporting bodies, and King Henry declared the city off limits except for physicians and apothecaries. The disease spread to Europe, arriving in Hamburg in July 1529 where one to two thousand victims died within the first few weeks.  During the following months it wreaked havoc in Prussia, Switzerland, and northern Europe. The last outbreak was in England in 1556. The disease – which killed tens of thousands of people – was probably influenza or a similar viral infection, but records from the time when medicine was not a science can be unreliable. As medicine became a science, the descriptions of disease became less vague. Although medicine could do little at the time to alleviate the suffering of the victims of infection, measures to control the spread of diseases were used. Restrictions on trade and travel were implemented, stricken families were isolated from their communities, buildings were fumigated and livestock killed.References to influenza infections date from the late 15th and early 16th centuries, but  infections almost certainly occurred long before then. In 1173, an epidemic occurred that was possibly the first in Europe, and in 1493, an outbreak of what is now thought to be swine influenza, struck Native Americans in Hispaniola. There is some evidence to suggest that source of the infection was pigs on Columbus's ships. During an influenza epidemic that occurred in England between 1557 and 1559, five per cent of the population – about 150,000 – died from the infection. The mortality rate was nearly five times that of the 1918–19 pandemic.  The first pandemic that was reliably recorded began in July 1580 and swept across Europe, Africa, and Asia. The mortality rate was high – 8,000 died in Rome. The next three pandemics occurred in the 18th century, including that during 1781–82, which was probably the most devastating in history. This began in November 1781 in China and reached Moscow in December. In February 1782 it hit Saint Petersburg, and by May it had reached Denmark. Within six weeks, 75 per cent of the British population were infected and the pandemic soon spread to the Americas.
The Americas and Australia remained free of measles and smallpox until the arrival of European colonists between the 15th and 18th centuries. Along with measles and influenza, smallpox was taken to the Americas by the Spanish. Smallpox was endemic in Spain, having been introduced by the Moors from Africa. In 1519, an epidemic of smallpox broke out in  the Aztec capital Tenochtitlan in Mexico. This was started by  the army of Pánfilo de Narváez,  who followed Hernán Cortés  from Cuba and had an African slave suffering from smallpox aboard his ship. When the Spanish finally entered the capital in the summer of 1521, they saw it strewn with the bodies of smallpox victims.  The epidemic, and those that followed during 1545–1548 and 1576–1581, eventually killed more than half of the native population. Most of the Spanish were immune;  with his army of fewer than 900 men it would not have been possible for Cortés to defeat the Aztecs and conquer Mexico without the help of smallpox. Many Native American populations were devastated later by the inadvertent spread of diseases introduced by Europeans. In the 150 years that followed Columbus's arrival in 1492, the Native American population of North America was reduced by 80 per cent from diseases, including measles, smallpox and influenza. The damage done by these viruses significantly aided European attempts to displace and conquer the native population.By the 18th century, smallpox was endemic in Europe. There were five epidemics in London between 1719 and 1746, and large outbreaks occurred in other major European cities. By the end of the century about 400,000 Europeans were dying from the disease each year. It reached South Africa in 1713, having been carried by ships from India, and in 1789 the disease struck Australia. In the 19th century, smallpox became the single most important cause of death of the Australian Aborigines.In 1546 Girolamo Fracastoro (1478–1553) wrote a classic description of measles. He thought the disease was caused by "seeds" (seminaria) that were spread from person to person. An epidemic hit London in 1670, recorded by Thomas Sydenham (1624–1689), who thought it was caused by toxic vapours emanating from the earth.  His theory was wrong but he was a skilled observer and kept meticulous records.Yellow fever is an often lethal disease caused by a flavivirus. The virus is transmitted to humans by mosquitoes (Aedes aegypti) and first appeared over 3,000 years ago. In 1647, the first recorded epidemic occurred on Barbados  and was called "Barbados distemper" by John Winthrop, who was the governor of the island at the time. He passed quarantine laws to protect the people – the first ever such laws in North America. Further epidemics of the disease occurred in North America in the 17th, 18th and 19th centuries. The first known cases of dengue fever occurred in Indonesia and Egypt in 1779. Trade ships brought the disease to the US, where an epidemic occurred in Philadelphia in 1780.
Many paintings can be found in the museums of Europe depicting tulips with attractive coloured stripes. Most, such as the still life studies of Johannes Bosschaert, were painted during the 17th century. These flowers were particularly popular and became sought after by those who could afford them. At the peak of this tulip mania in the 1630s, one bulb could cost as much as a house. It was not known at the time that the stripes were caused by a virus accidentally transferred by humans to tulips from jasmine. Weakened by the virus, the plants turned out to be a poor investment. Only a few bulbs produced flowers with the attractive characteristics of their parent plants.Until the Irish Great Famine of 1845–1852, the commonest cause of disease in potatoes was not the mould that causes blight, it was a virus. The disease, called "curl", is caused by potato leafroll virus, and it was widespread in England in the 1770s, where it destroyed 75 per cent of the potato crop. At that time, the Irish potato crop remained relatively unscathed.
Lady Mary Wortley Montagu (1689–1762) was an aristocrat, a writer and the wife of a Member of Parliament. In 1716, her husband, Edward Wortley Montagu, was appointed British Ambassador in Istanbul. She followed him there and two weeks after her arrival discovered the local practice of protection against smallpox by variolation – the injection of pus from smallpox victims into the skin. Her younger brother had died of smallpox, and she too had had the disease. Determined to spare her five-year-old son Edward from similar suffering, she ordered the embassy surgeon Charles Maitland to variolate him. On her return to London, she asked Maitland to variolate her four-year-old daughter in the presence of the king's physicians. Later, Montagu persuaded the Prince and Princess of Wales to sponsor a public demonstration of the procedure. Six prisoners who had been condemned to death and were awaiting execution at Newgate Prison were offered a full pardon for serving as the subjects of the public experiment. They accepted and were variolated in 1721. All the prisoners recovered from the procedure.  To test its protective effect one of them, a nineteen-year-old woman, was ordered to sleep in the same bed as a ten-year-old smallpox victim for six weeks. She did not contract the disease.The experiment was repeated on eleven orphan children, all of whom survived the ordeal, and by 1722  even King George I's grandchildren had been inoculated. The practice was not entirely safe and there was a one in fifty chance of death. The procedure was expensive; some medical practitioners charged between £5 and £10 and some sold the method to other practitioners for fees between £50 to £100, or for half of the profits. Variolation became a lucrative franchise, but it remained beyond the means of many until the late 1770s. At the time nothing was known about viruses or the immune system, and no one knew how the procedure afforded protection.
Edward Jenner (1749–1823), a British rural physician, was variolated as a boy. He had suffered greatly from the ordeal but survived fully protected from smallpox. Jenner knew of a local belief that dairy workers who had contracted a relatively mild infection called cowpox were immune to smallpox. He decided to test the theory (although he was probably not the first to do so). On 14 May 1796 he selected "a healthy boy, about eight years old for the purpose of inoculation for the Cow Pox". The boy,  James Phipps (1788–1853),  survived the experimental inoculation with cowpox virus and suffered only a mild fever. On 1 July 1796, Jenner took some "smallpox matter" (probably infected pus) and repeatedly inoculated Phipps's arms with it. Phipps survived and was subsequently inoculated with smallpox more than 20 times without succumbing to the disease. Vaccination – the word is derived from the Latin vacca meaning "cow" – had been invented. Jenner's method was soon shown to be safer than variolation, and by 1801 more than 100,000 people had been vaccinated.Despite objections from those medical practitioners  who still practised variolation, and who foresaw a decline in their income, free vaccination of the poor was introduced in the UK in 1840. Because of associated deaths, variolation was declared illegal in the same year. Vaccination was made compulsory in England and Wales by the 1853 Vaccination Act, and parents could be fined £1 if their children were not vaccinated before they were three months of age. The law was not adequately enforced, and the system for providing vaccinations,  unchanged since 1840, was ineffective. After an early compliance by the population only a small proportion were vaccinated. Compulsory vaccination was not well received and, following  protests, the Anti-Vaccination League and the Anti-Compulsory Vaccination League were formed in 1866. Following the anti-vaccination campaigns there was a severe outbreak of smallpox in Gloucester in 1895, the city's first  in twenty years; 434 people died, including 281 children. Despite this, the British government conceded to the protesters and the Vaccination Act of 1898 abolished fines and made provision for a "conscientious objector" clause – the first use of the term – for parents who did not believe in vaccination. During the following year, 250,000 objections were granted, and by 1912 less than half of the population of newborns were being vaccinated.  By 1948, smallpox vaccination was no longer compulsory in the UK.
Rabies is an often fatal disease caused by the infection of mammals with rabies virus. In the 21st century it is mainly a disease that affects wild mammals such as  foxes and bats, but it is one of the oldest known virus diseases: rabies is a Sanskrit word (rabhas) that dates from 3000 BC,  which means "madness" or "rage", and the disease has been known for over 4000 years. Descriptions of rabies can be found in  Mesopotamian texts, and the ancient Greeks called it "lyssa" or "lytta", meaning "madness".  References to rabies can be found in the Laws of Eshnunna, which date from 2300 BC. Aristotle (384–322 BC) wrote one of the earliest undisputed descriptions of the disease and how it was passed to humans. Celsus, in the first century AD, first recorded the symptom called hydrophobia and suggested that the saliva of infected animals and humans contained a slime or poison – to describe this he invented the  word "virus". Rabies does not cause epidemics, but the infection was greatly feared because of its terrible symptoms, which include insanity, hydrophobia and death.In France during the time of Louis Pasteur (1822–1895) there were only a few hundred rabies infections in humans each year, but cures were desperately sought. Aware of the possible danger, Pasteur  began to look for the "microbe" in mad dogs.  Pasteur showed that when the dried spinal cords from dogs that had died from rabies were crushed and injected into healthy dogs they did not become infected. He repeated the experiment several times on the same dog with tissue that had been dried for fewer and fewer days, until the dog survived even after injections of fresh rabies-infected spinal tissue. Pasteur had immunised the dog against rabies, as he later did with 50 more.
Although Pasteur had little idea how his method worked, he tested it on a boy, Joseph Meister (1876–1940), who was brought to Pasteur by his mother on 6 July 1885. He was covered in bites, having been set upon by a mad dog.  Meister's mother begged Pasteur to help her son. Pasteur was a scientist, not a physician, and he was well aware of the consequences for him if things were to go wrong. He nevertheless decided to help the boy and injected him with increasingly virulent rabid rabbit spinal tissue over the following 10 days. Later Pasteur wrote, "as the death of this child appeared inevitable, I decided, not without deep and severe unease ... to try out on Joseph Meister the procedure, which had consistently worked on dogs".  Meister recovered and returned home with his mother on 27 July. Pasteur successfully treated a second boy in October that same year; Jean-Baptiste Jupille (1869–1923) was a 15-year-old shepherd boy who had been severely bitten as he tried to protect other children from a rabid dog. Pasteur's method of treatment  remained in use for over 50 years.Little was known about the cause of the disease until 1903 when Adelchi Negri (1876–1912) first saw microscopic lesions – now called Negri bodies – in the brains of rabid animals. He wrongly thought they were protozoan parasites. Paul Remlinger (1871–1964) soon showed by filtration experiments that they were much smaller than protozoa, and even smaller than bacteria. Thirty years later, Negri bodies were shown to be accumulations of particles 100–150 nanometres long, now known to be the size of rhabdovirus particles – the virus that causes rabies.
At the turn of the 20th century, evidence for the existence of viruses was obtained from experiments with filters that had pores too small for bacteria to pass through; the term "filterable virus" was coined to describe them. Until the 1930s most scientists believed that viruses were small bacteria, but following the invention of the electron microscope in 1931 they were shown to be completely different, to a degree that not all scientists were convinced they were anything other than accumulations of toxic proteins. The situation changed radically when it was discovered that viruses contain genetic material in the form of DNA or RNA. Once they were recognised as distinct biological entities they were soon shown to be the cause of numerous infections of plants, animals and even bacteria.Of the many diseases of humans that were found to be caused by viruses in the 20th century one, smallpox, has been eradicated. The diseases caused by viruses such as HIV and influenza virus have proved to be more difficult to control. Other diseases, such as those caused by arboviruses, are presenting new challenges.As humans have changed their behaviour during history, so have viruses. In ancient times the human population was too small for pandemics to occur and, in the case of some viruses, too small for them to survive. In the 20th and 21st century increasing population densities, revolutionary changes in agriculture and farming methods, and high speed travel have contributed to the spread of new viruses and the re-appearance of old ones.  Like smallpox, some viral diseases might be conquered, but new ones, such as severe acute respiratory syndrome (SARS), will continue to emerge. Although vaccines are still the most powerful weapon against viruses, in recent decades antiviral drugs have been developed to specifically target viruses as they replicate in their hosts. The 2009 influenza pandemic showed how rapidly new strains of viruses continue to spread around the world, despite efforts to contain them.Advances in virus discovery and control continue to be made. Human metapneumovirus, which is a cause of respiratory infections including pneumonia, was discovered in 2001. A vaccine for the papillomaviruses that cause cervical cancer was developed between 2002 and 2006.  In 2005, human T lymphotropic viruses 3 and 4 were discovered. In 2008 the WHO Global Polio Eradication Initiative was re-launched with a plan to eradicate poliomyelitis  by 2015. In 2010, the largest virus, Megavirus chilensis was discovered to infect amoebae. These giant viruses have renewed interest in the role viruses play in evolution and their position in the tree of life.
Smallpox virus was a major cause of death in the 20th century, killing about 300 million people. It has probably killed more humans than any other virus. In 1966 an agreement was reached by the World Health Assembly (the decision-making body of the World Health Organization) to start an "intensified smallpox eradication programme" and attempt to eradicate the disease within ten years. At the time, smallpox was still endemic in 31 countries including Brazil, the whole of the Indian sub-continent, Indonesia and sub-Saharan Africa. This ambitious goal was considered achievable for several reasons: the vaccine afforded exceptional protection; there was only one type of the virus; there were no animals that naturally carried it; the incubation period of the infection was known and rarely varied from 12 days; and infections always gave rise to symptoms, so it was clear who had the disease.Following mass vaccinations, disease detection and containment were central to the eradication campaign. As soon as cases were detected, the victims were isolated as were their close contacts, who were vaccinated. Successes came quickly; by 1970 smallpox was no longer endemic in western Africa, nor, by 1971, in Brazil. By 1973, smallpox remained endemic only in the Indian sub-continent, Botswana and Ethiopia. Finally, after 13 years of coordinated disease surveillance and vaccination campaigns throughout the world, the World Health Organization declared smallpox eradicated in 1979. Although the main weapon used was vaccinia virus, which was used as the vaccine, no one seems to know exactly where vaccinia virus came from; it is not the strain of cowpox that Edward Jenner used, and it is not a weakened form of smallpox.The eradication campaign led to the death of Janet Parker (c. 1938–1978) and the subsequent suicide of the smallpox expert Henry Bedson (1930–1978). Parker was an employee of the University of Birmingham who worked in the same building as Bedson's smallpox laboratory. She was infected by a strain of smallpox virus that Bedson's team had been investigating. Ashamed of the accident and having blamed himself for it, Bedson committed suicide.Before the September 11 attacks on the United States in 2001, the World Health Organization proposed the destruction of all the known remaining stocks of smallpox virus that were kept in laboratories in the US and Russia. Fears of bioterrorism using smallpox virus and the possible need for the virus in the development of drugs to treat the infection have put an end to this plan.  Had the destruction gone ahead, smallpox virus might have been the first to be made extinct by human intervention.
Before the introduction of vaccination in the US in the 1960s there were more than 500,000 cases each year resulting in about 400 deaths. In developed countries children were mainly infected between the ages of three and five years old, but in developing  countries half the children were infected before the age of two.  In the US and the UK, there were regular annual or biannual epidemics of the disease, which depended on the number of children born each year. The current epidemic strain evolved in the first part of the 20th century – probably between 1908 and 1943.
In London between 1950 and 1968 there were epidemics every two years, but in  Liverpool, which had a higher birth rate, there was an annual cycle of epidemics. During the Great Depression in the US before the Second World War the birth rate was low, and epidemics of measles were sporadic. After the war the birth rate increased, and epidemics occurred regularly every two years. In developing countries with very high birth rates, epidemics occurred every year. Measles is still a major problem in densely populated, less-developed countries with high birth rates and lacking effective vaccination campaigns.By the mid-1970s, following a mass vaccination programme that was known as "make measles a memory", the incidence of measles in the US had fallen by 90 per cent. Similar vaccination campaigns in other countries have reduced the levels of infection by 99 per cent over the past 50 years. Susceptible individuals remain a source of infection and include those who have migrated from countries with ineffective vaccination schedules, or who refuse the vaccine or choose not to have their children vaccinated.
Humans are the only natural host of measles virus. Immunity to the disease following an infection is lifelong; that afforded by vaccination is long term but eventually wanes.The use of the vaccine has been controversial. In 1998, Andrew Wakefield and his colleagues published a fraudulent research paper and he claimed to link the MMR vaccine with autism. The study was widely reported and fed concern about the safety of vaccinations. Wakefield's research was identified as fraudulent and in 2010, he was struck off the UK medical register and can no longer practise medicine in the UK.  In the wake of the controversy, the MMR vaccination rate in the UK fell from 92 per cent in 1995, to less than 80 per cent in 2003. Cases of measles rose from 56 in 1998  to 1370 in 2008, and similar increases occurred throughout Europe. In April 2013, an epidemic of measles in Wales in the UK broke out, which mainly affected teenagers who had not been vaccinated.  Despite this controversy, measles has been eliminated from Finland, Sweden and Cuba. Japan abolished mandatory vaccination in 1992, and in 1995–1997 more than 200,000 cases were reported in the country. Measles remains a public health problem in Japan, where it is now endemic;  a National Measles Elimination Plan was established in December 2007, with a view to eliminating the disease from the country. The possibility of  global elimination of measles has been debated in  medical literature since the introduction of the vaccine in the 1960s. Should the current campaign to eradicate poliomyelitis be successful, it is likely that the debate will be renewed.
During the summers of the mid-20th century, parents in the US and Europe dreaded the annual appearance of poliomyelitis (or polio), which was commonly known as "infantile paralysis". The disease was rare at the beginning of the century, and worldwide there were only a few thousand cases per year, but by the 1950s there were 60,000 cases each year in the US alone and an average of 2,300 in England and Wales.During 1916 and 1917 there had been a major epidemic in the US; 27,000 cases and 6,000 deaths were recorded, with 9,000 cases in New York City. At the time nobody knew how the virus was spreading. Many of the city's inhabitants, including scientists, thought that impoverished slum-dwelling immigrants were to blame even though the prevalence of the disease was higher in the more prosperous districts such as Staten Island – a pattern that had also been seen in  cities like Philadelphia. Many other industrialised countries were affected at the same time. In particular, before the outbreaks in the US, large epidemics had occurred in Sweden.The reason for the rise of polio in industrialised countries in the 20th century has never been fully explained. The disease is caused by a virus that is passed from person to person by the faecal-oral route, and naturally infects only humans. It is a paradox that it became a problem during times of improved sanitation and increasing affluence. Although the virus was discovered at the beginning of the 20th century, its ubiquity was unrecognised until the 1950s. It is now known that fewer than two per cent of individuals who are infected develop the disease, and most infections are mild. During epidemics the virus was effectively everywhere, which explains why public health officials were unable to isolate a source.Following the development of vaccines in the mid-1950s, mass vaccination campaigns took place in many countries. In the US, after a campaign promoted by the March of Dimes, the annual number of polio cases fell dramatically; the last outbreak was in 1979. In 1988 the World Health Organization along with others launched the Global Polio Eradication Initiative, and by 1994 the Americas were declared to be free of disease, followed by the Pacific region in 2000 and Europe in 2003. At the end of 2012, only 223 cases were reported by the World Health Organization. Mainly poliovirus type 1 infections, 122 occurred in Nigeria, one in Chad, 58 in Pakistan and 37 in Afghanistan. Vaccination teams often face danger; seven vaccinators were murdered in Pakistan and nine in Nigeria at the beginning of 2013. In Pakistan, the campaign was further hampered by the murder on 26 February 2013 of a police officer who was providing security.
The human immunodeficiency virus (HIV) is the virus that – when the infection is not treated – can cause AIDS (acquired immunodeficiency syndrome). Most virologists believe that HIV originated in sub-Saharan Africa during the 20th century, and over 70 million individuals have been infected by the virus. By 2011, an estimated 35 million had died from AIDS, making it one of the most destructive epidemics in recorded history.HIV-1 is one of the most significant viruses to have emerged in the last quarter of the 20th century.  When, in 1981, a scientific article was published that reported the deaths of five young gay men, no one knew that they had died from AIDS. The full scale of the epidemic – and that the virus had been silently emerging over several decades – was not known.HIV crossed the species barrier between chimpanzees and humans in Africa in the early decades of the 20th century. During the years that followed there were enormous social changes and turmoil in Africa. Population shifts were unprecedented as vast numbers of people moved from rural farms to the expanding cities, and the virus was spread from remote regions to densely populated urban conurbations. The incubation period for AIDS is around 10 years, so a global epidemic starting in the early 1980s is credible. At this time there was much scapegoating and stigmatisation. The "out of Africa" theory for the origin of the HIV pandemic was not well received by Africans, who felt that the "blame" was misplaced. This led the World Health Assembly to pass a 1987 resolution, which stated that HIV is "a naturally occurring [virus] of undetermined geographic origin".The HIV pandemic has challenged communities and brought about social changes throughout the world. Opinions on sexuality are more openly discussed. Advice on sexual practices and drug use – which were once taboo – is sponsored by many governments and their healthcare providers. Debates on the ethics of provision and cost of anti-retroviral drugs, particularly in poorer countries, have highlighted inequalities in healthcare and stimulated far-reaching legislative changes. In developing countries the impact of HIV/AIDS has been profound; key organisations such as healthcare, defense and civil services have been severely disrupted. Life expectancy has fallen. In Zimbabwe, for example, life expectancy was 79 years in 1991 but by 2001 it had fallen to 39 years.
When influenza virus undergoes a genetic shift many humans have no immunity to the new strain, and if the population of susceptible individuals is high enough to maintain the chain of infection,  pandemics occur. The genetic changes usually happen when different strains of the virus co-infect animals, particularly birds and swine. Although many viruses of vertebrates are restricted to one species, influenza virus is an exception. The last pandemic of the 19th century occurred in 1899 and resulted in the deaths of 250,000 people in Europe. The virus, which originated in Russia or Asia, was the first to be rapidly spread by people on trains and steamships.A new strain of the virus emerged in 1918, and the subsequent pandemic of Spanish flu was one of the worst natural disasters in history. The death toll was enormous; throughout the world around 50 million people died from the infection. There were 550,000 reported deaths caused by the disease in the US, ten times the country's losses during the First World War, and 228,000 deaths in the UK.  In India there were more than 20 million deaths, and in Western Samoa 22 per cent of the population died.  Although cases of influenza occurred every winter, there were only two other pandemics in the 20th century.In 1957 another new strain of the virus emerged and caused a pandemic of Asian flu; although the virus was not as virulent as the 1918 strain, over one million died worldwide. The next pandemic occurred when Hong Kong flu emerged in 1968, a new strain of the virus that replaced the 1957 strain. Affecting mainly the elderly, the 1968 pandemic was the least severe, but 33,800 were killed in the US. New strains of influenza virus often originate in East Asia; in rural China the concentration of ducks, pigs, and humans in close proximity is the highest in the world.The most recent pandemic occurred in 2009, but none of the last three has caused anything near the devastation seen in 1918. Exactly why the strain of influenza that emerged in 1918 was so devastating is a question that still remains unanswered.
Arboviruses are viruses that are transmitted to humans and other vertebrates by blood-sucking insects. These viruses are diverse; the term "arbovirus" – which was derived from "arthropod-borne virus" – is no longer  used in formal taxonomy because many species of virus are known to be spread in this way. There are more than 500 species of arboviruses, but in the 1930s only three were known to cause disease in humans: yellow fever virus, dengue virus and Pappataci fever virus. More than 100 of such viruses are now known to cause human diseases including encephalitis.Yellow fever is the most notorious disease caused by a flavivirus. The last major epidemic in the US occurred in 1905. During the building of the Panama Canal thousands of workers died from the disease. Yellow fever originated in Africa and the virus was brought to the Americas on cargo ships, which were harbouring the Aedes aegypti mosquito that carries the virus. The first recorded epidemic in Africa occurred in Ghana, in West Africa, in 1926. In the 1930s the disease re-emerged in Brazil. Fred Soper, an American epidemiologist (1893–1977), discovered the importance of the sylvatic cycle of infection in non-human hosts, and that infection of humans was a "dead end" that broke this cycle. Although the yellow fever vaccine is one of the most successful ever developed, epidemics  continue to occur. In  1986–91 in West Africa,  over 20,000 people were infected, 4,000 of whom died.In the 1930s, St. Louis encephalitis, eastern equine encephalitis and western equine encephalitis emerged in the US. The virus that causes La Crosse encephalitis was discovered in the 1960s, and West Nile virus arrived in New York   in 1999. As of 2010, dengue virus is the most prevalent arbovirus and increasingly virulent strains of the virus have spread across Asia and the Americas.
Hepatitis is a disease of the liver that has been recognised since antiquity.  Symptoms include jaundice, a yellowing of the skin, eyes and body fluids.  There are numerous causes, including viruses – particularly hepatitis A virus, hepatitis B virus and hepatitis C virus.  Throughout history epidemics of jaundice have been reported, mainly affecting soldiers at war. This "campaign jaundice"  was common in the Middle Ages. It occurred among Napoleon's armies and during most of the major conflicts of the 19th and 20th centuries, including the American Civil War, where over 40,000 cases and around 150 deaths were reported. The viruses that cause epidemic jaundice were not discovered until the middle of the 20th century. The names for epidemic jaundice, hepatitis A, and for blood-borne infectious jaundice, hepatitis B, were first used in 1947, following a publication in 1946 giving evidence that the two diseases were distinct. In the 1960s, the first virus  that could cause hepatitis was discovered. This was hepatitis B virus, which was named after the disease it causes. Hepatitis A virus was  discovered in 1974.
The discovery of hepatitis B virus and the invention of tests to detect it have radically changed many medical, and some cosmetic procedures.  The screening of donated blood, which was introduced in the early 1970s, has dramatically reduced the transmission of the virus.  Donations of human blood plasma and Factor VIII collected before 1975 often contained infectious levels of hepatitis B virus. Until the late 1960s, hypodermic needles were often reused by medical professionals, and tattoo artists' needles were a common source of infection. In the late 1990s, needle exchange programmes were established in Europe and the US to prevent the spread of infections by intravenous drug users. These measures also helped to reduce the subsequent impact of HIV and hepatitis C virus.
Epizootics are outbreaks (epidemics) of disease among non-human animals. During the 20th century significant epizootics of viral diseases in animals, particularly livestock, occurred worldwide. The many diseases caused by viruses included foot-and-mouth disease, rinderpest of cattle, avian and swine influenza, swine fever and bluetongue of sheep. Viral diseases of livestock can be devastating both to farmers and the wider community, as the outbreak of foot-and-mouth disease in the UK in 2001 showed.First appearing in East Africa in 1891, rinderpest, a disease of cattle, spread rapidly across Africa. By 1892, 95 per cent of the cattle in East Africa had died. This resulted in a famine that devastated the farmers and nomadic people, some of whom were entirely dependent on their cattle. Two thirds of the population of Maasai people died. The situation was made worse by epidemics of smallpox that followed in the wake of the famine. In the early years of the 20th century rinderpest was common in Asia and parts of Europe. The prevalence of the disease was steadily reduced during the century by control measures that included vaccination. By 1908 Europe was free from the disease. Outbreaks did occur following the Second World War, but these were quickly controlled. The prevalence of the disease increased in Asia, and in 1957 Thailand had to appeal for aid because so many buffaloes had died that the paddy fields could not be prepared for rice growing. Russia west of the Ural Mountains remained free from the disease – Lenin approved several laws on the control of the disease – but cattle in eastern Russia were constantly infected with rinderpest that originated in Mongolia and China where the prevalence remained high. India controlled the spread of the disease, which had retained a foothold in the southern states of Tamil Nadu and Kerala, throughout the 20th century, and had eradicated the disease by 1995. Africa suffered two major panzootics in the 1920s and 1980s. There was a severe outbreak in Somalia in 1928 and the disease was widespread in the country until 1953. In the 1980s, outbreaks in Tanzania and Kenya were controlled by the use of 26 million doses of vaccine, and a recurrence of the disease in 1997 was suppressed by an intensive vaccination campaign. By the end of the century rinderpest had been eradicated from most countries. A few pockets of infection remained in Ethiopia and Sudan, and in 1994 the Global Rinderpest Eradication Programme was launched by the Food and Agriculture Organization (FAO) with the aim of global eradication by 2010. In May 2011, the FAO and the World Organisation for Animal Health announced that "rinderpest as a freely circulating viral disease has been eliminated from the world."Foot-and-mouth disease is a highly contagious infection caused by an aphthovirus, and is classified in the same family as poliovirus. The virus has infected animals, mainly ungulates, in Africa since ancient times and was probably brought  to the Americas in the 19th century by imported livestock.  Foot-and-mouth disease is rarely fatal, but the economic losses incurred by outbreaks in sheep and cattle herds can be high. The last occurrence  of the disease in the US was in 1929, but as recently as 2001, several large outbreaks occurred throughout the UK and thousands of animals were killed and burnt.The natural hosts of influenza viruses are pigs and birds, although it has probably infected humans since antiquity. The virus can cause mild to severe epizootics in wild and domesticated animals. Many species of wild birds migrate and this has spread influenza across the continents throughout the ages. The virus has evolved into numerous strains and continues to do so, posing an ever-present threat.In the early years of the 21st century epizootics in livestock caused by viruses continue to have serious consequences. Bluetongue disease, a disease caused by an orbivirus broke out in sheep in France in 2007. Until then the disease had been mainly confined to the Americas, Africa, southern Asia and northern Australia, but it is now an emerging disease around the Mediterranean.
During the 20th century, many "old" diseases of plants were found to be caused by viruses. These included maize streak and cassava mosaic disease.
As with humans, when plants thrive in close proximity, so do their viruses. This can cause huge economic losses and human tragedies. In Jordan during the 1970s, where tomatoes and cucurbits (cucumbers, melons and gourds) were  extensively grown, entire fields were infected with viruses. Similarly, in Côte d'Ivoire, thirty different viruses infected crops such as legumes and vegetables. In Kenya cassava mosaic virus, maize streak virus and groundnut viral diseases caused the loss of up to 70 per cent of the crop.Cassava is the most abundant crop that is grown in eastern Africa and it is a staple crop for more than 200 million people. It was introduced to Africa from South America and grows well in soils with poor fertility. The most important disease of cassava is caused by cassava mosaic virus, a geminivirus, which is transmitted between plants by whiteflies. The disease was first recorded in 1894 and outbreaks of the disease occurred in eastern Africa throughout the 20th century,   often resulting in famine.In the 1920s the sugarbeet growers in the western US suffered huge economic loss caused by damage done to their crops by the leafhopper-transmitted beet curly top virus. In 1956, between 25 and 50 per cent of the rice crop in Cuba and Venezuela was destroyed by rice hoja blanca virus. In 1958, it caused the loss of many rice fields in Colombia. Outbreaks recurred in 1981, which caused losses of up to 100 per cent. In Ghana between 1936 and 1977, the mealybug-transmitted cacao swollen-shoot virus caused the loss of 162 million cacao trees, and additional trees were lost at the rate of 15 million each year. In 1948, in Kansas, US, seven per cent of the wheat crop was destroyed by wheat streak mosaic virus, spread by the wheat curl mite  (Aceria tulipae). In the 1950s papaya ringspot virus – a potyvirus – caused a devastating loss of solo papaya crops on Oahu, Hawaii. Solo papaya had been introduced to the island in the previous century but the disease had not been seen on the island before the 1940s.Such disasters occurred when human intervention caused ecological changes by the introduction of crops to new vectors and viruses. Cacao is native to South America and was introduced to West Africa in the late 19th century. In 1936, swollen root disease had been transmitted to plantations by mealybugs from indigenous trees. New habitats can trigger outbreaks of plant virus diseases. Before 1970, the rice yellow mottle virus was only found in the Kisumu district of Kenya, but following the irrigation of large areas of East Africa and extensive rice cultivation, the virus spread throughout East Africa. Human activity  introduced plant viruses to native crops. The citrus tristeza virus (CTV) was introduced to South America from Africa between 1926 and 1930. At the same time, the aphid Toxoptera citricidus was carried from Asia to South America and this accelerated the transmission of the virus. By 1950, more than six million citrus trees had been killed by the virus in São Paulo, Brazil. CTV and citrus trees probably coevolved for centuries in their original countries. The dispersal of CTV to other regions and its interaction with new citrus varieties resulted in devastating outbreaks of plant diseases. Because of the problems caused by the introduction – by humans – of plant viruses, many countries have strict importation controls on any materials that can harbour dangerous plant viruses or their insect vectors.
Emerging viruses are those that have only relatively recently infected the host species.  In humans, many emerging viruses have come from other animals. When viruses jump to other species the diseases caused in humans are called zoonoses or zoonotic infections.
Severe acute respiratory syndrome (SARS) is caused by a new type of coronavirus. Other coronaviruses were known to cause mild infections in humans, so the virulence and rapid spread of this novel virus strain caused alarm among health professionals as well as public fear. The fears of a major pandemic were not realised, and by July 2003, after causing around 8,000 cases and 800 deaths, the outbreak had ended. The exact origin of the SARS virus is not known, but evidence suggests that it came from bats.
West Nile virus, a flavivirus,  was first identified in 1937 when it was found in the blood of a feverish woman. The virus, which is carried by mosquitoes and birds, caused outbreaks of infection in North Africa and the Middle East in the 1950s and by the 1960s horses in Europe  fell victim. The largest outbreak in humans occurred in 1974 in Cape Province, South Africa and 10,000 people became ill. An increasing frequency of epidemics and epizootics (in horses) began in 1996, around the Mediterranean basin, and by 1999 the virus had reached New York City. Since then the virus has spread throughout the US. In the US, mosquitoes carry the highest amounts of virus in late summer, and the number of cases of the disease increases in mid July to early September. When the weather becomes colder, the mosquitoes die and the risk of disease decreases. In Europe, many outbreaks have occurred;  in 2000 a surveillance programme began in the UK to monitor the incidence of the virus in humans, dead birds, mosquitoes and horses. The mosquito (Culex modestus) that can carry the virus breeds on the marshes of north Kent. This mosquito species was not previously thought to be present in the UK, but it is widespread in southern Europe where it carries West Nile virus.
In 1997 an outbreak of respiratory disease occurred in Malaysian farmers and their pigs. More than 265 cases of encephalitis, of which 105 were fatal, were recorded. A new paramyxovirus was discovered in a victim's brain; it was named Nipah virus, after the village where he had lived. The infection was caused by a virus from fruit bats, after their colony had been disrupted by deforestation. The bats had moved to trees nearer the pig farm and the pigs caught the virus from their droppings.
Several highly lethal viral pathogens are members of the Filoviridae. Filoviruses are filament-like viruses that cause viral haemorrhagic fever, and include the Ebola and Marburg viruses. The Marburg virus attracted widespread press attention in April 2005 after an outbreak in Angola. Beginning in October 2004 and continuing into 2005, there were 252 cases including 227 deaths.The Ebola virus epidemic in West Africa, which began in 2013, is the most devastating since the emergence of HIV. The initial outbreak occurred in December 2013 in Meliandou, a village in southern Guinea. Among the first victims were a two-year-old boy, his three-year-old sister, their mother and grandmother. After the grandmother's funeral, which was attended  by her family and caregivers, the disease spread to neighbouring villages. By March 2014 the outbreak was severe enough to raise the concern of local health officials who reported it to the Guinean Ministry of Health. By the middle of the year the epidemic had spread to Liberia and Sierra Leone. As of June 2015, the World Health Organization reported over 27,000 cases of the disease, which had resulted in more than 11,000 deaths.The natural source of Ebola virus is probably bats.  Marburg viruses are transmitted to humans by monkeys, and Lassa fever by rats (Mastomys natalensis). Zoonotic infections can be severe because humans often have no natural resistance to the infection and it is only when viruses become well-adapted to new host  that their virulence decreases. Some zoonotic infections are often "dead ends", in that after the initial outbreak the rate of subsequent infections subsides because the viruses are not efficient at spreading from person to person.The beginning of the 21st century saw an increase in the global awareness of devastating epidemics in  developing countries, which, in previous decades had passed relatively unnoticed by the international health community.
Sir Peter Medawar (1915–1987) described a virus as "a piece of bad news wrapped in a protein coat". With the exception of the bacteriophages, viruses had a well-deserved reputation for being nothing but the cause of diseases and death. The discovery of the abundance of viruses and their overwhelming presence in many ecosystems has led modern virologists to reconsider their role in the biosphere.It is estimated that there are about 1031 viruses on Earth. Most of them are bacteriophages, and most are in the oceans. Microorganisms constitute more than 90 per cent of the biomass in the sea, and it has been estimated that viruses kill approximately 20 per cent of this biomass each day and that there are fifteen times as many viruses in the oceans as there are bacteria and archaea. Viruses are the main agents responsible for the rapid destruction of harmful algal blooms, which often kill other marine life, and help maintain the ecological balance of different species of marine blue-green algae, and thus adequate oxygen production for life on Earth.The emergence of strains of bacteria that are resistant to a broad range of antibiotics has become a problem in the treatment of bacterial infections. Only two new classes of antibiotics have been developed in the past 30 years, and novel ways of combating bacterial infections are being sought. Bacteriophages were first used to control bacteria in the 1920s, and a large clinical trial was conducted by Soviet scientists in 1963. This work was unknown outside the Soviet Union until the results of the  trial were published in the West in 1989. The recent and escalating problems caused by antibiotic-resistant bacteria has stimulated a renewed interest in the use of  bacteriophages and phage therapy.The Human Genome Project has revealed the presence of numerous viral DNA sequences scattered throughout  the human genome. These sequences make up around eight per cent of human DNA, and appear to be the remains of ancient retrovirus infections of human ancestors. These pieces of DNA have firmly established themselves in human DNA. Most of this DNA is no longer functional, but some of these friendly viruses have brought with them novel genes that are important in human development. Viruses have transferred important genes to plants. About ten per cent of all photosynthesis uses the products of genes that have been transferred to plants from blue-green algae by viruses.

The Socialist Soviet Republic of Abkhazia (SSR Abkhazia) was a short-lived republic within the Caucasus region of the Soviet Union that covered the territory of Abkhazia, and existed from 31 March 1921 to 19 February 1931. Formed in the aftermath of the Red Army invasion of Georgia in 1921, it was independent until 16 December 1921, when it agreed to a treaty uniting it with the Georgian Soviet Socialist Republic (Georgian SSR). The SSR Abkhazia was largely similar to an autonomous Soviet republic, though it retained de facto independence from Georgia, being given certain features only full union republics had, like its own military units. Through its status as a "treaty republic" with Georgia, Abkhazia joined the Transcaucasian Soviet Federative Socialist Republic, which united Armenian, Azerbaijani, and Georgian SSRs into one federal unit, when the latter was formed in 1922. The SSR Abkhazia was abolished in 1931 and replaced with the Abkhaz Autonomous Soviet Socialist Republic within the Georgian SSR.
Throughout its existence, the SSR Abkhazia was led by Nestor Lakoba, who served officially as the Chairman of the Council of People's Commissars but controlled the republic to such an extent it was jokingly referred to as "Lakobistan". Due to Lakoba's close relationship with Soviet leader Joseph Stalin, collectivisation was delayed until after Abkhazia was incorporated into Georgia. Abkhazia remained a major tobacco producer in this era, growing over half of the USSR's supply. It also produced other agricultural produce, including tea, wine, and citrus fruits, leading to Abkhazia being one of the wealthiest regions in the Soviet Union. Its sub-tropical climate also made it a prime holiday destination; Stalin and other Soviet leaders had dachas (holiday homes) in the region and spent considerable time there.
An ethnically diverse region, Abkhazia was nominally led by the Abkhaz people, who made up less than 30 percent of the population. Other major groups included Georgians, Armenians, Greeks, and Russians. Even though they did not form the majority, the Abkhaz were heavily favoured and the Abkhaz language was promoted as a result of the korenizatsiia policies of the era. An Abkhaz national identity was promoted through these policies, leading to the rise of Abkhaz nationalism. The main legacy of the SSR Abkhazia is that for the first time in modern history, it created a defined geographic entity under the name Abkhazia. Though the quasi-independent republic was downgraded in 1931, the Abkhaz people did not forget that it had existed. With the advent of glasnost and perestroika in the late 1980s, Abkhaz leaders called for their state to be re-formed and secede from Georgia, citing the SSR Abkhazia as a precedent. This led to them restoring the 1925 SSR Abkhazian constitution, which led to the 1992–1993 war between Abkhazian secessionists and Georgia, and the modern Abkhaz–Georgian conflict.
The Russian Empire annexed Abkhazia in the early nineteenth century and had consolidated its authority over the region by 1864. Reluctant to create ethno-territorial units, the Russian authorities incorporated the region into the Kutais Governorate. Large-scale population transfers saw the ethnic composition of Abkhazia radically altered, with thousands of ethnic Abkhaz expelled and ethnic Mingrelians brought in to replace them. After the 1917 February Revolution, which ended the Russian Empire, the status of Abkhazia became contested and was unclear. Free from Russian rule, it considered joining the Mountainous Republic of the Northern Caucasus in 1917, but ultimately decided against this due to the distance between Abkhazia and the rest of the groups involved. In February 1918, Abkhaz Bolsheviks attempted to create a commune—a similar system to the soviets (councils) being formed in Russia. This was unsuccessful and the Bolshevik leaders, Efrem Eshba and Nestor Lakoba, fled. The Abkhaz People's Council (APC) was formed in the aftermath and effectively controlled the region. When the Democratic Republic of Georgia was formed in May 1918, it annexed Abkhazia, considering it an integral part of its territory. Georgia never fully established control of the region, leaving the APC to rule it until the Bolshevik invasion of 1921.The status of Abkhazia was confirmed in the Georgian constitution of 1921. Article 107 guaranteed "Abkhazeti (district of Soukhoum)" autonomy for "the administration of their affairs". The constitution was proclaimed after the Red Army invasion of Georgia in February 1921; the nature of the promised autonomy was never determined. According to the historian Timothy Blauvelt, this had a lasting legacy in the region because it marked the first time in modern history Abkhazia was defined as a distinct geographic entity.
On 15 February 1921, the Red Army invaded Georgia. Abkhazia was invaded two days later. Eshba and Lakoba returned to Abkhazia before the invasion and formed a Revolutionary Committee (Revkom) in preparation for a Bolshevik government. Sukhumi, the capital, was captured on 4 March. With fighting in Georgia continuing, the Revkom, who did not expect to be the sole authority over Abkhazia, took advantage of the confusion and moved to declare Abkhazia an independent republic. They sent a telegram to Moscow asking for advice on how to proceed, and suggested joining the Russian Soviet Federative Socialist Republic, but Sergo Ordzhonikidze—a leading Bolshevik and the leader of the Caucasus Bureau (Kavbiuro)—dismissed the idea. As a result, on 31 March 1921, it declared that "at the will of workers a new Socialist Soviet Republic of Abkhazia is born." This made Abkhazia a nominally independent republic with the understanding on both the Abkhaz and Georgian sides that eventually Abkhazia would join the newly-formed Georgian Soviet Socialist Republic (Georgian SSR). Until then it was regarded as being completely detached from Georgia and was treated as such. The Georgian Revkom, the governing body of the Georgian SSR, welcomed Abkhazia in a telegram on 21 May 1921, and said the form of relations should be settled during the first Workers' Congresses of both republics.
The Abkhaz Revkom, in a position of power, was reluctant to schedule a congress to determine the future status of Abkhazia because it would mean relinquishing control over the region. The Kavbiuro forced the Revkom to act and negotiations for a treaty between Abkhazia and Georgia began in October 1921. The result, signed on 16 December 1921, was a two-article treaty:
1. SSR Georgia and SSR Abkhazia enter into political, military and financial-economic union. 2. In order to fulfill the aforementioned goal both governments declare the merging of the following Commissariats: a) military, b) finance, c) peoples' agriculture, d) post and telegraph, e) ChKa, f) RKI, g) People's Commissariat of Justice, and h) [Commissariat of] Sea Transport.
The treaty united the two states, leaving Abkhazia as a "treaty republic" nominally subservient to Georgia. The special status of Abkhazia within Georgia was reinforced in the 1922 Georgian constitution, which mentioned the "special union treaty" between the two. The 1925 Abkhazian constitution noted it was united with Georgia "on the base of a special treaty". On 13 December 1922, while united with Georgia, Abkhazia joined the Transcaucasian Socialist Federative Soviet Republic (TSFSR), along with Armenia and Azerbaijan. This new federation was created ostensibly for economic purposes, but was more likely done to consolidate Soviet control over the region, which had been contentious. Abkhazia was mostly treated as an autonomous region of Georgia, though unlike other autonomous states in the Soviet Union, it had its own national symbols—a flag and coat of arms—and national army units, a right only given to full republics. The coat of arms was initially described in the 1925 constitution as being "composed of a golden hammer and sickle on the background of the Abkhazian landscape with inscription in the Abkhaz language 'SSR Abkhazia'". This was slightly modified in 1926, when the republican (and Soviet-wide) motto "Proletarians of all countries, unite!" was written in Abkhaz, Georgian, and Russian (previously it had only been written in Abkhaz). It also had its own constitution, created on 1 April 1925, another right only granted to full republics.The union with Georgia was not popular among the Abkhaz populace or leadership. It was also received poorly in Georgia, where it was regarded as a ploy by the Bolsheviks to divert Georgian hostility from the authorities in Moscow towards the Abkhaz, as the Georgians were one of the most hostile groups towards the Bolsheviks. As the only "treaty republic" in the USSR, the exact status of the SSR Abkhazia concerned the Soviet and Georgian authorities, which did not want other regions to demand a similar status. To resolve this it was decided to downgrade Abkhazia, and on 19 February 1931 it was re-formed as the Abkhaz Autonomous Soviet Socialist Republic, subservient to the Georgian SSR while remaining a member of the TSFSR. The move was met with public protests, the first large-scale protests in Abkhazia against the Soviet authorities.
Initially the Abkhaz Revkom, led by its chairman Efrem Eshba, controlled Abkhazia until a more permanent body could be established. On 17 February 1922 the Council of People's Commissars was established, and Nestor Lakoba was elected its Chairman, becoming the de facto head of the republic; this was a formality for Lakoba, who had effectively been in control of Abkhazia since the Bolsheviks took control in 1921. Alongside Eshba, he had been a leading Bolshevik in the aftermath of the Russian Revolution. Lakoba and Eshba led two abortive attempts to seize Abkhazia in February and April 1918. After the latter attempt failed, they both fled, only returning in March 1921 after Bolshevik control had been consolidated; Eshba was soon transferred to other positions, leaving Lakoba alone as the head of Abkhazia.Lakoba effectively controlled Abkhazia as a personal fiefdom, which was jokingly referred to as "Lakobistan", and his status as head of the republic was never contested or challenged. He resisted many of the repressive policies that were being implemented elsewhere in the Soviet Union, including collectivisation. Lakoba also financially supported the Abkhaz nobility, which he was able to do because of his close personal relationship with Soviet leader Joseph Stalin.
Abkhazia was a major producer of tobacco during the Soviet era. In the 1930s, it was responsible for up to 52 percent of the Soviet Union's tobacco exports. Other agricultural products, including tea, wine, and citrus fruits—especially tangerines—were produced in large quantities, making Abkhazia one of the most well-off regions in the entire Soviet Union, and considerably richer than Georgia. The export of these resources turned the region into "an island of prosperity in a war-ravaged Caucasus". Several factories were also built in the region as part of the overall development of the Soviet Union, though they had less impact on the overall economic strength of Abkhazia.Abkhazia was also prized as a major holiday destination for both the Soviet elite and the general population. Stalin visited annually throughout the 1920s and was joined by his associates from the Kremlin, who used this time to gain his trust. As host, Lakoba grew increasingly close to Stalin and became a confidant of his, allowing him to keep his dominant position over Abkhazia. This was most apparent when Lakoba refused to implement collectivisation, arguing that there were no kulaks (affluent peasants) in the state. Such a policy was defended by Stalin, who said the anti-kulak policy did not "take account of the specific peculiarities of Abkhaz social structure and made the mistake of mechanically transferring Russian models of social engineering to Abkhaz soil". Collectivisation was first carried out after Abkhazia was downgraded in 1931, and fully implemented in 1936 after Lakoba's death.Throughout the SSR's existence, the Soviet ruble was its official currency.
The SSR Abkhazia was an ethnically diverse region, whose demographics changed considerably in the decades after its annexation by Russia. Up to 100,000 Abkhaz had been deported in the late nineteenth century, mainly to the Ottoman Empire. By the time the SSR Abkhazia was formed, ethnic Abkhaz comprised less than 30 percent of the population. The korenizatsiia (nativization) policy implemented in this era, which was to promote minority groups within the USSR, saw the numbers of Abkhaz increase: between 1922 and 1926, ethnic Abkhaz grew by roughly 8%, while the number of ethnic Georgians dropped by 6%. Thus, according to the 1926 Soviet census, the only census conducted during the SSR's existence, the number of ethnic Abkhaz reached 55,918 or around 27.8% of the total population (which numbered 201,016), while the number of Georgians was around 67,494 (36%). Other major ethnic groups counted in the 1926 census were Armenians (25,677, or 12.7 percent), Greeks (14,045, or 7 percent), and Russians (12,553, or 6.2 percent).The script used for the Abkhaz language was modified during the era of the SSR Abkhazia. Under korenizatsiia the Abkhaz were not considered one of the "advanced" peoples in the USSR, and thus saw an increased focus on their national language and cultural development. As part of these policies, Abkhaz—along with many other regional languages in the USSR—was Latinized in 1928, moving it away from the original Cyrillic-based script. Emphasis was placed on developing Abkhaz culture, which was heavily promoted and financed. To further this, an Abkhazian Scientific Society was created in 1922, while an Academy of Abkhazian Language and Literature was founded in 1925.In recognition of the multiple ethnic groups within Abkhazia, Article 8 of the 1925 Abkhaz constitution called for three official languages—Abkhaz, Georgian, and Russian—while a later amendment stated, "all nationalities populating the SSR Abkhazia are guaranteed the right of free development and use of the native language both in national-cultural and in general state agencies". Most of the population did not understand Abkhaz so Russian was the dominant language of government while local regions used the language that was most prevalent there.
The exact status of Abkhazia as a "treaty republic" was never clarified during its existence, and historian Arsène Saparov has suggested even officials at the time did not know what the phrase meant. The status had symbolic meaning to the Abkhaz people, who never forgot they had, at least in theory, an independent state. With the advent of glasnost and perestroika in the 1980s, calls for Abkhazia to restore its status began. An assembly at Lykhny in 1989 called for the Soviet authorities to make Abkhazia a full union republic, claiming the SSR Abkhazia as a precedent for this move. When Abkhazia declared independence in 1990, it requested the restoration of the 1925 constitution, which called for Abkhazia and Georgia to unite, allowing for the possibility of a future union between the two states. The restoration of the 1925 constitution was a pretext for the 1992–1993 war and the ensuing dispute over the status of Abkhazia, which has led to Abkhazia being de facto independent of Georgia since 1992.

Chinese society during the Song dynasty (960–1279) was marked by political and legal reforms, a philosophical revival of Confucianism, and the development of cities beyond administrative purposes into centers of trade, industry, and maritime commerce. The inhabitants of rural areas were mostly farmers, although some were also hunters, fishers, or government employees working in mines or the salt marshes. Conversely, shopkeepers, artisans, city guards, entertainers, laborers, and wealthy merchants lived in the county and provincial centers along with the Chinese gentry—a small, elite community of educated scholars and scholar-officials.
As landholders and drafted government officials, the gentry considered themselves the leading members of society; gaining their cooperation and employment was essential for the county or provincial bureaucrat overburdened with official duties. In many ways, scholar-officials of the Song period differed from the more aristocratic scholar-officials of the Tang dynasty (618–907). Civil service examinations became the primary means of appointment to an official post as competitors vying for official degrees dramatically increased. Frequent disagreements amongst ministers of state on ideological and policy issues led to political strife and the rise of political factions. This undermined the marriage strategies of the professional elite, which broke apart as a social group and gave way to a multitude of families which provided sons for civil service.
Confucian or Legalist scholars in ancient China—perhaps as far back as the late Zhou dynasty (c. 1046–256 BC)—categorized all socio-economic groups into four broad and hierarchical occupations (in descending order): the shi (scholars, or gentry), the nong (peasant farmers), the gong (artisans and craftsmen), and the shang (merchants). Wealthy landholders and officials possessed the resources to better prepare their sons for the civil service examinations, yet they were often rivaled in their power and wealth by merchants of the Song period. Merchants frequently colluded commercially and politically with officials, despite the fact that scholar-officials looked down on mercantile vocations as less respectable pursuits than farming or craftsmanship. The military also provided a means for advancement in Song society for those who became officers, even though soldiers were not highly respected members of society. Although certain domestic and familial duties were expected of women in Song society, they nonetheless enjoyed a wide range of social and legal rights in an otherwise patriarchal society. Women's improved rights to property came gradually with the increasing value of dowries offered by brides' families.
Daoism and Buddhism were the dominant religions of China in the Song era, the latter deeply impacting many beliefs and principles of Neo-Confucianism throughout the dynasty. Ironically, Buddhism came under heavy criticism by staunch Confucian advocates and philosophers of the time. Older beliefs in ancient Chinese mythology, folk religion, and ancestor worship also played a large part in people's daily lives, as the Chinese believed that deities and ghosts of the spiritual realm frequently interacted with the living realm.
The Song justice system was maintained by policing sheriffs, investigators, official coroners, and exam-drafted officials who became county magistrates. Song magistrates were encouraged to apply both their practical knowledge as well as the written law in making judicial decisions that would promote societal morality. Advancements in early forensic science, a greater emphasis on gathering credible evidence, and careful recording by clerks of autopsy reports and witness testimonies aided authorities in convicting criminals.
Chinese cities of the Song period became some of the largest in the world, owing to technological advances and an agricultural revolution. Kaifeng, which served as the capital and seat of government during the Northern Song (960–1127), had some half a million residents in 1021, with another half-million living in the city's nine designated suburbs. By 1100, the civilian population within the city walls was 1,050,000; the army stationed there brought the total to 1.4 million. Hangzhou, the capital during the Southern Song (1127–1279), had more than 400,000 inhabitants during the late 12th century, primarily due to its trading position at the southern terminus of the Grand Canal, known as the lower Yangzi's "grain basket." During the 13th century, the city's population soared to approximately a million people, with the 1270 census counting 186,330 registered families living in the city. Although not as agriculturally rich as areas like western Sichuan, the region of Fujian also underwent a massive population growth; government records indicate a 1500% increase in the number of registered households from the years 742 to 1208.  With a thriving shipbuilding industry and new mining facilities, Fujian became the economic powerhouse of China during the Song period. The great seaport of China, Quanzhou, was located in Fujian, and by 1120 its governor claimed that the city's population had reached some 500,000. The inland Fujianese city of Jiankang was also very large at this time, with a population of about 200,000. Robert Hartwell states that from 742 to 1200 the population growth of North China increased by only 54% percent in comparison to the Southeast which grew by 695%, the middle Yangzi Valley by 483%, the Lingnan region by 150%, and the upper Yangzi Valley by 135%. From the 8th to 11th centuries the lower Yangzi Valley experienced modest population growth in comparison to other regions of South China. The shift of the capital to Hangzhou did not create an immediate dramatic change in population growth until the period from 1170 to 1225, when new polders allowed land reclamation for nearly all the arable land between Lake Tai and the East China Sea as well as the mouth of the Yangzi to the northern Zhejiang coast.
China's newly commercialized society was evident in the differences between its northern capital and the earlier Tang capital at Chang'an. A center of great wealth, Chang'an's importance as the political center eclipsed its importance as a commercial entrepôt; Yangzhou was the economic hub of China during the Tang period. On the other hand, Kaifeng's role as a commercial center in China was as important as its political role. After the curfew was abolished in 1063, marketplaces in Kaifeng were open every hour of the day, whereas a strict curfew was imposed upon the two official marketplaces of Tang era Chang'an starting at dusk; this curfew limited its commercial potential. Shopkeepers and peddlers in Kaifeng began selling their goods at dawn. Along the wide avenue of the Imperial Way, breakfast delicacies were sold in shops and stalls and peddlers offered hot water for washing the face at the entrances of bathhouses. Lively activity in the markets did not begin to wane until about the evening meal of the day, while noodle shops remained open all day and night. People in the Song era were also more eager to purchase houses located near bustling markets than in earlier periods. Kaifeng's wealthy, multi-story houses and common urban dwellings were situated along the streets of the city, rather than hidden inside walled compounds and gated wards as they had been in the earlier Tang capital.
The municipal government of Hangzhou enacted policies and programs that aided in the maintenance of the city and ensured the well-being of its inhabitants. In order to maintain order in such a large city, four or five guards were quartered in the city at intervals of about 300 yards (270 m). Their main duties were to prevent brawls and thievery, patrol the streets at night, and quickly warn the public when fires broke out. The government assigned 2,000 soldiers to 14 fire stations built to combat the spread of fire within the city, and stationed 1,200 soldiers in fire stations outside the city's ramparts.  These stations were placed 500 yards (460 m) apart, with watchtowers that were permanently manned by 100 men each. Like earlier cities, the Song capitals featured wide, open avenues to create fire breaks. However, widespread fires remained a constant threat. When a fire broke out in 1137, the government suspended the requirement of rent payments, alms of 108,840 kg (120 tons) of rice were distributed to the poor, and items such as bamboo, planks, and rush-matting were exempt from government taxation. Fires were not the only problem facing the residents of Hangzhou and other crowded cities. Far more than in the rural countryside, poverty was widespread and became a major topic of debate at the central court and in local governments. To mitigate its effects, the Song government enacted many initiatives, including the distribution of alms to the poor; the establishment of public clinics, pharmacies, and retirement homes; and the creation of paupers' graveyards. In fact, each administrative prefecture had public hospitals managed by the state, where the poor, aged, sick, and incurable could be cared for, free of charge.In order to maintain swift communication from one town or city to another, the Song laid out many miles of roadways and hundreds of bridges throughout rural China. They also maintained an efficient postal service nicknamed the hot-foot relay, which featured thousands of postal officers managed by the central government.  Postal clerks kept records of dispatches, and postal stations maintained a staff of cantonal officers who guarded mail delivery routes. After the Song period, the Yuan dynasty transformed the postal system into a more militarized organization, with couriers managed under controllers. This system persisted from the 14th century until the 19th century, when the telegraph and modern road-building were introduced to China from the West.
A wide variety of social clubs for affluent Chinese became popular during the Song period. A text dated 1235 mentions that in Hangzhou City alone there was the West Lake Poetry Club, the Buddhist Tea Society, the Physical Fitness Club, the Anglers' Club, the Occult Club, the Young Girls' Chorus, the Exotic Foods Club, the Plants and Fruits Club, the Antique Collectors' Club, the Horse-Lovers' Club, and the Refined Music Society.  No formal event or festival was complete without banquets, which necessitated catering companies.The entertainment quarters of Kaifeng, Hangzhou, and other cities featured amusements including snake charmers, sword swallowers, fortunetellers, acrobats, puppeteers, actors, storytellers, tea houses and restaurants, and brokers offering young women who could serve as hired maids, concubines, singing girls, or prostitutes.  These entertainment quarters, covered bazaars known as pleasure grounds, were places where strict social morals and formalities could be largely ignored. The pleasure grounds were located within the city, outside the ramparts near the gates, and in the suburbs; each was regulated by a state-appointed official. Games and entertainments were an all-day affair, while the taverns and singing girl houses were open until two o'clock in the morning. While being served by waiters and ladies who heated up wine for parties, drinking playboys in winehouses would often be approached by common folk called "idlers" (xianhan) who offered to run errands, fetch and send money, and summon singing girls.Dramatic performances, often accompanied by music, were popular in the markets. The actors were distinguished in rank by type and color of clothing, honing their acting skills at drama schools. Satirical sketches denouncing corrupt government officials were especially popular. Actors on stage always spoke their lines in Classical Chinese; vernacular Chinese that imitated the common spoken language was not introduced into theatrical performances until the subsequent Yuan dynasty. Although trained to speak in the erudite Classical language, acting troupes commonly drew their membership from one of the lowest social groups in society: prostitutes. Of the fifty some theatres located in the pleasure grounds of Kaifeng, four of these theatres were large enough to entertain audiences of several thousand each, drawing huge crowds which nearby businesses thrived upon.There were also many vibrant public festivities held in cities and rural communities. Martial arts were a source of public entertainment; the Chinese held fighting matches on lei tai, a raised platform without rails.  With the rise in popularity of distinctive urban and domestic activities during the Song dynasty, there was a decline in traditional outdoor Chinese pastimes such as hunting, horseback riding, and polo. In terms of domestic leisure, the Chinese enjoyed a host of different activities, including board games such as xiangqi and go. There were lavish garden spaces designated for those wishing to stroll, and people often took their boats out on the lake to entertain guests or to stage boat races.
In many ways, life for peasants in the countryside during the Song dynasty was similar to those living in previous dynasties. The people spent their days ploughing and planting in the fields, tending to their families, selling crops and goods at local markets, visiting local temples, and arranging ceremonies such as marriages. Cases of banditry, which local officials were forced to combat, occurred constantly in the countryside.There were varying types of land ownership and tenure depending on the topography and climate of one's locality. In hilly, peripheral areas far from trade routes, most peasant farmers owned and cultivated their own fields. In frontier regions such as Hunan and Sichuan, owners of wealthy estates gathered serfs to till their lands. The most advanced areas had few estates with serfs tilling the fields; these regions had long fostered wet-rice cultivation, which did not require centralized management of farming. Landlords set fixed rents for tenant farmers in these regions, while independent small farming families also owned their own lots.The Song government provided tax incentives to farmers who tilled lands along the edges of lakes, marshes, seas, and terraced mountain slopes. Farming was made possible in these difficult terrains due to improvements in damming techniques and using chain pumps to elevate water to higher irrigation planes. The 10th century introduction of early-ripening rice that could grow in varied climatic zones and topographic conditions allowed for a significantly large migration from the most productive lands that had been farmed for centuries into previously uninhabited areas in the surrounding hinterland of the Yangzi Valley and Southeast China, which experienced rapid development. The widespread cultivation of rice in China necessitated new trends of labor and agricultural techniques. An effective yield from rice paddies required careful transplanting of rows of rice seedlings, sufficient weeding, maintenance of water levels, and draining of fields for harvest. Planting and weeding often required a dirty day of work, since the farmers had to wade through the muddy water of the rice paddies on bare feet. For other crops, water buffalos were used as draft animals for ploughing and harrowing the fields, while properly aged and mixed compost and manure was constantly spread.
One of the fundamental changes in Chinese society from the Tang to the Song dynasty was the transformation of the scholarly elite, which included the scholar-officials and all those who held examination degrees or were candidates of the civil service examinations. The Song scholar-officials and examination candidates were better educated, less aristocratic in their habits, and more numerous than in the Tang period.  Following the logic of the Confucian philosophical classics, Song scholar-officials viewed themselves as highly moralistic figures whose responsibility was to keep greedy merchants and power-hungry military men in their place.  Even if a degree-holding scholar was never appointed to an official government post, he nonetheless felt himself responsible for upholding morality in society, and became an elite member of his community.Arguably the most influential factor shaping this new class was the competitive nature of scholarly candidates entering civil service through the imperial examinations. Although not all scholar-officials came from the landholding class, sons of prominent landholders had better access to higher education, and thus greater ability to pass examinations for government service. Gaining a scholarly degree by passing prefectural, circuit-level, or palace exams in the Song period was the most important prerequisite in being considered for appointment, especially to higher posts; this was a departure from the Tang period, when the examination system was enacted on a much smaller scale. A higher degree attained through the three levels of examinations meant a greater chance of obtaining higher offices in government. Not only did this ensure a higher salary, but also greater social prestige, visibly distinguished by dress. This institutionalized distinction of scholar-officials by dress included the type and even color of traditional silken robes, hats, and girdles, demarcating that scholar-official's level of administrative authority. This rigid code of dress was especially enforced during the beginning of the dynasty, although the prestigious clothing color of purple slowly began to diffuse through the ranks of middle and low grade officials.Scholar-officials and gentry also distinguished themselves through their intellectual pursuits. While some such as Shen Kuo (1031–1095) and Su Song (1020–1101) dabbled in every known field of science, study, and statecraft, Song elites were generally most interested in the leisurely pursuits of composing and reciting poetry, art collecting and antiquarianism. Yet even this pursuit could turn into a scholarly one. It was the official, historian, poet, and essayist Ouyang Xiu (1007–1072) who compiled an analytical catalogue of ancient rubbings on stone and bronze which pioneered ideas in early epigraphy and archeology. Shen Kuo even took an interdisciplinary approach to archeological study, in order to aid his work in astronomy, mathematics, and recording ancient musical measures. The scholar-official and historian Zeng Gong (1019–1083) reclaimed last chapters of the ancient Zhan Guo Ce, proofreading and editing the version that would become the accepted modern version. The ideal official and gentry scholars were also expected to employ these intellectual pursuits for the good of the community, such as writing local histories or gazetteers. In the case of Shen Kuo and Su Song, their pursuits in academic fields such as classifying pharmaceuticals and improving calendrical science through court work in astronomy fit this ideal.
Along with intellectual pursuits, the gentry exhibited habits and cultured hobbies which marked their social status and refinement. The erudite term of enjoying the company of the 'nine guests' (九客, jiuke)—an extension of the Four Arts of the Chinese Scholar—was a metaphor for accepted gentry pastimes of playing the Chinese zither, playing Chinese chess, Zen Buddhist meditation, ink (calligraphy and painting), tea drinking, alchemy, chanting poetry, conversation, and drinking wine. The painted artwork of the gentry shifted dramatically in style from Northern to Southern Song, due to underlying political, demographic, and social circumstance. Northern Song gentry and officials, who were concerned largely with tackling issues of national interest and not much for local affairs, preferred painting huge landscape scenes where any individuals were but tiny figures immersed within a larger context. During the Southern Song, political, familial, and social concerns became heavily embedded with localized interests; these changes correlate with the chief style of Southern Song paintings, where small, intimate scenes with a primary focus on individuals was emphasized.The wealthy families living on the estates of these scholar-officials – as well as rich merchants, princes, and nobles—often maintained a massive entourage of employed servants, technical staffs, and personal favorites. They hired personal artisans such as jewellers, sculptors, and embroiderers, while servants cleaned house, shopped for goods, attended to kitchen duties, and prepared furnishings for banquets, weddings, and funerals. Rich families also hosted literary men such as secretaries, copyists, and hired tutors to educate their sons. They were also the patrons of musicians, painters, poets, chess players, and storytellers.The historian Jacques Gernet stresses that these servants and favorites hosted by rich families represented the more fortunate members of the lower class. Other laborers and workers such as water-carriers, navvies, peddlers, physiognomists, and soothsayers "lived for the most part from hand to mouth." The entertainment business in the covered bazaars in the marketplace and at the entrances of bridges also provided a lowly means of occupation for storytellers, puppeteers, jugglers, acrobats, tightrope walkers, exhibitors of wild animals, and old soldiers who flaunted their strength by lifting heavy beams, iron weights, and stones for show. These people found the best and most competitive work during annual festivals. In contrast, the rural poor consisted mostly of peasant farmers. However, some in rural areas chose vocations centered chiefly around hunting, fishing, forestry, and state-offered occupations such as mining or working in the salt marshes.According to their Confucian ethics, elite and cultured scholar-officials viewed themselves as the pinnacle members of society (second only to the imperial family). Rural farmers were seen as the essential pillars that provided food for all of society; they were given more respect than the local or regional merchant, no matter how rich and powerful. The Confucian-taught scholar-official elite who ran China's vast bureaucracy viewed their society's growing interest in commercialism as a sign of moral decay. Nonetheless, Song Chinese urban society was teeming with wholesalers, shippers, storage keepers, brokers, traveling salesmen, retail shopkeepers, peddlers, and many other lowly commercial-based vocations.Despite the scholar-officials' suspicion and disdain for powerful merchants, the latter often colluded with the scholarly elite. The scholar-officials themselves often became involved in mercantile affairs, blurring the lines of who did and did not belong to the merchant class. Even rural farmers engaged in the small-scale production of wine, charcoal, paper, textiles, and other goods. Theoretically it was forbidden for an official to partake in private affairs of gaining capital while serving and receiving a salary from the state. In order to avoid ruining one's reputation as a moral Confucian, scholar-officials had to work through business intermediaries; as early as 955 a written decree revealed the use of intermediary agents for private business transactions with foreign countries. Since the Song government took over several key industries and imposed strict state monopolies, the government itself acted as a large commercial enterprise run by scholar-officials. The state also had to contend with the merchant and artisan guilds; whenever the state requisitioned goods and assessed taxes it dealt with guild heads, who ensured fair prices and fair wages via official intermediaries. Yet joining a guild was an immediate means to neither empowerment nor independence; historian Jacques Gernet states: "[the guilds] were too numerous and too varied to allow their influence to be felt."
From the scholar-official's view, the artisans and craftsmen were essential workers in society on a tier just below the farming peasants, and different from the merchants and traders who were considered parasitic. It was craftsmen and artisans who fashioned and manufactured all of the goods needed in Song society, such as standard-sized waterwheels and chain pumps made by skilled wheelwrights.  Although architects and carpenter builders were not as highly venerated as the scholar-officials, there were some architectural engineers and authors who gained wide acclaim at court and in the public sphere for their achievements. This included the official Li Jie (1065–1110), a scholar who was eventually promoted to high positions in government agencies of building and engineering. His written manual on building codes and procedures was sponsored by Emperor Huizong (r. 1100–1126) for these government agencies to employ and was widely printed for the benefit of literate craftsmen and artisans nationwide.  The technical written work of the earlier 10th-century architect Yu Hao was also given a great amount of praise by the polymath scholar-official Shen Kuo in his Dream Pool Essays of 1088.
Due to previous episodes of court eunuchs amassing power, they were looked upon with suspicion by scholar-officials and Confucian literati. Still, their association with inner palace life and their frequent appointments to high levels of military command provided them with significant prestige.  Although military officers with successful careers could gain a considerable amount of prestige, the soldier in Song society was looked upon with a bit of disdain by scholar-officials and cultured people.  This is best reflected in a Chinese proverb: "Good iron isn't used for nails; good men aren't used as soldiers." This attitude had several roots. Many people who enrolled themselves as soldiers in the armed forces were rural peasants in debt, many of them former workers of the salt trade who could not pay back their loans and had been reduced to flight. However, the prevailing attitude of gentry towards military servicemen stemmed largely from the knowledge of historical precedent, as military leaders in the late Tang dynasty and the Five Dynasties and Ten Kingdoms (907–960) period amassed more power than the civil officials, in some respects replacing them and the civilian government altogether. Song emperors expanded the civil service examination system and government school system in order to avoid the earlier scenario of domination by military strongmen over the civil order.
The first nationwide government-funded school system in China was established in the year 3 AD under Emperor Ping of Han (9 BC–5 AD). During the Northern Song dynasty, the government gradually reestablished an official school system after it was heavily damaged during the preceding Five Dynasties period. Government-established schools soon eclipsed the role of private academies by the mid-11th century. At the apex of higher education in the school system were the central schools located in the capital city, the Guozijian, the Taixue, and several vocational schools. The first major reform effort to rebuild prefectural and county schools was initiated by Chancellor Fan Zhongyan (989–1052) in the 1040s. Before this time, the bulk of funds allotted for the establishment of prefectural and county schools was left up to private financing and minimal amount of government funding; Fan's reform effort started the trend of greater government financing, at least for prefectural schools. Major expansion of educational facilities was initiated by Emperor Huizong, who used funds originally allotted for disaster relief and food-price stabilizing to fund new prefectural and county schools and demoted officials who neglected to repair, rebuild, and maintain these government schools. The historian John W. Chaffe states that by the early 12th century the state school system had 1,500,000 acres (6,100 km2) of land that could provide for some 200,000 student residents living in dormitories. After the widespread destruction of schools during the Jurchen invasions from the 1120s to 1140s, Emperor Gaozong of Song (r. 1127–1162) issued an edict to restore prefectural schools in 1142 and county schools in 1148, although the county schools by and large were reconstructed by the efforts of local county officials' private fundraising.
By the late 12th century, many critics of the examination system and government-run schools initiated a movement to revive private academies. During the course of the Southern Song, the academy became a viable alternative to the state school system. Even those that were semi-private or state-sponsored were still seen as independent of the state's influence and their teachers uninterested in larger, nationwide issues. One of the earliest academic institutions established in the Song period was the Yuelu Academy, founded in 976 during the reign of Emperor Taizu (r. 960–976). The Chinese scientist and statesman Shen Kuo was once the head chancellor of the Hanlin Academy, established during the Tang dynasty. The Neo-Confucian Donglin Academy, established in 1111, was founded upon the staunch teaching that adulterant influences of other ideologies such as Buddhism should not influence the teaching of their purely Confucian school. This belief hearkened back to the writings of the Tang essayist, prose stylist, and poet Han Yu (768–824), who was certainly a critic of Buddhism and its influence upon Confucian values. Although the White Deer Grotto Academy of the Southern Tang (937–976) had fallen out of use during the early half of the Song, the Neo-Confucian philosopher Zhu Xi (1130–1200) reinvigorated it.Zhu Xi was one of many critics who argued that government schools did not sufficiently encourage personal cultivation of the self and molded students into officials who cared only for profit and salary. Not all social and political philosophers in the Song period blamed the examination system as the root of the problem (but merely as a method of recruitment and selection), emphasizing instead the gentry's failure to take responsibility in society as the cultural elite. Zhu Xi also laid emphasis on the Four Books, a series of Confucian classics that would become the official introduction of education for all Confucian students, yet were initially discarded by his contemporaries. After his death, his commentary on the Four Books found appeal amongst scholar-officials and in 1241 his writings were adopted as mandatory readings for examination candidates with the support of Emperor Lizong (r. 1224–1264).
The number of applicants for the Imperial examinations far outmatched the actual number of jinshi, or "presented scholars" who were given official appointments in the Song dynasty. Five times more jinshi were accepted in the Song period than during the Tang, yet the larger number of degree holders did not lower the prestige of the degree. Rather, it encouraged more to enter and compete in the exams, which were held every three years.  Roughly 30,000 men took the prefectural exams in the early 11th century, increasing to nearly 80,000 around 1100, and finally to an astonishing 400,000 exam takers by the 13th century.  With these odds, the chances of an applicant passing the examination and becoming a graduate was 1 in 333. Once a degree was obtained, however, this did not ensure an immediate path to office. The total number of scholar-officials in the Tang was about 18,000, while the total number in the Song had only increased to about 20,000. With China's growing population and an almost stagnant number of officials accepted into government, the degree holders who were not appointed to office fulfilled an important role on the grassroots level of society. They became the local elite of their communities, while scholar-officials relied upon them for maintaining order and fulfilling various duties under their jurisdiction.An atmosphere of intellectual competition existed between aspiring Confucian scholars. Wealthy families were eager to gather stacks of published books for their personal libraries, collecting books that covered the Confucian classics as well as philosophical works, mathematical treatises, pharmaceutical documents, Buddhist sutras, and other literature aimed at the gentry class.  The advancement of widespread book manufacturing through woodblock printing and then movable type printing by the 11th century aided in the expansion of the number of educated candidates for the civil service exams. These developments also reduced the overall cost of books so that they became more accessible to those of lesser means.
Song scholar-officials were granted ranks, honors, and career appointments on the basis of merit, the standards of which were codified and more objective than those in the Tang dynasty. The anonymity of exam candidates guarded against fraud and favoritism by those who could judge papers based upon handwriting and/or signature calligraphy; a bureau of copyists was tasked with the job of recopying all the candidates' papers before grading. After passing the prefectural, provincial, and then palace exam (the most prestigious), scholarly degrees did not immediately ensure an appointment to office, but the more prestigious the degree, the more certain one's career in higher administrative posts would be. The central government held the exclusive right to appoint or remove officials. The case for removal was always carefully examined, since the central government kept a recorded dossier of reports on each official, stored in the capital for later review.
Ebrey states that meritocracy and a greater sense of social mobility were also prevalent in the civil service examination system, as the government held a list of all examination graduates, showing that only roughly half of those who passed had a father, or grandfather, or great-grandfather who served as a government official. However, Robert Hartwell and Robert P. Hymes state that this fact, first presented by Edward A. Kracke in 1947 and supported by Sudō Yoshiyuki and Ho Ping-ti, emphasizes the role of the nuclear family and only demonstrates three paternal ascendants of the candidates while ignoring the demographic reality of Song China, the significant proportion of males in each generation that had no surviving sons, and the role of the extended family. Male children with fathers who were incumbents in office had the advantage of early education and experience, as they were often appointed by their father to low-level staff positions. Yet with the so-called 'protection' (yin or yin-bu 荫补/蔭補) privilege this arrangement was extended to close relatives, as an elder brother, uncle, father-in-law, and even father-in-law to one's uncle could help one secure a future in office. The Song era poet Su Shi (1037–1101) wrote a poem called On the Birth of My Son, poking fun at the situation of children from affluent and politically connected backgrounds having the upper edge over bright children of lower status:
Robert Hartwell notes that in the Northern Song dynasty there were two types of elites who dominated the civil service: a founding elite and a professional elite. The founding elite consisted of the North China military governors of the 10th century, their associates, personal staffs, and bureaucrats who had served in the capitals of the administrations of the previous Five Dynasties. The professional bureaucracy consisted of elite families who had established residence in Kaifeng or subordinate capitals, claimed prestigious clan ancestry, had intermarried with other prominent families, had members in higher offices over generations, and periodically dominated Song government until the 12th century. The prominent families of this professional elite accounted for 18 of the 11th century chancellors, the highest official post. From 960 to 986, the founding military elite from Shanxi, Shaanxi, and Hebei represented 46% of fiscal offices, people from districts in Songzhou—the military governorship of the founding emperor—represented 22% of fiscal offices, and those from Kaifeng and Luoyang filled 13% of fiscal posts. In the same period, the founding elite and professional elite filled over 90% of policy-making positions. However, after 983, when the south had been conquered and consolidated into the empire, a semi-hereditary professional elite gradually replaced the founding elite. After 1086 not a single family of the founding elite had a member in either policy-making or financial positions. Between 998 and 1085, the 35 most important families of the professional elite represented only 5% of the families that had members in policy-making offices, yet they disproportionately held 23% of these positions. By the late 11th century the professional elite began to break apart as a distinguishable status group aiming for civil service. They were replaced by a multitude of local gentry lineages who had their children pursue a slew of different professions other than official careers. Hartwell states that this shift of power was the result of the professional elite's lineage strategies being undermined by the rise of factional partisan politics in the latter half of the 11th century.
Before the 1080s, the majority of officials drafted came from a regionally diverse background; afterwards, intraregional patterns of drafting officials became more common. Hartwell writes that during the Southern Song, the shift of power from central to regional administrations, the localized interests of the new gentry, the enforcement of prefectural quotas in preliminary examinations, and the uncertainties of a successful political career in the factionally split capital led many civil servants to choose positions that would allow them to remain in specific regions. Hymes demonstrates how this correlated with the decline in long-distance marriage alliances that had perpetuated the professional elite in the Northern Song, as the Southern Song gentry preferred local marriage prospects. It was not until the reign of Emperor Shenzong (r. 1068–1085) that the now heavily populated regions of South China began providing a quantity of officials in policy-making posts that were proportionate to their share of China's total population. From 1125 to 1205, about 80% of all those who held office in one of the six ministries of the central government had spent most of their low-grade official careers within the area of modern southern Anhui, southern Jiangsu, Zhejiang, and Fujian provinces. Almost 100% of these officials were born and buried within this southeastern macroregion.
Within the largest political divisions of the Song known as circuits (lu) there were a number of prefectures (zhou), which in turn were divided into the smallest political units of counties (xian); there were about 1,230 counties during the Song period. The prefect during the early Northern Song was the prime official of local government authority, who was the lowest regional official allowed to memorialize the throne, was primary tax collector, and head magistrate over several magistrates within his jurisdiction that dealt with civil disputes and maintaining order. By the late Northern Song, the growth in the number of counties with different proportions in population under a prefect's jurisdiction decreased the importance of the latter office, as it became more difficult for the prefect to manage the counties. This was part of a larger continuum of administrative trends from the Tang to Ming dynasties, with the gradual decline of importance of intermediate administrative units—the prefectures—alongside a shift of power from central government to large regional administrations; the latter experienced progressively less influence of central government in their routine affairs. In the Southern Song, four semi-autonomous regional command systems were established based on territorial and military units; this influenced the model of detached service secretariats which became the provincial administrations (sheng) of the Yuan (1279–1368), Ming (1368–1644), and Qing (1644–1912) dynasties. The administrative control of the Southern Song central government over the empire became increasingly limited to the circuits located in closer proximity to the capital at Hangzhou, while those farther away practiced greater autonomy.
After the tumultuous An Lushan Rebellion (755–763), the early Tang career path of officials rising in a hierarchy of six ministries—with Works given the lowest status and Personnel the highest—was changed into a system where officials chose specialized careers within one of the six ministries. The commissions of Salt and Iron, Funds, and Census that were created to deal with immediate financial crisis after An Lushan's insurrection were the influential basis for this change in career paths that became focused within functionally distinct hierarchies. The varied career backgrounds and expertise of early Northern Song officials meant that they were to be given specific assignment to work in only one of the ministries: Personnel, Revenue, Rites, War, Justice, or Works. As China's population increased and regional economies became more complex the central government could no longer handle the separate parts of the empire efficiently. As a result of this, in 1082 the reorganization of the central bureaucracy scrapped the hierarchies of commissions in favor of the early Tang model of officials advancing through a hierarchy of ministries, each with different levels of prestige.
In observing a multitude of biographies and funerary inscriptions, Hymes states that officials in the Northern Song era displayed a primary preoccupation with national interests, as they did not intervene in local or central government affairs for the benefit of their local prefecture or county. This trend was reversed in the Southern Song. Since the majority of central government officials in the Southern Song came from the macroregion of Anhui, Jiangsu, Zhejiang, and Fujian, Hartwell and Hymes state that there was a great amount of ad hoc local interests represented in central government policies.Lower-grade officials on the county and prefectural levels performed the necessary duties of administration such as collecting taxes, overseeing criminal cases, implementing efforts to fight famine and natural calamity, and occasionally supervising market affairs or public works. Since the growth of China's population far outmatched the total number of officials accepted as administrators in the Song government, educated gentry who had not been appointed to an official post were entrusted as supervisors of affairs in rural communities. It was the "upper gentry" of high-grade officials in the capital—comprising mostly those who passed the palace exams—who were in a position to influence and reform society.
The high echelons of the political scene during the Song dynasty left a notorious legacy of partisanship and strife among factions of state ministers. The careers of low-grade and middle-grade officials were largely secure; in the high ranks of the central administration, "reverses of fortune were to be feared," as Sinologist historian Jacques Gernet put it. The Chancellor Fan Zhongyan (989–1052) introduced a series of reforms between 1043 and 1045 that received heated backlash from the conservative element at court. Fan set out to erase corruption from the recruitment system by providing higher salaries for minor officials, in order to persuade them not to become corrupt and take bribes. He also established sponsorship programs that would ensure officials were drafted on their merits, administrative skills, and moral character more than their etiquette and cultured appearance.  However, the conservatives at court did not want their career paths and comfortable positions jeopardized by new standards, so they rallied to successfully halt the reforms.Inspired by Fan, the later Chancellor Wang Anshi (1021–1086) implemented a series of reforms in 1069 upon his ascendance to office. Wang promulgated a community-based law enforcement and civil order known as the Baojia system. Wang Anshi attempted to diminish the importance of landholding and private wealth in favor of mutual-responsibility social groups that shared similar values and could be easily controlled by the government. Just as scholar-officials owed their social prestige to their government degrees, Wang wanted to structure all of society as a mass of dependents loyal to the central government. He used various means, including the prohibition of landlords offering loans to tenants; this role was assumed by the government. Wang established local militias that could aid the official standing army and lessen the constrained state budget expenses for the military.  He set up low-cost loans for the benefit of rural farmers, whom he viewed as the backbone of the Song economy.  Since the land tax exacted from rural farmers filled the state treasury's coffers, Wang implemented a reform to update the land-survey system so that more accurate assessments could be gathered.  Wang removed the mandatory poetry requirement in the civil service exams, on the grounds that many otherwise skilled and knowledgeable Confucian students were being denied entry into the administration.  Wang also established government monopolies for tea, salt, and wine production. All of these programs received heavy criticism from conservative ministerial peers, who believed his reforms damaged local family wealth which provided the basis for the production of examination candidates, managers, merchants, landlords, and other essential members of society. Historian Paul J. Smith writes that Wang's reforms—the New Policies—represented the professional bureaucratic elite's final attempt to bring the thriving economy under state control to remedy the lack of state resources in combating powerful enemies to the north—the Liao and Western Xia.
Winston W. Lo argues that Wang's obstinate behavior and inability to consider revision or annulment of his reforms stemmed from his conviction that he was a latter-day sage. Confucian scholars of the Song believed that the 'way' (dao) embodied in the Five Classics was known by the ancient sages and was transmitted from one sage to another in an almost telepathic manner, but after it reached Mencius (c. 372–c. 289 BC) there was no one worthy of accepting the transference of the dao. Some believed that the long dormant dao could be revived if one were truly a sage; Lo writes of Song Neo-Confucianists, "it is this self-image which explained their militant stand in relation to conventional ethics and scholarship." Wang defined his life mission as restoring the unity of dao, as he believed it had not departed from the world but had become fragmented by schools of Confucian thought, each one propagating only half-truths. Lo asserts that Wang, believing that he was in possession of the dao, followed Yi Zhi and the Duke of Zhou's classic examples in resisting the wishes of selfish or foolish men by ignoring criticism and public opinion. If unflinching certitude in his sagehood and faultless reforms was not enough, Wang sought potential allies and formed a coalition that became known as the New Policies Group, which in turn emboldened his known political rivals to band together in opposition to him. Yet factional power struggles were not steeped in ideological discourse alone; cliques had formed naturally with shifting alliances of professional elite lineages and efforts to obtain a greater share of available offices for one's immediate and extended kinship over vying competitors. People such as Su Shi also opposed Wang's faction on practical grounds; for example, Su's critical poem hinting that Wang's salt monopoly hindered effective salt distribution.Wang resigned in 1076 and his leaderless faction faced uncertainty with the death of its patron emperor in 1085. The political faction led by the historian and official Sima Guang (1019–1086) then took control of the central government, allied with the dowager empress who acted as regent over the young Emperor Zhezong of Song (r. 1085–1100). Wang's new policies were completely reversed, including popular reforms like the tax substitution for corvée labor service.  When Emperor Zhezong came of age and replaced his grandmother as the state power, he favored Wang's policies and once again instituted the reforms in 1093. The reform party was favored during the reign of Huizong (r. 1100–1125) while conservatives were persecuted—especially during the chancellery of Cai Jing (1047–1126).  As each political faction gained advantage over the other, ministers of the opposing side were labeled "obstructionist" and were sent out of the capital to govern remote frontier regions of the empire. This form of political exile was not only politically damaging, but could also be physically threatening. Those who fell from favor could be sent to govern areas of the deep south where the deadly disease malaria was prevalent.
The Chinese philosophy of Confucius (551–479 BC) and the hierarchical social order his disciples adhered to had become embedded into mainstream Chinese culture since the reign of Emperor Wu of Han (r. 141–87 BC). During the Song dynasty, the entire Chinese society was theoretically modelled upon this familial social order of superiors and inferiors. Confucian dogma dictated what was proper moral behavior, and how a superior should regulate rewards or punishments when dealing with an inferior member of society or one's family. This is exemplified in the Tang law code, which was largely retained in the Song period. Gernet writes: "The family relationships supposed to exist in the ideal family were the foundation of the entire moral outlook, and even the law, in its total structure and its scale of penalties, was nothing but a codified expression of them."Under the Tang law code compiled in the 7th century, severe punishments were outlined for those who disobeyed or disrespected the hierarchical system of elders. Those who assaulted their parents could be put to death, those who assaulted an older brother could be put to forced labor, and those who assaulted an older cousin could be sentenced to caning. A household servant who killed his master could be sentenced to death, while a master who killed his servant would be arrested and forced into a year of hard labor for the state. Yet this reverence for elders and superiors was grounded in more than just secular Confucian discourse; Chinese beliefs of ancestor worship transformed the identity of one's parents into abstract, otherworldly figures. Song society was also built on social relationships governed not by abstract principles, but on the protection gained by devoting oneself to a superior.Perpetuating the family cult with many descendants was coupled with the notion that producing more children offered the family a layer of protection, reinforcing its power in the community. More children meant better odds of extending a family's power through marriage alliance with other prominent families, as well as better odds of having a child occupying a prestigious administrative post in government. Hymes notes that "elite families used such standards as official standing or wealth, prospects for office, length of pedigree, scholarly renown, and local reputation in choosing both sons-in-law and daughters-in-law." Since official promotion was considered by examination degree as well as recommendation to office by a superior, a family that acquired a significant amount of sons-in-law of high rank in the bureaucracy ensured kinship protection and prestigious career options for its members. Those who came from noteworthy families were treated with dignity, and a wider family influence meant a better chance for an individual to secure his own fortunes. No one was better prepared for society than one who gained plenty of experience in dealing with the members of his extended family, as it was common for upper-class families to have several generations living in the same household. However, one did not even have to share the same bloodline with others in order to build more social ties in their community. This could be done by accepting any number of artificial blood brothers in a ceremony assuring mutual obligations and shared loyalty.
In Song society, governed by the largely unaltered Tang era legal code, the act of primogeniture was not practiced in Chinese inheritance of property, and in fact was illegal. When the head of a family died, his offspring equally divided the property. This law was implemented in the Tang dynasty in order to challenge the powerful aristocratic clans of the northwest, and to prevent the rise of a society domineered by landed nobility. If an official family did not produce another official within a few generations, the future prospects of that family remaining wealthy and influential became uncertain.  Thus, the legal issues of familial inheritance had profound effects upon the rest of society.
When a member of the family died there were varying degrees of prostration and display of piety amongst family members, each one behaving differently according to the custom of kinship association with the deceased. There was to be no flashy or colorful attire while in the period of mourning, and proper funerary rituals were observed such as cleansing and clothing the deceased to rid him or her of impurities. This was one of the necessary steps in the observance of the deceased as one of the worshipped ancestors, which in turn raised the prestige of the family. Funerals were often expensive. A geomancer had to be consulted on where to bury the dead, caterers were hired to furnish the funeral banquet, and there was always the purchase of the coffin, which was burned along with paper images of horses, carriages, and servants in order for them to accompany the deceased into the next life. Due to the high cost of burial, most families opted for the cheaper practice of cremation. This was frowned upon by Confucian officials due to beliefs in the ancestral cult. They sought to ban the practice with prohibitions in 963 and 972; despite this, cremation amongst the poor and middle classes persisted. By the 12th century, the government came up with the solution of installing public cemeteries where a family's deceased could be buried on state owned property.
Historians note that women during the Tang dynasty were brazen, assertive, active, and relatively more socially liberated than Song women. Women of the Song period are typically seen as well educated and interested in expressing themselves through poetry, yet more reserved, respectful, "slender, petite and dainty," according to Gernet. Evidence of foot binding as a new trend in the Southern Song period certainly reinforces this notion. This trend had roots in Neo-Confucian beliefs according to Blake. "However, the greater number of documents due to more widespread printing reveal a much more complex and rich reality about family life and Song women. Through written stories, legal cases, and other documents, many different sources show that Song women held considerable clout in family decision-making, and some were quite economically savvy.  Men dominated the public sphere, while affluent wives spent most of their time indoors enjoying leisure activities and managing the household. However, women of the lower and middle classes were not solely bound to the domestic sphere. It was common for women to manage town inns, some to manage restaurants, farmers' daughters to weave mats and sell them on their own behalf, midwives to deliver babies, Buddhist nuns to study religious texts and sutras, female nurses to assist physicians, and women to keep a close eye on their own financial affairs. In the case of the latter, legal case documents describe childless widows who accused their nephews of stealing their property. There are also numerous mentions of women drawing upon their dowries to help their husband's sisters marry into other prominent families. One notable figure was Empress Liu 劉 (969-1033), the first empress in the Song dynasty, who wore the emperor’s robes while conducting an imperial sacrifice in the last year of her life.The economic prosperity of the Song period prompted many families to provide their daughters with larger dowries in order to attract the wealthiest sons-in-law to provide a stable life of economic security for their daughters. With large amounts of property allotted to a daughter's dowry, her family naturally sought benefits; as a result women's legal claims to property were greatly improved. Under certain circumstances, an unmarried daughter without brothers or a surviving mother without sons could inherit one-half of her father's share of undivided family property Under the Song law code, if an heirless man left no clear successor to his property and household, it was his widowed wife's right to designate her own heir in a process called liji ("adopting an heir"). If an heir was appointed by the parents' relatives after their deaths, the "appointed" heir did not have the same rights as a biological son to inherit the estate; instead he shared juehu ("extinct household") property with the parents' daughter(s), if there were any.Divorcing a spouse was permissible if there was mutual consent, while remarriage after the death of a spouse was common during the Song period. However, widows under post-Song dynasties did not often remarry, following the ethic of the Confucian philosopher Cheng Yi (1033–1107), who stated that it was better for a widow to die than lose her virtue by remarrying. Widows remarrying another after the death of a first spouse did not become common again until the late Qing dynasty (1644–1912), yet such an action was still regarded as morally inferior.
Despite advances in relative social freedoms and legal rights, women were still expected to attend to the duties of the home. Along with child-rearing, women were responsible for spinning yarn, weaving cloth, sewing clothing, and cooking meals. Women who belonged to families that sold silk were especially busy, since their duties included coddling the silkworms, feeding them chopped mulberry tree leaves, and keeping them warm to ensure that they would eventually spin their cocoons. In the family pecking order, the dominant female of the household was the mother-in-law, who was free to hand out orders and privileges to the wives of her sons. Mothers often had strong ties with their grown and married sons, since these men often stayed at home. If a mother-in-law could not find sufficient domestic help from the daughters-in-law, there was a market for women to be bought as maids or servants. There were also many professional courtesans (and concubines brought into the house) who kept men busy in the pursuits of entertainment, relations, and romantic affairs. It was also common for wives to be jealous and conniving towards concubines that their wealthy husbands brought home. Yet two could play at this game. Most concubines were found in the families of feudal lords and kings. The ideal of the chaste, modest, and pious young woman was somewhat distorted in urban settings such as Hangzhou and Suzhou, where there were greedy and flirtatious women, as one author put it. This author stated that the husbands of these women could not satisfy them, and so took on as many as five 'complementary husbands'; if they lived close to a monastery, even Buddhist monks could suffice for additional lovers.Although boys were taught at Confucian academies for the ultimate goal of government service, girls were often taught by their brothers how to read and write. By Song times, more women of the upper and educated classes were able to read due to advances in widespread printing, leaving behind a treasury of letters, poems, and other documents penned by women. Some women were educated enough to teach their sons before they were sent to an official school. For example, the mother of the statesman and scientist Shen Kuo taught him basic education and even military strategy that she had learned from her elder brother. Hu Wenrou, a granddaughter of a famous Song official Hu Su, was regarded by Shen Kuo as a remarkable female mathematician, as Shen would occasionally relay questions to Hu Wenrou through her husband in order for her to review and investigate possible errors in his mathematical work. Li Qingzhao (1084–1151), whose father was a friend of Su Shi, wrote many poems throughout her often turbulent life (only about 100 of these survive) and became a renowned poet during her lifetime. After the death of her husband, she wrote poems profusely about poring over his paintings, calligraphy, and ancient bronze vessels, as well as poems with deep emotional longing:
Ancient Chinese Daoism, ancestor worship, and foreign-originated Buddhism were the most prominent religious practices in the Song period. Daoism developed largely from the teachings of the Daodejing, attributed to the 6th century BC philosopher Laozi ("Old Master"), considered one of the Three Pure Ones (the prime deities of Daoism). Buddhism in China, introduced by Yuezhi, Persian, and Kushan missionaries in the first and second centuries, gradually became more native in character and was transformed into distinct Chinese Buddhism.
Many followed the teachings of Buddha and prominent monks such as Dahui Zonggao (1089–1163) and Wuzhun Shifan (1178–1249). However, there were also many critics of Buddhism's religious and philosophical tenets. This included the ardent nativist, scholar, and statesman Ouyang Xiu, who called Buddhism a "curse" upon China, an alien tradition that infiltrated the native beliefs of his country while at its weakest during the Southern and Northern Dynasties (420–581). The contention over Buddhism was at times a divisive issue within the gentry class and even within families. For example, the historian Zeng Gong lamented over the success of Buddhism, viewing it as a competing ideology with 'the Way of the Sages' of Confucianism, yet on his death in 1083 was buried in a Buddhist temple that his grandfather had helped build and that his brother Zeng Bu was able to declare as a private Merit Cloister for the family. Although conservative proponents of native Confucianism were highly skeptical of the teachings of Buddhism and often sought to distance themselves from it, others used Buddhist teachings to bolster their own Confucian philosophy. The Neo-Confucian philosophers and brothers Cheng Hao and Cheng Yi of the 11th century sought philosophical explanations for the workings of principle (li) and vital energy (qi) in nature, responding to the notions of highly complex metaphysics in popular Buddhist thought.  Neo-Confucian scholars also sought to borrow the Mahayana Buddhist ideal of self-sacrifice, welfare, and charity embodied in the bodhisattva.  Seeking to replace the Buddhist monastery's once prominent role in societal welfare and charity, supporters of Neo-Confucianism converted this ideal into practical measures of state-sponsored support for the poor under a secular mission of ethical universalism.Buddhism never fully recovered after several major persecutions in China from the 5th through the 10th centuries, although Daoism continued to thrive in Song China. In northern China under the Jin dynasty after 1127, the Daoist philosopher Wang Chongyang (1113–1170) established the Quanzhen School. Wang's seven disciples, known as the Seven Immortals, gained great fame throughout China. They included the prominent Daoist priestess Sun Bu'er (c. 1119–1182), who became a female role model in Daoism. There was also Qiu Chuji (1148–1227), who founded his own Quanzhen Daoist branch known as Longmen ("Dragon Gate"). In the Southern Song, cult centers of Daoism became popular at mountain sites that were reputed to be the earthly sojourns of Daoist deities; elite families had shrines erected in these mountain retreats in honor of the local deity thought to reside therein. Much more so than for Buddhist clergy, Daoist priests and holy men were sought when one prayed for having a son, when one was physically ill, or when there was need for change after a long spell of bad weather and poor harvest.Chinese folk religion continued as a tradition in China, drawing upon aspects of both ancient Chinese mythology and ancestor worship. Many people believed that spirits and deities of the spirit realm regularly interacted with the realm of the living. This subject was popular in Song literature. Hong Mai (1123–1202), a prominent member of an official family from Jiangxi, wrote a popular book called The Record of the Listener, which had many anecdotes dealing with the spirit realm and people's supposed interactions with it.  People in Song China believed that many of their daily misfortunes and blessings were caused by an array of different deities and spirits who interfered with their daily lives.  These deities included the nationally accepted deities of Buddhism and Daoism, as well as the local deities and demons from specific geographic locations.  If one displeased a long-dead relative, the dissatisfied ancestor would allegedly inflict natural ailments and illnesses. People also believed in mischievous demons and malevolent spirits who had the capability to extort sacrificial offerings meant for ancestors – in essence these were bullies of the spiritual realm.  The Chinese believed that spirits and deities had the same emotions and drives as the living did.  In some cases the chief deity of a local town or city was believed to act as a municipal official who could receive and dispatch orders on how to punish or reward spirits.  Residents of cities offered many sacrifices to their divinities in hopes that their city would be spared from disasters such as fire. However, not only common people felt the need to appease local deities. Magistrates and officials sent from the capital to various places of the empire often had to ensure the locals that his authority was supported by the local deity.
One of the duties of scholar-officials was hearing judicial cases in court. However, the county magistrate and prefects of the Song period were expected to know more than just the written laws. They were expected to promote morality in society, to punish the wicked, and carefully recognize in their sentences which party in a court case was truly at fault. It was often the most serious cases that came before the court; most people desired to settle legal quarrels privately, since court preparations were expensive. In ancient China, the accused in court were not viewed as fully innocent until proven otherwise, while even the accuser was viewed with suspicion by the judge. The accused were immediately put in filthy jails and nourished only by the efforts of friends and relatives. Yet the accuser also had to pay a price: in order to have their case heard, Gernet states that they had to provide an offering to the judge as "a matter of decorum."Gernet points out that disputes requiring arrest were mostly avoided or settled privately. Yet historian Patricia Ebrey states that legal cases in the Song period portrayed the courts as being overwhelmed with cases of neighbors and relatives suing each other over property rights. The Song author and official Yuan Cai (1140–1190) repeatedly warned against this, and like other officials of his time also cautioned his readers about the rise of banditry in Southern Song society and a need to physically protect self and property.
Chancellor Wang Anshi, also a renowned prose stylist, wrote a work on matters of state justice in the 11th century. Wang wrote that private interests, especially of those seeking vigilante justice, should in almost all circumstances never trump or interfere with public justice. In the ancient Classic of Rites, Rites of Zhou, and "Gongyang" commentary of the Spring and Autumn Annals, seeking vengeance for a violent crime against one's family is viewed as a moral and filial obligation, although in the Rites of Zhou state intervention between the instigating and avenging parties was emphasized. Wang believed that the state of Song China was far more stable than those in ancient times and abler to dispense fair justice. Although Wang praised the classic avenger Wu Zixu (526–484 BC), Michael Dalby writes that Wang "would have been filled with horror if Wu's deeds, so outdated in their political implications, had been repeated in Song times." For Wang, a victim exacting personal revenge against one who committed an egregious criminal act should only be considered acceptable when the government and its legal system became dysfunctional, chaotic, or ceased to exist. In his view, the hallmark of a properly functioning government was one where an innocent man was never executed. If this were to occur, his or her grieving relatives, friends, and associates should voice complaints to officials of ever increasing hierarchic status until grievances were properly addressed. If such a case reached the emperor—the last and final judge—and he decided that previous officials who heard the case had erred in their decisions, he would accordingly punish those officials and the original guilty party. If even the emperor for some reason made a fault in pardoning a party which was truly guilty, then Wang reasoned that the only explanation for a lack of justice was the will of heaven and its judgment which was beyond the control of mortal men. Wang insisted that submitting to the will of heaven in this regard was the right thing to do, while a murdered father or mother could still be honored through ritual sacrifices.
Many Song court cases serve as examples for the promotion of morality in society. Using his knowledge and understanding of townsmen and farmers, one Song judge made this ruling in the case of two brawling fishermen, who were labeled as Pan 52 and Li 7 by the court:
A proclamation: In the markets of the city the profits from commerce are monopolized by itinerant loiterers, while the little people from the rural villages are not allowed to sell their wares. There is not a single necessity of our clothing or food that is not the product of the fields of these old rustics. The men plow and the women weave. Their toil is extremely wearisome, yet what they gain from it is negligible, while manifold interest returns to these lazy idlers. This sort, in tens and hundreds, come together to form gangs. When the villagers come to sell things in the market place, before the goods have even left their hands, this crowd of idlers arrives and attacks them, assaulting them as a group. These idlers call this "the boxing of the community family." They are not at all afraid to act outrageously. I have myself seen that it is like this. Have they not given thought to the foodstuffs they require and the clothing they wear? Is it produced by these people of the marketplaces? Or is it produced by the rural farmers? When they recognize that these goods are produced by the farming people or the rural villages, how can they look at them in anger? How can they bully and insult them? Now, Pan Fifty-two and Li Seven are both fishmongers, but Pan lives in the city and fishmongering is his source of livelihood. Li Seven is a farmer, who does fishmongering between busy times. Pan Fifty-two at the end of the year has his profit, without having had the labor of raising the fish, but simply earning it from the selling of the fish. He hated Li and fought with him at the fish market. His lack of humanity is extreme! Li Seven is a village rustic. How could he fight with the itinerant armed loiterers who hang around the marketplace? Although no injuries resulted from the fight, we still must mete out some slight punishments. Pan Fifty-two is to be beaten fifteen blows with the heavy rod. In addition, Li Seven, although he is a village farmer, was still verbally abusive while the two men were stubbornly arguing. He clearly is not a man of simple and pure character. He must have done something to provoke this dispute. Li Seven is to be given a suspended sentence of a beating of ten blows, to be carried out if hereafter there are further violations.
In the Song dynasty, sheriffs were employed to investigate and apprehend suspected criminals, determining from the crime scene and evidence found on the body if the cause of death was disease, old age, an accident, or foul play.  If murder was considered the cause, an official from the prefecture was sent to investigate and draw up a formal inquest, to be signed by witnesses and used in court.  The documents of this inquest also included sketches of human bodies with details of where and what injuries were inflicted.Song Ci (1186–1249) was a Chinese physician and judge during the Southern Song dynasty. His famous work Collected Cases of Injustice Rectified was a basis for early forensic science in China. Song's predecessor Shen Kuo offered critical analysis of human anatomy, dispelling the old Chinese belief that the human throat had three valves instead of two. A Chinese autopsy in the early 12th century confirmed Shen's hypothesis of two throat valves: the esophagus and larynx.  However, dissection and examination of human bodies for solving criminal cases was of interest to Song Ci. His work was compiled on the basis of other Chinese works dealing with justice and forensics. His book provided a list of types of death (strangulation, drowning, poison, blows, etc.) and a means of physical examination in order to distinguish between murder, suicide, or accident. Besides instructions on proper ways to examine corpses, Song Ci also provided instructions on providing first aid for victims close to death from hanging, drowning, sunstroke, freezing to death, and undernourishment. For the specific case of drowning, Song Ci advised using the first aid technique of artificial respiration. He wrote of examinations of victims' bodies performed in the open amongst official clerks and attendants, a coroner's assistant (or midwife in the case of women), actual accused suspect of the crime and relatives of the deceased, with the results of the autopsy called out loud to the group and noted in the inquest report.  Song Ci wrote:
In all doubtful and difficult inquests, as well as when influential families are involved in the dispute, [the deputed official] must select reliable and experienced coroner’s assistants and Recorders of good character who are circumspect and self-possessed to accompany him. [. . .] Call a brief halt and wait for the involved parties to arrive. Otherwise, there will be requests for private favors. Supposing an examination is held to get the facts, the clerks will sometimes accept bribes to alter the reports of the affair. If the officials and clerks suffer for their crimes, that is a minor matter. But, if the facts are altered, the judicial abuse may cost someone his life. Factual accuracy is supremely important.
Song Ci also shared his opinion that having the accused suspect of the murder present at the autopsy of his victim, in close proximity to the grieving relatives of the deceased, was a very powerful psychological tool for the authorities to gain confessions. In the earliest known case of forensic entomology, a villager was hacked to death with a sickle, which led the local magistrate to assemble all the villagers in a town square to lay down their sickles in order for blow flies to gather around which sickle still had unseen remnants of the victim's blood; when it became apparent which sickle was used as the murder weapon, the confessing murderer was arrested on the spot.Although interests in human anatomy had a long tradition in the Western world, a forensic book such as Song Ci's did not appear in Western works until Roderic de Castro's book in the 17th century. There have been several modern books published about Song Ci's writing and translations of it into English. This includes W.A. Harland's Records of Washing away of Injuries (1855), Herbert Giles' The Hsi Yuan Lu, or Instructions to Coroners (1924), and Dr. Brian E. McKnight's The Washing Away of Wrongs: Forensic Medicine in Thirteenth-Century China (1981).
During the Song dynasty, for those without formal education, the quickest way to power and the upper echelons of society was to join the military.  If a man had a successful career in the military and could boast of victorious battles, he had a sure path to success in politics.  Exam-drafted scholar-officials came mostly from prominent families and could rely on their clan status to advance their careers and place in society. Many Song military officers did not have this advantage, and owed their status in society to the advantage that military power granted them.  Many court eunuchs such as Tong Guan (1054–1126) were eager to enlist as officers in the central army since this was a means to elevate their position at court.Ordinary soldiers were merely recruited or conscripted rural farmers, while surrendered bandits and mercenaries also joined the military. Soldiers were not awarded official status by Confucian scholars as belonging to one of the Four Occupations; the scholar-officials were wary of condoning or legitimizing those whose lives revolved around the uncivilized practices of wu (violence). Even though the military examinations, rankings, and posts were parallel to those of the civil order, scholar-officials and the gentry nonetheless viewed military pursuits as uncultivated. Despite this disdain and argument of moral high ground, scholar-officials often commanded troops and wielded military power. Yet scholar-officials were not at the apex of the military or even civilian order; at the pinnacle of society was the emperor. The emperor's use of violence was seen as a necessity to rein in rebellious elements of society and dominate violent and uncultivated Inner Asian tribes, who would then submit to the emperor and become transformed by China's superior wen (culture and civilization).
In the year 960 the Song military had 378,000 enlisted soldiers. Around the turn of the 11th century its size had grown to 900,000 soldiers, increasing to 1,000,000 by the year 1022, and well over 1,250,000 by 1041.  The overall expenses of upholding a military of this size consumed three-quarters of the state's entire annual revenue. To lessen the expense, in 1069 the Chancellor Wang Anshi created the institution of local militias as supporting units.  In 1073, Wang Anshi created a new bureau of the central government called the Directorate of Weapons, which supervised the manufacture of armaments and ensured quality control.
Despite the size of the army and these beneficial reforms, the high ranks of Song military command were heavily corrupt. At the beginning of the 12th century, Song generals collected funds based on the number of troops they recorded; instead of using the funds to benefit troops, they used this money to bolster their own salaries.  Troops of the standing army, meanwhile, were given very small salaries while assigned tasks of menial labor.  The scholar-officials running the government often paid little attention to the plight of soldiers and even to the demands of officers, since they were seen as being on a lower tier in society. Fairbank writes that the "civilian domination of the military was part of the ruling elite's control of the state, but it left the state military weak."The corruption of the high command and ineffectiveness of military strength was soon revealed once the Song made a joint effort with the Jurchen people to conquer the Khitan Liao dynasty (916–1125). After the successful rebellion of the Jurchens against their Khitan masters, the Jurchen observed the weakness of the Song army and broke their pact, then attacked the Song as well. By 1127, the capital at Kaifeng was captured and northern China overrun, while the remnants of the Song court fled south to Hangzhou and established the Southern Song. This was a crucial blow to the Song military elites, as they had been closely tied to the political structure until 1127; afterwards they became alienated from the emperor and the Song court. Although they had lost northern China to the new Jurchen Jin dynasty (1115–1234), this loss prompted the Song to make drastic and lasting military reforms. Emperor Gaozong, desperate to refill the decimated ranks of the central army, drafted men from all over the country. This had been done before, but not on the same scale. Only the most skilled soldiers became imperial guardsmen, while under Gaozong entire central army units were composed of soldiers from every region and background. The Southern Song eventually recovered their strength and commanded the loyalty of vaunted commanders such as Yue Fei (1103–1142), who successfully defended the border at the Huai River. The Jurchens and Song eventually signed a peace treaty in 1141.In 1131, the Chinese writer Zhang Yi noted the importance of employing a navy to fight the Jin, writing that China had to regard the sea and the river as her Great Wall, and use warships as its greatest watchtowers. Although navies had been used in China since the ancient Spring and Autumn period (722–481 BC), China's first permanent standing navy was established by the Southern Song in 1132.  The Jurchen launched an invasion against the Southern Song along the length of the Yangtze River, which resulted in two crucial Song victories at the Battle of Caishi and Battle of Tangdao in 1161. The Jin navy was defeated by the Song's standing navy, which employed trebuchets on their ships' top deckhouses to launch gunpowder bombs.
In the Song dynasty, infantry units were organized 50 men to a platoon, two platoons to a company, and those into battalions of 500 men each.  During the Northern Song, half of the entire army of 1 million was stationed in and around Kaifeng.  The remaining troops were posted in scattered forces along borders and near large municipalities, and in peacetime were used as means to maintain local security.  Although the Song military was rife with corruption and largely ignored by civil officials, it did provide some valuable strengths to the empire. During the Song era, military drills and training were studied as a science, while elite soldiers were allocated different responsibilities based on examinations of their skills in weaponry and athletic ability.  In their training, soldiers and officers were prepared for battle by following signal standards for troop movement, advancing when a flag or banner was raised, halting when the blaring sound of bells and drums rang out.Song crossbowmen comprised their own separate units apart from the infantry, and according to the Chinese Wujing Zongyao military manuscript of 1044, the crossbow used in mass was the most effective weapon used against northern nomadic cavalry charges.  Elite crossbowmen were also valued as long-range snipers; such was the case when the Liao general Xiao Talin was picked off by a Song crossbow at the Battle of Shanzhou in 1004.  Crossbows were mass-produced in state armories with designs improving as time went on, such as the use of a mulberry wood and brass crossbow in 1068 that could pierce a tree at 140 paces.  Song cavalry used an array of different weapons, including halberds, swords, bows, and fire lances that discharged a gunpowder blast of flame and shrapnel. In preparation for war, government armories manufactured weapons in enormous quantities, with tens of millions of arrowheads crafted each year, along with armor components by the tens of thousands. There were sixteen known varieties of catapults in the Song period, designed to fit many different proportions and requiring work crews in sizes ranging from dozens to several hundred men.
Unlike many other Chinese dynasties throughout history, the Song dynasty did not model its military infrastructure and organization on the precedent of northern nomadic armies, such as the earlier Xianbei and later Mongols.  Only twice in the Song era were non-Chinese people employed in Song cavalry units: in the beginning of the dynasty with the campaigns of Emperor Taizu, and later 13th century Mongol defectors who came over to fight for the Song.  With the Khitan and Tangut kingdoms possessing much of the pasture and grazing lands in the north, the Song military had a shortage of horses for cavalry. To make up for this shortage, statesmen like Wang Anshi advocated greater ties with Tibet, as the tea-horse trade with Tibet was continued by the Ming dynasty. Still, the Song established considerably large navies: in the 10th century, in the war to reunite China, and then a standing navy in the 12th century. Many of the warships in the Song dynasty's navy were paddle-wheel driven crafts and some Song naval ships could carry up to 1,000 soldiers.  It was also during the Song period that naval ships were first armed with gunpowder weapons.  The use of enormous pontoon bridges in the Song era on at least one occasion was essential to victory. The Song built a large floating bridge across the Yangtze River in 974; while troops were under attack, the pontoon bridge was used as a means of transport for troops and supplies to the other bank during the early Song conquest of the Southern Tang state.
Much like the multicultural and metropolitan atmosphere of the earlier Tang capital at Chang'an, the Song capitals at Kaifeng and Hangzhou were home to an array of traveling foreigners and ethnic minorities. There was a great amount of contact with the outside world. Trade and tribute embassies from Egypt, Yemen, India, Korea, the Kara-Khanid Khanate of Central Asia and elsewhere came to Song China in order to bolster trade relations, while the Chinese sent embassies abroad to encourage foreign trade. Song Chinese trade ships traveled to ports in Japan, Champa in southern Vietnam, Srivijaya in Maritime Southeast Asia, Bengal and South India, and the coasts of East Africa.During the 9th century, the Tang seaport at Guangzhou had a large Muslim population. During the Song dynasty the importance of the latter seaport declined as the ports of Quanzhou and Fuzhou in Fujian province eclipsed it. This was followed by a decline of Middle Eastern sea merchants in China and an increasing amount of Chinese ship owners engaging in maritime trade. However, Middle Eastern merchants and other foreigners were not entirely absent, and some even gained administrative posts. For example, the Muslim Pu Shougeng—of either Persian or Arab descent—served as the Commissioner of Merchant Shipping for Quanzhou between the years 1250 and 1275. There was also the Arab astronomer Ma Yize (910–1005), who became the chief astronomer of the Song court under Taizu. Aside from these elites, Chinese seaports were filled with resident Arabs, Persians, and Koreans who had special enclaves designated for each of them.Muslims represented the largest religious minority within Song China, although there were many others. There was a community of Kaifeng Jews who followed the exodus of the Song court to Hangzhou once the Jurchens invaded the north in 1126. Manichaeism from Persia was introduced during the Tang; during the Song, the Manichaean sects were most prominent in Fujian and Zhejiang. Nestorian Christianity in China had for the most part died out after the Tang dynasty; however, it was revived during the Mongol invasions in the 13th century. Followers of Zoroastrianism still had temples in China as well. Prospects of studying Chinese Chan Buddhism attracted foreign Buddhists to China, such as Enni Ben'en (圓爾辯圓; 1201–1280) of Japan who studied under the eminent Chinese monk Wuzhun Shifan (1178–1249) before establishing Tōfuku-ji in Kyoto. Tansen Sen states that Buddhist monks traveling from India to China and vice versa during the Song surpassed that of the Tang dynasty, while "Indian texts translated under the Song dynasty outnumbered those completed under the preceding dynasties."
There were many native ethnic groups within Song China that did not belong to the Han Chinese majority. This included the Yao people, who staged tribal uprisings against the Song in Guangdong in 1035 and Hunan in 1043, during the reign of Emperor Renzong of Song (r. 1023–1064). Song authorities employed Zhuang people as local officials in what is now Guangxi and Guangdong, where the Song placed them in charge of distributing land to the Yao and other tribal groups. The Yao peoples and others on the empire's frontier were incorporated into a feudal system, or fengjian shehui, which Ralph A. Litzinger says bypassed any possible native development of a primitive slave society, or nuli shehui, since the Yao and others lacked a sedentary tradition. Although mainland Chinese states made efforts to settle parts of Hainan Island since the 3rd century BC, it was not until the Song that a concerted effort was made to assimilate the Li people of its highlands, who at times had fought against and repelled Han Chinese settlers. During the 11th century, the Man people of Hainan wreaked havoc by joining bandit gangs of ten to several hundred men. The statesman Ouyang Xiu estimated in 1043 that there were at least several thousand Man bandits residing in a dozen or so prefectures of mainland China.To counter powerful neighbors such as the Kingdom of Dali (934–1253), the Song made alliances with tribal groups in southwest China which served as a protective buffer between their borders and Dali's. As long as these ethnic tribal groups paid tribute to the Song court and agreed to follow the course of its foreign policy, the Song agreed to grant military protection and allow the tribal leaders hereditary, autonomous local rule. During the 1050s, the Song put down local tribal insurrections along their borders with the Lý dynasty of Đại Việt, while their relations with Tai peoples and alliances with local clan leaders in the southern frontier led to a border war with Lý from 1075 to 1077.
